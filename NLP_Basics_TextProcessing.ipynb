{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shankar1302/NLP/blob/main/NLP_Basics_TextProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5micRlYmAB6"
      },
      "source": [
        "# *Merged Jupyter Notebook*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01VxBayqmACD"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 01-TokenizingTextIntoSentencesAndWords</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1WTgwcbmACE"
      },
      "source": [
        "## Tokenize text into words and sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyKeMcQHmACE",
        "outputId": "feecd676-94eb-41db-e70d-8ca954096084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.23.5\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "print(numpy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSIsSu19mACI",
        "outputId": "33911edb-aff7-4a6c-89a1-dce75ea17886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.7\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "print(nltk.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS3YPlQUmACI"
      },
      "source": [
        "#### Uses NLTK's recommended sentence tokenizer, the PunktSentenceTokenizer\n",
        "#### Uses NLTK's recommended word tokenizer, the TreebankWordTokenizer and the PunktSentencetokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRV_ddXkmACJ"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFtAK00WmACK",
        "outputId": "b3c91910-a233-4527-d8c6-53a3533e46cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does this tokenizer work?', 'These are two different sentences']\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = sent_tokenize('Does this tokenizer work? These are two different sentences')\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxEngWmXmACL",
        "outputId": "b5810979-1f31-4ac5-97c3-545f27f8e48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does', 'this', 'tokenizer', 'work', '?']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize('Does this tokenizer work?')\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyqfhyhpmACM"
      },
      "source": [
        "#### Punkt tokenizer\n",
        "\n",
        "https://www.nltk.org/_modules/nltk/tokenize/punkt.html\n",
        "http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt\n",
        "\n",
        "A sentence tokenizer which uses an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences; and then uses that model to find sentence boundaries. This approach has been shown to work well for many European languages.\n",
        "\n",
        "It must be trained on a large collection of plaintext in the target language before it can be used.\n",
        "\n",
        "The NLTK data package includes a pre-trained Punkt tokenizer for English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC5jB8dtmACN",
        "outputId": "70f6a9a3-3985-4e83-d938-ada30071bc54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\iyers\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c07Vyv-WmACP",
        "outputId": "c440603d-75c4-4115-8ad8-8be2396e3e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does this tokenizer work?', 'These are two different sentences']\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = sent_tokenize('Does this tokenizer work? These are two different sentences')\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUftRdaxmACQ",
        "outputId": "5c612041-10c5-4695-8c5d-34ac279572da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does', 'this', 'tokenizer', 'work', '?']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize('Does this tokenizer work?')\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2FTJQ19mACR",
        "outputId": "390f522a-633c-4ed3-b1bb-58b02b315fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.', 'Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.', 'These', 'watches', 'cost', '$', '1500', '!', 'The', 'ball', 'is', 'in', 'your', 'court', '.', 'Mr.', 'Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D', '.']\n"
          ]
        }
      ],
      "source": [
        "text = \"A bird in hand is worth two in the bush. \" +\\\n",
        "       \"Good things come to those who wait. \" +\\\n",
        "       \"These watches cost $1500! \" +\\\n",
        "       \"The ball is in your court. \" +\\\n",
        "       \"Mr. Smith Goes to Washington \" +\\\n",
        "       \"Doogie Howser M.D.\"\n",
        "\n",
        "word_tokens = word_tokenize(text, language='english')\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmOVG9skmACS",
        "outputId": "4041ed1b-b0e0-4e6a-99fa-5053aa7ab88f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcEullYpmACT",
        "outputId": "503b987f-4c91-4beb-de23-3aef5abb9db5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hand', 'is', 'worth', 'two', 'in']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens[3:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foYQFPVfmACU"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize.punkt import PunktSentenceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDiebzv2mACV"
      },
      "outputs": [],
      "source": [
        "pst = PunktSentenceTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9h7HKD6mACV",
        "outputId": "2ab14920-3c7d-4c58-9fec-df564d2dc35f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A bird in hand is worth two in the bush.', 'Good things come to those who wait.', 'These watches cost $1500!', 'The ball is in your court.', 'Mr.', 'Smith Goes to Washington Doogie Howser M.D.']\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = pst.tokenize(text)\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY78DSl5mACW",
        "outputId": "d9182416-6baf-4b00-975e-10ff46a19e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 40), (41, 76), (77, 102), (103, 129), (130, 133), (134, 177)]\n"
          ]
        }
      ],
      "source": [
        "span_tokens = pst.span_tokenize(text)\n",
        "\n",
        "print(list(span_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw2DznDpmACX",
        "outputId": "b0ceb8ea-3e5e-4c90-c719-95dfa345085a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.'],\n",
              " ['Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.'],\n",
              " ['These', 'watches', 'cost', '$', '1500', '!'],\n",
              " ['The', 'ball', 'is', 'in', 'your', 'court', '.'],\n",
              " ['Mr.'],\n",
              " ['Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D', '.']]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences = pst.sentences_from_tokens(word_tokens)\n",
        "\n",
        "list(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eijWdtzmACY"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzdCc-t8mACY"
      },
      "outputs": [],
      "source": [
        "wt = WhitespaceTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxBqd2lHmACZ",
        "outputId": "a8584acd-71a5-49f6-cc8d-780667fe9a48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush.', 'Good', 'things', 'come', 'to', 'those', 'who', 'wait.', 'These', 'watches', 'cost', '$1500!', 'The', 'ball', 'is', 'in', 'your', 'court.', 'Mr.', 'Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D.']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = wt.tokenize(text)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX7TK3FQmACa"
      },
      "source": [
        "### Reading Local Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACpC19OkmACb",
        "outputId": "f51101cd-e160-495b-dfe2-f5a6fefff809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqwyOjWImACb",
        "outputId": "8fdb97ec-5613-4dc4-b05e-a2f02412d293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie', 'Curie', 'was', 'a', 'Polish-born', 'physicist', 'and', 'chemist', 'and', 'one', 'of', 'the', 'most', 'famous', 'scientists', 'of', 'her', 'time', '.', 'Together', 'with', 'her', 'husband', 'Pierre', ',', 'she', 'was', 'awarded', 'the', 'Nobel', 'Prize', 'in', '1903', ',', 'and', 'she', 'went', 'on', 'to', 'win', 'another', 'in', '1911', '.', 'Marie', 'Sklodowska', 'was', 'born', 'in', 'Warsaw', 'on', '7', 'November', '1867', ',', 'the', 'daughter', 'of', 'a', 'teacher', '.', 'In', '1891', ',', 'she', 'went', 'to', 'Paris', 'to', 'study', 'physics', 'and', 'mathematics', 'at', 'the', 'Sorbonne', 'where', 'she', 'met', 'Pierre', 'Curie', ',', 'professor', 'of', 'the', 'School', 'of', 'Physics', '.', 'They', 'were', 'married', 'in', '1895', '.', 'The', 'Curies', 'worked', 'together', 'investigating', 'radioactivity', ',', 'building', 'on', 'the', 'work', 'of', 'the', 'German', 'physicist', 'Roentgen', 'and', 'the', 'French', 'physicist', 'Becquerel', '.', 'In', 'July', '1898', ',', 'the', 'Curies', 'announced', 'the', 'discovery', 'of', 'a', 'new', 'chemical', 'element', ',', 'polonium', '.', 'At', 'the', 'end', 'of', 'the', 'year', ',', 'they', 'announced', 'the', 'discovery', 'of', 'another', ',', 'radium', '.', 'The', 'Curies', ',', 'along', 'with', 'Becquerel', ',', 'were', 'awarded', 'the', 'Nobel', 'Prize', 'for', 'Physics', 'in', '1903', '.', 'Pierre', \"'s\", 'life', 'was', 'cut', 'short', 'in', '1906', 'when', 'he', 'was', 'knocked', 'down', 'and', 'killed', 'by', 'a', 'carriage', '.', 'Marie', 'took', 'over', 'his', 'teaching', 'post', ',', 'becoming', 'the', 'first', 'woman', 'to', 'teach', 'at', 'the', 'Sorbonne', ',', 'and', 'devoted', 'herself', 'to', 'continuing', 'the', 'work', 'that', 'they', 'had', 'begun', 'together', '.', 'She', 'received', 'a', 'second', 'Nobel', 'Prize', ',', 'for', 'Chemistry', ',', 'in', '1911', '.', 'The', 'Curie', \"'s\", 'research', 'was', 'crucial', 'in', 'the', 'development', 'of', 'x-rays', 'in', 'surgery', '.', 'During', 'World', 'War', 'One', 'Curie', 'helped', 'to', 'equip', 'ambulances', 'with', 'x-ray', 'equipment', ',', 'which', 'she', 'herself', 'drove', 'to', 'the', 'front', 'lines', '.', 'The', 'International', 'Red', 'Cross', 'made', 'her', 'head', 'of', 'its', 'radiological', 'service', 'and', 'she', 'held', 'training', 'courses', 'for', 'medical', 'orderlies', 'and', 'doctors', 'in', 'the', 'new', 'techniques', '.', 'Despite', 'her', 'success', ',', 'Marie', 'continued', 'to', 'face', 'great', 'opposition', 'from', 'male', 'scientists', 'in', 'France', ',', 'and', 'she', 'never', 'received', 'significant', 'financial', 'benefits', 'from', 'her', 'work', '.', 'By', 'the', 'late', '1920s', 'her', 'health', 'was', 'beginning', 'to', 'deteriorate', '.', 'She', 'died', 'on', '4', 'July', '1934', 'from', 'leukaemia', ',', 'caused', 'by', 'exposure', 'to', 'high-energy', 'radiation', 'from', 'her', 'research', '.', 'The', 'Curies', \"'\", 'eldest', 'daughter', 'Irene', 'was', 'herself', 'a', 'scientist', 'and', 'winner', 'of', 'the', 'Nobel', 'Prize', 'for', 'Chemistry', '.']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize(file_contents)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTdkz77EmACc"
      },
      "source": [
        "### Frequency distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMXjwrHvmACc"
      },
      "outputs": [],
      "source": [
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6dMBejUmACd",
        "outputId": "e1f58ae9-ce29-4441-a342-117eeb47ce2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FreqDist with 182 samples and 367 outcomes>\n"
          ]
        }
      ],
      "source": [
        "freq_dist = FreqDist(word_tokens)\n",
        "\n",
        "print(freq_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3zrBIX1mACd",
        "outputId": "3ca53034-67f7-43c0-f96e-4821473b27f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 22),\n",
              " (',', 20),\n",
              " ('.', 19),\n",
              " ('of', 12),\n",
              " ('and', 11),\n",
              " ('in', 11),\n",
              " ('to', 10),\n",
              " ('was', 8),\n",
              " ('her', 7),\n",
              " ('she', 7),\n",
              " ('a', 6),\n",
              " ('The', 5),\n",
              " ('Marie', 4),\n",
              " ('Curie', 4),\n",
              " ('Nobel', 4),\n",
              " ('Prize', 4),\n",
              " ('on', 4),\n",
              " ('Curies', 4),\n",
              " ('for', 4),\n",
              " ('from', 4)]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q78CVScWmACd"
      },
      "source": [
        "Return the frequency of a given sample. The frequency of a sample is defined as the count of that sample divided by the total number of sample outcomes that have been recorded by this FreqDist. The count of a sample is defined as the number of times that sample outcome was recorded by this FreqDist. Frequencies are always real numbers in the range [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kO_vkUbCmACe",
        "outputId": "2f4f4b22-8a6a-4a4c-b348-640978e29d0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.05994550408719346"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.freq('the')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V0FRxg7mACe",
        "outputId": "751e2d1e-85f0-48c1-c799-8303df6e4d96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0027247956403269754"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.freq('exposure')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpeC10LHmACf",
        "outputId": "1a6d0b8a-4551-4666-ca98-6342812fca47"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "freq_dist.plot(20, cumulative=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfeClAlCmACf",
        "outputId": "b24bcf87-b1b7-4552-a344-53e6813f2b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['marie', 'curie', 'was', 'a', 'polish-born', 'physicist', 'and', 'chemist', 'and', 'one', 'of', 'the', 'most', 'famous', 'scientists', 'of', 'her', 'time.', 'together', 'with', 'her', 'husband', 'pierre,', 'she', 'was', 'awarded', 'the', 'nobel', 'prize', 'in', '1903,', 'and', 'she', 'went', 'on', 'to', 'win', 'another', 'in', '1911.', 'marie', 'sklodowska', 'was', 'born', 'in', 'warsaw', 'on', '7', 'november', '1867,', 'the', 'daughter', 'of', 'a', 'teacher.', 'in', '1891,', 'she', 'went', 'to', 'paris', 'to', 'study', 'physics', 'and', 'mathematics', 'at', 'the', 'sorbonne', 'where', 'she', 'met', 'pierre', 'curie,', 'professor', 'of', 'the', 'school', 'of', 'physics.', 'they', 'were', 'married', 'in', '1895.', 'the', 'curies', 'worked', 'together', 'investigating', 'radioactivity,', 'building', 'on', 'the', 'work', 'of', 'the', 'german', 'physicist', 'roentgen', 'and', 'the', 'french', 'physicist', 'becquerel.', 'in', 'july', '1898,', 'the', 'curies', 'announced', 'the', 'discovery', 'of', 'a', 'new', 'chemical', 'element,', 'polonium.', 'at', 'the', 'end', 'of', 'the', 'year,', 'they', 'announced', 'the', 'discovery', 'of', 'another,', 'radium.', 'the', 'curies,', 'along', 'with', 'becquerel,', 'were', 'awarded', 'the', 'nobel', 'prize', 'for', 'physics', 'in', '1903.', \"pierre's\", 'life', 'was', 'cut', 'short', 'in', '1906', 'when', 'he', 'was', 'knocked', 'down', 'and', 'killed', 'by', 'a', 'carriage.', 'marie', 'took', 'over', 'his', 'teaching', 'post,', 'becoming', 'the', 'first', 'woman', 'to', 'teach', 'at', 'the', 'sorbonne,', 'and', 'devoted', 'herself', 'to', 'continuing', 'the', 'work', 'that', 'they', 'had', 'begun', 'together.', 'she', 'received', 'a', 'second', 'nobel', 'prize,', 'for', 'chemistry,', 'in', '1911.', 'the', \"curie's\", 'research', 'was', 'crucial', 'in', 'the', 'development', 'of', 'x-rays', 'in', 'surgery.', 'during', 'world', 'war', 'one', 'curie', 'helped', 'to', 'equip', 'ambulances', 'with', 'x-ray', 'equipment,', 'which', 'she', 'herself', 'drove', 'to', 'the', 'front', 'lines.', 'the', 'international', 'red', 'cross', 'made', 'her', 'head', 'of', 'its', 'radiological', 'service', 'and', 'she', 'held', 'training', 'courses', 'for', 'medical', 'orderlies', 'and', 'doctors', 'in', 'the', 'new', 'techniques.', 'despite', 'her', 'success,', 'marie', 'continued', 'to', 'face', 'great', 'opposition', 'from', 'male', 'scientists', 'in', 'france,', 'and', 'she', 'never', 'received', 'significant', 'financial', 'benefits', 'from', 'her', 'work.', 'by', 'the', 'late', '1920s', 'her', 'health', 'was', 'beginning', 'to', 'deteriorate.', 'she', 'died', 'on', '4', 'july', '1934', 'from', 'leukaemia,', 'caused', 'by', 'exposure', 'to', 'high-energy', 'radiation', 'from', 'her', 'research.', 'the', \"curies'\", 'eldest', 'daughter', 'irene', 'was', 'herself', 'a', 'scientist', 'and', 'winner', 'of', 'the', 'nobel', 'prize', 'for', 'chemistry.']\n"
          ]
        }
      ],
      "source": [
        "file_contents = file_contents.lower()\n",
        "\n",
        "word_tokens = wt.tokenize(file_contents)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAEoVzfGmACg",
        "outputId": "161deec6-a2c0-47a3-8ee0-3566d0e06b26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DagL9faZmACg",
        "outputId": "df0056c4-9b84-4c8d-cd59-d569c4c19c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'an', 'should', \"needn't\", 'o', 'ours', 'yourselves', 'am', 't', 'd', 'our', 'yourself', 'himself', 'wasn', 'above', 'you', 'me', 'did', \"hasn't\", 'shan', 'about', 'wouldn', 'shouldn', 'because', 'myself', 'where', 'hasn', 'hadn', 'own', 'hers', 'at', \"mightn't\", 'now', 'with', 'how', 'some', 'or', 'had', 'having', 'aren', 'm', \"shouldn't\", 'was', 'don', 'same', \"didn't\", 'against', 'why', 'y', 'any', 'do', 'being', 'll', 'up', 'doesn', 'which', 'again', 'as', 'in', 'mightn', \"you'll\", \"that'll\", 'can', 'for', 'haven', 's', 'him', 'ain', 'from', 'then', 'once', 'that', \"you're\", 'such', 'does', '.', 'these', 'be', 'only', 'just', 'will', 'into', 'she', \"aren't\", 'and', 'they', 'isn', 'been', 'until', 'theirs', \"don't\", \"couldn't\", 'we', 'ourselves', 'under', 'is', 'by', 'what', \"hadn't\", \"weren't\", 'too', 'ma', 'needn', 'those', 'are', 'more', 'there', 'to', 'between', 'herself', 'has', 'a', 'the', 'yours', 'who', 'than', 'not', 'of', 'nor', \"isn't\", 'when', 'whom', \"it's\", 'i', 'my', 'were', 'mustn', 'doing', 'down', \"won't\", 'all', 'have', \"you'd\", 'his', 'other', 'but', 'if', 'very', 'off', 'before', 'both', 'each', 'didn', 'further', 'no', 'most', \"doesn't\", 'couldn', 'them', 'through', 'weren', 'won', \"wouldn't\", 'The', 're', \"wasn't\", 'few', 'here', 'so', ',', 'its', 'their', 'below', \"shan't\", 'out', \"mustn't\", 'it', 'over', 'itself', 'while', \"you've\", 'themselves', 'after', 'your', 'her', \"should've\", \"haven't\", 'this', 'on', 've', \"she's\", 'he', 'during'}\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(['.', ',', 'The'])\n",
        "\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgEEpEe8mACh",
        "outputId": "2fd74bb6-b05b-46d0-b7db-8fe22b05f06c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['marie', 'curie', 'polish-born', 'physicist', 'chemist', 'one', 'famous', 'scientists', 'time.', 'together', 'husband', 'pierre,', 'awarded', 'nobel', 'prize', '1903,', 'went', 'win', 'another', '1911.', 'marie', 'sklodowska', 'born', 'warsaw', '7', 'november', '1867,', 'daughter', 'teacher.', '1891,', 'went', 'paris', 'study', 'physics', 'mathematics', 'sorbonne', 'met', 'pierre', 'curie,', 'professor', 'school', 'physics.', 'married', '1895.', 'curies', 'worked', 'together', 'investigating', 'radioactivity,', 'building', 'work', 'german', 'physicist', 'roentgen', 'french', 'physicist', 'becquerel.', 'july', '1898,', 'curies', 'announced', 'discovery', 'new', 'chemical', 'element,', 'polonium.', 'end', 'year,', 'announced', 'discovery', 'another,', 'radium.', 'curies,', 'along', 'becquerel,', 'awarded', 'nobel', 'prize', 'physics', '1903.', \"pierre's\", 'life', 'cut', 'short', '1906', 'knocked', 'killed', 'carriage.', 'marie', 'took', 'teaching', 'post,', 'becoming', 'first', 'woman', 'teach', 'sorbonne,', 'devoted', 'continuing', 'work', 'begun', 'together.', 'received', 'second', 'nobel', 'prize,', 'chemistry,', '1911.', \"curie's\", 'research', 'crucial', 'development', 'x-rays', 'surgery.', 'world', 'war', 'one', 'curie', 'helped', 'equip', 'ambulances', 'x-ray', 'equipment,', 'drove', 'front', 'lines.', 'international', 'red', 'cross', 'made', 'head', 'radiological', 'service', 'held', 'training', 'courses', 'medical', 'orderlies', 'doctors', 'new', 'techniques.', 'despite', 'success,', 'marie', 'continued', 'face', 'great', 'opposition', 'male', 'scientists', 'france,', 'never', 'received', 'significant', 'financial', 'benefits', 'work.', 'late', '1920s', 'health', 'beginning', 'deteriorate.', 'died', '4', 'july', '1934', 'leukaemia,', 'caused', 'exposure', 'high-energy', 'radiation', 'research.', \"curies'\", 'eldest', 'daughter', 'irene', 'scientist', 'winner', 'nobel', 'prize', 'chemistry.']\n"
          ]
        }
      ],
      "source": [
        "filtered_words = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_words.append(w)\n",
        "\n",
        "print(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UEwO0WemACv"
      },
      "outputs": [],
      "source": [
        "freq_dist = FreqDist(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MjVSBygmACw",
        "outputId": "674113a7-cab6-4fc0-99c1-f727c62fb40f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('marie', 4),\n",
              " ('nobel', 4),\n",
              " ('physicist', 3),\n",
              " ('prize', 3),\n",
              " ('curie', 2),\n",
              " ('one', 2),\n",
              " ('scientists', 2),\n",
              " ('together', 2),\n",
              " ('awarded', 2),\n",
              " ('went', 2),\n",
              " ('1911.', 2),\n",
              " ('daughter', 2),\n",
              " ('physics', 2),\n",
              " ('curies', 2),\n",
              " ('work', 2),\n",
              " ('july', 2),\n",
              " ('announced', 2),\n",
              " ('discovery', 2),\n",
              " ('new', 2),\n",
              " ('received', 2)]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFLz636EmACx",
        "outputId": "0996a1b1-13bc-4fe6-ce54-95a329eb8721"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "freq_dist.plot(20, cumulative=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEkjBHPamACy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPJbKwH-mAC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaXZs_kvmAC3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYN7BHpvmAC3"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 02-VectorizeTextAsABagOfWords_CountVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8nFXSA7mAC4"
      },
      "source": [
        "## Vectorize text as a bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5qaqie4mAC4",
        "outputId": "87e2d633-9ce6-46af-e71b-c843681ff94c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.20.3\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6prkUwOmAC5"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRXpF4CymAC6"
      },
      "outputs": [],
      "source": [
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]\n",
        "\n",
        "count_vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py6H306emAC6",
        "outputId": "4ca5c1aa-24e3-4ce3-f7ad-00df0194e05f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.fit(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v610tTpmAC7",
        "outputId": "4dcbc223-0482-4785-e494-c5389d0d0eda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1500',\n",
              " 'are',\n",
              " 'ball',\n",
              " 'bird',\n",
              " 'bush',\n",
              " 'come',\n",
              " 'cost',\n",
              " 'court',\n",
              " 'doogie',\n",
              " 'fish',\n",
              " 'goes',\n",
              " 'good',\n",
              " 'hand',\n",
              " 'howser',\n",
              " 'in',\n",
              " 'is',\n",
              " 'mr',\n",
              " 'other',\n",
              " 'sea',\n",
              " 'smith',\n",
              " 'the',\n",
              " 'there',\n",
              " 'these',\n",
              " 'things',\n",
              " 'those',\n",
              " 'to',\n",
              " 'two',\n",
              " 'wait',\n",
              " 'washington',\n",
              " 'watches',\n",
              " 'who',\n",
              " 'worth',\n",
              " 'your']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoCEI5nimAC8"
      },
      "outputs": [],
      "source": [
        "count_vectorizer.get_stop_words()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDPl3cuGmAC9",
        "outputId": "1394db6f-37bb-4674-bdb1-095be1673f83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 3,\n",
              " 'in': 14,\n",
              " 'hand': 12,\n",
              " 'is': 15,\n",
              " 'worth': 31,\n",
              " 'two': 26,\n",
              " 'the': 20,\n",
              " 'bush': 4,\n",
              " 'good': 11,\n",
              " 'things': 23,\n",
              " 'come': 5,\n",
              " 'to': 25,\n",
              " 'those': 24,\n",
              " 'who': 30,\n",
              " 'wait': 27,\n",
              " 'these': 22,\n",
              " 'watches': 29,\n",
              " 'cost': 6,\n",
              " '1500': 0,\n",
              " 'there': 21,\n",
              " 'are': 1,\n",
              " 'other': 17,\n",
              " 'fish': 9,\n",
              " 'sea': 18,\n",
              " 'ball': 2,\n",
              " 'your': 32,\n",
              " 'court': 7,\n",
              " 'mr': 16,\n",
              " 'smith': 19,\n",
              " 'goes': 10,\n",
              " 'washington': 28,\n",
              " 'doogie': 8,\n",
              " 'howser': 13}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHXm5GIRmAC-",
        "outputId": "40a444b5-4c1c-49c5-ac09-313793e47e21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_.get('things')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chYCeuvJmAC_",
        "outputId": "d80401fa-f76b-442a-c0f4-2b73bbd2df78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A bird in hand is worth two in the bush.',\n",
              " 'Good things come to those who wait.',\n",
              " 'These watches cost $1500! ',\n",
              " 'There are other fish in the sea.',\n",
              " 'The ball is in your court.',\n",
              " 'Mr. Smith Goes to Washington ',\n",
              " 'Doogie Howser M.D.']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkyPunKnmAC_"
      },
      "outputs": [],
      "source": [
        "transformed_vector = count_vectorizer.transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_9wRjs2mADA",
        "outputId": "f68fdee0-cb5b-4233-8b33-00d64e6968ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 33)\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kuh0kLFtmADB",
        "outputId": "52679163-9a2b-4e36-ad7f-02767063bdaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 1 0 0 0 0 0 0 0 1 0 2 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZiKhJOzmADC",
        "outputId": "f6ce08e8-297f-4306-a4ca-eff031790a6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_text = [\"Every cloud has a silver lining.\"]\n",
        "\n",
        "count_vectorizer.transform(test_text).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN0ZDwIomADD",
        "outputId": "4946f83f-6578-474d-bc48-660577961cf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.fit(train_text + test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aar8I1bzmADE",
        "outputId": "3632aa5e-b0aa-4e23-806f-9cfe6480df92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bird': 3, 'in': 17, 'hand': 14, 'is': 18, 'worth': 36, 'two': 31, 'the': 25, 'bush': 4, 'good': 13, 'things': 28, 'come': 6, 'to': 30, 'those': 29, 'who': 35, 'wait': 32, 'these': 27, 'watches': 34, 'cost': 7, '1500': 0, 'there': 26, 'are': 1, 'other': 21, 'fish': 11, 'sea': 22, 'ball': 2, 'your': 37, 'court': 8, 'mr': 20, 'smith': 24, 'goes': 12, 'washington': 33, 'doogie': 9, 'howser': 16, 'every': 10, 'cloud': 5, 'has': 15, 'silver': 23, 'lining': 19}\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVdA8pNGmADE",
        "outputId": "3bad3dcb-7138-4617-ba8c-eccb68c963be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.transform(test_text).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx188qg_mADF",
        "outputId": "861910fb-5231-4366-dec5-575caa2e5adb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<3x38 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 9 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = [\"That bird is sitting in the bush and this bird is in hand.\",\n",
        "        \"Wait and then walk\",\n",
        "        \"Watches are cool \"]\n",
        "\n",
        "transformed_vector = count_vectorizer.transform(text)\n",
        "\n",
        "transformed_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rgpXwyKmADG",
        "outputId": "33ec69b8-4556-46cc-ba00-ae33ca70bfe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3)\t2\n",
            "  (0, 4)\t1\n",
            "  (0, 14)\t1\n",
            "  (0, 17)\t2\n",
            "  (0, 18)\t2\n",
            "  (0, 25)\t1\n",
            "  (1, 32)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 34)\t1\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_LOmIG6mADG",
        "outputId": "2543c0d3-f3ca-4cae-f592-32a9045fa0e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 38)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMgdoKmUmADH",
        "outputId": "c7b24a37-0001-40ea-e71f-a4d8267c0e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 2 1 0 0 0 0 0 0 0 0 0 1 0 0 2 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            "  0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhDUksgVmADH"
      },
      "source": [
        "### CountVectorizer on text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2zBzgHPmADI",
        "outputId": "9e350d76-02a0-409e-c054-3f712aad8c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cnk-NAyimADI",
        "outputId": "fea18bac-93a8-42d8-9bec-d8d78873dfcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.', 'Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.', 'Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.', 'In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.', 'They were married in 1895.', 'The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.', 'In July 1898, the Curies announced the discovery of a new chemical element, polonium.', 'At the end of the year, they announced the discovery of another, radium.', 'The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.', \"Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\", 'Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.', 'She received a second Nobel Prize, for Chemistry, in 1911.', \"The Curie's research was crucial in the development of x-rays in surgery.\", 'During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.', 'The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.', 'Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.', 'By the late 1920s her health was beginning to deteriorate.', 'She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.', \"The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\"]\n"
          ]
        }
      ],
      "source": [
        "sentences = file_contents.split('\\n')\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlulBZJemADJ",
        "outputId": "c84eb240-5133-4dd9-e607-ec796ad9952d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19, 167)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector = count_vectorizer.fit_transform(sentences)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BeNzBQImADK",
        "outputId": "c0a45daa-d75c-41d3-ac85-715a9d1144ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 146)\t1\n",
            "  (0, 72)\t1\n",
            "  (0, 128)\t1\n",
            "  (0, 56)\t1\n",
            "  (0, 96)\t1\n",
            "  (0, 144)\t1\n",
            "  (0, 101)\t2\n",
            "  (0, 103)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 11)\t2\n",
            "  (0, 108)\t1\n",
            "  (0, 21)\t1\n",
            "  (0, 111)\t1\n",
            "  (0, 153)\t1\n",
            "  (0, 34)\t1\n",
            "  (0, 91)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 13)\t1\n",
            "  (1, 159)\t1\n",
            "  (1, 147)\t1\n",
            "  (1, 102)\t1\n",
            "  (1, 154)\t1\n",
            "  (1, 4)\t1\n",
            "  (1, 77)\t2\n",
            "  (1, 114)\t1\n",
            "  :\t:\n",
            "  (17, 8)\t1\n",
            "  (17, 42)\t1\n",
            "  (17, 62)\t2\n",
            "  (17, 124)\t1\n",
            "  (17, 23)\t1\n",
            "  (17, 82)\t1\n",
            "  (17, 147)\t1\n",
            "  (17, 102)\t1\n",
            "  (17, 131)\t1\n",
            "  (17, 72)\t1\n",
            "  (18, 160)\t1\n",
            "  (18, 127)\t1\n",
            "  (18, 80)\t1\n",
            "  (18, 48)\t1\n",
            "  (18, 28)\t1\n",
            "  (18, 73)\t1\n",
            "  (18, 59)\t1\n",
            "  (18, 35)\t1\n",
            "  (18, 37)\t1\n",
            "  (18, 114)\t1\n",
            "  (18, 99)\t1\n",
            "  (18, 144)\t2\n",
            "  (18, 101)\t1\n",
            "  (18, 11)\t1\n",
            "  (18, 153)\t1\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WxTxLBBmADL",
        "outputId": "576e52f8-4387-4374-d937-f56d95f91f6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'marie': 91, 'curie': 34, 'was': 153, 'polish': 111, 'born': 21, 'physicist': 108, 'and': 11, 'chemist': 27, 'one': 103, 'of': 101, 'the': 144, 'most': 96, 'famous': 56, 'scientists': 128, 'her': 72, 'time': 146, 'together': 148, 'with': 161, 'husband': 76, 'pierre': 110, 'she': 131, 'awarded': 15, 'nobel': 99, 'prize': 114, 'in': 77, '1903': 4, 'went': 154, 'on': 102, 'to': 147, 'win': 159, 'another': 13, '1911': 6, 'sklodowska': 134, 'warsaw': 152, 'november': 100, '1867': 0, 'daughter': 37, 'teacher': 140, '1891': 1, 'paris': 107, 'study': 136, 'physics': 109, 'mathematics': 93, 'at': 14, 'sorbonne': 135, 'where': 157, 'met': 95, 'professor': 115, 'school': 126, 'they': 145, 'were': 155, 'married': 92, '1895': 2, 'curies': 35, 'worked': 164, 'investigating': 79, 'radioactivity': 117, 'building': 22, 'work': 163, 'german': 64, 'roentgen': 125, 'french': 61, 'becquerel': 17, 'july': 82, '1898': 3, 'announced': 12, 'discovery': 43, 'new': 98, 'chemical': 26, 'element': 49, 'polonium': 112, 'end': 50, 'year': 166, 'radium': 119, 'along': 9, 'for': 59, 'life': 87, 'cut': 36, 'short': 132, '1906': 5, 'when': 156, 'he': 67, 'knocked': 84, 'down': 45, 'killed': 83, 'by': 23, 'carriage': 24, 'took': 149, 'over': 106, 'his': 75, 'teaching': 141, 'post': 113, 'becoming': 16, 'first': 58, 'woman': 162, 'teach': 139, 'devoted': 41, 'herself': 73, 'continuing': 30, 'that': 143, 'had': 66, 'begun': 19, 'received': 122, 'second': 129, 'chemistry': 28, 'research': 124, 'crucial': 33, 'development': 40, 'rays': 121, 'surgery': 138, 'during': 47, 'world': 165, 'war': 151, 'helped': 71, 'equip': 52, 'ambulances': 10, 'ray': 120, 'equipment': 53, 'which': 158, 'drove': 46, 'front': 63, 'lines': 88, 'international': 78, 'red': 123, 'cross': 32, 'made': 89, 'head': 68, 'its': 81, 'radiological': 118, 'service': 130, 'held': 70, 'training': 150, 'courses': 31, 'medical': 94, 'orderlies': 105, 'doctors': 44, 'techniques': 142, 'despite': 38, 'success': 137, 'continued': 29, 'face': 55, 'great': 65, 'opposition': 104, 'from': 62, 'male': 90, 'france': 60, 'never': 97, 'significant': 133, 'financial': 57, 'benefits': 20, 'late': 85, '1920s': 7, 'health': 69, 'beginning': 18, 'deteriorate': 39, 'died': 42, '1934': 8, 'leukaemia': 86, 'caused': 25, 'exposure': 54, 'high': 74, 'energy': 51, 'radiation': 116, 'eldest': 48, 'irene': 80, 'scientist': 127, 'winner': 160}\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMwNNBzlmADM"
      },
      "source": [
        "We lost:\n",
        "\n",
        "* The meaning of text corpus\n",
        "* The ordering of the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQnF4LidmADM",
        "outputId": "db25b807-6f1e-4643-8cba-c16253c5184b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['time', 'her', 'scientists', 'famous', 'most', 'the', 'of', 'one',\n",
              "        'chemist', 'and', 'physicist', 'born', 'polish', 'was', 'curie',\n",
              "        'marie'], dtype='<U13'),\n",
              " array(['1911', 'another', 'win', 'to', 'on', 'went', '1903', 'in',\n",
              "        'prize', 'nobel', 'awarded', 'she', 'pierre', 'husband', 'with',\n",
              "        'together', 'her', 'the', 'and', 'was'], dtype='<U13'),\n",
              " array(['teacher', 'daughter', '1867', 'november', 'warsaw', 'sklodowska',\n",
              "        'on', 'in', 'the', 'of', 'born', 'was', 'marie'], dtype='<U13'),\n",
              " array(['school', 'professor', 'met', 'where', 'sorbonne', 'at',\n",
              "        'mathematics', 'physics', 'study', 'paris', '1891', 'to', 'went',\n",
              "        'in', 'she', 'pierre', 'the', 'of', 'and', 'curie'], dtype='<U13'),\n",
              " array(['1895', 'married', 'were', 'they', 'in'], dtype='<U13'),\n",
              " array(['becquerel', 'french', 'roentgen', 'german', 'work', 'building',\n",
              "        'radioactivity', 'investigating', 'worked', 'curies', 'on',\n",
              "        'together', 'the', 'of', 'and', 'physicist'], dtype='<U13'),\n",
              " array(['polonium', 'element', 'chemical', 'new', 'discovery', 'announced',\n",
              "        '1898', 'july', 'curies', 'in', 'the', 'of'], dtype='<U13'),\n",
              " array(['radium', 'year', 'end', 'discovery', 'announced', 'they', 'at',\n",
              "        'another', 'the', 'of'], dtype='<U13'),\n",
              " array(['for', 'along', 'becquerel', 'curies', 'were', 'physics', '1903',\n",
              "        'in', 'prize', 'nobel', 'awarded', 'with', 'the'], dtype='<U13'),\n",
              " array(['carriage', 'by', 'killed', 'down', 'knocked', 'he', 'when',\n",
              "        '1906', 'short', 'cut', 'life', 'in', 'pierre', 'and', 'was'],\n",
              "       dtype='<U13'),\n",
              " array(['begun', 'had', 'that', 'continuing', 'herself', 'devoted',\n",
              "        'teach', 'woman', 'first', 'becoming', 'post', 'teaching', 'his',\n",
              "        'over', 'took', 'work', 'they', 'sorbonne', 'at', 'to', 'together',\n",
              "        'the', 'and', 'marie'], dtype='<U13'),\n",
              " array(['chemistry', 'second', 'received', 'for', '1911', 'in', 'prize',\n",
              "        'nobel', 'she'], dtype='<U13'),\n",
              " array(['surgery', 'rays', 'development', 'crucial', 'research', 'in',\n",
              "        'the', 'of', 'was', 'curie'], dtype='<U13'),\n",
              " array(['lines', 'front', 'drove', 'which', 'equipment', 'ray',\n",
              "        'ambulances', 'equip', 'helped', 'war', 'world', 'during',\n",
              "        'herself', 'to', 'she', 'with', 'the', 'one', 'curie'],\n",
              "       dtype='<U13'),\n",
              " array(['techniques', 'doctors', 'orderlies', 'medical', 'courses',\n",
              "        'training', 'held', 'service', 'radiological', 'its', 'head',\n",
              "        'made', 'cross', 'red', 'international', 'for', 'new', 'in', 'she',\n",
              "        'her', 'the', 'of', 'and'], dtype='<U13'),\n",
              " array(['benefits', 'financial', 'significant', 'never', 'france', 'male',\n",
              "        'from', 'opposition', 'great', 'face', 'continued', 'success',\n",
              "        'despite', 'received', 'work', 'to', 'in', 'she', 'her',\n",
              "        'scientists', 'and', 'marie'], dtype='<U13'),\n",
              " array(['deteriorate', 'beginning', 'health', '1920s', 'late', 'by', 'to',\n",
              "        'her', 'the', 'was'], dtype='<U13'),\n",
              " array(['radiation', 'energy', 'high', 'exposure', 'caused', 'leukaemia',\n",
              "        '1934', 'died', 'from', 'research', 'by', 'july', 'to', 'on',\n",
              "        'she', 'her'], dtype='<U13'),\n",
              " array(['winner', 'scientist', 'irene', 'eldest', 'chemistry', 'herself',\n",
              "        'for', 'curies', 'daughter', 'prize', 'nobel', 'the', 'of', 'and',\n",
              "        'was'], dtype='<U13')]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.inverse_transform(transformed_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtPaJQyGmADN"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 03-VectorizeTextAsABagOfNGrams_CountVectorizer_Nltk</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPCxL-OhmADN"
      },
      "source": [
        "## Vectorize text as a bag-of-n-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEbfeCklmADO"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3hAJBW9mADO"
      },
      "outputs": [],
      "source": [
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JznRd1i7mADP"
      },
      "outputs": [],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7sBdW6TmADP"
      },
      "outputs": [],
      "source": [
        "transformed_vector = n_gram_vectorizer.fit_transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJcp-ExgmADQ",
        "outputId": "003f5c3f-280e-47f1-be6d-ec903ad1cae8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird in': 2,\n",
              " 'in hand': 10,\n",
              " 'hand is': 9,\n",
              " 'is worth': 14,\n",
              " 'worth two': 30,\n",
              " 'two in': 27,\n",
              " 'in the': 11,\n",
              " 'the bush': 19,\n",
              " 'good things': 8,\n",
              " 'things come': 23,\n",
              " 'come to': 3,\n",
              " 'to those': 25,\n",
              " 'those who': 24,\n",
              " 'who wait': 29,\n",
              " 'these watches': 22,\n",
              " 'watches cost': 28,\n",
              " 'cost 1500': 4,\n",
              " 'there are': 21,\n",
              " 'are other': 0,\n",
              " 'other fish': 16,\n",
              " 'fish in': 6,\n",
              " 'the sea': 20,\n",
              " 'the ball': 18,\n",
              " 'ball is': 1,\n",
              " 'is in': 13,\n",
              " 'in your': 12,\n",
              " 'your court': 31,\n",
              " 'mr smith': 15,\n",
              " 'smith goes': 17,\n",
              " 'goes to': 7,\n",
              " 'to washington': 26,\n",
              " 'doogie howser': 5}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHU9mc1DmADQ",
        "outputId": "d5cb8f24-1eef-4dba-e0a3-9ff890bca1a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLDwm04emADR",
        "outputId": "9390bcbf-f123-464d-bf67-06689f8332e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 5,\n",
              " 'in': 24,\n",
              " 'hand': 21,\n",
              " 'is': 28,\n",
              " 'worth': 61,\n",
              " 'two': 53,\n",
              " 'the': 38,\n",
              " 'bush': 7,\n",
              " 'bird in': 6,\n",
              " 'in hand': 25,\n",
              " 'hand is': 22,\n",
              " 'is worth': 30,\n",
              " 'worth two': 62,\n",
              " 'two in': 54,\n",
              " 'in the': 26,\n",
              " 'the bush': 40,\n",
              " 'good': 19,\n",
              " 'things': 46,\n",
              " 'come': 8,\n",
              " 'to': 50,\n",
              " 'those': 48,\n",
              " 'who': 59,\n",
              " 'wait': 55,\n",
              " 'good things': 20,\n",
              " 'things come': 47,\n",
              " 'come to': 9,\n",
              " 'to those': 51,\n",
              " 'those who': 49,\n",
              " 'who wait': 60,\n",
              " 'these': 44,\n",
              " 'watches': 57,\n",
              " 'cost': 10,\n",
              " '1500': 0,\n",
              " 'these watches': 45,\n",
              " 'watches cost': 58,\n",
              " 'cost 1500': 11,\n",
              " 'there': 42,\n",
              " 'are': 1,\n",
              " 'other': 33,\n",
              " 'fish': 15,\n",
              " 'sea': 35,\n",
              " 'there are': 43,\n",
              " 'are other': 2,\n",
              " 'other fish': 34,\n",
              " 'fish in': 16,\n",
              " 'the sea': 41,\n",
              " 'ball': 3,\n",
              " 'your': 63,\n",
              " 'court': 12,\n",
              " 'the ball': 39,\n",
              " 'ball is': 4,\n",
              " 'is in': 29,\n",
              " 'in your': 27,\n",
              " 'your court': 64,\n",
              " 'mr': 31,\n",
              " 'smith': 36,\n",
              " 'goes': 17,\n",
              " 'washington': 56,\n",
              " 'mr smith': 32,\n",
              " 'smith goes': 37,\n",
              " 'goes to': 18,\n",
              " 'to washington': 52,\n",
              " 'doogie': 13,\n",
              " 'howser': 23,\n",
              " 'doogie howser': 14}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "transformed_vector = n_gram_vectorizer.fit_transform(train_text)\n",
        "\n",
        "n_gram_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAdiImuCmADS",
        "outputId": "f2722c51-6944-4135-c5d0-2e8316b05bb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        1, 0, 2, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CXFGOylmADT"
      },
      "source": [
        "#### Bigram and Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGCvtRxlmADT",
        "outputId": "7bafccb4-d0de-4f7c-d87b-e4ffda7dc853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyQ2KFHjmADU",
        "outputId": "3e49c27f-5af6-4f05-9fcb-b9c4eda058ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.', 'Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.', 'Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.', 'In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.', 'They were married in 1895.', 'The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.', 'In July 1898, the Curies announced the discovery of a new chemical element, polonium.', 'At the end of the year, they announced the discovery of another, radium.', 'The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.', \"Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\", 'Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.', 'She received a second Nobel Prize, for Chemistry, in 1911.', \"The Curie's research was crucial in the development of x-rays in surgery.\", 'During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.', 'The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.', 'Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.', 'By the late 1920s her health was beginning to deteriorate.', 'She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.', \"The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\"]\n"
          ]
        }
      ],
      "source": [
        "sentences = file_contents.split('\\n')\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrbbCmVCmADV"
      },
      "outputs": [],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-amRh-6mADW"
      },
      "outputs": [],
      "source": [
        "transformed_vector = n_gram_vectorizer.fit_transform(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNHWKphVmADW",
        "outputId": "f5aebd0b-486a-478f-9769-c30e067266e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'marie curie': 251,\n",
              " 'curie was': 92,\n",
              " 'was polish': 504,\n",
              " 'polish born': 330,\n",
              " 'born physicist': 59,\n",
              " 'physicist and': 315,\n",
              " 'and chemist': 18,\n",
              " 'chemist and': 72,\n",
              " 'and one': 28,\n",
              " 'one of': 305,\n",
              " 'of the': 289,\n",
              " 'the most': 437,\n",
              " 'most famous': 265,\n",
              " 'famous scientists': 142,\n",
              " 'scientists of': 367,\n",
              " 'of her': 279,\n",
              " 'her time': 191,\n",
              " 'marie curie was': 252,\n",
              " 'curie was polish': 93,\n",
              " 'was polish born': 505,\n",
              " 'polish born physicist': 331,\n",
              " 'born physicist and': 60,\n",
              " 'physicist and chemist': 316,\n",
              " 'and chemist and': 19,\n",
              " 'chemist and one': 73,\n",
              " 'and one of': 29,\n",
              " 'one of the': 306,\n",
              " 'of the most': 291,\n",
              " 'the most famous': 438,\n",
              " 'most famous scientists': 266,\n",
              " 'famous scientists of': 143,\n",
              " 'scientists of her': 368,\n",
              " 'of her time': 280,\n",
              " 'together with': 480,\n",
              " 'with her': 526,\n",
              " 'her husband': 186,\n",
              " 'husband pierre': 203,\n",
              " 'pierre she': 328,\n",
              " 'she was': 385,\n",
              " 'was awarded': 490,\n",
              " 'awarded the': 46,\n",
              " 'the nobel': 441,\n",
              " 'nobel prize': 272,\n",
              " 'prize in': 337,\n",
              " 'in 1903': 208,\n",
              " '1903 and': 6,\n",
              " 'and she': 30,\n",
              " 'she went': 387,\n",
              " 'went on': 506,\n",
              " 'on to': 301,\n",
              " 'to win': 476,\n",
              " 'win another': 520,\n",
              " 'another in': 40,\n",
              " 'in 1911': 212,\n",
              " 'together with her': 481,\n",
              " 'with her husband': 527,\n",
              " 'her husband pierre': 187,\n",
              " 'husband pierre she': 204,\n",
              " 'pierre she was': 329,\n",
              " 'she was awarded': 386,\n",
              " 'was awarded the': 491,\n",
              " 'awarded the nobel': 47,\n",
              " 'the nobel prize': 442,\n",
              " 'nobel prize in': 274,\n",
              " 'prize in 1903': 338,\n",
              " 'in 1903 and': 209,\n",
              " '1903 and she': 7,\n",
              " 'and she went': 33,\n",
              " 'she went on': 388,\n",
              " 'went on to': 507,\n",
              " 'on to win': 302,\n",
              " 'to win another': 477,\n",
              " 'win another in': 521,\n",
              " 'another in 1911': 41,\n",
              " 'marie sklodowska': 253,\n",
              " 'sklodowska was': 394,\n",
              " 'was born': 494,\n",
              " 'born in': 57,\n",
              " 'in warsaw': 221,\n",
              " 'warsaw on': 488,\n",
              " 'on november': 297,\n",
              " 'november 1867': 275,\n",
              " '1867 the': 0,\n",
              " 'the daughter': 417,\n",
              " 'daughter of': 106,\n",
              " 'of teacher': 288,\n",
              " 'marie sklodowska was': 254,\n",
              " 'sklodowska was born': 395,\n",
              " 'was born in': 495,\n",
              " 'born in warsaw': 58,\n",
              " 'in warsaw on': 222,\n",
              " 'warsaw on november': 489,\n",
              " 'on november 1867': 298,\n",
              " 'november 1867 the': 276,\n",
              " '1867 the daughter': 1,\n",
              " 'the daughter of': 418,\n",
              " 'daughter of teacher': 107,\n",
              " 'in 1891': 205,\n",
              " '1891 she': 2,\n",
              " 'went to': 508,\n",
              " 'to paris': 468,\n",
              " 'paris to': 313,\n",
              " 'to study': 470,\n",
              " 'study physics': 400,\n",
              " 'physics and': 320,\n",
              " 'and mathematics': 26,\n",
              " 'mathematics at': 259,\n",
              " 'at the': 43,\n",
              " 'the sorbonne': 445,\n",
              " 'sorbonne where': 398,\n",
              " 'where she': 516,\n",
              " 'she met': 379,\n",
              " 'met pierre': 263,\n",
              " 'pierre curie': 324,\n",
              " 'curie professor': 88,\n",
              " 'professor of': 339,\n",
              " 'the school': 443,\n",
              " 'school of': 361,\n",
              " 'of physics': 285,\n",
              " 'in 1891 she': 206,\n",
              " '1891 she went': 3,\n",
              " 'she went to': 389,\n",
              " 'went to paris': 509,\n",
              " 'to paris to': 469,\n",
              " 'paris to study': 314,\n",
              " 'to study physics': 471,\n",
              " 'study physics and': 401,\n",
              " 'physics and mathematics': 321,\n",
              " 'and mathematics at': 27,\n",
              " 'mathematics at the': 260,\n",
              " 'at the sorbonne': 45,\n",
              " 'the sorbonne where': 447,\n",
              " 'sorbonne where she': 399,\n",
              " 'where she met': 517,\n",
              " 'she met pierre': 380,\n",
              " 'met pierre curie': 264,\n",
              " 'pierre curie professor': 325,\n",
              " 'curie professor of': 89,\n",
              " 'professor of the': 340,\n",
              " 'of the school': 293,\n",
              " 'the school of': 444,\n",
              " 'school of physics': 362,\n",
              " 'they were': 457,\n",
              " 'were married': 512,\n",
              " 'married in': 257,\n",
              " 'in 1895': 207,\n",
              " 'they were married': 458,\n",
              " 'were married in': 513,\n",
              " 'married in 1895': 258,\n",
              " 'the curies': 412,\n",
              " 'curies worked': 100,\n",
              " 'worked together': 536,\n",
              " 'together investigating': 478,\n",
              " 'investigating radioactivity': 225,\n",
              " 'radioactivity building': 343,\n",
              " 'building on': 61,\n",
              " 'on the': 299,\n",
              " 'the work': 448,\n",
              " 'work of': 532,\n",
              " 'the german': 431,\n",
              " 'german physicist': 166,\n",
              " 'physicist roentgen': 318,\n",
              " 'roentgen and': 359,\n",
              " 'and the': 34,\n",
              " 'the french': 427,\n",
              " 'french physicist': 156,\n",
              " 'physicist becquerel': 317,\n",
              " 'the curies worked': 416,\n",
              " 'curies worked together': 101,\n",
              " 'worked together investigating': 537,\n",
              " 'together investigating radioactivity': 479,\n",
              " 'investigating radioactivity building': 226,\n",
              " 'radioactivity building on': 344,\n",
              " 'building on the': 62,\n",
              " 'on the work': 300,\n",
              " 'the work of': 449,\n",
              " 'work of the': 533,\n",
              " 'of the german': 290,\n",
              " 'the german physicist': 432,\n",
              " 'german physicist roentgen': 167,\n",
              " 'physicist roentgen and': 319,\n",
              " 'roentgen and the': 360,\n",
              " 'and the french': 35,\n",
              " 'the french physicist': 428,\n",
              " 'french physicist becquerel': 157,\n",
              " 'in july': 215,\n",
              " 'july 1898': 231,\n",
              " '1898 the': 4,\n",
              " 'curies announced': 96,\n",
              " 'announced the': 38,\n",
              " 'the discovery': 421,\n",
              " 'discovery of': 116,\n",
              " 'of new': 283,\n",
              " 'new chemical': 269,\n",
              " 'chemical element': 70,\n",
              " 'element polonium': 129,\n",
              " 'in july 1898': 216,\n",
              " 'july 1898 the': 232,\n",
              " '1898 the curies': 5,\n",
              " 'the curies announced': 414,\n",
              " 'curies announced the': 97,\n",
              " 'announced the discovery': 39,\n",
              " 'the discovery of': 422,\n",
              " 'discovery of new': 118,\n",
              " 'of new chemical': 284,\n",
              " 'new chemical element': 270,\n",
              " 'chemical element polonium': 71,\n",
              " 'the end': 423,\n",
              " 'end of': 130,\n",
              " 'the year': 451,\n",
              " 'year they': 540,\n",
              " 'they announced': 453,\n",
              " 'of another': 277,\n",
              " 'another radium': 42,\n",
              " 'at the end': 44,\n",
              " 'the end of': 424,\n",
              " 'end of the': 131,\n",
              " 'of the year': 294,\n",
              " 'the year they': 452,\n",
              " 'year they announced': 541,\n",
              " 'they announced the': 454,\n",
              " 'discovery of another': 117,\n",
              " 'of another radium': 278,\n",
              " 'curies along': 94,\n",
              " 'along with': 14,\n",
              " 'with becquerel': 524,\n",
              " 'becquerel were': 50,\n",
              " 'were awarded': 510,\n",
              " 'prize for': 334,\n",
              " 'for physics': 152,\n",
              " 'physics in': 322,\n",
              " 'the curies along': 413,\n",
              " 'curies along with': 95,\n",
              " 'along with becquerel': 15,\n",
              " 'with becquerel were': 525,\n",
              " 'becquerel were awarded': 51,\n",
              " 'were awarded the': 511,\n",
              " 'nobel prize for': 273,\n",
              " 'prize for physics': 336,\n",
              " 'for physics in': 153,\n",
              " 'physics in 1903': 323,\n",
              " 'pierre life': 326,\n",
              " 'life was': 243,\n",
              " 'was cut': 498,\n",
              " 'cut short': 102,\n",
              " 'short in': 390,\n",
              " 'in 1906': 210,\n",
              " '1906 when': 8,\n",
              " 'when he': 514,\n",
              " 'he was': 172,\n",
              " 'was knocked': 502,\n",
              " 'knocked down': 237,\n",
              " 'down and': 121,\n",
              " 'and killed': 24,\n",
              " 'killed by': 235,\n",
              " 'by carriage': 63,\n",
              " 'pierre life was': 327,\n",
              " 'life was cut': 244,\n",
              " 'was cut short': 499,\n",
              " 'cut short in': 103,\n",
              " 'short in 1906': 391,\n",
              " 'in 1906 when': 211,\n",
              " '1906 when he': 9,\n",
              " 'when he was': 515,\n",
              " 'he was knocked': 173,\n",
              " 'was knocked down': 503,\n",
              " 'knocked down and': 238,\n",
              " 'down and killed': 122,\n",
              " 'and killed by': 25,\n",
              " 'killed by carriage': 236,\n",
              " 'marie took': 255,\n",
              " 'took over': 482,\n",
              " 'over his': 311,\n",
              " 'his teaching': 201,\n",
              " 'teaching post': 406,\n",
              " 'post becoming': 332,\n",
              " 'becoming the': 48,\n",
              " 'the first': 425,\n",
              " 'first woman': 146,\n",
              " 'woman to': 530,\n",
              " 'to teach': 472,\n",
              " 'teach at': 404,\n",
              " 'sorbonne and': 396,\n",
              " 'and devoted': 20,\n",
              " 'devoted herself': 112,\n",
              " 'herself to': 197,\n",
              " 'to continuing': 459,\n",
              " 'continuing the': 78,\n",
              " 'work that': 534,\n",
              " 'that they': 408,\n",
              " 'they had': 455,\n",
              " 'had begun': 170,\n",
              " 'begun together': 54,\n",
              " 'marie took over': 256,\n",
              " 'took over his': 483,\n",
              " 'over his teaching': 312,\n",
              " 'his teaching post': 202,\n",
              " 'teaching post becoming': 407,\n",
              " 'post becoming the': 333,\n",
              " 'becoming the first': 49,\n",
              " 'the first woman': 426,\n",
              " 'first woman to': 147,\n",
              " 'woman to teach': 531,\n",
              " 'to teach at': 473,\n",
              " 'teach at the': 405,\n",
              " 'the sorbonne and': 446,\n",
              " 'sorbonne and devoted': 397,\n",
              " 'and devoted herself': 21,\n",
              " 'devoted herself to': 113,\n",
              " 'herself to continuing': 198,\n",
              " 'to continuing the': 460,\n",
              " 'continuing the work': 79,\n",
              " 'the work that': 450,\n",
              " 'work that they': 535,\n",
              " 'that they had': 409,\n",
              " 'they had begun': 456,\n",
              " 'had begun together': 171,\n",
              " 'she received': 383,\n",
              " 'received second': 351,\n",
              " 'second nobel': 369,\n",
              " 'for chemistry': 148,\n",
              " 'chemistry in': 74,\n",
              " 'she received second': 384,\n",
              " 'received second nobel': 352,\n",
              " 'second nobel prize': 370,\n",
              " 'prize for chemistry': 335,\n",
              " 'for chemistry in': 149,\n",
              " 'chemistry in 1911': 75,\n",
              " 'the curie': 410,\n",
              " 'curie research': 90,\n",
              " 'research was': 357,\n",
              " 'was crucial': 496,\n",
              " 'crucial in': 84,\n",
              " 'in the': 218,\n",
              " 'the development': 419,\n",
              " 'development of': 110,\n",
              " 'of rays': 286,\n",
              " 'rays in': 349,\n",
              " 'in surgery': 217,\n",
              " 'the curie research': 411,\n",
              " 'curie research was': 91,\n",
              " 'research was crucial': 358,\n",
              " 'was crucial in': 497,\n",
              " 'crucial in the': 85,\n",
              " 'in the development': 219,\n",
              " 'the development of': 420,\n",
              " 'development of rays': 111,\n",
              " 'of rays in': 287,\n",
              " 'rays in surgery': 350,\n",
              " 'during world': 125,\n",
              " 'world war': 538,\n",
              " 'war one': 486,\n",
              " 'one curie': 303,\n",
              " 'curie helped': 86,\n",
              " 'helped to': 180,\n",
              " 'to equip': 462,\n",
              " 'equip ambulances': 134,\n",
              " 'ambulances with': 16,\n",
              " 'with ray': 528,\n",
              " 'ray equipment': 347,\n",
              " 'equipment which': 136,\n",
              " 'which she': 518,\n",
              " 'she herself': 377,\n",
              " 'herself drove': 193,\n",
              " 'drove to': 123,\n",
              " 'to the': 474,\n",
              " 'the front': 429,\n",
              " 'front lines': 165,\n",
              " 'during world war': 126,\n",
              " 'world war one': 539,\n",
              " 'war one curie': 487,\n",
              " 'one curie helped': 304,\n",
              " 'curie helped to': 87,\n",
              " 'helped to equip': 181,\n",
              " 'to equip ambulances': 463,\n",
              " 'equip ambulances with': 135,\n",
              " 'ambulances with ray': 17,\n",
              " 'with ray equipment': 529,\n",
              " 'ray equipment which': 348,\n",
              " 'equipment which she': 137,\n",
              " 'which she herself': 519,\n",
              " 'she herself drove': 378,\n",
              " 'herself drove to': 194,\n",
              " 'drove to the': 124,\n",
              " 'to the front': 475,\n",
              " 'the front lines': 430,\n",
              " 'the international': 433,\n",
              " 'international red': 223,\n",
              " 'red cross': 355,\n",
              " 'cross made': 82,\n",
              " 'made her': 245,\n",
              " 'her head': 182,\n",
              " 'head of': 174,\n",
              " 'of its': 281,\n",
              " 'its radiological': 229,\n",
              " 'radiological service': 345,\n",
              " 'service and': 371,\n",
              " 'she held': 375,\n",
              " 'held training': 178,\n",
              " 'training courses': 484,\n",
              " 'courses for': 80,\n",
              " 'for medical': 150,\n",
              " 'medical orderlies': 261,\n",
              " 'orderlies and': 309,\n",
              " 'and doctors': 22,\n",
              " 'doctors in': 119,\n",
              " 'the new': 439,\n",
              " 'new techniques': 271,\n",
              " 'the international red': 434,\n",
              " 'international red cross': 224,\n",
              " 'red cross made': 356,\n",
              " 'cross made her': 83,\n",
              " 'made her head': 246,\n",
              " 'her head of': 183,\n",
              " 'head of its': 175,\n",
              " 'of its radiological': 282,\n",
              " 'its radiological service': 230,\n",
              " 'radiological service and': 346,\n",
              " 'service and she': 372,\n",
              " 'and she held': 31,\n",
              " 'she held training': 376,\n",
              " 'held training courses': 179,\n",
              " 'training courses for': 485,\n",
              " 'courses for medical': 81,\n",
              " 'for medical orderlies': 151,\n",
              " 'medical orderlies and': 262,\n",
              " 'orderlies and doctors': 310,\n",
              " 'and doctors in': 23,\n",
              " 'doctors in the': 120,\n",
              " 'in the new': 220,\n",
              " 'the new techniques': 440,\n",
              " 'despite her': 108,\n",
              " 'her success': 189,\n",
              " 'success marie': 402,\n",
              " 'marie continued': 249,\n",
              " 'continued to': 76,\n",
              " 'to face': 464,\n",
              " 'face great': 140,\n",
              " 'great opposition': 168,\n",
              " 'opposition from': 307,\n",
              " 'from male': 163,\n",
              " 'male scientists': 247,\n",
              " 'scientists in': 365,\n",
              " 'in france': 213,\n",
              " 'france and': 154,\n",
              " 'she never': 381,\n",
              " 'never received': 267,\n",
              " 'received significant': 353,\n",
              " 'significant financial': 392,\n",
              " 'financial benefits': 144,\n",
              " 'benefits from': 55,\n",
              " 'from her': 158,\n",
              " 'her work': 192,\n",
              " 'despite her success': 109,\n",
              " 'her success marie': 190,\n",
              " 'success marie continued': 403,\n",
              " 'marie continued to': 250,\n",
              " 'continued to face': 77,\n",
              " 'to face great': 465,\n",
              " 'face great opposition': 141,\n",
              " 'great opposition from': 169,\n",
              " 'opposition from male': 308,\n",
              " 'from male scientists': 164,\n",
              " 'male scientists in': 248,\n",
              " 'scientists in france': 366,\n",
              " 'in france and': 214,\n",
              " 'france and she': 155,\n",
              " 'and she never': 32,\n",
              " 'she never received': 382,\n",
              " 'never received significant': 268,\n",
              " 'received significant financial': 354,\n",
              " 'significant financial benefits': 393,\n",
              " 'financial benefits from': 145,\n",
              " 'benefits from her': 56,\n",
              " 'from her work': 160,\n",
              " 'by the': 66,\n",
              " 'the late': 435,\n",
              " 'late 1920s': 239,\n",
              " '1920s her': 10,\n",
              " 'her health': 184,\n",
              " 'health was': 176,\n",
              " 'was beginning': 492,\n",
              " 'beginning to': 52,\n",
              " 'to deteriorate': 461,\n",
              " 'by the late': 67,\n",
              " 'the late 1920s': 436,\n",
              " 'late 1920s her': 240,\n",
              " '1920s her health': 11,\n",
              " 'her health was': 185,\n",
              " 'health was beginning': 177,\n",
              " 'was beginning to': 493,\n",
              " 'beginning to deteriorate': 53,\n",
              " 'she died': 373,\n",
              " 'died on': 114,\n",
              " 'on july': 295,\n",
              " 'july 1934': 233,\n",
              " '1934 from': 12,\n",
              " 'from leukaemia': 161,\n",
              " 'leukaemia caused': 241,\n",
              " 'caused by': 68,\n",
              " 'by exposure': 64,\n",
              " 'exposure to': 138,\n",
              " 'to high': 466,\n",
              " 'high energy': 199,\n",
              " 'energy radiation': 132,\n",
              " 'radiation from': 341,\n",
              " 'her research': 188,\n",
              " 'she died on': 374,\n",
              " 'died on july': 115,\n",
              " 'on july 1934': 296,\n",
              " 'july 1934 from': 234,\n",
              " '1934 from leukaemia': 13,\n",
              " 'from leukaemia caused': 162,\n",
              " 'leukaemia caused by': 242,\n",
              " 'caused by exposure': 69,\n",
              " 'by exposure to': 65,\n",
              " 'exposure to high': 139,\n",
              " 'to high energy': 467,\n",
              " 'high energy radiation': 200,\n",
              " 'energy radiation from': 133,\n",
              " 'radiation from her': 342,\n",
              " 'from her research': 159,\n",
              " 'curies eldest': 98,\n",
              " 'eldest daughter': 127,\n",
              " 'daughter irene': 104,\n",
              " 'irene was': 227,\n",
              " 'was herself': 500,\n",
              " 'herself scientist': 195,\n",
              " 'scientist and': 363,\n",
              " 'and winner': 36,\n",
              " 'winner of': 522,\n",
              " 'the curies eldest': 415,\n",
              " 'curies eldest daughter': 99,\n",
              " 'eldest daughter irene': 128,\n",
              " 'daughter irene was': 105,\n",
              " 'irene was herself': 228,\n",
              " 'was herself scientist': 501,\n",
              " 'herself scientist and': 196,\n",
              " 'scientist and winner': 364,\n",
              " 'and winner of': 37,\n",
              " 'winner of the': 523,\n",
              " 'of the nobel': 292}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary = n_gram_vectorizer.vocabulary_\n",
        "\n",
        "vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87w7OddTmADX",
        "outputId": "d681f553-9822-489e-caf2-e89809715918"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_.get('marie curie')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufGBlDKkmADY",
        "outputId": "01cbf45e-7502-41b9-b774-458befa0e823"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "279"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_.get('of her')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiSKpfT9mADZ"
      },
      "source": [
        "* https://stackoverflow.com/questions/11763613/python-list-of-ngrams-with-frequencies\n",
        "* https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG1d5qpvmADZ"
      },
      "source": [
        "word_count is a vector that contains the sum of each word occurrence in all texts in the corpus. In other words, we are adding the elements for each column of vector matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuVNvAv2mADa",
        "outputId": "f8d5e28d-d0e3-4257-e343-ed5e574a4eb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1CkRUpDmADb",
        "outputId": "da382bf9-7a31-4781-9f4b-154625d18b69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3,\n",
              "       1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 3, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_count = transformed_vector.toarray().sum(axis=0)\n",
        "\n",
        "word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO5ajjimmADb",
        "outputId": "3a2eb2c0-65e2-4bbd-c5fa-ded4f3630ecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_items([('marie curie', 251), ('curie was', 92), ('was polish', 504), ('polish born', 330), ('born physicist', 59), ('physicist and', 315), ('and chemist', 18), ('chemist and', 72), ('and one', 28), ('one of', 305), ('of the', 289), ('the most', 437), ('most famous', 265), ('famous scientists', 142), ('scientists of', 367), ('of her', 279), ('her time', 191), ('marie curie was', 252), ('curie was polish', 93), ('was polish born', 505), ('polish born physicist', 331), ('born physicist and', 60), ('physicist and chemist', 316), ('and chemist and', 19), ('chemist and one', 73), ('and one of', 29), ('one of the', 306), ('of the most', 291), ('the most famous', 438), ('most famous scientists', 266), ('famous scientists of', 143), ('scientists of her', 368), ('of her time', 280), ('together with', 480), ('with her', 526), ('her husband', 186), ('husband pierre', 203), ('pierre she', 328), ('she was', 385), ('was awarded', 490), ('awarded the', 46), ('the nobel', 441), ('nobel prize', 272), ('prize in', 337), ('in 1903', 208), ('1903 and', 6), ('and she', 30), ('she went', 387), ('went on', 506), ('on to', 301), ('to win', 476), ('win another', 520), ('another in', 40), ('in 1911', 212), ('together with her', 481), ('with her husband', 527), ('her husband pierre', 187), ('husband pierre she', 204), ('pierre she was', 329), ('she was awarded', 386), ('was awarded the', 491), ('awarded the nobel', 47), ('the nobel prize', 442), ('nobel prize in', 274), ('prize in 1903', 338), ('in 1903 and', 209), ('1903 and she', 7), ('and she went', 33), ('she went on', 388), ('went on to', 507), ('on to win', 302), ('to win another', 477), ('win another in', 521), ('another in 1911', 41), ('marie sklodowska', 253), ('sklodowska was', 394), ('was born', 494), ('born in', 57), ('in warsaw', 221), ('warsaw on', 488), ('on november', 297), ('november 1867', 275), ('1867 the', 0), ('the daughter', 417), ('daughter of', 106), ('of teacher', 288), ('marie sklodowska was', 254), ('sklodowska was born', 395), ('was born in', 495), ('born in warsaw', 58), ('in warsaw on', 222), ('warsaw on november', 489), ('on november 1867', 298), ('november 1867 the', 276), ('1867 the daughter', 1), ('the daughter of', 418), ('daughter of teacher', 107), ('in 1891', 205), ('1891 she', 2), ('went to', 508), ('to paris', 468), ('paris to', 313), ('to study', 470), ('study physics', 400), ('physics and', 320), ('and mathematics', 26), ('mathematics at', 259), ('at the', 43), ('the sorbonne', 445), ('sorbonne where', 398), ('where she', 516), ('she met', 379), ('met pierre', 263), ('pierre curie', 324), ('curie professor', 88), ('professor of', 339), ('the school', 443), ('school of', 361), ('of physics', 285), ('in 1891 she', 206), ('1891 she went', 3), ('she went to', 389), ('went to paris', 509), ('to paris to', 469), ('paris to study', 314), ('to study physics', 471), ('study physics and', 401), ('physics and mathematics', 321), ('and mathematics at', 27), ('mathematics at the', 260), ('at the sorbonne', 45), ('the sorbonne where', 447), ('sorbonne where she', 399), ('where she met', 517), ('she met pierre', 380), ('met pierre curie', 264), ('pierre curie professor', 325), ('curie professor of', 89), ('professor of the', 340), ('of the school', 293), ('the school of', 444), ('school of physics', 362), ('they were', 457), ('were married', 512), ('married in', 257), ('in 1895', 207), ('they were married', 458), ('were married in', 513), ('married in 1895', 258), ('the curies', 412), ('curies worked', 100), ('worked together', 536), ('together investigating', 478), ('investigating radioactivity', 225), ('radioactivity building', 343), ('building on', 61), ('on the', 299), ('the work', 448), ('work of', 532), ('the german', 431), ('german physicist', 166), ('physicist roentgen', 318), ('roentgen and', 359), ('and the', 34), ('the french', 427), ('french physicist', 156), ('physicist becquerel', 317), ('the curies worked', 416), ('curies worked together', 101), ('worked together investigating', 537), ('together investigating radioactivity', 479), ('investigating radioactivity building', 226), ('radioactivity building on', 344), ('building on the', 62), ('on the work', 300), ('the work of', 449), ('work of the', 533), ('of the german', 290), ('the german physicist', 432), ('german physicist roentgen', 167), ('physicist roentgen and', 319), ('roentgen and the', 360), ('and the french', 35), ('the french physicist', 428), ('french physicist becquerel', 157), ('in july', 215), ('july 1898', 231), ('1898 the', 4), ('curies announced', 96), ('announced the', 38), ('the discovery', 421), ('discovery of', 116), ('of new', 283), ('new chemical', 269), ('chemical element', 70), ('element polonium', 129), ('in july 1898', 216), ('july 1898 the', 232), ('1898 the curies', 5), ('the curies announced', 414), ('curies announced the', 97), ('announced the discovery', 39), ('the discovery of', 422), ('discovery of new', 118), ('of new chemical', 284), ('new chemical element', 270), ('chemical element polonium', 71), ('the end', 423), ('end of', 130), ('the year', 451), ('year they', 540), ('they announced', 453), ('of another', 277), ('another radium', 42), ('at the end', 44), ('the end of', 424), ('end of the', 131), ('of the year', 294), ('the year they', 452), ('year they announced', 541), ('they announced the', 454), ('discovery of another', 117), ('of another radium', 278), ('curies along', 94), ('along with', 14), ('with becquerel', 524), ('becquerel were', 50), ('were awarded', 510), ('prize for', 334), ('for physics', 152), ('physics in', 322), ('the curies along', 413), ('curies along with', 95), ('along with becquerel', 15), ('with becquerel were', 525), ('becquerel were awarded', 51), ('were awarded the', 511), ('nobel prize for', 273), ('prize for physics', 336), ('for physics in', 153), ('physics in 1903', 323), ('pierre life', 326), ('life was', 243), ('was cut', 498), ('cut short', 102), ('short in', 390), ('in 1906', 210), ('1906 when', 8), ('when he', 514), ('he was', 172), ('was knocked', 502), ('knocked down', 237), ('down and', 121), ('and killed', 24), ('killed by', 235), ('by carriage', 63), ('pierre life was', 327), ('life was cut', 244), ('was cut short', 499), ('cut short in', 103), ('short in 1906', 391), ('in 1906 when', 211), ('1906 when he', 9), ('when he was', 515), ('he was knocked', 173), ('was knocked down', 503), ('knocked down and', 238), ('down and killed', 122), ('and killed by', 25), ('killed by carriage', 236), ('marie took', 255), ('took over', 482), ('over his', 311), ('his teaching', 201), ('teaching post', 406), ('post becoming', 332), ('becoming the', 48), ('the first', 425), ('first woman', 146), ('woman to', 530), ('to teach', 472), ('teach at', 404), ('sorbonne and', 396), ('and devoted', 20), ('devoted herself', 112), ('herself to', 197), ('to continuing', 459), ('continuing the', 78), ('work that', 534), ('that they', 408), ('they had', 455), ('had begun', 170), ('begun together', 54), ('marie took over', 256), ('took over his', 483), ('over his teaching', 312), ('his teaching post', 202), ('teaching post becoming', 407), ('post becoming the', 333), ('becoming the first', 49), ('the first woman', 426), ('first woman to', 147), ('woman to teach', 531), ('to teach at', 473), ('teach at the', 405), ('the sorbonne and', 446), ('sorbonne and devoted', 397), ('and devoted herself', 21), ('devoted herself to', 113), ('herself to continuing', 198), ('to continuing the', 460), ('continuing the work', 79), ('the work that', 450), ('work that they', 535), ('that they had', 409), ('they had begun', 456), ('had begun together', 171), ('she received', 383), ('received second', 351), ('second nobel', 369), ('for chemistry', 148), ('chemistry in', 74), ('she received second', 384), ('received second nobel', 352), ('second nobel prize', 370), ('prize for chemistry', 335), ('for chemistry in', 149), ('chemistry in 1911', 75), ('the curie', 410), ('curie research', 90), ('research was', 357), ('was crucial', 496), ('crucial in', 84), ('in the', 218), ('the development', 419), ('development of', 110), ('of rays', 286), ('rays in', 349), ('in surgery', 217), ('the curie research', 411), ('curie research was', 91), ('research was crucial', 358), ('was crucial in', 497), ('crucial in the', 85), ('in the development', 219), ('the development of', 420), ('development of rays', 111), ('of rays in', 287), ('rays in surgery', 350), ('during world', 125), ('world war', 538), ('war one', 486), ('one curie', 303), ('curie helped', 86), ('helped to', 180), ('to equip', 462), ('equip ambulances', 134), ('ambulances with', 16), ('with ray', 528), ('ray equipment', 347), ('equipment which', 136), ('which she', 518), ('she herself', 377), ('herself drove', 193), ('drove to', 123), ('to the', 474), ('the front', 429), ('front lines', 165), ('during world war', 126), ('world war one', 539), ('war one curie', 487), ('one curie helped', 304), ('curie helped to', 87), ('helped to equip', 181), ('to equip ambulances', 463), ('equip ambulances with', 135), ('ambulances with ray', 17), ('with ray equipment', 529), ('ray equipment which', 348), ('equipment which she', 137), ('which she herself', 519), ('she herself drove', 378), ('herself drove to', 194), ('drove to the', 124), ('to the front', 475), ('the front lines', 430), ('the international', 433), ('international red', 223), ('red cross', 355), ('cross made', 82), ('made her', 245), ('her head', 182), ('head of', 174), ('of its', 281), ('its radiological', 229), ('radiological service', 345), ('service and', 371), ('she held', 375), ('held training', 178), ('training courses', 484), ('courses for', 80), ('for medical', 150), ('medical orderlies', 261), ('orderlies and', 309), ('and doctors', 22), ('doctors in', 119), ('the new', 439), ('new techniques', 271), ('the international red', 434), ('international red cross', 224), ('red cross made', 356), ('cross made her', 83), ('made her head', 246), ('her head of', 183), ('head of its', 175), ('of its radiological', 282), ('its radiological service', 230), ('radiological service and', 346), ('service and she', 372), ('and she held', 31), ('she held training', 376), ('held training courses', 179), ('training courses for', 485), ('courses for medical', 81), ('for medical orderlies', 151), ('medical orderlies and', 262), ('orderlies and doctors', 310), ('and doctors in', 23), ('doctors in the', 120), ('in the new', 220), ('the new techniques', 440), ('despite her', 108), ('her success', 189), ('success marie', 402), ('marie continued', 249), ('continued to', 76), ('to face', 464), ('face great', 140), ('great opposition', 168), ('opposition from', 307), ('from male', 163), ('male scientists', 247), ('scientists in', 365), ('in france', 213), ('france and', 154), ('she never', 381), ('never received', 267), ('received significant', 353), ('significant financial', 392), ('financial benefits', 144), ('benefits from', 55), ('from her', 158), ('her work', 192), ('despite her success', 109), ('her success marie', 190), ('success marie continued', 403), ('marie continued to', 250), ('continued to face', 77), ('to face great', 465), ('face great opposition', 141), ('great opposition from', 169), ('opposition from male', 308), ('from male scientists', 164), ('male scientists in', 248), ('scientists in france', 366), ('in france and', 214), ('france and she', 155), ('and she never', 32), ('she never received', 382), ('never received significant', 268), ('received significant financial', 354), ('significant financial benefits', 393), ('financial benefits from', 145), ('benefits from her', 56), ('from her work', 160), ('by the', 66), ('the late', 435), ('late 1920s', 239), ('1920s her', 10), ('her health', 184), ('health was', 176), ('was beginning', 492), ('beginning to', 52), ('to deteriorate', 461), ('by the late', 67), ('the late 1920s', 436), ('late 1920s her', 240), ('1920s her health', 11), ('her health was', 185), ('health was beginning', 177), ('was beginning to', 493), ('beginning to deteriorate', 53), ('she died', 373), ('died on', 114), ('on july', 295), ('july 1934', 233), ('1934 from', 12), ('from leukaemia', 161), ('leukaemia caused', 241), ('caused by', 68), ('by exposure', 64), ('exposure to', 138), ('to high', 466), ('high energy', 199), ('energy radiation', 132), ('radiation from', 341), ('her research', 188), ('she died on', 374), ('died on july', 115), ('on july 1934', 296), ('july 1934 from', 234), ('1934 from leukaemia', 13), ('from leukaemia caused', 162), ('leukaemia caused by', 242), ('caused by exposure', 69), ('by exposure to', 65), ('exposure to high', 139), ('to high energy', 467), ('high energy radiation', 200), ('energy radiation from', 133), ('radiation from her', 342), ('from her research', 159), ('curies eldest', 98), ('eldest daughter', 127), ('daughter irene', 104), ('irene was', 227), ('was herself', 500), ('herself scientist', 195), ('scientist and', 363), ('and winner', 36), ('winner of', 522), ('the curies eldest', 415), ('curies eldest daughter', 99), ('eldest daughter irene', 128), ('daughter irene was', 105), ('irene was herself', 228), ('was herself scientist', 501), ('herself scientist and', 196), ('scientist and winner', 364), ('and winner of', 37), ('winner of the', 523), ('of the nobel', 292)])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPE7yVWimADc",
        "outputId": "43f3052b-0718-4e25-95d3-de7a7d2b4a2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(5, 'of the'),\n",
              " (4, 'the curies'),\n",
              " (4, 'nobel prize'),\n",
              " (3, 'the nobel prize'),\n",
              " (3, 'the nobel'),\n",
              " (3, 'prize for'),\n",
              " (3, 'nobel prize for'),\n",
              " (3, 'at the'),\n",
              " (3, 'and she'),\n",
              " (2, 'the work'),\n",
              " (2, 'the sorbonne'),\n",
              " (2, 'the discovery of'),\n",
              " (2, 'the discovery'),\n",
              " (2, 'she went'),\n",
              " (2, 'prize for chemistry'),\n",
              " (2, 'in the'),\n",
              " (2, 'in 1911'),\n",
              " (2, 'in 1903'),\n",
              " (2, 'from her'),\n",
              " (2, 'for chemistry'),\n",
              " (2, 'discovery of'),\n",
              " (2, 'awarded the nobel'),\n",
              " (2, 'awarded the'),\n",
              " (2, 'at the sorbonne'),\n",
              " (2, 'announced the discovery'),\n",
              " (2, 'announced the'),\n",
              " (1, 'year they announced'),\n",
              " (1, 'year they'),\n",
              " (1, 'world war one'),\n",
              " (1, 'world war'),\n",
              " (1, 'worked together investigating'),\n",
              " (1, 'worked together'),\n",
              " (1, 'work that they'),\n",
              " (1, 'work that'),\n",
              " (1, 'work of the'),\n",
              " (1, 'work of'),\n",
              " (1, 'woman to teach'),\n",
              " (1, 'woman to'),\n",
              " (1, 'with ray equipment'),\n",
              " (1, 'with ray'),\n",
              " (1, 'with her husband'),\n",
              " (1, 'with her'),\n",
              " (1, 'with becquerel were'),\n",
              " (1, 'with becquerel'),\n",
              " (1, 'winner of the'),\n",
              " (1, 'winner of'),\n",
              " (1, 'win another in'),\n",
              " (1, 'win another'),\n",
              " (1, 'which she herself'),\n",
              " (1, 'which she'),\n",
              " (1, 'where she met'),\n",
              " (1, 'where she'),\n",
              " (1, 'when he was'),\n",
              " (1, 'when he'),\n",
              " (1, 'were married in'),\n",
              " (1, 'were married'),\n",
              " (1, 'were awarded the'),\n",
              " (1, 'were awarded'),\n",
              " (1, 'went to paris'),\n",
              " (1, 'went to'),\n",
              " (1, 'went on to'),\n",
              " (1, 'went on'),\n",
              " (1, 'was polish born'),\n",
              " (1, 'was polish'),\n",
              " (1, 'was knocked down'),\n",
              " (1, 'was knocked'),\n",
              " (1, 'was herself scientist'),\n",
              " (1, 'was herself'),\n",
              " (1, 'was cut short'),\n",
              " (1, 'was cut'),\n",
              " (1, 'was crucial in'),\n",
              " (1, 'was crucial'),\n",
              " (1, 'was born in'),\n",
              " (1, 'was born'),\n",
              " (1, 'was beginning to'),\n",
              " (1, 'was beginning'),\n",
              " (1, 'was awarded the'),\n",
              " (1, 'was awarded'),\n",
              " (1, 'warsaw on november'),\n",
              " (1, 'warsaw on'),\n",
              " (1, 'war one curie'),\n",
              " (1, 'war one'),\n",
              " (1, 'training courses for'),\n",
              " (1, 'training courses'),\n",
              " (1, 'took over his'),\n",
              " (1, 'took over'),\n",
              " (1, 'together with her'),\n",
              " (1, 'together with'),\n",
              " (1, 'together investigating radioactivity'),\n",
              " (1, 'together investigating'),\n",
              " (1, 'to win another'),\n",
              " (1, 'to win'),\n",
              " (1, 'to the front'),\n",
              " (1, 'to the'),\n",
              " (1, 'to teach at'),\n",
              " (1, 'to teach'),\n",
              " (1, 'to study physics'),\n",
              " (1, 'to study'),\n",
              " (1, 'to paris to'),\n",
              " (1, 'to paris'),\n",
              " (1, 'to high energy'),\n",
              " (1, 'to high'),\n",
              " (1, 'to face great'),\n",
              " (1, 'to face'),\n",
              " (1, 'to equip ambulances'),\n",
              " (1, 'to equip'),\n",
              " (1, 'to deteriorate'),\n",
              " (1, 'to continuing the'),\n",
              " (1, 'to continuing'),\n",
              " (1, 'they were married'),\n",
              " (1, 'they were'),\n",
              " (1, 'they had begun'),\n",
              " (1, 'they had'),\n",
              " (1, 'they announced the'),\n",
              " (1, 'they announced'),\n",
              " (1, 'the year they'),\n",
              " (1, 'the year'),\n",
              " (1, 'the work that'),\n",
              " (1, 'the work of'),\n",
              " (1, 'the sorbonne where'),\n",
              " (1, 'the sorbonne and'),\n",
              " (1, 'the school of'),\n",
              " (1, 'the school'),\n",
              " (1, 'the new techniques'),\n",
              " (1, 'the new'),\n",
              " (1, 'the most famous'),\n",
              " (1, 'the most'),\n",
              " (1, 'the late 1920s'),\n",
              " (1, 'the late'),\n",
              " (1, 'the international red'),\n",
              " (1, 'the international'),\n",
              " (1, 'the german physicist'),\n",
              " (1, 'the german'),\n",
              " (1, 'the front lines'),\n",
              " (1, 'the front'),\n",
              " (1, 'the french physicist'),\n",
              " (1, 'the french'),\n",
              " (1, 'the first woman'),\n",
              " (1, 'the first'),\n",
              " (1, 'the end of'),\n",
              " (1, 'the end'),\n",
              " (1, 'the development of'),\n",
              " (1, 'the development'),\n",
              " (1, 'the daughter of'),\n",
              " (1, 'the daughter'),\n",
              " (1, 'the curies worked'),\n",
              " (1, 'the curies eldest'),\n",
              " (1, 'the curies announced'),\n",
              " (1, 'the curies along'),\n",
              " (1, 'the curie research'),\n",
              " (1, 'the curie'),\n",
              " (1, 'that they had'),\n",
              " (1, 'that they'),\n",
              " (1, 'teaching post becoming'),\n",
              " (1, 'teaching post'),\n",
              " (1, 'teach at the'),\n",
              " (1, 'teach at'),\n",
              " (1, 'success marie continued'),\n",
              " (1, 'success marie'),\n",
              " (1, 'study physics and'),\n",
              " (1, 'study physics'),\n",
              " (1, 'sorbonne where she'),\n",
              " (1, 'sorbonne where'),\n",
              " (1, 'sorbonne and devoted'),\n",
              " (1, 'sorbonne and'),\n",
              " (1, 'sklodowska was born'),\n",
              " (1, 'sklodowska was'),\n",
              " (1, 'significant financial benefits'),\n",
              " (1, 'significant financial'),\n",
              " (1, 'short in 1906'),\n",
              " (1, 'short in'),\n",
              " (1, 'she went to'),\n",
              " (1, 'she went on'),\n",
              " (1, 'she was awarded'),\n",
              " (1, 'she was'),\n",
              " (1, 'she received second'),\n",
              " (1, 'she received'),\n",
              " (1, 'she never received'),\n",
              " (1, 'she never'),\n",
              " (1, 'she met pierre'),\n",
              " (1, 'she met'),\n",
              " (1, 'she herself drove'),\n",
              " (1, 'she herself'),\n",
              " (1, 'she held training'),\n",
              " (1, 'she held'),\n",
              " (1, 'she died on'),\n",
              " (1, 'she died'),\n",
              " (1, 'service and she'),\n",
              " (1, 'service and'),\n",
              " (1, 'second nobel prize'),\n",
              " (1, 'second nobel'),\n",
              " (1, 'scientists of her'),\n",
              " (1, 'scientists of'),\n",
              " (1, 'scientists in france'),\n",
              " (1, 'scientists in'),\n",
              " (1, 'scientist and winner'),\n",
              " (1, 'scientist and'),\n",
              " (1, 'school of physics'),\n",
              " (1, 'school of'),\n",
              " (1, 'roentgen and the'),\n",
              " (1, 'roentgen and'),\n",
              " (1, 'research was crucial'),\n",
              " (1, 'research was'),\n",
              " (1, 'red cross made'),\n",
              " (1, 'red cross'),\n",
              " (1, 'received significant financial'),\n",
              " (1, 'received significant'),\n",
              " (1, 'received second nobel'),\n",
              " (1, 'received second'),\n",
              " (1, 'rays in surgery'),\n",
              " (1, 'rays in'),\n",
              " (1, 'ray equipment which'),\n",
              " (1, 'ray equipment'),\n",
              " (1, 'radiological service and'),\n",
              " (1, 'radiological service'),\n",
              " (1, 'radioactivity building on'),\n",
              " (1, 'radioactivity building'),\n",
              " (1, 'radiation from her'),\n",
              " (1, 'radiation from'),\n",
              " (1, 'professor of the'),\n",
              " (1, 'professor of'),\n",
              " (1, 'prize in 1903'),\n",
              " (1, 'prize in'),\n",
              " (1, 'prize for physics'),\n",
              " (1, 'post becoming the'),\n",
              " (1, 'post becoming'),\n",
              " (1, 'polish born physicist'),\n",
              " (1, 'polish born'),\n",
              " (1, 'pierre she was'),\n",
              " (1, 'pierre she'),\n",
              " (1, 'pierre life was'),\n",
              " (1, 'pierre life'),\n",
              " (1, 'pierre curie professor'),\n",
              " (1, 'pierre curie'),\n",
              " (1, 'physics in 1903'),\n",
              " (1, 'physics in'),\n",
              " (1, 'physics and mathematics'),\n",
              " (1, 'physics and'),\n",
              " (1, 'physicist roentgen and'),\n",
              " (1, 'physicist roentgen'),\n",
              " (1, 'physicist becquerel'),\n",
              " (1, 'physicist and chemist'),\n",
              " (1, 'physicist and'),\n",
              " (1, 'paris to study'),\n",
              " (1, 'paris to'),\n",
              " (1, 'over his teaching'),\n",
              " (1, 'over his'),\n",
              " (1, 'orderlies and doctors'),\n",
              " (1, 'orderlies and'),\n",
              " (1, 'opposition from male'),\n",
              " (1, 'opposition from'),\n",
              " (1, 'one of the'),\n",
              " (1, 'one of'),\n",
              " (1, 'one curie helped'),\n",
              " (1, 'one curie'),\n",
              " (1, 'on to win'),\n",
              " (1, 'on to'),\n",
              " (1, 'on the work'),\n",
              " (1, 'on the'),\n",
              " (1, 'on november 1867'),\n",
              " (1, 'on november'),\n",
              " (1, 'on july 1934'),\n",
              " (1, 'on july'),\n",
              " (1, 'of the year'),\n",
              " (1, 'of the school'),\n",
              " (1, 'of the nobel'),\n",
              " (1, 'of the most'),\n",
              " (1, 'of the german'),\n",
              " (1, 'of teacher'),\n",
              " (1, 'of rays in'),\n",
              " (1, 'of rays'),\n",
              " (1, 'of physics'),\n",
              " (1, 'of new chemical'),\n",
              " (1, 'of new'),\n",
              " (1, 'of its radiological'),\n",
              " (1, 'of its'),\n",
              " (1, 'of her time'),\n",
              " (1, 'of her'),\n",
              " (1, 'of another radium'),\n",
              " (1, 'of another'),\n",
              " (1, 'november 1867 the'),\n",
              " (1, 'november 1867'),\n",
              " (1, 'nobel prize in'),\n",
              " (1, 'new techniques'),\n",
              " (1, 'new chemical element'),\n",
              " (1, 'new chemical'),\n",
              " (1, 'never received significant'),\n",
              " (1, 'never received'),\n",
              " (1, 'most famous scientists'),\n",
              " (1, 'most famous'),\n",
              " (1, 'met pierre curie'),\n",
              " (1, 'met pierre'),\n",
              " (1, 'medical orderlies and'),\n",
              " (1, 'medical orderlies'),\n",
              " (1, 'mathematics at the'),\n",
              " (1, 'mathematics at'),\n",
              " (1, 'married in 1895'),\n",
              " (1, 'married in'),\n",
              " (1, 'marie took over'),\n",
              " (1, 'marie took'),\n",
              " (1, 'marie sklodowska was'),\n",
              " (1, 'marie sklodowska'),\n",
              " (1, 'marie curie was'),\n",
              " (1, 'marie curie'),\n",
              " (1, 'marie continued to'),\n",
              " (1, 'marie continued'),\n",
              " (1, 'male scientists in'),\n",
              " (1, 'male scientists'),\n",
              " (1, 'made her head'),\n",
              " (1, 'made her'),\n",
              " (1, 'life was cut'),\n",
              " (1, 'life was'),\n",
              " (1, 'leukaemia caused by'),\n",
              " (1, 'leukaemia caused'),\n",
              " (1, 'late 1920s her'),\n",
              " (1, 'late 1920s'),\n",
              " (1, 'knocked down and'),\n",
              " (1, 'knocked down'),\n",
              " (1, 'killed by carriage'),\n",
              " (1, 'killed by'),\n",
              " (1, 'july 1934 from'),\n",
              " (1, 'july 1934'),\n",
              " (1, 'july 1898 the'),\n",
              " (1, 'july 1898'),\n",
              " (1, 'its radiological service'),\n",
              " (1, 'its radiological'),\n",
              " (1, 'irene was herself'),\n",
              " (1, 'irene was'),\n",
              " (1, 'investigating radioactivity building'),\n",
              " (1, 'investigating radioactivity'),\n",
              " (1, 'international red cross'),\n",
              " (1, 'international red'),\n",
              " (1, 'in warsaw on'),\n",
              " (1, 'in warsaw'),\n",
              " (1, 'in the new'),\n",
              " (1, 'in the development'),\n",
              " (1, 'in surgery'),\n",
              " (1, 'in july 1898'),\n",
              " (1, 'in july'),\n",
              " (1, 'in france and'),\n",
              " (1, 'in france'),\n",
              " (1, 'in 1906 when'),\n",
              " (1, 'in 1906'),\n",
              " (1, 'in 1903 and'),\n",
              " (1, 'in 1895'),\n",
              " (1, 'in 1891 she'),\n",
              " (1, 'in 1891'),\n",
              " (1, 'husband pierre she'),\n",
              " (1, 'husband pierre'),\n",
              " (1, 'his teaching post'),\n",
              " (1, 'his teaching'),\n",
              " (1, 'high energy radiation'),\n",
              " (1, 'high energy'),\n",
              " (1, 'herself to continuing'),\n",
              " (1, 'herself to'),\n",
              " (1, 'herself scientist and'),\n",
              " (1, 'herself scientist'),\n",
              " (1, 'herself drove to'),\n",
              " (1, 'herself drove'),\n",
              " (1, 'her work'),\n",
              " (1, 'her time'),\n",
              " (1, 'her success marie'),\n",
              " (1, 'her success'),\n",
              " (1, 'her research'),\n",
              " (1, 'her husband pierre'),\n",
              " (1, 'her husband'),\n",
              " (1, 'her health was'),\n",
              " (1, 'her health'),\n",
              " (1, 'her head of'),\n",
              " (1, 'her head'),\n",
              " (1, 'helped to equip'),\n",
              " (1, 'helped to'),\n",
              " (1, 'held training courses'),\n",
              " (1, 'held training'),\n",
              " (1, 'health was beginning'),\n",
              " (1, 'health was'),\n",
              " (1, 'head of its'),\n",
              " (1, 'head of'),\n",
              " (1, 'he was knocked'),\n",
              " (1, 'he was'),\n",
              " (1, 'had begun together'),\n",
              " (1, 'had begun'),\n",
              " (1, 'great opposition from'),\n",
              " (1, 'great opposition'),\n",
              " (1, 'german physicist roentgen'),\n",
              " (1, 'german physicist'),\n",
              " (1, 'front lines'),\n",
              " (1, 'from male scientists'),\n",
              " (1, 'from male'),\n",
              " (1, 'from leukaemia caused'),\n",
              " (1, 'from leukaemia'),\n",
              " (1, 'from her work'),\n",
              " (1, 'from her research'),\n",
              " (1, 'french physicist becquerel'),\n",
              " (1, 'french physicist'),\n",
              " (1, 'france and she'),\n",
              " (1, 'france and'),\n",
              " (1, 'for physics in'),\n",
              " (1, 'for physics'),\n",
              " (1, 'for medical orderlies'),\n",
              " (1, 'for medical'),\n",
              " (1, 'for chemistry in'),\n",
              " (1, 'first woman to'),\n",
              " (1, 'first woman'),\n",
              " (1, 'financial benefits from'),\n",
              " (1, 'financial benefits'),\n",
              " (1, 'famous scientists of'),\n",
              " (1, 'famous scientists'),\n",
              " (1, 'face great opposition'),\n",
              " (1, 'face great'),\n",
              " (1, 'exposure to high'),\n",
              " (1, 'exposure to'),\n",
              " (1, 'equipment which she'),\n",
              " (1, 'equipment which'),\n",
              " (1, 'equip ambulances with'),\n",
              " (1, 'equip ambulances'),\n",
              " (1, 'energy radiation from'),\n",
              " (1, 'energy radiation'),\n",
              " (1, 'end of the'),\n",
              " (1, 'end of'),\n",
              " (1, 'element polonium'),\n",
              " (1, 'eldest daughter irene'),\n",
              " (1, 'eldest daughter'),\n",
              " (1, 'during world war'),\n",
              " (1, 'during world'),\n",
              " (1, 'drove to the'),\n",
              " (1, 'drove to'),\n",
              " (1, 'down and killed'),\n",
              " (1, 'down and'),\n",
              " (1, 'doctors in the'),\n",
              " (1, 'doctors in'),\n",
              " (1, 'discovery of new'),\n",
              " (1, 'discovery of another'),\n",
              " (1, 'died on july'),\n",
              " (1, 'died on'),\n",
              " (1, 'devoted herself to'),\n",
              " (1, 'devoted herself'),\n",
              " (1, 'development of rays'),\n",
              " (1, 'development of'),\n",
              " (1, 'despite her success'),\n",
              " (1, 'despite her'),\n",
              " (1, 'daughter of teacher'),\n",
              " (1, 'daughter of'),\n",
              " (1, 'daughter irene was'),\n",
              " (1, 'daughter irene'),\n",
              " (1, 'cut short in'),\n",
              " (1, 'cut short'),\n",
              " (1, 'curies worked together'),\n",
              " (1, 'curies worked'),\n",
              " (1, 'curies eldest daughter'),\n",
              " (1, 'curies eldest'),\n",
              " (1, 'curies announced the'),\n",
              " (1, 'curies announced'),\n",
              " (1, 'curies along with'),\n",
              " (1, 'curies along'),\n",
              " (1, 'curie was polish'),\n",
              " (1, 'curie was'),\n",
              " (1, 'curie research was'),\n",
              " (1, 'curie research'),\n",
              " (1, 'curie professor of'),\n",
              " (1, 'curie professor'),\n",
              " (1, 'curie helped to'),\n",
              " (1, 'curie helped'),\n",
              " (1, 'crucial in the'),\n",
              " (1, 'crucial in'),\n",
              " (1, 'cross made her'),\n",
              " (1, 'cross made'),\n",
              " (1, 'courses for medical'),\n",
              " (1, 'courses for'),\n",
              " (1, 'continuing the work'),\n",
              " (1, 'continuing the'),\n",
              " (1, 'continued to face'),\n",
              " (1, 'continued to'),\n",
              " (1, 'chemistry in 1911'),\n",
              " (1, 'chemistry in'),\n",
              " (1, 'chemist and one'),\n",
              " (1, 'chemist and'),\n",
              " (1, 'chemical element polonium'),\n",
              " (1, 'chemical element'),\n",
              " (1, 'caused by exposure'),\n",
              " (1, 'caused by'),\n",
              " (1, 'by the late'),\n",
              " (1, 'by the'),\n",
              " (1, 'by exposure to'),\n",
              " (1, 'by exposure'),\n",
              " (1, 'by carriage'),\n",
              " (1, 'building on the'),\n",
              " (1, 'building on'),\n",
              " (1, 'born physicist and'),\n",
              " (1, 'born physicist'),\n",
              " (1, 'born in warsaw'),\n",
              " (1, 'born in'),\n",
              " (1, 'benefits from her'),\n",
              " (1, 'benefits from'),\n",
              " (1, 'begun together'),\n",
              " (1, 'beginning to deteriorate'),\n",
              " (1, 'beginning to'),\n",
              " (1, 'becquerel were awarded'),\n",
              " (1, 'becquerel were'),\n",
              " (1, 'becoming the first'),\n",
              " (1, 'becoming the'),\n",
              " (1, 'at the end'),\n",
              " (1, 'another radium'),\n",
              " (1, 'another in 1911'),\n",
              " (1, 'another in'),\n",
              " (1, 'and winner of'),\n",
              " (1, 'and winner'),\n",
              " (1, 'and the french'),\n",
              " (1, 'and the'),\n",
              " (1, 'and she went'),\n",
              " (1, 'and she never'),\n",
              " (1, 'and she held'),\n",
              " (1, 'and one of'),\n",
              " (1, 'and one'),\n",
              " (1, 'and mathematics at'),\n",
              " (1, 'and mathematics'),\n",
              " (1, 'and killed by'),\n",
              " (1, 'and killed'),\n",
              " (1, 'and doctors in'),\n",
              " (1, 'and doctors'),\n",
              " (1, 'and devoted herself'),\n",
              " (1, 'and devoted'),\n",
              " (1, 'and chemist and'),\n",
              " (1, 'and chemist'),\n",
              " (1, 'ambulances with ray'),\n",
              " (1, 'ambulances with'),\n",
              " (1, 'along with becquerel'),\n",
              " (1, 'along with'),\n",
              " (1, '1934 from leukaemia'),\n",
              " (1, '1934 from'),\n",
              " (1, '1920s her health'),\n",
              " (1, '1920s her'),\n",
              " (1, '1906 when he'),\n",
              " (1, '1906 when'),\n",
              " (1, '1903 and she'),\n",
              " (1, '1903 and'),\n",
              " (1, '1898 the curies'),\n",
              " (1, '1898 the'),\n",
              " (1, '1891 she went'),\n",
              " (1, '1891 she'),\n",
              " (1, '1867 the daughter'),\n",
              " (1, '1867 the')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_word_list = sorted([(word_count[i], n_gram) for n_gram, i in vocabulary.items()], reverse=True)\n",
        "\n",
        "sorted_word_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i362UoMXmADc"
      },
      "source": [
        "### Using nltk to find ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5548InyWmADd",
        "outputId": "1c7ce35a-483b-4278-c0f2-a700acf1ba5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A bird in hand is worth two in the bush.',\n",
              " 'Good things come to those who wait.',\n",
              " 'These watches cost $1500! ',\n",
              " 'There are other fish in the sea.',\n",
              " 'The ball is in your court.',\n",
              " 'Mr. Smith Goes to Washington ',\n",
              " 'Doogie Howser M.D.']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deN8hbfzmADd"
      },
      "outputs": [],
      "source": [
        "from nltk import bigrams\n",
        "from nltk import trigrams\n",
        "\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZvgo7LYmADe",
        "outputId": "86bc022f-0630-4176-8a4f-2ecc3462f674"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A',\n",
              " 'bird',\n",
              " 'in',\n",
              " 'hand',\n",
              " 'is',\n",
              " 'worth',\n",
              " 'two',\n",
              " 'in',\n",
              " 'the',\n",
              " 'bush',\n",
              " '.',\n",
              " 'Good',\n",
              " 'things',\n",
              " 'come',\n",
              " 'to',\n",
              " 'those',\n",
              " 'who',\n",
              " 'wait',\n",
              " '.',\n",
              " 'These',\n",
              " 'watches',\n",
              " 'cost',\n",
              " '$',\n",
              " '1500',\n",
              " '!',\n",
              " 'There',\n",
              " 'are',\n",
              " 'other',\n",
              " 'fish',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sea',\n",
              " '.',\n",
              " 'The',\n",
              " 'ball',\n",
              " 'is',\n",
              " 'in',\n",
              " 'your',\n",
              " 'court',\n",
              " '.',\n",
              " 'Mr.',\n",
              " 'Smith',\n",
              " 'Goes',\n",
              " 'to',\n",
              " 'Washington',\n",
              " 'Doogie',\n",
              " 'Howser',\n",
              " 'M.D',\n",
              " '.']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = word_tokenize(\" \".join(train_text))\n",
        "\n",
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2c7pBWhmADe",
        "outputId": "610989b5-068f-4b30-9b87-21f26988d2b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'bird'),\n",
              " ('bird', 'in'),\n",
              " ('in', 'hand'),\n",
              " ('hand', 'is'),\n",
              " ('is', 'worth'),\n",
              " ('worth', 'two'),\n",
              " ('two', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'bush'),\n",
              " ('bush', '.'),\n",
              " ('.', 'Good'),\n",
              " ('Good', 'things'),\n",
              " ('things', 'come'),\n",
              " ('come', 'to'),\n",
              " ('to', 'those'),\n",
              " ('those', 'who'),\n",
              " ('who', 'wait'),\n",
              " ('wait', '.'),\n",
              " ('.', 'These'),\n",
              " ('These', 'watches'),\n",
              " ('watches', 'cost'),\n",
              " ('cost', '$'),\n",
              " ('$', '1500'),\n",
              " ('1500', '!'),\n",
              " ('!', 'There'),\n",
              " ('There', 'are'),\n",
              " ('are', 'other'),\n",
              " ('other', 'fish'),\n",
              " ('fish', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'sea'),\n",
              " ('sea', '.'),\n",
              " ('.', 'The'),\n",
              " ('The', 'ball'),\n",
              " ('ball', 'is'),\n",
              " ('is', 'in'),\n",
              " ('in', 'your'),\n",
              " ('your', 'court'),\n",
              " ('court', '.'),\n",
              " ('.', 'Mr.'),\n",
              " ('Mr.', 'Smith'),\n",
              " ('Smith', 'Goes'),\n",
              " ('Goes', 'to'),\n",
              " ('to', 'Washington'),\n",
              " ('Washington', 'Doogie'),\n",
              " ('Doogie', 'Howser'),\n",
              " ('Howser', 'M.D'),\n",
              " ('M.D', '.')]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_bigrams = bigrams(word_tokens)\n",
        "\n",
        "list(nltk_bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhwFFp-amADf",
        "outputId": "7dae99f4-1a87-489e-a880-d1bcd9d13cd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'bird', 'in'),\n",
              " ('bird', 'in', 'hand'),\n",
              " ('in', 'hand', 'is'),\n",
              " ('hand', 'is', 'worth'),\n",
              " ('is', 'worth', 'two'),\n",
              " ('worth', 'two', 'in'),\n",
              " ('two', 'in', 'the'),\n",
              " ('in', 'the', 'bush'),\n",
              " ('the', 'bush', '.'),\n",
              " ('bush', '.', 'Good'),\n",
              " ('.', 'Good', 'things'),\n",
              " ('Good', 'things', 'come'),\n",
              " ('things', 'come', 'to'),\n",
              " ('come', 'to', 'those'),\n",
              " ('to', 'those', 'who'),\n",
              " ('those', 'who', 'wait'),\n",
              " ('who', 'wait', '.'),\n",
              " ('wait', '.', 'These'),\n",
              " ('.', 'These', 'watches'),\n",
              " ('These', 'watches', 'cost'),\n",
              " ('watches', 'cost', '$'),\n",
              " ('cost', '$', '1500'),\n",
              " ('$', '1500', '!'),\n",
              " ('1500', '!', 'There'),\n",
              " ('!', 'There', 'are'),\n",
              " ('There', 'are', 'other'),\n",
              " ('are', 'other', 'fish'),\n",
              " ('other', 'fish', 'in'),\n",
              " ('fish', 'in', 'the'),\n",
              " ('in', 'the', 'sea'),\n",
              " ('the', 'sea', '.'),\n",
              " ('sea', '.', 'The'),\n",
              " ('.', 'The', 'ball'),\n",
              " ('The', 'ball', 'is'),\n",
              " ('ball', 'is', 'in'),\n",
              " ('is', 'in', 'your'),\n",
              " ('in', 'your', 'court'),\n",
              " ('your', 'court', '.'),\n",
              " ('court', '.', 'Mr.'),\n",
              " ('.', 'Mr.', 'Smith'),\n",
              " ('Mr.', 'Smith', 'Goes'),\n",
              " ('Smith', 'Goes', 'to'),\n",
              " ('Goes', 'to', 'Washington'),\n",
              " ('to', 'Washington', 'Doogie'),\n",
              " ('Washington', 'Doogie', 'Howser'),\n",
              " ('Doogie', 'Howser', 'M.D'),\n",
              " ('Howser', 'M.D', '.')]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_trigrams = trigrams(word_tokens)\n",
        "\n",
        "list(nltk_trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqw6Ow-TmADf",
        "outputId": "d99338cd-9e6b-41b4-bd49-3fcc53c2cf05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('A', 'bird', 'in', 'hand', 'is')\n",
            "('bird', 'in', 'hand', 'is', 'worth')\n",
            "('in', 'hand', 'is', 'worth', 'two')\n",
            "('hand', 'is', 'worth', 'two', 'in')\n",
            "('is', 'worth', 'two', 'in', 'the')\n",
            "('worth', 'two', 'in', 'the', 'bush')\n",
            "('two', 'in', 'the', 'bush', '.')\n",
            "('in', 'the', 'bush', '.', 'Good')\n",
            "('the', 'bush', '.', 'Good', 'things')\n",
            "('bush', '.', 'Good', 'things', 'come')\n",
            "('.', 'Good', 'things', 'come', 'to')\n",
            "('Good', 'things', 'come', 'to', 'those')\n",
            "('things', 'come', 'to', 'those', 'who')\n",
            "('come', 'to', 'those', 'who', 'wait')\n",
            "('to', 'those', 'who', 'wait', '.')\n",
            "('those', 'who', 'wait', '.', 'These')\n",
            "('who', 'wait', '.', 'These', 'watches')\n",
            "('wait', '.', 'These', 'watches', 'cost')\n",
            "('.', 'These', 'watches', 'cost', '$')\n",
            "('These', 'watches', 'cost', '$', '1500')\n",
            "('watches', 'cost', '$', '1500', '!')\n",
            "('cost', '$', '1500', '!', 'There')\n",
            "('$', '1500', '!', 'There', 'are')\n",
            "('1500', '!', 'There', 'are', 'other')\n",
            "('!', 'There', 'are', 'other', 'fish')\n",
            "('There', 'are', 'other', 'fish', 'in')\n",
            "('are', 'other', 'fish', 'in', 'the')\n",
            "('other', 'fish', 'in', 'the', 'sea')\n",
            "('fish', 'in', 'the', 'sea', '.')\n",
            "('in', 'the', 'sea', '.', 'The')\n",
            "('the', 'sea', '.', 'The', 'ball')\n",
            "('sea', '.', 'The', 'ball', 'is')\n",
            "('.', 'The', 'ball', 'is', 'in')\n",
            "('The', 'ball', 'is', 'in', 'your')\n",
            "('ball', 'is', 'in', 'your', 'court')\n",
            "('is', 'in', 'your', 'court', '.')\n",
            "('in', 'your', 'court', '.', 'Mr.')\n",
            "('your', 'court', '.', 'Mr.', 'Smith')\n",
            "('court', '.', 'Mr.', 'Smith', 'Goes')\n",
            "('.', 'Mr.', 'Smith', 'Goes', 'to')\n",
            "('Mr.', 'Smith', 'Goes', 'to', 'Washington')\n",
            "('Smith', 'Goes', 'to', 'Washington', 'Doogie')\n",
            "('Goes', 'to', 'Washington', 'Doogie', 'Howser')\n",
            "('to', 'Washington', 'Doogie', 'Howser', 'M.D')\n",
            "('Washington', 'Doogie', 'Howser', 'M.D', '.')\n"
          ]
        }
      ],
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "fivegrams = ngrams(word_tokens, 5)\n",
        "\n",
        "for grams in fivegrams:\n",
        "    print(grams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B1AKuiWmADg"
      },
      "source": [
        "* https://tedboy.github.io/nlps/generated/generated/nltk.BigramAssocMeasures\n",
        "* http://www.nltk.org/_modules/nltk/collocations.html#BigramCollocationFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTfQHEfbmADg"
      },
      "outputs": [],
      "source": [
        "from nltk.collocations import BigramAssocMeasures\n",
        "from nltk.collocations import BigramCollocationFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiGMLs3JmADh"
      },
      "outputs": [],
      "source": [
        "word_tokens = word_tokenize(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq9r1fJ1mADh",
        "outputId": "11858096-3e61-4b2b-ab46-8b0c1cc7f04a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('.', 'The'),\n",
              " ('of', 'the'),\n",
              " ('Nobel', 'Prize'),\n",
              " (',', 'and'),\n",
              " ('The', 'Curies'),\n",
              " ('and', 'she'),\n",
              " ('the', 'Nobel')]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_measures = BigramAssocMeasures()\n",
        "\n",
        "finder = BigramCollocationFinder.from_words(word_tokens)\n",
        "\n",
        "finder.apply_freq_filter(3)\n",
        "\n",
        "matches = finder.nbest(bigram_measures.raw_freq, 15)\n",
        "\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNejS9vZmADi",
        "outputId": "46b8f499-baaa-48b8-99f5-afd03324f376"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('.', 'The'),\n",
              " ('of', 'the'),\n",
              " ('Nobel', 'Prize'),\n",
              " (',', 'and'),\n",
              " ('The', 'Curies'),\n",
              " ('and', 'she'),\n",
              " ('the', 'Nobel'),\n",
              " (',', 'she'),\n",
              " (',', 'the'),\n",
              " ('.', 'In'),\n",
              " ('.', 'Marie'),\n",
              " ('.', 'She'),\n",
              " ('1911', '.'),\n",
              " ('Prize', 'for'),\n",
              " ('announced', 'the')]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_measures = BigramAssocMeasures()\n",
        "\n",
        "finder = BigramCollocationFinder.from_words(word_tokens)\n",
        "\n",
        "finder.apply_freq_filter(2)\n",
        "\n",
        "matches = finder.nbest(bigram_measures.raw_freq, 15)\n",
        "\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HysWTSHhmADi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRf8B5tamADj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmyv0x3umADj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlCjb1OzmADj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PND4bBEmADk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9LRUsAMmADk"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 04-VectorizeText_TfidfTransformer_TfidfVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfZCpy9OmADk"
      },
      "source": [
        "<b>TfidfTransformer</b> :\n",
        "\n",
        "* Transform a count matrix to a normalized tf or tf-idf representation\n",
        "* Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGjwCnB1mADl"
      },
      "source": [
        "* A <b>Term Frequency</b> is a count of how many times a word occurs in a given document (synonymous with bag of words).\n",
        "* The <b>Inverse Document Frequency</b> is the the number of times a word occurs in a corpus of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scmGstDamADl"
      },
      "source": [
        "The first step is to create our training and testing document set and computing the term frequency matrix\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKryGCT6mADm"
      },
      "source": [
        "### Creating a count vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC1LaSM8mADm"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a2ZkelzmADn"
      },
      "outputs": [],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "frequency_term_matrix = count_vectorizer.fit_transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSq3Ddl3mADn",
        "outputId": "ece29f87-1701-43f9-e311-71231ba17ead"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LxVbuzQmADo",
        "outputId": "6386e602-f197-48e0-8b40-abc9df389401"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_term_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5cU4JrXmADo",
        "outputId": "26770f91-754f-4554-cc0f-dea25f251a54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_term_matrix.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596gMiTZmADp"
      },
      "source": [
        "### Building the tf-idf matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic89tiXBmADq"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO27xsW6mADq",
        "outputId": "015a3c42-bbb9-4b16-81d0-872cb435c853"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector1 = tfidf_transformer.fit_transform(frequency_term_matrix)\n",
        "\n",
        "tfidf_vector1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXxUQhE3mADr",
        "outputId": "d12fe97b-9581-48c5-bf4b-c312210ebfce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.34908308, 0.34908308,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34908308, 0.        , 0.49536976,\n",
              "        0.28976893, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24768488, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38665001, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.38665001, 0.38665001,\n",
              "        0.32095271, 0.        , 0.38665001, 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.40801493,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28949879,\n",
              "        0.        , 0.        , 0.40801493, 0.40801493, 0.        ,\n",
              "        0.28949879, 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.3274243 ,\n",
              "        0.38305686, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3274243 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46180424, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46180424, 0.        , 0.        , 0.46180424,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38333718, 0.        , 0.        , 0.46180424, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector1.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-KghtY1mADr",
        "outputId": "0eed270a-5c94-45fa-955c-21de6386146c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.34908308 0.34908308 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.34908308 0.         0.49536976 0.28976893 0.         0.\n",
            "  0.         0.         0.24768488 0.         0.         0.\n",
            "  0.         0.         0.34908308 0.         0.         0.\n",
            "  0.         0.34908308 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.38665001\n",
            "  0.         0.         0.         0.         0.         0.38665001\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.38665001\n",
            "  0.38665001 0.32095271 0.         0.38665001 0.         0.\n",
            "  0.38665001 0.         0.        ]\n",
            " [0.5        0.         0.         0.         0.         0.\n",
            "  0.5        0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.5        0.\n",
            "  0.         0.         0.         0.         0.         0.5\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.40801493 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.40801493 0.         0.\n",
            "  0.         0.         0.28949879 0.         0.         0.40801493\n",
            "  0.40801493 0.         0.28949879 0.40801493 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.46146654 0.         0.         0.\n",
            "  0.         0.46146654 0.         0.         0.         0.\n",
            "  0.         0.         0.3274243  0.38305686 0.         0.\n",
            "  0.         0.         0.3274243  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.46146654]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.46180424 0.\n",
            "  0.         0.         0.         0.         0.46180424 0.\n",
            "  0.         0.46180424 0.         0.         0.         0.\n",
            "  0.         0.38333718 0.         0.         0.46180424 0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.70710678 0.         0.         0.\n",
            "  0.         0.70710678 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector1.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf9u3HoxmADs"
      },
      "source": [
        "## TfidfVectorizer = CountVectorizer + TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBCcXBEimADs"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZR08DN1mADt",
        "outputId": "0172673d-c708-46a8-daf5-ffc9ee5ad6a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 3,\n",
              " 'in': 14,\n",
              " 'hand': 12,\n",
              " 'is': 15,\n",
              " 'worth': 31,\n",
              " 'two': 26,\n",
              " 'the': 20,\n",
              " 'bush': 4,\n",
              " 'good': 11,\n",
              " 'things': 23,\n",
              " 'come': 5,\n",
              " 'to': 25,\n",
              " 'those': 24,\n",
              " 'who': 30,\n",
              " 'wait': 27,\n",
              " 'these': 22,\n",
              " 'watches': 29,\n",
              " 'cost': 6,\n",
              " '1500': 0,\n",
              " 'there': 21,\n",
              " 'are': 1,\n",
              " 'other': 17,\n",
              " 'fish': 9,\n",
              " 'sea': 18,\n",
              " 'ball': 2,\n",
              " 'your': 32,\n",
              " 'court': 7,\n",
              " 'mr': 16,\n",
              " 'smith': 19,\n",
              " 'goes': 10,\n",
              " 'washington': 28,\n",
              " 'doogie': 8,\n",
              " 'howser': 13}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2 = tfidf_vectorizer.fit_transform(train_text)\n",
        "\n",
        "tfidf_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEsg2pRKmADt",
        "outputId": "2b1e2e0a-df92-4773-904b-2b65fef0a443"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU1aN9WBmADu",
        "outputId": "c4e7a9d7-4d24-4efa-883b-2d8b9452e1fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.38629436, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436, 2.38629436, 1.69314718,\n",
              "       1.98082925, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       1.69314718, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       1.98082925, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer.idf_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9N8uSYVmADv",
        "outputId": "8d6d6f2c-702c-43f7-c211-a0a0fe48eff7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'1500': 2.386294361119891,\n",
              " 'are': 2.386294361119891,\n",
              " 'ball': 2.386294361119891,\n",
              " 'bird': 2.386294361119891,\n",
              " 'bush': 2.386294361119891,\n",
              " 'come': 2.386294361119891,\n",
              " 'cost': 2.386294361119891,\n",
              " 'court': 2.386294361119891,\n",
              " 'doogie': 2.386294361119891,\n",
              " 'fish': 2.386294361119891,\n",
              " 'goes': 2.386294361119891,\n",
              " 'good': 2.386294361119891,\n",
              " 'hand': 2.386294361119891,\n",
              " 'howser': 2.386294361119891,\n",
              " 'in': 1.6931471805599454,\n",
              " 'is': 1.9808292530117262,\n",
              " 'mr': 2.386294361119891,\n",
              " 'other': 2.386294361119891,\n",
              " 'sea': 2.386294361119891,\n",
              " 'smith': 2.386294361119891,\n",
              " 'the': 1.6931471805599454,\n",
              " 'there': 2.386294361119891,\n",
              " 'these': 2.386294361119891,\n",
              " 'things': 2.386294361119891,\n",
              " 'those': 2.386294361119891,\n",
              " 'to': 1.9808292530117262,\n",
              " 'two': 2.386294361119891,\n",
              " 'wait': 2.386294361119891,\n",
              " 'washington': 2.386294361119891,\n",
              " 'watches': 2.386294361119891,\n",
              " 'who': 2.386294361119891,\n",
              " 'worth': 2.386294361119891,\n",
              " 'your': 2.386294361119891}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilUNtetVmADw"
      },
      "source": [
        "### Final scorings of each word from the other words in the vocabulary.\n",
        "* The scores are normalized to values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnmPwqNCmADw",
        "outputId": "80717987-d7b6-447c-e99d-107fdb343f91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.34908308, 0.34908308,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34908308, 0.        , 0.49536976,\n",
              "        0.28976893, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24768488, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38665001, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.38665001, 0.38665001,\n",
              "        0.32095271, 0.        , 0.38665001, 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.40801493,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28949879,\n",
              "        0.        , 0.        , 0.40801493, 0.40801493, 0.        ,\n",
              "        0.28949879, 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.3274243 ,\n",
              "        0.38305686, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3274243 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46180424, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46180424, 0.        , 0.        , 0.46180424,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38333718, 0.        , 0.        , 0.46180424, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oTVJLIImADx",
        "outputId": "fe0fd17f-6b22-467a-8a7b-69c00d6cf265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3)\t0.3490830767264469\n",
            "  (0, 14)\t0.49536975552604884\n",
            "  (0, 12)\t0.3490830767264469\n",
            "  (0, 15)\t0.2897689326921819\n",
            "  (0, 31)\t0.3490830767264469\n",
            "  (0, 26)\t0.3490830767264469\n",
            "  (0, 20)\t0.24768487776302442\n",
            "  (0, 4)\t0.3490830767264469\n",
            "  (1, 11)\t0.386650005027498\n",
            "  (1, 23)\t0.386650005027498\n",
            "  (1, 5)\t0.386650005027498\n",
            "  (1, 25)\t0.32095270940344806\n",
            "  (1, 24)\t0.386650005027498\n",
            "  (1, 30)\t0.386650005027498\n",
            "  (1, 27)\t0.386650005027498\n",
            "  (2, 22)\t0.5\n",
            "  (2, 29)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (2, 0)\t0.5\n",
            "  (3, 14)\t0.2894987873064995\n",
            "  (3, 20)\t0.2894987873064995\n",
            "  (3, 21)\t0.40801492725049476\n",
            "  (3, 1)\t0.40801492725049476\n",
            "  (3, 17)\t0.40801492725049476\n",
            "  (3, 9)\t0.40801492725049476\n",
            "  (3, 18)\t0.40801492725049476\n",
            "  (4, 14)\t0.3274243027464032\n",
            "  (4, 15)\t0.38305685676572565\n",
            "  (4, 20)\t0.3274243027464032\n",
            "  (4, 2)\t0.4614665377636916\n",
            "  (4, 32)\t0.4614665377636916\n",
            "  (4, 7)\t0.4614665377636916\n",
            "  (5, 25)\t0.38333717539523177\n",
            "  (5, 16)\t0.4618042361109319\n",
            "  (5, 19)\t0.4618042361109319\n",
            "  (5, 10)\t0.4618042361109319\n",
            "  (5, 28)\t0.4618042361109319\n",
            "  (6, 8)\t0.7071067811865476\n",
            "  (6, 13)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8abPXEMgmADx",
        "outputId": "2d214ce3-5298-4479-d1f6-e2008fa9e4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 31)\t0.34908307672644684\n",
            "  (0, 26)\t0.34908307672644684\n",
            "  (0, 20)\t0.2476848777630244\n",
            "  (0, 15)\t0.2897689326921819\n",
            "  (0, 14)\t0.4953697555260488\n",
            "  (0, 12)\t0.34908307672644684\n",
            "  (0, 4)\t0.34908307672644684\n",
            "  (0, 3)\t0.34908307672644684\n",
            "  (1, 30)\t0.386650005027498\n",
            "  (1, 27)\t0.386650005027498\n",
            "  (1, 25)\t0.32095270940344806\n",
            "  (1, 24)\t0.386650005027498\n",
            "  (1, 23)\t0.386650005027498\n",
            "  (1, 11)\t0.386650005027498\n",
            "  (1, 5)\t0.386650005027498\n",
            "  (2, 29)\t0.5\n",
            "  (2, 22)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (2, 0)\t0.5\n",
            "  (3, 21)\t0.40801492725049476\n",
            "  (3, 20)\t0.2894987873064995\n",
            "  (3, 18)\t0.40801492725049476\n",
            "  (3, 17)\t0.40801492725049476\n",
            "  (3, 14)\t0.2894987873064995\n",
            "  (3, 9)\t0.40801492725049476\n",
            "  (3, 1)\t0.40801492725049476\n",
            "  (4, 32)\t0.4614665377636916\n",
            "  (4, 20)\t0.3274243027464032\n",
            "  (4, 15)\t0.38305685676572565\n",
            "  (4, 14)\t0.3274243027464032\n",
            "  (4, 7)\t0.4614665377636916\n",
            "  (4, 2)\t0.4614665377636916\n",
            "  (5, 28)\t0.4618042361109319\n",
            "  (5, 25)\t0.38333717539523177\n",
            "  (5, 19)\t0.4618042361109319\n",
            "  (5, 16)\t0.4618042361109319\n",
            "  (5, 10)\t0.4618042361109319\n",
            "  (6, 13)\t0.7071067811865476\n",
            "  (6, 8)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-4Xy_PbmADy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x532RShrmADy"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 01-TokenizingTextIntoSentencesAndWords</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDUccMLumADz"
      },
      "source": [
        "## Tokenize text into words and sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1OuM2gGmAD0",
        "outputId": "65a6f189-5e05-4921-df9e-d8ce69aa6881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.16.1\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "print(numpy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0o1_Ax8mAD0",
        "outputId": "7761c01b-2a0b-4552-ab50-73040dc6a3d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.4\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "print(nltk.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKQdFoLZmAD1"
      },
      "source": [
        "#### Uses NLTK's recommended sentence tokenizer, the PunktSentenceTokenizer\n",
        "#### Uses NLTK's recommended word tokenizer, the TreebankWordTokenizer and the PunktSentencetokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21HOpv2dmAD1"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlSYunRRmAD2",
        "outputId": "031f54f7-3174-40e5-d5e9-6970544d8977"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-27d5e78d663c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Does this tokenizer work? These are two different sentences'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = sent_tokenize('Does this tokenizer work? These are two different sentences')\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB246pC-mAD2",
        "outputId": "d92e3976-b37e-4c8b-b951-96d5ff8abb8a"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-42e4b9771e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Does this tokenizer work?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     return [\n\u001b[1;32m    145\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize('Does this tokenizer work?')\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-Wf1gY9mAD3"
      },
      "source": [
        "#### Punkt tokenizer\n",
        "\n",
        "https://www.nltk.org/_modules/nltk/tokenize/punkt.html\n",
        "http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt\n",
        "\n",
        "A sentence tokenizer which uses an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences; and then uses that model to find sentence boundaries. This approach has been shown to work well for many European languages.\n",
        "\n",
        "It must be trained on a large collection of plaintext in the target language before it can be used.\n",
        "\n",
        "The NLTK data package includes a pre-trained Punkt tokenizer for English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBYJYzZBmAD3",
        "outputId": "8fafafbf-3317-4bd4-e35a-db5ce14801f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhMFhLpymAD4",
        "outputId": "057bfa92-7e30-4b3e-8aae-f2ef446de266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does this tokenizer work?', 'These are two different sentences']\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = sent_tokenize('Does this tokenizer work? These are two different sentences')\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo4VkwblmAD4",
        "outputId": "92c6f5a8-3d7f-4fe1-ecac-e77ade675026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does', 'this', 'tokenizer', 'work', '?']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize('Does this tokenizer work?')\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3-K929WmAD5",
        "outputId": "edfad801-124a-4da2-ac3b-35d72b3b98d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.', 'Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.', 'These', 'watches', 'cost', '$', '1500', '!', 'The', 'ball', 'is', 'in', 'your', 'court', '.', 'Mr.', 'Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D', '.']\n"
          ]
        }
      ],
      "source": [
        "text = \"A bird in hand is worth two in the bush. \" +\\\n",
        "       \"Good things come to those who wait. \" +\\\n",
        "       \"These watches cost $1500! \" +\\\n",
        "       \"The ball is in your court. \" +\\\n",
        "       \"Mr. Smith Goes to Washington \" +\\\n",
        "       \"Doogie Howser M.D.\"\n",
        "\n",
        "word_tokens = word_tokenize(text, language='english')\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4RljcF8mAD6",
        "outputId": "701f6915-e088-4dd7-ab73-cbf769aa2565"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NmAI1eXmAD7",
        "outputId": "c13ae486-dd79-41d1-cac3-a2657928c852"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hand', 'is', 'worth', 'two', 'in']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens[3:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYUa6PrEmAD8"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize.punkt import PunktSentenceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWlbHWZUmAD8"
      },
      "outputs": [],
      "source": [
        "pst = PunktSentenceTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VCtMUMwmAD9",
        "outputId": "76ffc0f1-4c2a-4a79-bd48-a51b3992af52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A bird in hand is worth two in the bush.', 'Good things come to those who wait.', 'These watches cost $1500!', 'The ball is in your court.', 'Mr.', 'Smith Goes to Washington Doogie Howser M.D.']\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = pst.tokenize(text)\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyCZqmZ_mAD-",
        "outputId": "a9e937e5-aa27-493a-f48d-9014033aae89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 40), (41, 76), (77, 102), (103, 129), (130, 133), (134, 177)]\n"
          ]
        }
      ],
      "source": [
        "span_tokens = pst.span_tokenize(text)\n",
        "\n",
        "print(list(span_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZXAGha2mAD-",
        "outputId": "4f572fd8-f7ff-40d8-9fdd-ab86611f5652"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.'],\n",
              " ['Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.'],\n",
              " ['These', 'watches', 'cost', '$', '1500', '!'],\n",
              " ['The', 'ball', 'is', 'in', 'your', 'court', '.'],\n",
              " ['Mr.'],\n",
              " ['Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D', '.']]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences = pst.sentences_from_tokens(word_tokens)\n",
        "\n",
        "list(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXfLQS3BmAD_"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3Rk4G5gmAD_"
      },
      "outputs": [],
      "source": [
        "wt = WhitespaceTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwBBUU0PmAEA",
        "outputId": "fe5cb5d8-a548-47e3-a960-7027c651a0a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush.', 'Good', 'things', 'come', 'to', 'those', 'who', 'wait.', 'These', 'watches', 'cost', '$1500!', 'The', 'ball', 'is', 'in', 'your', 'court.', 'Mr.', 'Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D.']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = wt.tokenize(text)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBdub_O5mAEB"
      },
      "source": [
        "### Reading Local Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jH6FEOEmAEB",
        "outputId": "2a1424ff-b100-4595-d56b-39be0793bfdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L2O6WfpmAEC",
        "outputId": "75308e13-2c24-4ba4-fa8f-07c114264e0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie', 'Curie', 'was', 'a', 'Polish-born', 'physicist', 'and', 'chemist', 'and', 'one', 'of', 'the', 'most', 'famous', 'scientists', 'of', 'her', 'time', '.', 'Together', 'with', 'her', 'husband', 'Pierre', ',', 'she', 'was', 'awarded', 'the', 'Nobel', 'Prize', 'in', '1903', ',', 'and', 'she', 'went', 'on', 'to', 'win', 'another', 'in', '1911', '.', 'Marie', 'Sklodowska', 'was', 'born', 'in', 'Warsaw', 'on', '7', 'November', '1867', ',', 'the', 'daughter', 'of', 'a', 'teacher', '.', 'In', '1891', ',', 'she', 'went', 'to', 'Paris', 'to', 'study', 'physics', 'and', 'mathematics', 'at', 'the', 'Sorbonne', 'where', 'she', 'met', 'Pierre', 'Curie', ',', 'professor', 'of', 'the', 'School', 'of', 'Physics', '.', 'They', 'were', 'married', 'in', '1895', '.', 'The', 'Curies', 'worked', 'together', 'investigating', 'radioactivity', ',', 'building', 'on', 'the', 'work', 'of', 'the', 'German', 'physicist', 'Roentgen', 'and', 'the', 'French', 'physicist', 'Becquerel', '.', 'In', 'July', '1898', ',', 'the', 'Curies', 'announced', 'the', 'discovery', 'of', 'a', 'new', 'chemical', 'element', ',', 'polonium', '.', 'At', 'the', 'end', 'of', 'the', 'year', ',', 'they', 'announced', 'the', 'discovery', 'of', 'another', ',', 'radium', '.', 'The', 'Curies', ',', 'along', 'with', 'Becquerel', ',', 'were', 'awarded', 'the', 'Nobel', 'Prize', 'for', 'Physics', 'in', '1903', '.', 'Pierre', \"'s\", 'life', 'was', 'cut', 'short', 'in', '1906', 'when', 'he', 'was', 'knocked', 'down', 'and', 'killed', 'by', 'a', 'carriage', '.', 'Marie', 'took', 'over', 'his', 'teaching', 'post', ',', 'becoming', 'the', 'first', 'woman', 'to', 'teach', 'at', 'the', 'Sorbonne', ',', 'and', 'devoted', 'herself', 'to', 'continuing', 'the', 'work', 'that', 'they', 'had', 'begun', 'together', '.', 'She', 'received', 'a', 'second', 'Nobel', 'Prize', ',', 'for', 'Chemistry', ',', 'in', '1911', '.', 'The', 'Curie', \"'s\", 'research', 'was', 'crucial', 'in', 'the', 'development', 'of', 'x-rays', 'in', 'surgery', '.', 'During', 'World', 'War', 'One', 'Curie', 'helped', 'to', 'equip', 'ambulances', 'with', 'x-ray', 'equipment', ',', 'which', 'she', 'herself', 'drove', 'to', 'the', 'front', 'lines', '.', 'The', 'International', 'Red', 'Cross', 'made', 'her', 'head', 'of', 'its', 'radiological', 'service', 'and', 'she', 'held', 'training', 'courses', 'for', 'medical', 'orderlies', 'and', 'doctors', 'in', 'the', 'new', 'techniques', '.', 'Despite', 'her', 'success', ',', 'Marie', 'continued', 'to', 'face', 'great', 'opposition', 'from', 'male', 'scientists', 'in', 'France', ',', 'and', 'she', 'never', 'received', 'significant', 'financial', 'benefits', 'from', 'her', 'work', '.', 'By', 'the', 'late', '1920s', 'her', 'health', 'was', 'beginning', 'to', 'deteriorate', '.', 'She', 'died', 'on', '4', 'July', '1934', 'from', 'leukaemia', ',', 'caused', 'by', 'exposure', 'to', 'high-energy', 'radiation', 'from', 'her', 'research', '.', 'The', 'Curies', \"'\", 'eldest', 'daughter', 'Irene', 'was', 'herself', 'a', 'scientist', 'and', 'winner', 'of', 'the', 'Nobel', 'Prize', 'for', 'Chemistry', '.']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize(file_contents)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6PU77nzmAEC"
      },
      "source": [
        "### Frequency distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCRpVOqGmAEC"
      },
      "outputs": [],
      "source": [
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmJ0lyiEmAED",
        "outputId": "09793135-1fb7-4b17-fca1-f5dcefceac7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FreqDist with 182 samples and 367 outcomes>\n"
          ]
        }
      ],
      "source": [
        "freq_dist = FreqDist(word_tokens)\n",
        "\n",
        "print(freq_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwKvwqFzmAEE",
        "outputId": "af547d4a-73b5-460c-e9f8-036958edf1c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 22),\n",
              " (',', 20),\n",
              " ('.', 19),\n",
              " ('of', 12),\n",
              " ('and', 11),\n",
              " ('in', 11),\n",
              " ('to', 10),\n",
              " ('was', 8),\n",
              " ('her', 7),\n",
              " ('she', 7),\n",
              " ('a', 6),\n",
              " ('The', 5),\n",
              " ('Marie', 4),\n",
              " ('Curie', 4),\n",
              " ('Nobel', 4),\n",
              " ('Prize', 4),\n",
              " ('on', 4),\n",
              " ('Curies', 4),\n",
              " ('for', 4),\n",
              " ('from', 4)]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thk9Dtw4mAEF"
      },
      "source": [
        "Return the frequency of a given sample. The frequency of a sample is defined as the count of that sample divided by the total number of sample outcomes that have been recorded by this FreqDist. The count of a sample is defined as the number of times that sample outcome was recorded by this FreqDist. Frequencies are always real numbers in the range [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a39PQNoEmAEF",
        "outputId": "d63643ad-c469-4a83-8253-115ea368d5c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.05994550408719346"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.freq('the')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFkrMhFmmAEJ",
        "outputId": "11516abd-5ee5-499d-83b8-8a04aff34299"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0027247956403269754"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.freq('exposure')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhiJsVO4mAEK",
        "outputId": "b01cfd1c-5ed5-4e26-e077-f2bca394ca8b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "freq_dist.plot(20, cumulative=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoYQzBunmAEK",
        "outputId": "b61c7a0a-b144-4b2b-9424-5d5d9ef4527b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['marie', 'curie', 'was', 'a', 'polish-born', 'physicist', 'and', 'chemist', 'and', 'one', 'of', 'the', 'most', 'famous', 'scientists', 'of', 'her', 'time.', 'together', 'with', 'her', 'husband', 'pierre,', 'she', 'was', 'awarded', 'the', 'nobel', 'prize', 'in', '1903,', 'and', 'she', 'went', 'on', 'to', 'win', 'another', 'in', '1911.', 'marie', 'sklodowska', 'was', 'born', 'in', 'warsaw', 'on', '7', 'november', '1867,', 'the', 'daughter', 'of', 'a', 'teacher.', 'in', '1891,', 'she', 'went', 'to', 'paris', 'to', 'study', 'physics', 'and', 'mathematics', 'at', 'the', 'sorbonne', 'where', 'she', 'met', 'pierre', 'curie,', 'professor', 'of', 'the', 'school', 'of', 'physics.', 'they', 'were', 'married', 'in', '1895.', 'the', 'curies', 'worked', 'together', 'investigating', 'radioactivity,', 'building', 'on', 'the', 'work', 'of', 'the', 'german', 'physicist', 'roentgen', 'and', 'the', 'french', 'physicist', 'becquerel.', 'in', 'july', '1898,', 'the', 'curies', 'announced', 'the', 'discovery', 'of', 'a', 'new', 'chemical', 'element,', 'polonium.', 'at', 'the', 'end', 'of', 'the', 'year,', 'they', 'announced', 'the', 'discovery', 'of', 'another,', 'radium.', 'the', 'curies,', 'along', 'with', 'becquerel,', 'were', 'awarded', 'the', 'nobel', 'prize', 'for', 'physics', 'in', '1903.', \"pierre's\", 'life', 'was', 'cut', 'short', 'in', '1906', 'when', 'he', 'was', 'knocked', 'down', 'and', 'killed', 'by', 'a', 'carriage.', 'marie', 'took', 'over', 'his', 'teaching', 'post,', 'becoming', 'the', 'first', 'woman', 'to', 'teach', 'at', 'the', 'sorbonne,', 'and', 'devoted', 'herself', 'to', 'continuing', 'the', 'work', 'that', 'they', 'had', 'begun', 'together.', 'she', 'received', 'a', 'second', 'nobel', 'prize,', 'for', 'chemistry,', 'in', '1911.', 'the', \"curie's\", 'research', 'was', 'crucial', 'in', 'the', 'development', 'of', 'x-rays', 'in', 'surgery.', 'during', 'world', 'war', 'one', 'curie', 'helped', 'to', 'equip', 'ambulances', 'with', 'x-ray', 'equipment,', 'which', 'she', 'herself', 'drove', 'to', 'the', 'front', 'lines.', 'the', 'international', 'red', 'cross', 'made', 'her', 'head', 'of', 'its', 'radiological', 'service', 'and', 'she', 'held', 'training', 'courses', 'for', 'medical', 'orderlies', 'and', 'doctors', 'in', 'the', 'new', 'techniques.', 'despite', 'her', 'success,', 'marie', 'continued', 'to', 'face', 'great', 'opposition', 'from', 'male', 'scientists', 'in', 'france,', 'and', 'she', 'never', 'received', 'significant', 'financial', 'benefits', 'from', 'her', 'work.', 'by', 'the', 'late', '1920s', 'her', 'health', 'was', 'beginning', 'to', 'deteriorate.', 'she', 'died', 'on', '4', 'july', '1934', 'from', 'leukaemia,', 'caused', 'by', 'exposure', 'to', 'high-energy', 'radiation', 'from', 'her', 'research.', 'the', \"curies'\", 'eldest', 'daughter', 'irene', 'was', 'herself', 'a', 'scientist', 'and', 'winner', 'of', 'the', 'nobel', 'prize', 'for', 'chemistry.']\n"
          ]
        }
      ],
      "source": [
        "file_contents = file_contents.lower()\n",
        "\n",
        "word_tokens = wt.tokenize(file_contents)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRNAhA5MmAEL",
        "outputId": "931fb30b-ced9-40a6-8ead-ae8c2236a1c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqCD8AqBmAEL",
        "outputId": "23a18e26-faae-43c7-d98c-19805f023a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'an', 'should', \"needn't\", 'o', 'ours', 'yourselves', 'am', 't', 'd', 'our', 'yourself', 'himself', 'wasn', 'above', 'you', 'me', 'did', \"hasn't\", 'shan', 'about', 'wouldn', 'shouldn', 'because', 'myself', 'where', 'hasn', 'hadn', 'own', 'hers', 'at', \"mightn't\", 'now', 'with', 'how', 'some', 'or', 'had', 'having', 'aren', 'm', \"shouldn't\", 'was', 'don', 'same', \"didn't\", 'against', 'why', 'y', 'any', 'do', 'being', 'll', 'up', 'doesn', 'which', 'again', 'as', 'in', 'mightn', \"you'll\", \"that'll\", 'can', 'for', 'haven', 's', 'him', 'ain', 'from', 'then', 'once', 'that', \"you're\", 'such', 'does', '.', 'these', 'be', 'only', 'just', 'will', 'into', 'she', \"aren't\", 'and', 'they', 'isn', 'been', 'until', 'theirs', \"don't\", \"couldn't\", 'we', 'ourselves', 'under', 'is', 'by', 'what', \"hadn't\", \"weren't\", 'too', 'ma', 'needn', 'those', 'are', 'more', 'there', 'to', 'between', 'herself', 'has', 'a', 'the', 'yours', 'who', 'than', 'not', 'of', 'nor', \"isn't\", 'when', 'whom', \"it's\", 'i', 'my', 'were', 'mustn', 'doing', 'down', \"won't\", 'all', 'have', \"you'd\", 'his', 'other', 'but', 'if', 'very', 'off', 'before', 'both', 'each', 'didn', 'further', 'no', 'most', \"doesn't\", 'couldn', 'them', 'through', 'weren', 'won', \"wouldn't\", 'The', 're', \"wasn't\", 'few', 'here', 'so', ',', 'its', 'their', 'below', \"shan't\", 'out', \"mustn't\", 'it', 'over', 'itself', 'while', \"you've\", 'themselves', 'after', 'your', 'her', \"should've\", \"haven't\", 'this', 'on', 've', \"she's\", 'he', 'during'}\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(['.', ',', 'The'])\n",
        "\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqIsTnpOmAEM",
        "outputId": "0267453b-5260-45e7-a801-d90e4d82c78a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['marie', 'curie', 'polish-born', 'physicist', 'chemist', 'one', 'famous', 'scientists', 'time.', 'together', 'husband', 'pierre,', 'awarded', 'nobel', 'prize', '1903,', 'went', 'win', 'another', '1911.', 'marie', 'sklodowska', 'born', 'warsaw', '7', 'november', '1867,', 'daughter', 'teacher.', '1891,', 'went', 'paris', 'study', 'physics', 'mathematics', 'sorbonne', 'met', 'pierre', 'curie,', 'professor', 'school', 'physics.', 'married', '1895.', 'curies', 'worked', 'together', 'investigating', 'radioactivity,', 'building', 'work', 'german', 'physicist', 'roentgen', 'french', 'physicist', 'becquerel.', 'july', '1898,', 'curies', 'announced', 'discovery', 'new', 'chemical', 'element,', 'polonium.', 'end', 'year,', 'announced', 'discovery', 'another,', 'radium.', 'curies,', 'along', 'becquerel,', 'awarded', 'nobel', 'prize', 'physics', '1903.', \"pierre's\", 'life', 'cut', 'short', '1906', 'knocked', 'killed', 'carriage.', 'marie', 'took', 'teaching', 'post,', 'becoming', 'first', 'woman', 'teach', 'sorbonne,', 'devoted', 'continuing', 'work', 'begun', 'together.', 'received', 'second', 'nobel', 'prize,', 'chemistry,', '1911.', \"curie's\", 'research', 'crucial', 'development', 'x-rays', 'surgery.', 'world', 'war', 'one', 'curie', 'helped', 'equip', 'ambulances', 'x-ray', 'equipment,', 'drove', 'front', 'lines.', 'international', 'red', 'cross', 'made', 'head', 'radiological', 'service', 'held', 'training', 'courses', 'medical', 'orderlies', 'doctors', 'new', 'techniques.', 'despite', 'success,', 'marie', 'continued', 'face', 'great', 'opposition', 'male', 'scientists', 'france,', 'never', 'received', 'significant', 'financial', 'benefits', 'work.', 'late', '1920s', 'health', 'beginning', 'deteriorate.', 'died', '4', 'july', '1934', 'leukaemia,', 'caused', 'exposure', 'high-energy', 'radiation', 'research.', \"curies'\", 'eldest', 'daughter', 'irene', 'scientist', 'winner', 'nobel', 'prize', 'chemistry.']\n"
          ]
        }
      ],
      "source": [
        "filtered_words = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_words.append(w)\n",
        "\n",
        "print(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFDh8VqImAEM"
      },
      "outputs": [],
      "source": [
        "freq_dist = FreqDist(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIWAExXTmAEN",
        "outputId": "d87c53af-a55f-4aaf-9f7c-2620e80cba28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('marie', 4),\n",
              " ('nobel', 4),\n",
              " ('physicist', 3),\n",
              " ('prize', 3),\n",
              " ('curie', 2),\n",
              " ('one', 2),\n",
              " ('scientists', 2),\n",
              " ('together', 2),\n",
              " ('awarded', 2),\n",
              " ('went', 2),\n",
              " ('1911.', 2),\n",
              " ('daughter', 2),\n",
              " ('physics', 2),\n",
              " ('curies', 2),\n",
              " ('work', 2),\n",
              " ('july', 2),\n",
              " ('announced', 2),\n",
              " ('discovery', 2),\n",
              " ('new', 2),\n",
              " ('received', 2)]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73CeedSSmAEN",
        "outputId": "f7b58cdd-9d89-4d26-9acf-cb1a4b8f8ad5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "freq_dist.plot(20, cumulative=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlMIGe2FmAEO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIGchwUdmAEO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0tjjJezmAEO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF0OjGqdmAEP"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 02-VectorizeTextAsABagOfWords_CountVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8r_5RdSmAEQ"
      },
      "source": [
        "## Vectorize text as a bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFbPTntdmAEQ",
        "outputId": "13a2d675-df6c-4312-d4f6-8c084026884a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.20.3\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1B62oNkmAEQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp-TTa37mAER"
      },
      "outputs": [],
      "source": [
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]\n",
        "\n",
        "count_vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc7q7iLWmAER",
        "outputId": "f5b8e327-63e6-4ba0-c10b-c682f10033e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.fit(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ_NR8L6mAES",
        "outputId": "8af21580-221b-4768-e290-a1c76c027e50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1500',\n",
              " 'are',\n",
              " 'ball',\n",
              " 'bird',\n",
              " 'bush',\n",
              " 'come',\n",
              " 'cost',\n",
              " 'court',\n",
              " 'doogie',\n",
              " 'fish',\n",
              " 'goes',\n",
              " 'good',\n",
              " 'hand',\n",
              " 'howser',\n",
              " 'in',\n",
              " 'is',\n",
              " 'mr',\n",
              " 'other',\n",
              " 'sea',\n",
              " 'smith',\n",
              " 'the',\n",
              " 'there',\n",
              " 'these',\n",
              " 'things',\n",
              " 'those',\n",
              " 'to',\n",
              " 'two',\n",
              " 'wait',\n",
              " 'washington',\n",
              " 'watches',\n",
              " 'who',\n",
              " 'worth',\n",
              " 'your']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_C_qjoQmAES"
      },
      "outputs": [],
      "source": [
        "count_vectorizer.get_stop_words()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81TnTedimAET",
        "outputId": "d082099b-5dd1-495d-b85e-e341689d2f46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 3,\n",
              " 'in': 14,\n",
              " 'hand': 12,\n",
              " 'is': 15,\n",
              " 'worth': 31,\n",
              " 'two': 26,\n",
              " 'the': 20,\n",
              " 'bush': 4,\n",
              " 'good': 11,\n",
              " 'things': 23,\n",
              " 'come': 5,\n",
              " 'to': 25,\n",
              " 'those': 24,\n",
              " 'who': 30,\n",
              " 'wait': 27,\n",
              " 'these': 22,\n",
              " 'watches': 29,\n",
              " 'cost': 6,\n",
              " '1500': 0,\n",
              " 'there': 21,\n",
              " 'are': 1,\n",
              " 'other': 17,\n",
              " 'fish': 9,\n",
              " 'sea': 18,\n",
              " 'ball': 2,\n",
              " 'your': 32,\n",
              " 'court': 7,\n",
              " 'mr': 16,\n",
              " 'smith': 19,\n",
              " 'goes': 10,\n",
              " 'washington': 28,\n",
              " 'doogie': 8,\n",
              " 'howser': 13}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie57qfKhmAET",
        "outputId": "f75d1e05-8855-4c6b-a954-14df1b7def54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_.get('things')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFd6QW7YmAEU",
        "outputId": "ab9b0f65-88a1-4f4e-e6d5-10f13d32fdce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A bird in hand is worth two in the bush.',\n",
              " 'Good things come to those who wait.',\n",
              " 'These watches cost $1500! ',\n",
              " 'There are other fish in the sea.',\n",
              " 'The ball is in your court.',\n",
              " 'Mr. Smith Goes to Washington ',\n",
              " 'Doogie Howser M.D.']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iqkacpf1mAEU"
      },
      "outputs": [],
      "source": [
        "transformed_vector = count_vectorizer.transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km6vPt_smAEV",
        "outputId": "22e73474-f101-4fcc-cf23-69dc6f420125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 33)\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq7nWVGGmAEW",
        "outputId": "65c07e08-de51-4ecb-a15e-773a737d57cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 1 0 0 0 0 0 0 0 1 0 2 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS7gGj08mAEX",
        "outputId": "7f230f09-3ea5-410d-c6c9-e2d9b813b7c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_text = [\"Every cloud has a silver lining.\"]\n",
        "\n",
        "count_vectorizer.transform(test_text).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--3vQZrsmAEX",
        "outputId": "4c063d74-64a1-4752-add2-3993b1ea1910"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.fit(train_text + test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aRXHB9LmAEY",
        "outputId": "682cd1bc-ef40-4a26-deb1-d109eca1fa24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bird': 3, 'in': 17, 'hand': 14, 'is': 18, 'worth': 36, 'two': 31, 'the': 25, 'bush': 4, 'good': 13, 'things': 28, 'come': 6, 'to': 30, 'those': 29, 'who': 35, 'wait': 32, 'these': 27, 'watches': 34, 'cost': 7, '1500': 0, 'there': 26, 'are': 1, 'other': 21, 'fish': 11, 'sea': 22, 'ball': 2, 'your': 37, 'court': 8, 'mr': 20, 'smith': 24, 'goes': 12, 'washington': 33, 'doogie': 9, 'howser': 16, 'every': 10, 'cloud': 5, 'has': 15, 'silver': 23, 'lining': 19}\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7cdx9QCmAEZ",
        "outputId": "37c4ddb2-173f-4c0d-f14d-85021f7c5e42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.transform(test_text).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIgTDQ-RmAEa",
        "outputId": "12a2af40-483c-4a5e-af2d-2c9c8499aeca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<3x38 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 9 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = [\"That bird is sitting in the bush and this bird is in hand.\",\n",
        "        \"Wait and then walk\",\n",
        "        \"Watches are cool \"]\n",
        "\n",
        "transformed_vector = count_vectorizer.transform(text)\n",
        "\n",
        "transformed_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R_RZH51mAEb",
        "outputId": "1ba72ff4-6830-4de1-9b01-0358b3aa1792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3)\t2\n",
            "  (0, 4)\t1\n",
            "  (0, 14)\t1\n",
            "  (0, 17)\t2\n",
            "  (0, 18)\t2\n",
            "  (0, 25)\t1\n",
            "  (1, 32)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 34)\t1\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U1ZSOdnmAEb",
        "outputId": "e6b2d08f-8281-4772-9a6f-155af7062e1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 38)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiYoYqXkmAEc",
        "outputId": "358513ff-0aa4-405c-bd5f-62eeb225c5c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 2 1 0 0 0 0 0 0 0 0 0 1 0 0 2 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            "  0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nocnGurmAEd"
      },
      "source": [
        "### CountVectorizer on text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsK7B6uQmAEd",
        "outputId": "e8083ea9-a4ed-4952-a5ca-fc2ba0931c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhCXmAgNmAEd",
        "outputId": "132ad595-e7d4-4a47-9bba-b503e0306794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.', 'Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.', 'Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.', 'In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.', 'They were married in 1895.', 'The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.', 'In July 1898, the Curies announced the discovery of a new chemical element, polonium.', 'At the end of the year, they announced the discovery of another, radium.', 'The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.', \"Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\", 'Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.', 'She received a second Nobel Prize, for Chemistry, in 1911.', \"The Curie's research was crucial in the development of x-rays in surgery.\", 'During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.', 'The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.', 'Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.', 'By the late 1920s her health was beginning to deteriorate.', 'She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.', \"The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\"]\n"
          ]
        }
      ],
      "source": [
        "sentences = file_contents.split('\\n')\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOPuWeYHmAEe",
        "outputId": "d6799184-741a-4e41-8e62-b018186d3096"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19, 167)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector = count_vectorizer.fit_transform(sentences)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr27gbuXmAEe",
        "outputId": "ea24bea4-3bcb-4870-f08f-cb66ab9abb56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 146)\t1\n",
            "  (0, 72)\t1\n",
            "  (0, 128)\t1\n",
            "  (0, 56)\t1\n",
            "  (0, 96)\t1\n",
            "  (0, 144)\t1\n",
            "  (0, 101)\t2\n",
            "  (0, 103)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 11)\t2\n",
            "  (0, 108)\t1\n",
            "  (0, 21)\t1\n",
            "  (0, 111)\t1\n",
            "  (0, 153)\t1\n",
            "  (0, 34)\t1\n",
            "  (0, 91)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 13)\t1\n",
            "  (1, 159)\t1\n",
            "  (1, 147)\t1\n",
            "  (1, 102)\t1\n",
            "  (1, 154)\t1\n",
            "  (1, 4)\t1\n",
            "  (1, 77)\t2\n",
            "  (1, 114)\t1\n",
            "  :\t:\n",
            "  (17, 8)\t1\n",
            "  (17, 42)\t1\n",
            "  (17, 62)\t2\n",
            "  (17, 124)\t1\n",
            "  (17, 23)\t1\n",
            "  (17, 82)\t1\n",
            "  (17, 147)\t1\n",
            "  (17, 102)\t1\n",
            "  (17, 131)\t1\n",
            "  (17, 72)\t1\n",
            "  (18, 160)\t1\n",
            "  (18, 127)\t1\n",
            "  (18, 80)\t1\n",
            "  (18, 48)\t1\n",
            "  (18, 28)\t1\n",
            "  (18, 73)\t1\n",
            "  (18, 59)\t1\n",
            "  (18, 35)\t1\n",
            "  (18, 37)\t1\n",
            "  (18, 114)\t1\n",
            "  (18, 99)\t1\n",
            "  (18, 144)\t2\n",
            "  (18, 101)\t1\n",
            "  (18, 11)\t1\n",
            "  (18, 153)\t1\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG9ceODJmAEj",
        "outputId": "af36b73a-c842-4b44-eda3-6318fe52175a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'marie': 91, 'curie': 34, 'was': 153, 'polish': 111, 'born': 21, 'physicist': 108, 'and': 11, 'chemist': 27, 'one': 103, 'of': 101, 'the': 144, 'most': 96, 'famous': 56, 'scientists': 128, 'her': 72, 'time': 146, 'together': 148, 'with': 161, 'husband': 76, 'pierre': 110, 'she': 131, 'awarded': 15, 'nobel': 99, 'prize': 114, 'in': 77, '1903': 4, 'went': 154, 'on': 102, 'to': 147, 'win': 159, 'another': 13, '1911': 6, 'sklodowska': 134, 'warsaw': 152, 'november': 100, '1867': 0, 'daughter': 37, 'teacher': 140, '1891': 1, 'paris': 107, 'study': 136, 'physics': 109, 'mathematics': 93, 'at': 14, 'sorbonne': 135, 'where': 157, 'met': 95, 'professor': 115, 'school': 126, 'they': 145, 'were': 155, 'married': 92, '1895': 2, 'curies': 35, 'worked': 164, 'investigating': 79, 'radioactivity': 117, 'building': 22, 'work': 163, 'german': 64, 'roentgen': 125, 'french': 61, 'becquerel': 17, 'july': 82, '1898': 3, 'announced': 12, 'discovery': 43, 'new': 98, 'chemical': 26, 'element': 49, 'polonium': 112, 'end': 50, 'year': 166, 'radium': 119, 'along': 9, 'for': 59, 'life': 87, 'cut': 36, 'short': 132, '1906': 5, 'when': 156, 'he': 67, 'knocked': 84, 'down': 45, 'killed': 83, 'by': 23, 'carriage': 24, 'took': 149, 'over': 106, 'his': 75, 'teaching': 141, 'post': 113, 'becoming': 16, 'first': 58, 'woman': 162, 'teach': 139, 'devoted': 41, 'herself': 73, 'continuing': 30, 'that': 143, 'had': 66, 'begun': 19, 'received': 122, 'second': 129, 'chemistry': 28, 'research': 124, 'crucial': 33, 'development': 40, 'rays': 121, 'surgery': 138, 'during': 47, 'world': 165, 'war': 151, 'helped': 71, 'equip': 52, 'ambulances': 10, 'ray': 120, 'equipment': 53, 'which': 158, 'drove': 46, 'front': 63, 'lines': 88, 'international': 78, 'red': 123, 'cross': 32, 'made': 89, 'head': 68, 'its': 81, 'radiological': 118, 'service': 130, 'held': 70, 'training': 150, 'courses': 31, 'medical': 94, 'orderlies': 105, 'doctors': 44, 'techniques': 142, 'despite': 38, 'success': 137, 'continued': 29, 'face': 55, 'great': 65, 'opposition': 104, 'from': 62, 'male': 90, 'france': 60, 'never': 97, 'significant': 133, 'financial': 57, 'benefits': 20, 'late': 85, '1920s': 7, 'health': 69, 'beginning': 18, 'deteriorate': 39, 'died': 42, '1934': 8, 'leukaemia': 86, 'caused': 25, 'exposure': 54, 'high': 74, 'energy': 51, 'radiation': 116, 'eldest': 48, 'irene': 80, 'scientist': 127, 'winner': 160}\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JSl61-WmAEk"
      },
      "source": [
        "We lost:\n",
        "\n",
        "* The meaning of text corpus\n",
        "* The ordering of the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8h9YprBmAEk",
        "outputId": "15110eb4-4c37-4711-8c21-ae864cc360c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['time', 'her', 'scientists', 'famous', 'most', 'the', 'of', 'one',\n",
              "        'chemist', 'and', 'physicist', 'born', 'polish', 'was', 'curie',\n",
              "        'marie'], dtype='<U13'),\n",
              " array(['1911', 'another', 'win', 'to', 'on', 'went', '1903', 'in',\n",
              "        'prize', 'nobel', 'awarded', 'she', 'pierre', 'husband', 'with',\n",
              "        'together', 'her', 'the', 'and', 'was'], dtype='<U13'),\n",
              " array(['teacher', 'daughter', '1867', 'november', 'warsaw', 'sklodowska',\n",
              "        'on', 'in', 'the', 'of', 'born', 'was', 'marie'], dtype='<U13'),\n",
              " array(['school', 'professor', 'met', 'where', 'sorbonne', 'at',\n",
              "        'mathematics', 'physics', 'study', 'paris', '1891', 'to', 'went',\n",
              "        'in', 'she', 'pierre', 'the', 'of', 'and', 'curie'], dtype='<U13'),\n",
              " array(['1895', 'married', 'were', 'they', 'in'], dtype='<U13'),\n",
              " array(['becquerel', 'french', 'roentgen', 'german', 'work', 'building',\n",
              "        'radioactivity', 'investigating', 'worked', 'curies', 'on',\n",
              "        'together', 'the', 'of', 'and', 'physicist'], dtype='<U13'),\n",
              " array(['polonium', 'element', 'chemical', 'new', 'discovery', 'announced',\n",
              "        '1898', 'july', 'curies', 'in', 'the', 'of'], dtype='<U13'),\n",
              " array(['radium', 'year', 'end', 'discovery', 'announced', 'they', 'at',\n",
              "        'another', 'the', 'of'], dtype='<U13'),\n",
              " array(['for', 'along', 'becquerel', 'curies', 'were', 'physics', '1903',\n",
              "        'in', 'prize', 'nobel', 'awarded', 'with', 'the'], dtype='<U13'),\n",
              " array(['carriage', 'by', 'killed', 'down', 'knocked', 'he', 'when',\n",
              "        '1906', 'short', 'cut', 'life', 'in', 'pierre', 'and', 'was'],\n",
              "       dtype='<U13'),\n",
              " array(['begun', 'had', 'that', 'continuing', 'herself', 'devoted',\n",
              "        'teach', 'woman', 'first', 'becoming', 'post', 'teaching', 'his',\n",
              "        'over', 'took', 'work', 'they', 'sorbonne', 'at', 'to', 'together',\n",
              "        'the', 'and', 'marie'], dtype='<U13'),\n",
              " array(['chemistry', 'second', 'received', 'for', '1911', 'in', 'prize',\n",
              "        'nobel', 'she'], dtype='<U13'),\n",
              " array(['surgery', 'rays', 'development', 'crucial', 'research', 'in',\n",
              "        'the', 'of', 'was', 'curie'], dtype='<U13'),\n",
              " array(['lines', 'front', 'drove', 'which', 'equipment', 'ray',\n",
              "        'ambulances', 'equip', 'helped', 'war', 'world', 'during',\n",
              "        'herself', 'to', 'she', 'with', 'the', 'one', 'curie'],\n",
              "       dtype='<U13'),\n",
              " array(['techniques', 'doctors', 'orderlies', 'medical', 'courses',\n",
              "        'training', 'held', 'service', 'radiological', 'its', 'head',\n",
              "        'made', 'cross', 'red', 'international', 'for', 'new', 'in', 'she',\n",
              "        'her', 'the', 'of', 'and'], dtype='<U13'),\n",
              " array(['benefits', 'financial', 'significant', 'never', 'france', 'male',\n",
              "        'from', 'opposition', 'great', 'face', 'continued', 'success',\n",
              "        'despite', 'received', 'work', 'to', 'in', 'she', 'her',\n",
              "        'scientists', 'and', 'marie'], dtype='<U13'),\n",
              " array(['deteriorate', 'beginning', 'health', '1920s', 'late', 'by', 'to',\n",
              "        'her', 'the', 'was'], dtype='<U13'),\n",
              " array(['radiation', 'energy', 'high', 'exposure', 'caused', 'leukaemia',\n",
              "        '1934', 'died', 'from', 'research', 'by', 'july', 'to', 'on',\n",
              "        'she', 'her'], dtype='<U13'),\n",
              " array(['winner', 'scientist', 'irene', 'eldest', 'chemistry', 'herself',\n",
              "        'for', 'curies', 'daughter', 'prize', 'nobel', 'the', 'of', 'and',\n",
              "        'was'], dtype='<U13')]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.inverse_transform(transformed_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJvWc13zmAEl"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 03-VectorizeTextAsABagOfNGrams_CountVectorizer_Nltk</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1h5bbRLmAEl"
      },
      "source": [
        "## Vectorize text as a bag-of-n-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5EqtWsymAEl"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDNa7uxumAEm"
      },
      "outputs": [],
      "source": [
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yypRnxGYmAEm"
      },
      "outputs": [],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4UruuV3mAEn"
      },
      "outputs": [],
      "source": [
        "transformed_vector = n_gram_vectorizer.fit_transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBZp_Q4xmAEn",
        "outputId": "19817cb6-a18e-4b17-9671-44a6d3a1dca2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird in': 2,\n",
              " 'in hand': 10,\n",
              " 'hand is': 9,\n",
              " 'is worth': 14,\n",
              " 'worth two': 30,\n",
              " 'two in': 27,\n",
              " 'in the': 11,\n",
              " 'the bush': 19,\n",
              " 'good things': 8,\n",
              " 'things come': 23,\n",
              " 'come to': 3,\n",
              " 'to those': 25,\n",
              " 'those who': 24,\n",
              " 'who wait': 29,\n",
              " 'these watches': 22,\n",
              " 'watches cost': 28,\n",
              " 'cost 1500': 4,\n",
              " 'there are': 21,\n",
              " 'are other': 0,\n",
              " 'other fish': 16,\n",
              " 'fish in': 6,\n",
              " 'the sea': 20,\n",
              " 'the ball': 18,\n",
              " 'ball is': 1,\n",
              " 'is in': 13,\n",
              " 'in your': 12,\n",
              " 'your court': 31,\n",
              " 'mr smith': 15,\n",
              " 'smith goes': 17,\n",
              " 'goes to': 7,\n",
              " 'to washington': 26,\n",
              " 'doogie howser': 5}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5zYq_19mAEo",
        "outputId": "9d5c0691-ed91-4bb2-883d-92adc2637fd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhrFm6symAEo",
        "outputId": "9b668971-0a1a-499d-f617-c402f1862608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 5,\n",
              " 'in': 24,\n",
              " 'hand': 21,\n",
              " 'is': 28,\n",
              " 'worth': 61,\n",
              " 'two': 53,\n",
              " 'the': 38,\n",
              " 'bush': 7,\n",
              " 'bird in': 6,\n",
              " 'in hand': 25,\n",
              " 'hand is': 22,\n",
              " 'is worth': 30,\n",
              " 'worth two': 62,\n",
              " 'two in': 54,\n",
              " 'in the': 26,\n",
              " 'the bush': 40,\n",
              " 'good': 19,\n",
              " 'things': 46,\n",
              " 'come': 8,\n",
              " 'to': 50,\n",
              " 'those': 48,\n",
              " 'who': 59,\n",
              " 'wait': 55,\n",
              " 'good things': 20,\n",
              " 'things come': 47,\n",
              " 'come to': 9,\n",
              " 'to those': 51,\n",
              " 'those who': 49,\n",
              " 'who wait': 60,\n",
              " 'these': 44,\n",
              " 'watches': 57,\n",
              " 'cost': 10,\n",
              " '1500': 0,\n",
              " 'these watches': 45,\n",
              " 'watches cost': 58,\n",
              " 'cost 1500': 11,\n",
              " 'there': 42,\n",
              " 'are': 1,\n",
              " 'other': 33,\n",
              " 'fish': 15,\n",
              " 'sea': 35,\n",
              " 'there are': 43,\n",
              " 'are other': 2,\n",
              " 'other fish': 34,\n",
              " 'fish in': 16,\n",
              " 'the sea': 41,\n",
              " 'ball': 3,\n",
              " 'your': 63,\n",
              " 'court': 12,\n",
              " 'the ball': 39,\n",
              " 'ball is': 4,\n",
              " 'is in': 29,\n",
              " 'in your': 27,\n",
              " 'your court': 64,\n",
              " 'mr': 31,\n",
              " 'smith': 36,\n",
              " 'goes': 17,\n",
              " 'washington': 56,\n",
              " 'mr smith': 32,\n",
              " 'smith goes': 37,\n",
              " 'goes to': 18,\n",
              " 'to washington': 52,\n",
              " 'doogie': 13,\n",
              " 'howser': 23,\n",
              " 'doogie howser': 14}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "transformed_vector = n_gram_vectorizer.fit_transform(train_text)\n",
        "\n",
        "n_gram_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmPRTY1emAEp",
        "outputId": "c7e9e260-4d26-4489-f1f8-21df30857200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        1, 0, 2, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VHAhkpOmAEp"
      },
      "source": [
        "#### Bigram and Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIfRGWyBmAEp",
        "outputId": "830334cd-9d45-46e7-e384-40bc83b72734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJULy3KjmAEq",
        "outputId": "ba7379f5-29b9-4817-cf43-29ac668358df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.', 'Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.', 'Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.', 'In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.', 'They were married in 1895.', 'The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.', 'In July 1898, the Curies announced the discovery of a new chemical element, polonium.', 'At the end of the year, they announced the discovery of another, radium.', 'The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.', \"Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\", 'Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.', 'She received a second Nobel Prize, for Chemistry, in 1911.', \"The Curie's research was crucial in the development of x-rays in surgery.\", 'During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.', 'The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.', 'Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.', 'By the late 1920s her health was beginning to deteriorate.', 'She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.', \"The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\"]\n"
          ]
        }
      ],
      "source": [
        "sentences = file_contents.split('\\n')\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFIBTbJImAEq"
      },
      "outputs": [],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uv2NYMzmAEr"
      },
      "outputs": [],
      "source": [
        "transformed_vector = n_gram_vectorizer.fit_transform(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM_SxRnFmAEr",
        "outputId": "665f3c66-59a8-42f0-b36c-f3d805ee2cca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'marie curie': 251,\n",
              " 'curie was': 92,\n",
              " 'was polish': 504,\n",
              " 'polish born': 330,\n",
              " 'born physicist': 59,\n",
              " 'physicist and': 315,\n",
              " 'and chemist': 18,\n",
              " 'chemist and': 72,\n",
              " 'and one': 28,\n",
              " 'one of': 305,\n",
              " 'of the': 289,\n",
              " 'the most': 437,\n",
              " 'most famous': 265,\n",
              " 'famous scientists': 142,\n",
              " 'scientists of': 367,\n",
              " 'of her': 279,\n",
              " 'her time': 191,\n",
              " 'marie curie was': 252,\n",
              " 'curie was polish': 93,\n",
              " 'was polish born': 505,\n",
              " 'polish born physicist': 331,\n",
              " 'born physicist and': 60,\n",
              " 'physicist and chemist': 316,\n",
              " 'and chemist and': 19,\n",
              " 'chemist and one': 73,\n",
              " 'and one of': 29,\n",
              " 'one of the': 306,\n",
              " 'of the most': 291,\n",
              " 'the most famous': 438,\n",
              " 'most famous scientists': 266,\n",
              " 'famous scientists of': 143,\n",
              " 'scientists of her': 368,\n",
              " 'of her time': 280,\n",
              " 'together with': 480,\n",
              " 'with her': 526,\n",
              " 'her husband': 186,\n",
              " 'husband pierre': 203,\n",
              " 'pierre she': 328,\n",
              " 'she was': 385,\n",
              " 'was awarded': 490,\n",
              " 'awarded the': 46,\n",
              " 'the nobel': 441,\n",
              " 'nobel prize': 272,\n",
              " 'prize in': 337,\n",
              " 'in 1903': 208,\n",
              " '1903 and': 6,\n",
              " 'and she': 30,\n",
              " 'she went': 387,\n",
              " 'went on': 506,\n",
              " 'on to': 301,\n",
              " 'to win': 476,\n",
              " 'win another': 520,\n",
              " 'another in': 40,\n",
              " 'in 1911': 212,\n",
              " 'together with her': 481,\n",
              " 'with her husband': 527,\n",
              " 'her husband pierre': 187,\n",
              " 'husband pierre she': 204,\n",
              " 'pierre she was': 329,\n",
              " 'she was awarded': 386,\n",
              " 'was awarded the': 491,\n",
              " 'awarded the nobel': 47,\n",
              " 'the nobel prize': 442,\n",
              " 'nobel prize in': 274,\n",
              " 'prize in 1903': 338,\n",
              " 'in 1903 and': 209,\n",
              " '1903 and she': 7,\n",
              " 'and she went': 33,\n",
              " 'she went on': 388,\n",
              " 'went on to': 507,\n",
              " 'on to win': 302,\n",
              " 'to win another': 477,\n",
              " 'win another in': 521,\n",
              " 'another in 1911': 41,\n",
              " 'marie sklodowska': 253,\n",
              " 'sklodowska was': 394,\n",
              " 'was born': 494,\n",
              " 'born in': 57,\n",
              " 'in warsaw': 221,\n",
              " 'warsaw on': 488,\n",
              " 'on november': 297,\n",
              " 'november 1867': 275,\n",
              " '1867 the': 0,\n",
              " 'the daughter': 417,\n",
              " 'daughter of': 106,\n",
              " 'of teacher': 288,\n",
              " 'marie sklodowska was': 254,\n",
              " 'sklodowska was born': 395,\n",
              " 'was born in': 495,\n",
              " 'born in warsaw': 58,\n",
              " 'in warsaw on': 222,\n",
              " 'warsaw on november': 489,\n",
              " 'on november 1867': 298,\n",
              " 'november 1867 the': 276,\n",
              " '1867 the daughter': 1,\n",
              " 'the daughter of': 418,\n",
              " 'daughter of teacher': 107,\n",
              " 'in 1891': 205,\n",
              " '1891 she': 2,\n",
              " 'went to': 508,\n",
              " 'to paris': 468,\n",
              " 'paris to': 313,\n",
              " 'to study': 470,\n",
              " 'study physics': 400,\n",
              " 'physics and': 320,\n",
              " 'and mathematics': 26,\n",
              " 'mathematics at': 259,\n",
              " 'at the': 43,\n",
              " 'the sorbonne': 445,\n",
              " 'sorbonne where': 398,\n",
              " 'where she': 516,\n",
              " 'she met': 379,\n",
              " 'met pierre': 263,\n",
              " 'pierre curie': 324,\n",
              " 'curie professor': 88,\n",
              " 'professor of': 339,\n",
              " 'the school': 443,\n",
              " 'school of': 361,\n",
              " 'of physics': 285,\n",
              " 'in 1891 she': 206,\n",
              " '1891 she went': 3,\n",
              " 'she went to': 389,\n",
              " 'went to paris': 509,\n",
              " 'to paris to': 469,\n",
              " 'paris to study': 314,\n",
              " 'to study physics': 471,\n",
              " 'study physics and': 401,\n",
              " 'physics and mathematics': 321,\n",
              " 'and mathematics at': 27,\n",
              " 'mathematics at the': 260,\n",
              " 'at the sorbonne': 45,\n",
              " 'the sorbonne where': 447,\n",
              " 'sorbonne where she': 399,\n",
              " 'where she met': 517,\n",
              " 'she met pierre': 380,\n",
              " 'met pierre curie': 264,\n",
              " 'pierre curie professor': 325,\n",
              " 'curie professor of': 89,\n",
              " 'professor of the': 340,\n",
              " 'of the school': 293,\n",
              " 'the school of': 444,\n",
              " 'school of physics': 362,\n",
              " 'they were': 457,\n",
              " 'were married': 512,\n",
              " 'married in': 257,\n",
              " 'in 1895': 207,\n",
              " 'they were married': 458,\n",
              " 'were married in': 513,\n",
              " 'married in 1895': 258,\n",
              " 'the curies': 412,\n",
              " 'curies worked': 100,\n",
              " 'worked together': 536,\n",
              " 'together investigating': 478,\n",
              " 'investigating radioactivity': 225,\n",
              " 'radioactivity building': 343,\n",
              " 'building on': 61,\n",
              " 'on the': 299,\n",
              " 'the work': 448,\n",
              " 'work of': 532,\n",
              " 'the german': 431,\n",
              " 'german physicist': 166,\n",
              " 'physicist roentgen': 318,\n",
              " 'roentgen and': 359,\n",
              " 'and the': 34,\n",
              " 'the french': 427,\n",
              " 'french physicist': 156,\n",
              " 'physicist becquerel': 317,\n",
              " 'the curies worked': 416,\n",
              " 'curies worked together': 101,\n",
              " 'worked together investigating': 537,\n",
              " 'together investigating radioactivity': 479,\n",
              " 'investigating radioactivity building': 226,\n",
              " 'radioactivity building on': 344,\n",
              " 'building on the': 62,\n",
              " 'on the work': 300,\n",
              " 'the work of': 449,\n",
              " 'work of the': 533,\n",
              " 'of the german': 290,\n",
              " 'the german physicist': 432,\n",
              " 'german physicist roentgen': 167,\n",
              " 'physicist roentgen and': 319,\n",
              " 'roentgen and the': 360,\n",
              " 'and the french': 35,\n",
              " 'the french physicist': 428,\n",
              " 'french physicist becquerel': 157,\n",
              " 'in july': 215,\n",
              " 'july 1898': 231,\n",
              " '1898 the': 4,\n",
              " 'curies announced': 96,\n",
              " 'announced the': 38,\n",
              " 'the discovery': 421,\n",
              " 'discovery of': 116,\n",
              " 'of new': 283,\n",
              " 'new chemical': 269,\n",
              " 'chemical element': 70,\n",
              " 'element polonium': 129,\n",
              " 'in july 1898': 216,\n",
              " 'july 1898 the': 232,\n",
              " '1898 the curies': 5,\n",
              " 'the curies announced': 414,\n",
              " 'curies announced the': 97,\n",
              " 'announced the discovery': 39,\n",
              " 'the discovery of': 422,\n",
              " 'discovery of new': 118,\n",
              " 'of new chemical': 284,\n",
              " 'new chemical element': 270,\n",
              " 'chemical element polonium': 71,\n",
              " 'the end': 423,\n",
              " 'end of': 130,\n",
              " 'the year': 451,\n",
              " 'year they': 540,\n",
              " 'they announced': 453,\n",
              " 'of another': 277,\n",
              " 'another radium': 42,\n",
              " 'at the end': 44,\n",
              " 'the end of': 424,\n",
              " 'end of the': 131,\n",
              " 'of the year': 294,\n",
              " 'the year they': 452,\n",
              " 'year they announced': 541,\n",
              " 'they announced the': 454,\n",
              " 'discovery of another': 117,\n",
              " 'of another radium': 278,\n",
              " 'curies along': 94,\n",
              " 'along with': 14,\n",
              " 'with becquerel': 524,\n",
              " 'becquerel were': 50,\n",
              " 'were awarded': 510,\n",
              " 'prize for': 334,\n",
              " 'for physics': 152,\n",
              " 'physics in': 322,\n",
              " 'the curies along': 413,\n",
              " 'curies along with': 95,\n",
              " 'along with becquerel': 15,\n",
              " 'with becquerel were': 525,\n",
              " 'becquerel were awarded': 51,\n",
              " 'were awarded the': 511,\n",
              " 'nobel prize for': 273,\n",
              " 'prize for physics': 336,\n",
              " 'for physics in': 153,\n",
              " 'physics in 1903': 323,\n",
              " 'pierre life': 326,\n",
              " 'life was': 243,\n",
              " 'was cut': 498,\n",
              " 'cut short': 102,\n",
              " 'short in': 390,\n",
              " 'in 1906': 210,\n",
              " '1906 when': 8,\n",
              " 'when he': 514,\n",
              " 'he was': 172,\n",
              " 'was knocked': 502,\n",
              " 'knocked down': 237,\n",
              " 'down and': 121,\n",
              " 'and killed': 24,\n",
              " 'killed by': 235,\n",
              " 'by carriage': 63,\n",
              " 'pierre life was': 327,\n",
              " 'life was cut': 244,\n",
              " 'was cut short': 499,\n",
              " 'cut short in': 103,\n",
              " 'short in 1906': 391,\n",
              " 'in 1906 when': 211,\n",
              " '1906 when he': 9,\n",
              " 'when he was': 515,\n",
              " 'he was knocked': 173,\n",
              " 'was knocked down': 503,\n",
              " 'knocked down and': 238,\n",
              " 'down and killed': 122,\n",
              " 'and killed by': 25,\n",
              " 'killed by carriage': 236,\n",
              " 'marie took': 255,\n",
              " 'took over': 482,\n",
              " 'over his': 311,\n",
              " 'his teaching': 201,\n",
              " 'teaching post': 406,\n",
              " 'post becoming': 332,\n",
              " 'becoming the': 48,\n",
              " 'the first': 425,\n",
              " 'first woman': 146,\n",
              " 'woman to': 530,\n",
              " 'to teach': 472,\n",
              " 'teach at': 404,\n",
              " 'sorbonne and': 396,\n",
              " 'and devoted': 20,\n",
              " 'devoted herself': 112,\n",
              " 'herself to': 197,\n",
              " 'to continuing': 459,\n",
              " 'continuing the': 78,\n",
              " 'work that': 534,\n",
              " 'that they': 408,\n",
              " 'they had': 455,\n",
              " 'had begun': 170,\n",
              " 'begun together': 54,\n",
              " 'marie took over': 256,\n",
              " 'took over his': 483,\n",
              " 'over his teaching': 312,\n",
              " 'his teaching post': 202,\n",
              " 'teaching post becoming': 407,\n",
              " 'post becoming the': 333,\n",
              " 'becoming the first': 49,\n",
              " 'the first woman': 426,\n",
              " 'first woman to': 147,\n",
              " 'woman to teach': 531,\n",
              " 'to teach at': 473,\n",
              " 'teach at the': 405,\n",
              " 'the sorbonne and': 446,\n",
              " 'sorbonne and devoted': 397,\n",
              " 'and devoted herself': 21,\n",
              " 'devoted herself to': 113,\n",
              " 'herself to continuing': 198,\n",
              " 'to continuing the': 460,\n",
              " 'continuing the work': 79,\n",
              " 'the work that': 450,\n",
              " 'work that they': 535,\n",
              " 'that they had': 409,\n",
              " 'they had begun': 456,\n",
              " 'had begun together': 171,\n",
              " 'she received': 383,\n",
              " 'received second': 351,\n",
              " 'second nobel': 369,\n",
              " 'for chemistry': 148,\n",
              " 'chemistry in': 74,\n",
              " 'she received second': 384,\n",
              " 'received second nobel': 352,\n",
              " 'second nobel prize': 370,\n",
              " 'prize for chemistry': 335,\n",
              " 'for chemistry in': 149,\n",
              " 'chemistry in 1911': 75,\n",
              " 'the curie': 410,\n",
              " 'curie research': 90,\n",
              " 'research was': 357,\n",
              " 'was crucial': 496,\n",
              " 'crucial in': 84,\n",
              " 'in the': 218,\n",
              " 'the development': 419,\n",
              " 'development of': 110,\n",
              " 'of rays': 286,\n",
              " 'rays in': 349,\n",
              " 'in surgery': 217,\n",
              " 'the curie research': 411,\n",
              " 'curie research was': 91,\n",
              " 'research was crucial': 358,\n",
              " 'was crucial in': 497,\n",
              " 'crucial in the': 85,\n",
              " 'in the development': 219,\n",
              " 'the development of': 420,\n",
              " 'development of rays': 111,\n",
              " 'of rays in': 287,\n",
              " 'rays in surgery': 350,\n",
              " 'during world': 125,\n",
              " 'world war': 538,\n",
              " 'war one': 486,\n",
              " 'one curie': 303,\n",
              " 'curie helped': 86,\n",
              " 'helped to': 180,\n",
              " 'to equip': 462,\n",
              " 'equip ambulances': 134,\n",
              " 'ambulances with': 16,\n",
              " 'with ray': 528,\n",
              " 'ray equipment': 347,\n",
              " 'equipment which': 136,\n",
              " 'which she': 518,\n",
              " 'she herself': 377,\n",
              " 'herself drove': 193,\n",
              " 'drove to': 123,\n",
              " 'to the': 474,\n",
              " 'the front': 429,\n",
              " 'front lines': 165,\n",
              " 'during world war': 126,\n",
              " 'world war one': 539,\n",
              " 'war one curie': 487,\n",
              " 'one curie helped': 304,\n",
              " 'curie helped to': 87,\n",
              " 'helped to equip': 181,\n",
              " 'to equip ambulances': 463,\n",
              " 'equip ambulances with': 135,\n",
              " 'ambulances with ray': 17,\n",
              " 'with ray equipment': 529,\n",
              " 'ray equipment which': 348,\n",
              " 'equipment which she': 137,\n",
              " 'which she herself': 519,\n",
              " 'she herself drove': 378,\n",
              " 'herself drove to': 194,\n",
              " 'drove to the': 124,\n",
              " 'to the front': 475,\n",
              " 'the front lines': 430,\n",
              " 'the international': 433,\n",
              " 'international red': 223,\n",
              " 'red cross': 355,\n",
              " 'cross made': 82,\n",
              " 'made her': 245,\n",
              " 'her head': 182,\n",
              " 'head of': 174,\n",
              " 'of its': 281,\n",
              " 'its radiological': 229,\n",
              " 'radiological service': 345,\n",
              " 'service and': 371,\n",
              " 'she held': 375,\n",
              " 'held training': 178,\n",
              " 'training courses': 484,\n",
              " 'courses for': 80,\n",
              " 'for medical': 150,\n",
              " 'medical orderlies': 261,\n",
              " 'orderlies and': 309,\n",
              " 'and doctors': 22,\n",
              " 'doctors in': 119,\n",
              " 'the new': 439,\n",
              " 'new techniques': 271,\n",
              " 'the international red': 434,\n",
              " 'international red cross': 224,\n",
              " 'red cross made': 356,\n",
              " 'cross made her': 83,\n",
              " 'made her head': 246,\n",
              " 'her head of': 183,\n",
              " 'head of its': 175,\n",
              " 'of its radiological': 282,\n",
              " 'its radiological service': 230,\n",
              " 'radiological service and': 346,\n",
              " 'service and she': 372,\n",
              " 'and she held': 31,\n",
              " 'she held training': 376,\n",
              " 'held training courses': 179,\n",
              " 'training courses for': 485,\n",
              " 'courses for medical': 81,\n",
              " 'for medical orderlies': 151,\n",
              " 'medical orderlies and': 262,\n",
              " 'orderlies and doctors': 310,\n",
              " 'and doctors in': 23,\n",
              " 'doctors in the': 120,\n",
              " 'in the new': 220,\n",
              " 'the new techniques': 440,\n",
              " 'despite her': 108,\n",
              " 'her success': 189,\n",
              " 'success marie': 402,\n",
              " 'marie continued': 249,\n",
              " 'continued to': 76,\n",
              " 'to face': 464,\n",
              " 'face great': 140,\n",
              " 'great opposition': 168,\n",
              " 'opposition from': 307,\n",
              " 'from male': 163,\n",
              " 'male scientists': 247,\n",
              " 'scientists in': 365,\n",
              " 'in france': 213,\n",
              " 'france and': 154,\n",
              " 'she never': 381,\n",
              " 'never received': 267,\n",
              " 'received significant': 353,\n",
              " 'significant financial': 392,\n",
              " 'financial benefits': 144,\n",
              " 'benefits from': 55,\n",
              " 'from her': 158,\n",
              " 'her work': 192,\n",
              " 'despite her success': 109,\n",
              " 'her success marie': 190,\n",
              " 'success marie continued': 403,\n",
              " 'marie continued to': 250,\n",
              " 'continued to face': 77,\n",
              " 'to face great': 465,\n",
              " 'face great opposition': 141,\n",
              " 'great opposition from': 169,\n",
              " 'opposition from male': 308,\n",
              " 'from male scientists': 164,\n",
              " 'male scientists in': 248,\n",
              " 'scientists in france': 366,\n",
              " 'in france and': 214,\n",
              " 'france and she': 155,\n",
              " 'and she never': 32,\n",
              " 'she never received': 382,\n",
              " 'never received significant': 268,\n",
              " 'received significant financial': 354,\n",
              " 'significant financial benefits': 393,\n",
              " 'financial benefits from': 145,\n",
              " 'benefits from her': 56,\n",
              " 'from her work': 160,\n",
              " 'by the': 66,\n",
              " 'the late': 435,\n",
              " 'late 1920s': 239,\n",
              " '1920s her': 10,\n",
              " 'her health': 184,\n",
              " 'health was': 176,\n",
              " 'was beginning': 492,\n",
              " 'beginning to': 52,\n",
              " 'to deteriorate': 461,\n",
              " 'by the late': 67,\n",
              " 'the late 1920s': 436,\n",
              " 'late 1920s her': 240,\n",
              " '1920s her health': 11,\n",
              " 'her health was': 185,\n",
              " 'health was beginning': 177,\n",
              " 'was beginning to': 493,\n",
              " 'beginning to deteriorate': 53,\n",
              " 'she died': 373,\n",
              " 'died on': 114,\n",
              " 'on july': 295,\n",
              " 'july 1934': 233,\n",
              " '1934 from': 12,\n",
              " 'from leukaemia': 161,\n",
              " 'leukaemia caused': 241,\n",
              " 'caused by': 68,\n",
              " 'by exposure': 64,\n",
              " 'exposure to': 138,\n",
              " 'to high': 466,\n",
              " 'high energy': 199,\n",
              " 'energy radiation': 132,\n",
              " 'radiation from': 341,\n",
              " 'her research': 188,\n",
              " 'she died on': 374,\n",
              " 'died on july': 115,\n",
              " 'on july 1934': 296,\n",
              " 'july 1934 from': 234,\n",
              " '1934 from leukaemia': 13,\n",
              " 'from leukaemia caused': 162,\n",
              " 'leukaemia caused by': 242,\n",
              " 'caused by exposure': 69,\n",
              " 'by exposure to': 65,\n",
              " 'exposure to high': 139,\n",
              " 'to high energy': 467,\n",
              " 'high energy radiation': 200,\n",
              " 'energy radiation from': 133,\n",
              " 'radiation from her': 342,\n",
              " 'from her research': 159,\n",
              " 'curies eldest': 98,\n",
              " 'eldest daughter': 127,\n",
              " 'daughter irene': 104,\n",
              " 'irene was': 227,\n",
              " 'was herself': 500,\n",
              " 'herself scientist': 195,\n",
              " 'scientist and': 363,\n",
              " 'and winner': 36,\n",
              " 'winner of': 522,\n",
              " 'the curies eldest': 415,\n",
              " 'curies eldest daughter': 99,\n",
              " 'eldest daughter irene': 128,\n",
              " 'daughter irene was': 105,\n",
              " 'irene was herself': 228,\n",
              " 'was herself scientist': 501,\n",
              " 'herself scientist and': 196,\n",
              " 'scientist and winner': 364,\n",
              " 'and winner of': 37,\n",
              " 'winner of the': 523,\n",
              " 'of the nobel': 292}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary = n_gram_vectorizer.vocabulary_\n",
        "\n",
        "vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aBQpABBmAEs",
        "outputId": "196b6b2a-08a4-46fe-fa69-ed63c2682194"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_.get('marie curie')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOhzb9XBmAEs",
        "outputId": "4be1ad65-5125-418c-8d21-ce60267041cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "279"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_.get('of her')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTSu4bAJmAEt"
      },
      "source": [
        "* https://stackoverflow.com/questions/11763613/python-list-of-ngrams-with-frequencies\n",
        "* https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnCo8-zJmAEt"
      },
      "source": [
        "word_count is a vector that contains the sum of each word occurrence in all texts in the corpus. In other words, we are adding the elements for each column of vector matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y_lPRKOmAEt",
        "outputId": "bdf11878-820b-494b-e020-1b10e653318f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bSrLr2BmAEu",
        "outputId": "b370a2c5-7db0-4cd9-8849-eaf5497befb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3,\n",
              "       1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 3, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_count = transformed_vector.toarray().sum(axis=0)\n",
        "\n",
        "word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AqXVY-6mAEu",
        "outputId": "1169a2e1-d900-4d4b-a0ec-0a0aa4400bad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_items([('marie curie', 251), ('curie was', 92), ('was polish', 504), ('polish born', 330), ('born physicist', 59), ('physicist and', 315), ('and chemist', 18), ('chemist and', 72), ('and one', 28), ('one of', 305), ('of the', 289), ('the most', 437), ('most famous', 265), ('famous scientists', 142), ('scientists of', 367), ('of her', 279), ('her time', 191), ('marie curie was', 252), ('curie was polish', 93), ('was polish born', 505), ('polish born physicist', 331), ('born physicist and', 60), ('physicist and chemist', 316), ('and chemist and', 19), ('chemist and one', 73), ('and one of', 29), ('one of the', 306), ('of the most', 291), ('the most famous', 438), ('most famous scientists', 266), ('famous scientists of', 143), ('scientists of her', 368), ('of her time', 280), ('together with', 480), ('with her', 526), ('her husband', 186), ('husband pierre', 203), ('pierre she', 328), ('she was', 385), ('was awarded', 490), ('awarded the', 46), ('the nobel', 441), ('nobel prize', 272), ('prize in', 337), ('in 1903', 208), ('1903 and', 6), ('and she', 30), ('she went', 387), ('went on', 506), ('on to', 301), ('to win', 476), ('win another', 520), ('another in', 40), ('in 1911', 212), ('together with her', 481), ('with her husband', 527), ('her husband pierre', 187), ('husband pierre she', 204), ('pierre she was', 329), ('she was awarded', 386), ('was awarded the', 491), ('awarded the nobel', 47), ('the nobel prize', 442), ('nobel prize in', 274), ('prize in 1903', 338), ('in 1903 and', 209), ('1903 and she', 7), ('and she went', 33), ('she went on', 388), ('went on to', 507), ('on to win', 302), ('to win another', 477), ('win another in', 521), ('another in 1911', 41), ('marie sklodowska', 253), ('sklodowska was', 394), ('was born', 494), ('born in', 57), ('in warsaw', 221), ('warsaw on', 488), ('on november', 297), ('november 1867', 275), ('1867 the', 0), ('the daughter', 417), ('daughter of', 106), ('of teacher', 288), ('marie sklodowska was', 254), ('sklodowska was born', 395), ('was born in', 495), ('born in warsaw', 58), ('in warsaw on', 222), ('warsaw on november', 489), ('on november 1867', 298), ('november 1867 the', 276), ('1867 the daughter', 1), ('the daughter of', 418), ('daughter of teacher', 107), ('in 1891', 205), ('1891 she', 2), ('went to', 508), ('to paris', 468), ('paris to', 313), ('to study', 470), ('study physics', 400), ('physics and', 320), ('and mathematics', 26), ('mathematics at', 259), ('at the', 43), ('the sorbonne', 445), ('sorbonne where', 398), ('where she', 516), ('she met', 379), ('met pierre', 263), ('pierre curie', 324), ('curie professor', 88), ('professor of', 339), ('the school', 443), ('school of', 361), ('of physics', 285), ('in 1891 she', 206), ('1891 she went', 3), ('she went to', 389), ('went to paris', 509), ('to paris to', 469), ('paris to study', 314), ('to study physics', 471), ('study physics and', 401), ('physics and mathematics', 321), ('and mathematics at', 27), ('mathematics at the', 260), ('at the sorbonne', 45), ('the sorbonne where', 447), ('sorbonne where she', 399), ('where she met', 517), ('she met pierre', 380), ('met pierre curie', 264), ('pierre curie professor', 325), ('curie professor of', 89), ('professor of the', 340), ('of the school', 293), ('the school of', 444), ('school of physics', 362), ('they were', 457), ('were married', 512), ('married in', 257), ('in 1895', 207), ('they were married', 458), ('were married in', 513), ('married in 1895', 258), ('the curies', 412), ('curies worked', 100), ('worked together', 536), ('together investigating', 478), ('investigating radioactivity', 225), ('radioactivity building', 343), ('building on', 61), ('on the', 299), ('the work', 448), ('work of', 532), ('the german', 431), ('german physicist', 166), ('physicist roentgen', 318), ('roentgen and', 359), ('and the', 34), ('the french', 427), ('french physicist', 156), ('physicist becquerel', 317), ('the curies worked', 416), ('curies worked together', 101), ('worked together investigating', 537), ('together investigating radioactivity', 479), ('investigating radioactivity building', 226), ('radioactivity building on', 344), ('building on the', 62), ('on the work', 300), ('the work of', 449), ('work of the', 533), ('of the german', 290), ('the german physicist', 432), ('german physicist roentgen', 167), ('physicist roentgen and', 319), ('roentgen and the', 360), ('and the french', 35), ('the french physicist', 428), ('french physicist becquerel', 157), ('in july', 215), ('july 1898', 231), ('1898 the', 4), ('curies announced', 96), ('announced the', 38), ('the discovery', 421), ('discovery of', 116), ('of new', 283), ('new chemical', 269), ('chemical element', 70), ('element polonium', 129), ('in july 1898', 216), ('july 1898 the', 232), ('1898 the curies', 5), ('the curies announced', 414), ('curies announced the', 97), ('announced the discovery', 39), ('the discovery of', 422), ('discovery of new', 118), ('of new chemical', 284), ('new chemical element', 270), ('chemical element polonium', 71), ('the end', 423), ('end of', 130), ('the year', 451), ('year they', 540), ('they announced', 453), ('of another', 277), ('another radium', 42), ('at the end', 44), ('the end of', 424), ('end of the', 131), ('of the year', 294), ('the year they', 452), ('year they announced', 541), ('they announced the', 454), ('discovery of another', 117), ('of another radium', 278), ('curies along', 94), ('along with', 14), ('with becquerel', 524), ('becquerel were', 50), ('were awarded', 510), ('prize for', 334), ('for physics', 152), ('physics in', 322), ('the curies along', 413), ('curies along with', 95), ('along with becquerel', 15), ('with becquerel were', 525), ('becquerel were awarded', 51), ('were awarded the', 511), ('nobel prize for', 273), ('prize for physics', 336), ('for physics in', 153), ('physics in 1903', 323), ('pierre life', 326), ('life was', 243), ('was cut', 498), ('cut short', 102), ('short in', 390), ('in 1906', 210), ('1906 when', 8), ('when he', 514), ('he was', 172), ('was knocked', 502), ('knocked down', 237), ('down and', 121), ('and killed', 24), ('killed by', 235), ('by carriage', 63), ('pierre life was', 327), ('life was cut', 244), ('was cut short', 499), ('cut short in', 103), ('short in 1906', 391), ('in 1906 when', 211), ('1906 when he', 9), ('when he was', 515), ('he was knocked', 173), ('was knocked down', 503), ('knocked down and', 238), ('down and killed', 122), ('and killed by', 25), ('killed by carriage', 236), ('marie took', 255), ('took over', 482), ('over his', 311), ('his teaching', 201), ('teaching post', 406), ('post becoming', 332), ('becoming the', 48), ('the first', 425), ('first woman', 146), ('woman to', 530), ('to teach', 472), ('teach at', 404), ('sorbonne and', 396), ('and devoted', 20), ('devoted herself', 112), ('herself to', 197), ('to continuing', 459), ('continuing the', 78), ('work that', 534), ('that they', 408), ('they had', 455), ('had begun', 170), ('begun together', 54), ('marie took over', 256), ('took over his', 483), ('over his teaching', 312), ('his teaching post', 202), ('teaching post becoming', 407), ('post becoming the', 333), ('becoming the first', 49), ('the first woman', 426), ('first woman to', 147), ('woman to teach', 531), ('to teach at', 473), ('teach at the', 405), ('the sorbonne and', 446), ('sorbonne and devoted', 397), ('and devoted herself', 21), ('devoted herself to', 113), ('herself to continuing', 198), ('to continuing the', 460), ('continuing the work', 79), ('the work that', 450), ('work that they', 535), ('that they had', 409), ('they had begun', 456), ('had begun together', 171), ('she received', 383), ('received second', 351), ('second nobel', 369), ('for chemistry', 148), ('chemistry in', 74), ('she received second', 384), ('received second nobel', 352), ('second nobel prize', 370), ('prize for chemistry', 335), ('for chemistry in', 149), ('chemistry in 1911', 75), ('the curie', 410), ('curie research', 90), ('research was', 357), ('was crucial', 496), ('crucial in', 84), ('in the', 218), ('the development', 419), ('development of', 110), ('of rays', 286), ('rays in', 349), ('in surgery', 217), ('the curie research', 411), ('curie research was', 91), ('research was crucial', 358), ('was crucial in', 497), ('crucial in the', 85), ('in the development', 219), ('the development of', 420), ('development of rays', 111), ('of rays in', 287), ('rays in surgery', 350), ('during world', 125), ('world war', 538), ('war one', 486), ('one curie', 303), ('curie helped', 86), ('helped to', 180), ('to equip', 462), ('equip ambulances', 134), ('ambulances with', 16), ('with ray', 528), ('ray equipment', 347), ('equipment which', 136), ('which she', 518), ('she herself', 377), ('herself drove', 193), ('drove to', 123), ('to the', 474), ('the front', 429), ('front lines', 165), ('during world war', 126), ('world war one', 539), ('war one curie', 487), ('one curie helped', 304), ('curie helped to', 87), ('helped to equip', 181), ('to equip ambulances', 463), ('equip ambulances with', 135), ('ambulances with ray', 17), ('with ray equipment', 529), ('ray equipment which', 348), ('equipment which she', 137), ('which she herself', 519), ('she herself drove', 378), ('herself drove to', 194), ('drove to the', 124), ('to the front', 475), ('the front lines', 430), ('the international', 433), ('international red', 223), ('red cross', 355), ('cross made', 82), ('made her', 245), ('her head', 182), ('head of', 174), ('of its', 281), ('its radiological', 229), ('radiological service', 345), ('service and', 371), ('she held', 375), ('held training', 178), ('training courses', 484), ('courses for', 80), ('for medical', 150), ('medical orderlies', 261), ('orderlies and', 309), ('and doctors', 22), ('doctors in', 119), ('the new', 439), ('new techniques', 271), ('the international red', 434), ('international red cross', 224), ('red cross made', 356), ('cross made her', 83), ('made her head', 246), ('her head of', 183), ('head of its', 175), ('of its radiological', 282), ('its radiological service', 230), ('radiological service and', 346), ('service and she', 372), ('and she held', 31), ('she held training', 376), ('held training courses', 179), ('training courses for', 485), ('courses for medical', 81), ('for medical orderlies', 151), ('medical orderlies and', 262), ('orderlies and doctors', 310), ('and doctors in', 23), ('doctors in the', 120), ('in the new', 220), ('the new techniques', 440), ('despite her', 108), ('her success', 189), ('success marie', 402), ('marie continued', 249), ('continued to', 76), ('to face', 464), ('face great', 140), ('great opposition', 168), ('opposition from', 307), ('from male', 163), ('male scientists', 247), ('scientists in', 365), ('in france', 213), ('france and', 154), ('she never', 381), ('never received', 267), ('received significant', 353), ('significant financial', 392), ('financial benefits', 144), ('benefits from', 55), ('from her', 158), ('her work', 192), ('despite her success', 109), ('her success marie', 190), ('success marie continued', 403), ('marie continued to', 250), ('continued to face', 77), ('to face great', 465), ('face great opposition', 141), ('great opposition from', 169), ('opposition from male', 308), ('from male scientists', 164), ('male scientists in', 248), ('scientists in france', 366), ('in france and', 214), ('france and she', 155), ('and she never', 32), ('she never received', 382), ('never received significant', 268), ('received significant financial', 354), ('significant financial benefits', 393), ('financial benefits from', 145), ('benefits from her', 56), ('from her work', 160), ('by the', 66), ('the late', 435), ('late 1920s', 239), ('1920s her', 10), ('her health', 184), ('health was', 176), ('was beginning', 492), ('beginning to', 52), ('to deteriorate', 461), ('by the late', 67), ('the late 1920s', 436), ('late 1920s her', 240), ('1920s her health', 11), ('her health was', 185), ('health was beginning', 177), ('was beginning to', 493), ('beginning to deteriorate', 53), ('she died', 373), ('died on', 114), ('on july', 295), ('july 1934', 233), ('1934 from', 12), ('from leukaemia', 161), ('leukaemia caused', 241), ('caused by', 68), ('by exposure', 64), ('exposure to', 138), ('to high', 466), ('high energy', 199), ('energy radiation', 132), ('radiation from', 341), ('her research', 188), ('she died on', 374), ('died on july', 115), ('on july 1934', 296), ('july 1934 from', 234), ('1934 from leukaemia', 13), ('from leukaemia caused', 162), ('leukaemia caused by', 242), ('caused by exposure', 69), ('by exposure to', 65), ('exposure to high', 139), ('to high energy', 467), ('high energy radiation', 200), ('energy radiation from', 133), ('radiation from her', 342), ('from her research', 159), ('curies eldest', 98), ('eldest daughter', 127), ('daughter irene', 104), ('irene was', 227), ('was herself', 500), ('herself scientist', 195), ('scientist and', 363), ('and winner', 36), ('winner of', 522), ('the curies eldest', 415), ('curies eldest daughter', 99), ('eldest daughter irene', 128), ('daughter irene was', 105), ('irene was herself', 228), ('was herself scientist', 501), ('herself scientist and', 196), ('scientist and winner', 364), ('and winner of', 37), ('winner of the', 523), ('of the nobel', 292)])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWYh4gNYmAEv",
        "outputId": "a691a2cf-c16b-424f-df8a-c39706fea56f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(5, 'of the'),\n",
              " (4, 'the curies'),\n",
              " (4, 'nobel prize'),\n",
              " (3, 'the nobel prize'),\n",
              " (3, 'the nobel'),\n",
              " (3, 'prize for'),\n",
              " (3, 'nobel prize for'),\n",
              " (3, 'at the'),\n",
              " (3, 'and she'),\n",
              " (2, 'the work'),\n",
              " (2, 'the sorbonne'),\n",
              " (2, 'the discovery of'),\n",
              " (2, 'the discovery'),\n",
              " (2, 'she went'),\n",
              " (2, 'prize for chemistry'),\n",
              " (2, 'in the'),\n",
              " (2, 'in 1911'),\n",
              " (2, 'in 1903'),\n",
              " (2, 'from her'),\n",
              " (2, 'for chemistry'),\n",
              " (2, 'discovery of'),\n",
              " (2, 'awarded the nobel'),\n",
              " (2, 'awarded the'),\n",
              " (2, 'at the sorbonne'),\n",
              " (2, 'announced the discovery'),\n",
              " (2, 'announced the'),\n",
              " (1, 'year they announced'),\n",
              " (1, 'year they'),\n",
              " (1, 'world war one'),\n",
              " (1, 'world war'),\n",
              " (1, 'worked together investigating'),\n",
              " (1, 'worked together'),\n",
              " (1, 'work that they'),\n",
              " (1, 'work that'),\n",
              " (1, 'work of the'),\n",
              " (1, 'work of'),\n",
              " (1, 'woman to teach'),\n",
              " (1, 'woman to'),\n",
              " (1, 'with ray equipment'),\n",
              " (1, 'with ray'),\n",
              " (1, 'with her husband'),\n",
              " (1, 'with her'),\n",
              " (1, 'with becquerel were'),\n",
              " (1, 'with becquerel'),\n",
              " (1, 'winner of the'),\n",
              " (1, 'winner of'),\n",
              " (1, 'win another in'),\n",
              " (1, 'win another'),\n",
              " (1, 'which she herself'),\n",
              " (1, 'which she'),\n",
              " (1, 'where she met'),\n",
              " (1, 'where she'),\n",
              " (1, 'when he was'),\n",
              " (1, 'when he'),\n",
              " (1, 'were married in'),\n",
              " (1, 'were married'),\n",
              " (1, 'were awarded the'),\n",
              " (1, 'were awarded'),\n",
              " (1, 'went to paris'),\n",
              " (1, 'went to'),\n",
              " (1, 'went on to'),\n",
              " (1, 'went on'),\n",
              " (1, 'was polish born'),\n",
              " (1, 'was polish'),\n",
              " (1, 'was knocked down'),\n",
              " (1, 'was knocked'),\n",
              " (1, 'was herself scientist'),\n",
              " (1, 'was herself'),\n",
              " (1, 'was cut short'),\n",
              " (1, 'was cut'),\n",
              " (1, 'was crucial in'),\n",
              " (1, 'was crucial'),\n",
              " (1, 'was born in'),\n",
              " (1, 'was born'),\n",
              " (1, 'was beginning to'),\n",
              " (1, 'was beginning'),\n",
              " (1, 'was awarded the'),\n",
              " (1, 'was awarded'),\n",
              " (1, 'warsaw on november'),\n",
              " (1, 'warsaw on'),\n",
              " (1, 'war one curie'),\n",
              " (1, 'war one'),\n",
              " (1, 'training courses for'),\n",
              " (1, 'training courses'),\n",
              " (1, 'took over his'),\n",
              " (1, 'took over'),\n",
              " (1, 'together with her'),\n",
              " (1, 'together with'),\n",
              " (1, 'together investigating radioactivity'),\n",
              " (1, 'together investigating'),\n",
              " (1, 'to win another'),\n",
              " (1, 'to win'),\n",
              " (1, 'to the front'),\n",
              " (1, 'to the'),\n",
              " (1, 'to teach at'),\n",
              " (1, 'to teach'),\n",
              " (1, 'to study physics'),\n",
              " (1, 'to study'),\n",
              " (1, 'to paris to'),\n",
              " (1, 'to paris'),\n",
              " (1, 'to high energy'),\n",
              " (1, 'to high'),\n",
              " (1, 'to face great'),\n",
              " (1, 'to face'),\n",
              " (1, 'to equip ambulances'),\n",
              " (1, 'to equip'),\n",
              " (1, 'to deteriorate'),\n",
              " (1, 'to continuing the'),\n",
              " (1, 'to continuing'),\n",
              " (1, 'they were married'),\n",
              " (1, 'they were'),\n",
              " (1, 'they had begun'),\n",
              " (1, 'they had'),\n",
              " (1, 'they announced the'),\n",
              " (1, 'they announced'),\n",
              " (1, 'the year they'),\n",
              " (1, 'the year'),\n",
              " (1, 'the work that'),\n",
              " (1, 'the work of'),\n",
              " (1, 'the sorbonne where'),\n",
              " (1, 'the sorbonne and'),\n",
              " (1, 'the school of'),\n",
              " (1, 'the school'),\n",
              " (1, 'the new techniques'),\n",
              " (1, 'the new'),\n",
              " (1, 'the most famous'),\n",
              " (1, 'the most'),\n",
              " (1, 'the late 1920s'),\n",
              " (1, 'the late'),\n",
              " (1, 'the international red'),\n",
              " (1, 'the international'),\n",
              " (1, 'the german physicist'),\n",
              " (1, 'the german'),\n",
              " (1, 'the front lines'),\n",
              " (1, 'the front'),\n",
              " (1, 'the french physicist'),\n",
              " (1, 'the french'),\n",
              " (1, 'the first woman'),\n",
              " (1, 'the first'),\n",
              " (1, 'the end of'),\n",
              " (1, 'the end'),\n",
              " (1, 'the development of'),\n",
              " (1, 'the development'),\n",
              " (1, 'the daughter of'),\n",
              " (1, 'the daughter'),\n",
              " (1, 'the curies worked'),\n",
              " (1, 'the curies eldest'),\n",
              " (1, 'the curies announced'),\n",
              " (1, 'the curies along'),\n",
              " (1, 'the curie research'),\n",
              " (1, 'the curie'),\n",
              " (1, 'that they had'),\n",
              " (1, 'that they'),\n",
              " (1, 'teaching post becoming'),\n",
              " (1, 'teaching post'),\n",
              " (1, 'teach at the'),\n",
              " (1, 'teach at'),\n",
              " (1, 'success marie continued'),\n",
              " (1, 'success marie'),\n",
              " (1, 'study physics and'),\n",
              " (1, 'study physics'),\n",
              " (1, 'sorbonne where she'),\n",
              " (1, 'sorbonne where'),\n",
              " (1, 'sorbonne and devoted'),\n",
              " (1, 'sorbonne and'),\n",
              " (1, 'sklodowska was born'),\n",
              " (1, 'sklodowska was'),\n",
              " (1, 'significant financial benefits'),\n",
              " (1, 'significant financial'),\n",
              " (1, 'short in 1906'),\n",
              " (1, 'short in'),\n",
              " (1, 'she went to'),\n",
              " (1, 'she went on'),\n",
              " (1, 'she was awarded'),\n",
              " (1, 'she was'),\n",
              " (1, 'she received second'),\n",
              " (1, 'she received'),\n",
              " (1, 'she never received'),\n",
              " (1, 'she never'),\n",
              " (1, 'she met pierre'),\n",
              " (1, 'she met'),\n",
              " (1, 'she herself drove'),\n",
              " (1, 'she herself'),\n",
              " (1, 'she held training'),\n",
              " (1, 'she held'),\n",
              " (1, 'she died on'),\n",
              " (1, 'she died'),\n",
              " (1, 'service and she'),\n",
              " (1, 'service and'),\n",
              " (1, 'second nobel prize'),\n",
              " (1, 'second nobel'),\n",
              " (1, 'scientists of her'),\n",
              " (1, 'scientists of'),\n",
              " (1, 'scientists in france'),\n",
              " (1, 'scientists in'),\n",
              " (1, 'scientist and winner'),\n",
              " (1, 'scientist and'),\n",
              " (1, 'school of physics'),\n",
              " (1, 'school of'),\n",
              " (1, 'roentgen and the'),\n",
              " (1, 'roentgen and'),\n",
              " (1, 'research was crucial'),\n",
              " (1, 'research was'),\n",
              " (1, 'red cross made'),\n",
              " (1, 'red cross'),\n",
              " (1, 'received significant financial'),\n",
              " (1, 'received significant'),\n",
              " (1, 'received second nobel'),\n",
              " (1, 'received second'),\n",
              " (1, 'rays in surgery'),\n",
              " (1, 'rays in'),\n",
              " (1, 'ray equipment which'),\n",
              " (1, 'ray equipment'),\n",
              " (1, 'radiological service and'),\n",
              " (1, 'radiological service'),\n",
              " (1, 'radioactivity building on'),\n",
              " (1, 'radioactivity building'),\n",
              " (1, 'radiation from her'),\n",
              " (1, 'radiation from'),\n",
              " (1, 'professor of the'),\n",
              " (1, 'professor of'),\n",
              " (1, 'prize in 1903'),\n",
              " (1, 'prize in'),\n",
              " (1, 'prize for physics'),\n",
              " (1, 'post becoming the'),\n",
              " (1, 'post becoming'),\n",
              " (1, 'polish born physicist'),\n",
              " (1, 'polish born'),\n",
              " (1, 'pierre she was'),\n",
              " (1, 'pierre she'),\n",
              " (1, 'pierre life was'),\n",
              " (1, 'pierre life'),\n",
              " (1, 'pierre curie professor'),\n",
              " (1, 'pierre curie'),\n",
              " (1, 'physics in 1903'),\n",
              " (1, 'physics in'),\n",
              " (1, 'physics and mathematics'),\n",
              " (1, 'physics and'),\n",
              " (1, 'physicist roentgen and'),\n",
              " (1, 'physicist roentgen'),\n",
              " (1, 'physicist becquerel'),\n",
              " (1, 'physicist and chemist'),\n",
              " (1, 'physicist and'),\n",
              " (1, 'paris to study'),\n",
              " (1, 'paris to'),\n",
              " (1, 'over his teaching'),\n",
              " (1, 'over his'),\n",
              " (1, 'orderlies and doctors'),\n",
              " (1, 'orderlies and'),\n",
              " (1, 'opposition from male'),\n",
              " (1, 'opposition from'),\n",
              " (1, 'one of the'),\n",
              " (1, 'one of'),\n",
              " (1, 'one curie helped'),\n",
              " (1, 'one curie'),\n",
              " (1, 'on to win'),\n",
              " (1, 'on to'),\n",
              " (1, 'on the work'),\n",
              " (1, 'on the'),\n",
              " (1, 'on november 1867'),\n",
              " (1, 'on november'),\n",
              " (1, 'on july 1934'),\n",
              " (1, 'on july'),\n",
              " (1, 'of the year'),\n",
              " (1, 'of the school'),\n",
              " (1, 'of the nobel'),\n",
              " (1, 'of the most'),\n",
              " (1, 'of the german'),\n",
              " (1, 'of teacher'),\n",
              " (1, 'of rays in'),\n",
              " (1, 'of rays'),\n",
              " (1, 'of physics'),\n",
              " (1, 'of new chemical'),\n",
              " (1, 'of new'),\n",
              " (1, 'of its radiological'),\n",
              " (1, 'of its'),\n",
              " (1, 'of her time'),\n",
              " (1, 'of her'),\n",
              " (1, 'of another radium'),\n",
              " (1, 'of another'),\n",
              " (1, 'november 1867 the'),\n",
              " (1, 'november 1867'),\n",
              " (1, 'nobel prize in'),\n",
              " (1, 'new techniques'),\n",
              " (1, 'new chemical element'),\n",
              " (1, 'new chemical'),\n",
              " (1, 'never received significant'),\n",
              " (1, 'never received'),\n",
              " (1, 'most famous scientists'),\n",
              " (1, 'most famous'),\n",
              " (1, 'met pierre curie'),\n",
              " (1, 'met pierre'),\n",
              " (1, 'medical orderlies and'),\n",
              " (1, 'medical orderlies'),\n",
              " (1, 'mathematics at the'),\n",
              " (1, 'mathematics at'),\n",
              " (1, 'married in 1895'),\n",
              " (1, 'married in'),\n",
              " (1, 'marie took over'),\n",
              " (1, 'marie took'),\n",
              " (1, 'marie sklodowska was'),\n",
              " (1, 'marie sklodowska'),\n",
              " (1, 'marie curie was'),\n",
              " (1, 'marie curie'),\n",
              " (1, 'marie continued to'),\n",
              " (1, 'marie continued'),\n",
              " (1, 'male scientists in'),\n",
              " (1, 'male scientists'),\n",
              " (1, 'made her head'),\n",
              " (1, 'made her'),\n",
              " (1, 'life was cut'),\n",
              " (1, 'life was'),\n",
              " (1, 'leukaemia caused by'),\n",
              " (1, 'leukaemia caused'),\n",
              " (1, 'late 1920s her'),\n",
              " (1, 'late 1920s'),\n",
              " (1, 'knocked down and'),\n",
              " (1, 'knocked down'),\n",
              " (1, 'killed by carriage'),\n",
              " (1, 'killed by'),\n",
              " (1, 'july 1934 from'),\n",
              " (1, 'july 1934'),\n",
              " (1, 'july 1898 the'),\n",
              " (1, 'july 1898'),\n",
              " (1, 'its radiological service'),\n",
              " (1, 'its radiological'),\n",
              " (1, 'irene was herself'),\n",
              " (1, 'irene was'),\n",
              " (1, 'investigating radioactivity building'),\n",
              " (1, 'investigating radioactivity'),\n",
              " (1, 'international red cross'),\n",
              " (1, 'international red'),\n",
              " (1, 'in warsaw on'),\n",
              " (1, 'in warsaw'),\n",
              " (1, 'in the new'),\n",
              " (1, 'in the development'),\n",
              " (1, 'in surgery'),\n",
              " (1, 'in july 1898'),\n",
              " (1, 'in july'),\n",
              " (1, 'in france and'),\n",
              " (1, 'in france'),\n",
              " (1, 'in 1906 when'),\n",
              " (1, 'in 1906'),\n",
              " (1, 'in 1903 and'),\n",
              " (1, 'in 1895'),\n",
              " (1, 'in 1891 she'),\n",
              " (1, 'in 1891'),\n",
              " (1, 'husband pierre she'),\n",
              " (1, 'husband pierre'),\n",
              " (1, 'his teaching post'),\n",
              " (1, 'his teaching'),\n",
              " (1, 'high energy radiation'),\n",
              " (1, 'high energy'),\n",
              " (1, 'herself to continuing'),\n",
              " (1, 'herself to'),\n",
              " (1, 'herself scientist and'),\n",
              " (1, 'herself scientist'),\n",
              " (1, 'herself drove to'),\n",
              " (1, 'herself drove'),\n",
              " (1, 'her work'),\n",
              " (1, 'her time'),\n",
              " (1, 'her success marie'),\n",
              " (1, 'her success'),\n",
              " (1, 'her research'),\n",
              " (1, 'her husband pierre'),\n",
              " (1, 'her husband'),\n",
              " (1, 'her health was'),\n",
              " (1, 'her health'),\n",
              " (1, 'her head of'),\n",
              " (1, 'her head'),\n",
              " (1, 'helped to equip'),\n",
              " (1, 'helped to'),\n",
              " (1, 'held training courses'),\n",
              " (1, 'held training'),\n",
              " (1, 'health was beginning'),\n",
              " (1, 'health was'),\n",
              " (1, 'head of its'),\n",
              " (1, 'head of'),\n",
              " (1, 'he was knocked'),\n",
              " (1, 'he was'),\n",
              " (1, 'had begun together'),\n",
              " (1, 'had begun'),\n",
              " (1, 'great opposition from'),\n",
              " (1, 'great opposition'),\n",
              " (1, 'german physicist roentgen'),\n",
              " (1, 'german physicist'),\n",
              " (1, 'front lines'),\n",
              " (1, 'from male scientists'),\n",
              " (1, 'from male'),\n",
              " (1, 'from leukaemia caused'),\n",
              " (1, 'from leukaemia'),\n",
              " (1, 'from her work'),\n",
              " (1, 'from her research'),\n",
              " (1, 'french physicist becquerel'),\n",
              " (1, 'french physicist'),\n",
              " (1, 'france and she'),\n",
              " (1, 'france and'),\n",
              " (1, 'for physics in'),\n",
              " (1, 'for physics'),\n",
              " (1, 'for medical orderlies'),\n",
              " (1, 'for medical'),\n",
              " (1, 'for chemistry in'),\n",
              " (1, 'first woman to'),\n",
              " (1, 'first woman'),\n",
              " (1, 'financial benefits from'),\n",
              " (1, 'financial benefits'),\n",
              " (1, 'famous scientists of'),\n",
              " (1, 'famous scientists'),\n",
              " (1, 'face great opposition'),\n",
              " (1, 'face great'),\n",
              " (1, 'exposure to high'),\n",
              " (1, 'exposure to'),\n",
              " (1, 'equipment which she'),\n",
              " (1, 'equipment which'),\n",
              " (1, 'equip ambulances with'),\n",
              " (1, 'equip ambulances'),\n",
              " (1, 'energy radiation from'),\n",
              " (1, 'energy radiation'),\n",
              " (1, 'end of the'),\n",
              " (1, 'end of'),\n",
              " (1, 'element polonium'),\n",
              " (1, 'eldest daughter irene'),\n",
              " (1, 'eldest daughter'),\n",
              " (1, 'during world war'),\n",
              " (1, 'during world'),\n",
              " (1, 'drove to the'),\n",
              " (1, 'drove to'),\n",
              " (1, 'down and killed'),\n",
              " (1, 'down and'),\n",
              " (1, 'doctors in the'),\n",
              " (1, 'doctors in'),\n",
              " (1, 'discovery of new'),\n",
              " (1, 'discovery of another'),\n",
              " (1, 'died on july'),\n",
              " (1, 'died on'),\n",
              " (1, 'devoted herself to'),\n",
              " (1, 'devoted herself'),\n",
              " (1, 'development of rays'),\n",
              " (1, 'development of'),\n",
              " (1, 'despite her success'),\n",
              " (1, 'despite her'),\n",
              " (1, 'daughter of teacher'),\n",
              " (1, 'daughter of'),\n",
              " (1, 'daughter irene was'),\n",
              " (1, 'daughter irene'),\n",
              " (1, 'cut short in'),\n",
              " (1, 'cut short'),\n",
              " (1, 'curies worked together'),\n",
              " (1, 'curies worked'),\n",
              " (1, 'curies eldest daughter'),\n",
              " (1, 'curies eldest'),\n",
              " (1, 'curies announced the'),\n",
              " (1, 'curies announced'),\n",
              " (1, 'curies along with'),\n",
              " (1, 'curies along'),\n",
              " (1, 'curie was polish'),\n",
              " (1, 'curie was'),\n",
              " (1, 'curie research was'),\n",
              " (1, 'curie research'),\n",
              " (1, 'curie professor of'),\n",
              " (1, 'curie professor'),\n",
              " (1, 'curie helped to'),\n",
              " (1, 'curie helped'),\n",
              " (1, 'crucial in the'),\n",
              " (1, 'crucial in'),\n",
              " (1, 'cross made her'),\n",
              " (1, 'cross made'),\n",
              " (1, 'courses for medical'),\n",
              " (1, 'courses for'),\n",
              " (1, 'continuing the work'),\n",
              " (1, 'continuing the'),\n",
              " (1, 'continued to face'),\n",
              " (1, 'continued to'),\n",
              " (1, 'chemistry in 1911'),\n",
              " (1, 'chemistry in'),\n",
              " (1, 'chemist and one'),\n",
              " (1, 'chemist and'),\n",
              " (1, 'chemical element polonium'),\n",
              " (1, 'chemical element'),\n",
              " (1, 'caused by exposure'),\n",
              " (1, 'caused by'),\n",
              " (1, 'by the late'),\n",
              " (1, 'by the'),\n",
              " (1, 'by exposure to'),\n",
              " (1, 'by exposure'),\n",
              " (1, 'by carriage'),\n",
              " (1, 'building on the'),\n",
              " (1, 'building on'),\n",
              " (1, 'born physicist and'),\n",
              " (1, 'born physicist'),\n",
              " (1, 'born in warsaw'),\n",
              " (1, 'born in'),\n",
              " (1, 'benefits from her'),\n",
              " (1, 'benefits from'),\n",
              " (1, 'begun together'),\n",
              " (1, 'beginning to deteriorate'),\n",
              " (1, 'beginning to'),\n",
              " (1, 'becquerel were awarded'),\n",
              " (1, 'becquerel were'),\n",
              " (1, 'becoming the first'),\n",
              " (1, 'becoming the'),\n",
              " (1, 'at the end'),\n",
              " (1, 'another radium'),\n",
              " (1, 'another in 1911'),\n",
              " (1, 'another in'),\n",
              " (1, 'and winner of'),\n",
              " (1, 'and winner'),\n",
              " (1, 'and the french'),\n",
              " (1, 'and the'),\n",
              " (1, 'and she went'),\n",
              " (1, 'and she never'),\n",
              " (1, 'and she held'),\n",
              " (1, 'and one of'),\n",
              " (1, 'and one'),\n",
              " (1, 'and mathematics at'),\n",
              " (1, 'and mathematics'),\n",
              " (1, 'and killed by'),\n",
              " (1, 'and killed'),\n",
              " (1, 'and doctors in'),\n",
              " (1, 'and doctors'),\n",
              " (1, 'and devoted herself'),\n",
              " (1, 'and devoted'),\n",
              " (1, 'and chemist and'),\n",
              " (1, 'and chemist'),\n",
              " (1, 'ambulances with ray'),\n",
              " (1, 'ambulances with'),\n",
              " (1, 'along with becquerel'),\n",
              " (1, 'along with'),\n",
              " (1, '1934 from leukaemia'),\n",
              " (1, '1934 from'),\n",
              " (1, '1920s her health'),\n",
              " (1, '1920s her'),\n",
              " (1, '1906 when he'),\n",
              " (1, '1906 when'),\n",
              " (1, '1903 and she'),\n",
              " (1, '1903 and'),\n",
              " (1, '1898 the curies'),\n",
              " (1, '1898 the'),\n",
              " (1, '1891 she went'),\n",
              " (1, '1891 she'),\n",
              " (1, '1867 the daughter'),\n",
              " (1, '1867 the')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_word_list = sorted([(word_count[i], n_gram) for n_gram, i in vocabulary.items()], reverse=True)\n",
        "\n",
        "sorted_word_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxT78V5HmAEv"
      },
      "source": [
        "### Using nltk to find ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I1CR8nZmAEw",
        "outputId": "81a7d09e-36f0-4cfd-ffd4-19af12239d6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A bird in hand is worth two in the bush.',\n",
              " 'Good things come to those who wait.',\n",
              " 'These watches cost $1500! ',\n",
              " 'There are other fish in the sea.',\n",
              " 'The ball is in your court.',\n",
              " 'Mr. Smith Goes to Washington ',\n",
              " 'Doogie Howser M.D.']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_lKlpTHmAEw"
      },
      "outputs": [],
      "source": [
        "from nltk import bigrams\n",
        "from nltk import trigrams\n",
        "\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7-IHVtomAEx",
        "outputId": "a2416235-9fc0-4f62-ee18-7c3d52d2a361"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A',\n",
              " 'bird',\n",
              " 'in',\n",
              " 'hand',\n",
              " 'is',\n",
              " 'worth',\n",
              " 'two',\n",
              " 'in',\n",
              " 'the',\n",
              " 'bush',\n",
              " '.',\n",
              " 'Good',\n",
              " 'things',\n",
              " 'come',\n",
              " 'to',\n",
              " 'those',\n",
              " 'who',\n",
              " 'wait',\n",
              " '.',\n",
              " 'These',\n",
              " 'watches',\n",
              " 'cost',\n",
              " '$',\n",
              " '1500',\n",
              " '!',\n",
              " 'There',\n",
              " 'are',\n",
              " 'other',\n",
              " 'fish',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sea',\n",
              " '.',\n",
              " 'The',\n",
              " 'ball',\n",
              " 'is',\n",
              " 'in',\n",
              " 'your',\n",
              " 'court',\n",
              " '.',\n",
              " 'Mr.',\n",
              " 'Smith',\n",
              " 'Goes',\n",
              " 'to',\n",
              " 'Washington',\n",
              " 'Doogie',\n",
              " 'Howser',\n",
              " 'M.D',\n",
              " '.']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = word_tokenize(\" \".join(train_text))\n",
        "\n",
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODh0WlFamAEx",
        "outputId": "e774ff77-2670-45e6-8948-64d14dc8abd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'bird'),\n",
              " ('bird', 'in'),\n",
              " ('in', 'hand'),\n",
              " ('hand', 'is'),\n",
              " ('is', 'worth'),\n",
              " ('worth', 'two'),\n",
              " ('two', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'bush'),\n",
              " ('bush', '.'),\n",
              " ('.', 'Good'),\n",
              " ('Good', 'things'),\n",
              " ('things', 'come'),\n",
              " ('come', 'to'),\n",
              " ('to', 'those'),\n",
              " ('those', 'who'),\n",
              " ('who', 'wait'),\n",
              " ('wait', '.'),\n",
              " ('.', 'These'),\n",
              " ('These', 'watches'),\n",
              " ('watches', 'cost'),\n",
              " ('cost', '$'),\n",
              " ('$', '1500'),\n",
              " ('1500', '!'),\n",
              " ('!', 'There'),\n",
              " ('There', 'are'),\n",
              " ('are', 'other'),\n",
              " ('other', 'fish'),\n",
              " ('fish', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'sea'),\n",
              " ('sea', '.'),\n",
              " ('.', 'The'),\n",
              " ('The', 'ball'),\n",
              " ('ball', 'is'),\n",
              " ('is', 'in'),\n",
              " ('in', 'your'),\n",
              " ('your', 'court'),\n",
              " ('court', '.'),\n",
              " ('.', 'Mr.'),\n",
              " ('Mr.', 'Smith'),\n",
              " ('Smith', 'Goes'),\n",
              " ('Goes', 'to'),\n",
              " ('to', 'Washington'),\n",
              " ('Washington', 'Doogie'),\n",
              " ('Doogie', 'Howser'),\n",
              " ('Howser', 'M.D'),\n",
              " ('M.D', '.')]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_bigrams = bigrams(word_tokens)\n",
        "\n",
        "list(nltk_bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh7SXHuxmAEy",
        "outputId": "ae57527b-93fd-47bb-a3c0-f3eb2e1e0e05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'bird', 'in'),\n",
              " ('bird', 'in', 'hand'),\n",
              " ('in', 'hand', 'is'),\n",
              " ('hand', 'is', 'worth'),\n",
              " ('is', 'worth', 'two'),\n",
              " ('worth', 'two', 'in'),\n",
              " ('two', 'in', 'the'),\n",
              " ('in', 'the', 'bush'),\n",
              " ('the', 'bush', '.'),\n",
              " ('bush', '.', 'Good'),\n",
              " ('.', 'Good', 'things'),\n",
              " ('Good', 'things', 'come'),\n",
              " ('things', 'come', 'to'),\n",
              " ('come', 'to', 'those'),\n",
              " ('to', 'those', 'who'),\n",
              " ('those', 'who', 'wait'),\n",
              " ('who', 'wait', '.'),\n",
              " ('wait', '.', 'These'),\n",
              " ('.', 'These', 'watches'),\n",
              " ('These', 'watches', 'cost'),\n",
              " ('watches', 'cost', '$'),\n",
              " ('cost', '$', '1500'),\n",
              " ('$', '1500', '!'),\n",
              " ('1500', '!', 'There'),\n",
              " ('!', 'There', 'are'),\n",
              " ('There', 'are', 'other'),\n",
              " ('are', 'other', 'fish'),\n",
              " ('other', 'fish', 'in'),\n",
              " ('fish', 'in', 'the'),\n",
              " ('in', 'the', 'sea'),\n",
              " ('the', 'sea', '.'),\n",
              " ('sea', '.', 'The'),\n",
              " ('.', 'The', 'ball'),\n",
              " ('The', 'ball', 'is'),\n",
              " ('ball', 'is', 'in'),\n",
              " ('is', 'in', 'your'),\n",
              " ('in', 'your', 'court'),\n",
              " ('your', 'court', '.'),\n",
              " ('court', '.', 'Mr.'),\n",
              " ('.', 'Mr.', 'Smith'),\n",
              " ('Mr.', 'Smith', 'Goes'),\n",
              " ('Smith', 'Goes', 'to'),\n",
              " ('Goes', 'to', 'Washington'),\n",
              " ('to', 'Washington', 'Doogie'),\n",
              " ('Washington', 'Doogie', 'Howser'),\n",
              " ('Doogie', 'Howser', 'M.D'),\n",
              " ('Howser', 'M.D', '.')]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_trigrams = trigrams(word_tokens)\n",
        "\n",
        "list(nltk_trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdf261SlmAEy",
        "outputId": "77098f97-11dc-4689-8882-c682004ffb6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('A', 'bird', 'in', 'hand', 'is')\n",
            "('bird', 'in', 'hand', 'is', 'worth')\n",
            "('in', 'hand', 'is', 'worth', 'two')\n",
            "('hand', 'is', 'worth', 'two', 'in')\n",
            "('is', 'worth', 'two', 'in', 'the')\n",
            "('worth', 'two', 'in', 'the', 'bush')\n",
            "('two', 'in', 'the', 'bush', '.')\n",
            "('in', 'the', 'bush', '.', 'Good')\n",
            "('the', 'bush', '.', 'Good', 'things')\n",
            "('bush', '.', 'Good', 'things', 'come')\n",
            "('.', 'Good', 'things', 'come', 'to')\n",
            "('Good', 'things', 'come', 'to', 'those')\n",
            "('things', 'come', 'to', 'those', 'who')\n",
            "('come', 'to', 'those', 'who', 'wait')\n",
            "('to', 'those', 'who', 'wait', '.')\n",
            "('those', 'who', 'wait', '.', 'These')\n",
            "('who', 'wait', '.', 'These', 'watches')\n",
            "('wait', '.', 'These', 'watches', 'cost')\n",
            "('.', 'These', 'watches', 'cost', '$')\n",
            "('These', 'watches', 'cost', '$', '1500')\n",
            "('watches', 'cost', '$', '1500', '!')\n",
            "('cost', '$', '1500', '!', 'There')\n",
            "('$', '1500', '!', 'There', 'are')\n",
            "('1500', '!', 'There', 'are', 'other')\n",
            "('!', 'There', 'are', 'other', 'fish')\n",
            "('There', 'are', 'other', 'fish', 'in')\n",
            "('are', 'other', 'fish', 'in', 'the')\n",
            "('other', 'fish', 'in', 'the', 'sea')\n",
            "('fish', 'in', 'the', 'sea', '.')\n",
            "('in', 'the', 'sea', '.', 'The')\n",
            "('the', 'sea', '.', 'The', 'ball')\n",
            "('sea', '.', 'The', 'ball', 'is')\n",
            "('.', 'The', 'ball', 'is', 'in')\n",
            "('The', 'ball', 'is', 'in', 'your')\n",
            "('ball', 'is', 'in', 'your', 'court')\n",
            "('is', 'in', 'your', 'court', '.')\n",
            "('in', 'your', 'court', '.', 'Mr.')\n",
            "('your', 'court', '.', 'Mr.', 'Smith')\n",
            "('court', '.', 'Mr.', 'Smith', 'Goes')\n",
            "('.', 'Mr.', 'Smith', 'Goes', 'to')\n",
            "('Mr.', 'Smith', 'Goes', 'to', 'Washington')\n",
            "('Smith', 'Goes', 'to', 'Washington', 'Doogie')\n",
            "('Goes', 'to', 'Washington', 'Doogie', 'Howser')\n",
            "('to', 'Washington', 'Doogie', 'Howser', 'M.D')\n",
            "('Washington', 'Doogie', 'Howser', 'M.D', '.')\n"
          ]
        }
      ],
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "fivegrams = ngrams(word_tokens, 5)\n",
        "\n",
        "for grams in fivegrams:\n",
        "    print(grams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1dT0L5EmAEz"
      },
      "source": [
        "* https://tedboy.github.io/nlps/generated/generated/nltk.BigramAssocMeasures\n",
        "* http://www.nltk.org/_modules/nltk/collocations.html#BigramCollocationFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3ffJ9PcmAE0"
      },
      "outputs": [],
      "source": [
        "from nltk.collocations import BigramAssocMeasures\n",
        "from nltk.collocations import BigramCollocationFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgYEWKpxmAE1"
      },
      "outputs": [],
      "source": [
        "word_tokens = word_tokenize(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrNQFP0rmAE2",
        "outputId": "334936a2-a92d-46cb-eebb-374267126d80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('.', 'The'),\n",
              " ('of', 'the'),\n",
              " ('Nobel', 'Prize'),\n",
              " (',', 'and'),\n",
              " ('The', 'Curies'),\n",
              " ('and', 'she'),\n",
              " ('the', 'Nobel')]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_measures = BigramAssocMeasures()\n",
        "\n",
        "finder = BigramCollocationFinder.from_words(word_tokens)\n",
        "\n",
        "finder.apply_freq_filter(3)\n",
        "\n",
        "matches = finder.nbest(bigram_measures.raw_freq, 15)\n",
        "\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vnr2EegjmAE3",
        "outputId": "fc95a9ba-06a6-4081-e51e-0c8d331094f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('.', 'The'),\n",
              " ('of', 'the'),\n",
              " ('Nobel', 'Prize'),\n",
              " (',', 'and'),\n",
              " ('The', 'Curies'),\n",
              " ('and', 'she'),\n",
              " ('the', 'Nobel'),\n",
              " (',', 'she'),\n",
              " (',', 'the'),\n",
              " ('.', 'In'),\n",
              " ('.', 'Marie'),\n",
              " ('.', 'She'),\n",
              " ('1911', '.'),\n",
              " ('Prize', 'for'),\n",
              " ('announced', 'the')]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_measures = BigramAssocMeasures()\n",
        "\n",
        "finder = BigramCollocationFinder.from_words(word_tokens)\n",
        "\n",
        "finder.apply_freq_filter(2)\n",
        "\n",
        "matches = finder.nbest(bigram_measures.raw_freq, 15)\n",
        "\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8VmI8pjmAE4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMN7rVMPmAE4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfoqGjmfmAE5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN0blMBFmAE6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jUqyfElmAE6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-G-t_EdmAE7"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 04-VectorizeText_TfidfTransformer_TfidfVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcA9MbnTmAE8"
      },
      "source": [
        "<b>TfidfTransformer</b> :\n",
        "\n",
        "* Transform a count matrix to a normalized tf or tf-idf representation\n",
        "* Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWDuUv4WmAE9"
      },
      "source": [
        "* A <b>Term Frequency</b> is a count of how many times a word occurs in a given document (synonymous with bag of words).\n",
        "* The <b>Inverse Document Frequency</b> is the the number of times a word occurs in a corpus of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcwUiXYQmAE-"
      },
      "source": [
        "The first step is to create our training and testing document set and computing the term frequency matrix\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0klCyXTzmAE-"
      },
      "source": [
        "### Creating a count vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl5H1BZzmAE_"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btI_Yx61mAFA"
      },
      "outputs": [],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "frequency_term_matrix = count_vectorizer.fit_transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftASdxvHmAFA",
        "outputId": "571dec7f-b989-410b-f39b-0f686249f5c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OM8SZbNmAFB",
        "outputId": "e69be31d-75f0-4214-81a1-d1e315f23fc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_term_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38eVbQwImAFC",
        "outputId": "b17ec0db-dd08-404d-d5cb-43f2692c4552"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_term_matrix.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWl-vxRxmAFD"
      },
      "source": [
        "### Building the tf-idf matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A9PANHnmAFE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qdaUN8PmAFE",
        "outputId": "cb562035-5557-4343-85d8-9acbe1475b7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector1 = tfidf_transformer.fit_transform(frequency_term_matrix)\n",
        "\n",
        "tfidf_vector1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPFAJ4bNmAFF",
        "outputId": "54662981-05b9-4afd-8bdb-c1626641cc85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.34908308, 0.34908308,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34908308, 0.        , 0.49536976,\n",
              "        0.28976893, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24768488, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38665001, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.38665001, 0.38665001,\n",
              "        0.32095271, 0.        , 0.38665001, 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.40801493,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28949879,\n",
              "        0.        , 0.        , 0.40801493, 0.40801493, 0.        ,\n",
              "        0.28949879, 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.3274243 ,\n",
              "        0.38305686, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3274243 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46180424, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46180424, 0.        , 0.        , 0.46180424,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38333718, 0.        , 0.        , 0.46180424, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector1.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW0WCjc7mAFG",
        "outputId": "498cba2c-082a-41ca-fadc-a04d0d660788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.34908308 0.34908308 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.34908308 0.         0.49536976 0.28976893 0.         0.\n",
            "  0.         0.         0.24768488 0.         0.         0.\n",
            "  0.         0.         0.34908308 0.         0.         0.\n",
            "  0.         0.34908308 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.38665001\n",
            "  0.         0.         0.         0.         0.         0.38665001\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.38665001\n",
            "  0.38665001 0.32095271 0.         0.38665001 0.         0.\n",
            "  0.38665001 0.         0.        ]\n",
            " [0.5        0.         0.         0.         0.         0.\n",
            "  0.5        0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.5        0.\n",
            "  0.         0.         0.         0.         0.         0.5\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.40801493 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.40801493 0.         0.\n",
            "  0.         0.         0.28949879 0.         0.         0.40801493\n",
            "  0.40801493 0.         0.28949879 0.40801493 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.46146654 0.         0.         0.\n",
            "  0.         0.46146654 0.         0.         0.         0.\n",
            "  0.         0.         0.3274243  0.38305686 0.         0.\n",
            "  0.         0.         0.3274243  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.46146654]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.46180424 0.\n",
            "  0.         0.         0.         0.         0.46180424 0.\n",
            "  0.         0.46180424 0.         0.         0.         0.\n",
            "  0.         0.38333718 0.         0.         0.46180424 0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.70710678 0.         0.         0.\n",
            "  0.         0.70710678 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector1.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NslKS7MQmAFH"
      },
      "source": [
        "## TfidfVectorizer = CountVectorizer + TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXuAfmS3mAFH"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itOT0BOsmAFI",
        "outputId": "001a5aab-0cc8-4136-ec86-82e3f3819042"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 3,\n",
              " 'in': 14,\n",
              " 'hand': 12,\n",
              " 'is': 15,\n",
              " 'worth': 31,\n",
              " 'two': 26,\n",
              " 'the': 20,\n",
              " 'bush': 4,\n",
              " 'good': 11,\n",
              " 'things': 23,\n",
              " 'come': 5,\n",
              " 'to': 25,\n",
              " 'those': 24,\n",
              " 'who': 30,\n",
              " 'wait': 27,\n",
              " 'these': 22,\n",
              " 'watches': 29,\n",
              " 'cost': 6,\n",
              " '1500': 0,\n",
              " 'there': 21,\n",
              " 'are': 1,\n",
              " 'other': 17,\n",
              " 'fish': 9,\n",
              " 'sea': 18,\n",
              " 'ball': 2,\n",
              " 'your': 32,\n",
              " 'court': 7,\n",
              " 'mr': 16,\n",
              " 'smith': 19,\n",
              " 'goes': 10,\n",
              " 'washington': 28,\n",
              " 'doogie': 8,\n",
              " 'howser': 13}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2 = tfidf_vectorizer.fit_transform(train_text)\n",
        "\n",
        "tfidf_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrvfRdZ6mAFJ",
        "outputId": "7509424b-8c43-464b-bbb7-2844a1e1f693"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSTSDsC-mAFJ",
        "outputId": "9fba7878-200b-4b63-a19d-cb8cea0cdbf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.38629436, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436, 2.38629436, 1.69314718,\n",
              "       1.98082925, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       1.69314718, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       1.98082925, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer.idf_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgfUJuknmAFK",
        "outputId": "650738cf-793d-4320-cc2f-25d5ce20500b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'1500': 2.386294361119891,\n",
              " 'are': 2.386294361119891,\n",
              " 'ball': 2.386294361119891,\n",
              " 'bird': 2.386294361119891,\n",
              " 'bush': 2.386294361119891,\n",
              " 'come': 2.386294361119891,\n",
              " 'cost': 2.386294361119891,\n",
              " 'court': 2.386294361119891,\n",
              " 'doogie': 2.386294361119891,\n",
              " 'fish': 2.386294361119891,\n",
              " 'goes': 2.386294361119891,\n",
              " 'good': 2.386294361119891,\n",
              " 'hand': 2.386294361119891,\n",
              " 'howser': 2.386294361119891,\n",
              " 'in': 1.6931471805599454,\n",
              " 'is': 1.9808292530117262,\n",
              " 'mr': 2.386294361119891,\n",
              " 'other': 2.386294361119891,\n",
              " 'sea': 2.386294361119891,\n",
              " 'smith': 2.386294361119891,\n",
              " 'the': 1.6931471805599454,\n",
              " 'there': 2.386294361119891,\n",
              " 'these': 2.386294361119891,\n",
              " 'things': 2.386294361119891,\n",
              " 'those': 2.386294361119891,\n",
              " 'to': 1.9808292530117262,\n",
              " 'two': 2.386294361119891,\n",
              " 'wait': 2.386294361119891,\n",
              " 'washington': 2.386294361119891,\n",
              " 'watches': 2.386294361119891,\n",
              " 'who': 2.386294361119891,\n",
              " 'worth': 2.386294361119891,\n",
              " 'your': 2.386294361119891}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "212iYb_cmAFK"
      },
      "source": [
        "### Final scorings of each word from the other words in the vocabulary.\n",
        "* The scores are normalized to values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHqlNQy9mAFL",
        "outputId": "1acf51d9-0d28-4d49-dc25-0ac1fb454852"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.34908308, 0.34908308,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34908308, 0.        , 0.49536976,\n",
              "        0.28976893, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24768488, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38665001, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.38665001, 0.38665001,\n",
              "        0.32095271, 0.        , 0.38665001, 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.40801493,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28949879,\n",
              "        0.        , 0.        , 0.40801493, 0.40801493, 0.        ,\n",
              "        0.28949879, 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.3274243 ,\n",
              "        0.38305686, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3274243 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46180424, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46180424, 0.        , 0.        , 0.46180424,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38333718, 0.        , 0.        , 0.46180424, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDJdcX0qmAFL",
        "outputId": "b67a16be-5e33-4fb6-9d30-7db4d580624f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3)\t0.3490830767264469\n",
            "  (0, 14)\t0.49536975552604884\n",
            "  (0, 12)\t0.3490830767264469\n",
            "  (0, 15)\t0.2897689326921819\n",
            "  (0, 31)\t0.3490830767264469\n",
            "  (0, 26)\t0.3490830767264469\n",
            "  (0, 20)\t0.24768487776302442\n",
            "  (0, 4)\t0.3490830767264469\n",
            "  (1, 11)\t0.386650005027498\n",
            "  (1, 23)\t0.386650005027498\n",
            "  (1, 5)\t0.386650005027498\n",
            "  (1, 25)\t0.32095270940344806\n",
            "  (1, 24)\t0.386650005027498\n",
            "  (1, 30)\t0.386650005027498\n",
            "  (1, 27)\t0.386650005027498\n",
            "  (2, 22)\t0.5\n",
            "  (2, 29)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (2, 0)\t0.5\n",
            "  (3, 14)\t0.2894987873064995\n",
            "  (3, 20)\t0.2894987873064995\n",
            "  (3, 21)\t0.40801492725049476\n",
            "  (3, 1)\t0.40801492725049476\n",
            "  (3, 17)\t0.40801492725049476\n",
            "  (3, 9)\t0.40801492725049476\n",
            "  (3, 18)\t0.40801492725049476\n",
            "  (4, 14)\t0.3274243027464032\n",
            "  (4, 15)\t0.38305685676572565\n",
            "  (4, 20)\t0.3274243027464032\n",
            "  (4, 2)\t0.4614665377636916\n",
            "  (4, 32)\t0.4614665377636916\n",
            "  (4, 7)\t0.4614665377636916\n",
            "  (5, 25)\t0.38333717539523177\n",
            "  (5, 16)\t0.4618042361109319\n",
            "  (5, 19)\t0.4618042361109319\n",
            "  (5, 10)\t0.4618042361109319\n",
            "  (5, 28)\t0.4618042361109319\n",
            "  (6, 8)\t0.7071067811865476\n",
            "  (6, 13)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWmmQOGamAFM",
        "outputId": "8054f0f4-ee04-4e4d-8b01-9f1ac04f9767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 31)\t0.34908307672644684\n",
            "  (0, 26)\t0.34908307672644684\n",
            "  (0, 20)\t0.2476848777630244\n",
            "  (0, 15)\t0.2897689326921819\n",
            "  (0, 14)\t0.4953697555260488\n",
            "  (0, 12)\t0.34908307672644684\n",
            "  (0, 4)\t0.34908307672644684\n",
            "  (0, 3)\t0.34908307672644684\n",
            "  (1, 30)\t0.386650005027498\n",
            "  (1, 27)\t0.386650005027498\n",
            "  (1, 25)\t0.32095270940344806\n",
            "  (1, 24)\t0.386650005027498\n",
            "  (1, 23)\t0.386650005027498\n",
            "  (1, 11)\t0.386650005027498\n",
            "  (1, 5)\t0.386650005027498\n",
            "  (2, 29)\t0.5\n",
            "  (2, 22)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (2, 0)\t0.5\n",
            "  (3, 21)\t0.40801492725049476\n",
            "  (3, 20)\t0.2894987873064995\n",
            "  (3, 18)\t0.40801492725049476\n",
            "  (3, 17)\t0.40801492725049476\n",
            "  (3, 14)\t0.2894987873064995\n",
            "  (3, 9)\t0.40801492725049476\n",
            "  (3, 1)\t0.40801492725049476\n",
            "  (4, 32)\t0.4614665377636916\n",
            "  (4, 20)\t0.3274243027464032\n",
            "  (4, 15)\t0.38305685676572565\n",
            "  (4, 14)\t0.3274243027464032\n",
            "  (4, 7)\t0.4614665377636916\n",
            "  (4, 2)\t0.4614665377636916\n",
            "  (5, 28)\t0.4618042361109319\n",
            "  (5, 25)\t0.38333717539523177\n",
            "  (5, 19)\t0.4618042361109319\n",
            "  (5, 16)\t0.4618042361109319\n",
            "  (5, 10)\t0.4618042361109319\n",
            "  (6, 13)\t0.7071067811865476\n",
            "  (6, 8)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soHWP701mAFM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q2zE-iBmAFN"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 05-StopwordAndFrequencyFiltering</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0CsuGmCmAFN"
      },
      "source": [
        "## Remove Stop Words Using NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZupMYKRmAFN"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4S3eEmDmAFO",
        "outputId": "38ba63b6-e399-4c02-b3a6-28cb4fdfc164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['arabic', 'azerbaijani', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish', 'turkish']\n"
          ]
        }
      ],
      "source": [
        "print(stopwords.fileids())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkp6wirEmAFO",
        "outputId": "a13167ca-9020-4b65-8148-59efef9e6e63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpWZvVD5mAFP",
        "outputId": "100ef2c1-45e3-44e2-efbe-b85a4397efd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['إذ',\n",
              " 'إذا',\n",
              " 'إذما',\n",
              " 'إذن',\n",
              " 'أف',\n",
              " 'أقل',\n",
              " 'أكثر',\n",
              " 'ألا',\n",
              " 'إلا',\n",
              " 'التي',\n",
              " 'الذي',\n",
              " 'الذين',\n",
              " 'اللاتي',\n",
              " 'اللائي',\n",
              " 'اللتان',\n",
              " 'اللتيا',\n",
              " 'اللتين',\n",
              " 'اللذان',\n",
              " 'اللذين',\n",
              " 'اللواتي',\n",
              " 'إلى',\n",
              " 'إليك',\n",
              " 'إليكم',\n",
              " 'إليكما',\n",
              " 'إليكن',\n",
              " 'أم',\n",
              " 'أما',\n",
              " 'أما',\n",
              " 'إما',\n",
              " 'أن',\n",
              " 'إن',\n",
              " 'إنا',\n",
              " 'أنا',\n",
              " 'أنت',\n",
              " 'أنتم',\n",
              " 'أنتما',\n",
              " 'أنتن',\n",
              " 'إنما',\n",
              " 'إنه',\n",
              " 'أنى',\n",
              " 'أنى',\n",
              " 'آه',\n",
              " 'آها',\n",
              " 'أو',\n",
              " 'أولاء',\n",
              " 'أولئك',\n",
              " 'أوه',\n",
              " 'آي',\n",
              " 'أي',\n",
              " 'أيها',\n",
              " 'إي',\n",
              " 'أين',\n",
              " 'أين',\n",
              " 'أينما',\n",
              " 'إيه',\n",
              " 'بخ',\n",
              " 'بس',\n",
              " 'بعد',\n",
              " 'بعض',\n",
              " 'بك',\n",
              " 'بكم',\n",
              " 'بكم',\n",
              " 'بكما',\n",
              " 'بكن',\n",
              " 'بل',\n",
              " 'بلى',\n",
              " 'بما',\n",
              " 'بماذا',\n",
              " 'بمن',\n",
              " 'بنا',\n",
              " 'به',\n",
              " 'بها',\n",
              " 'بهم',\n",
              " 'بهما',\n",
              " 'بهن',\n",
              " 'بي',\n",
              " 'بين',\n",
              " 'بيد',\n",
              " 'تلك',\n",
              " 'تلكم',\n",
              " 'تلكما',\n",
              " 'ته',\n",
              " 'تي',\n",
              " 'تين',\n",
              " 'تينك',\n",
              " 'ثم',\n",
              " 'ثمة',\n",
              " 'حاشا',\n",
              " 'حبذا',\n",
              " 'حتى',\n",
              " 'حيث',\n",
              " 'حيثما',\n",
              " 'حين',\n",
              " 'خلا',\n",
              " 'دون',\n",
              " 'ذا',\n",
              " 'ذات',\n",
              " 'ذاك',\n",
              " 'ذان',\n",
              " 'ذانك',\n",
              " 'ذلك',\n",
              " 'ذلكم',\n",
              " 'ذلكما',\n",
              " 'ذلكن',\n",
              " 'ذه',\n",
              " 'ذو',\n",
              " 'ذوا',\n",
              " 'ذواتا',\n",
              " 'ذواتي',\n",
              " 'ذي',\n",
              " 'ذين',\n",
              " 'ذينك',\n",
              " 'ريث',\n",
              " 'سوف',\n",
              " 'سوى',\n",
              " 'شتان',\n",
              " 'عدا',\n",
              " 'عسى',\n",
              " 'عل',\n",
              " 'على',\n",
              " 'عليك',\n",
              " 'عليه',\n",
              " 'عما',\n",
              " 'عن',\n",
              " 'عند',\n",
              " 'غير',\n",
              " 'فإذا',\n",
              " 'فإن',\n",
              " 'فلا',\n",
              " 'فمن',\n",
              " 'في',\n",
              " 'فيم',\n",
              " 'فيما',\n",
              " 'فيه',\n",
              " 'فيها',\n",
              " 'قد',\n",
              " 'كأن',\n",
              " 'كأنما',\n",
              " 'كأي',\n",
              " 'كأين',\n",
              " 'كذا',\n",
              " 'كذلك',\n",
              " 'كل',\n",
              " 'كلا',\n",
              " 'كلاهما',\n",
              " 'كلتا',\n",
              " 'كلما',\n",
              " 'كليكما',\n",
              " 'كليهما',\n",
              " 'كم',\n",
              " 'كم',\n",
              " 'كما',\n",
              " 'كي',\n",
              " 'كيت',\n",
              " 'كيف',\n",
              " 'كيفما',\n",
              " 'لا',\n",
              " 'لاسيما',\n",
              " 'لدى',\n",
              " 'لست',\n",
              " 'لستم',\n",
              " 'لستما',\n",
              " 'لستن',\n",
              " 'لسن',\n",
              " 'لسنا',\n",
              " 'لعل',\n",
              " 'لك',\n",
              " 'لكم',\n",
              " 'لكما',\n",
              " 'لكن',\n",
              " 'لكنما',\n",
              " 'لكي',\n",
              " 'لكيلا',\n",
              " 'لم',\n",
              " 'لما',\n",
              " 'لن',\n",
              " 'لنا',\n",
              " 'له',\n",
              " 'لها',\n",
              " 'لهم',\n",
              " 'لهما',\n",
              " 'لهن',\n",
              " 'لو',\n",
              " 'لولا',\n",
              " 'لوما',\n",
              " 'لي',\n",
              " 'لئن',\n",
              " 'ليت',\n",
              " 'ليس',\n",
              " 'ليسا',\n",
              " 'ليست',\n",
              " 'ليستا',\n",
              " 'ليسوا',\n",
              " 'ما',\n",
              " 'ماذا',\n",
              " 'متى',\n",
              " 'مذ',\n",
              " 'مع',\n",
              " 'مما',\n",
              " 'ممن',\n",
              " 'من',\n",
              " 'منه',\n",
              " 'منها',\n",
              " 'منذ',\n",
              " 'مه',\n",
              " 'مهما',\n",
              " 'نحن',\n",
              " 'نحو',\n",
              " 'نعم',\n",
              " 'ها',\n",
              " 'هاتان',\n",
              " 'هاته',\n",
              " 'هاتي',\n",
              " 'هاتين',\n",
              " 'هاك',\n",
              " 'هاهنا',\n",
              " 'هذا',\n",
              " 'هذان',\n",
              " 'هذه',\n",
              " 'هذي',\n",
              " 'هذين',\n",
              " 'هكذا',\n",
              " 'هل',\n",
              " 'هلا',\n",
              " 'هم',\n",
              " 'هما',\n",
              " 'هن',\n",
              " 'هنا',\n",
              " 'هناك',\n",
              " 'هنالك',\n",
              " 'هو',\n",
              " 'هؤلاء',\n",
              " 'هي',\n",
              " 'هيا',\n",
              " 'هيت',\n",
              " 'هيهات',\n",
              " 'والذي',\n",
              " 'والذين',\n",
              " 'وإذ',\n",
              " 'وإذا',\n",
              " 'وإن',\n",
              " 'ولا',\n",
              " 'ولكن',\n",
              " 'ولو',\n",
              " 'وما',\n",
              " 'ومن',\n",
              " 'وهو',\n",
              " 'يا']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords.words('arabic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3k7s27QmAFP",
        "outputId": "5fbaa5d2-ed8d-42a2-fa9a-a86d52e23513"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A bird in hand is worth two in the bush. Good things come to those who wait. These watches cost $1500!  There are other fish in the sea. The ball is in your court. Mr. Smith Goes to Washington  Doogie Howser M.D.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_array = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]\n",
        "\n",
        "text = \" \".join(text_array)\n",
        "\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v04cFggOmAFQ",
        "outputId": "431764b7-2ef9-438b-cf5b-ea96682833ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A',\n",
              " 'bird',\n",
              " 'in',\n",
              " 'hand',\n",
              " 'is',\n",
              " 'worth',\n",
              " 'two',\n",
              " 'in',\n",
              " 'the',\n",
              " 'bush',\n",
              " '.',\n",
              " 'Good',\n",
              " 'things',\n",
              " 'come',\n",
              " 'to',\n",
              " 'those',\n",
              " 'who',\n",
              " 'wait',\n",
              " '.',\n",
              " 'These',\n",
              " 'watches',\n",
              " 'cost',\n",
              " '$',\n",
              " '1500',\n",
              " '!',\n",
              " 'There',\n",
              " 'are',\n",
              " 'other',\n",
              " 'fish',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sea',\n",
              " '.',\n",
              " 'The',\n",
              " 'ball',\n",
              " 'is',\n",
              " 'in',\n",
              " 'your',\n",
              " 'court',\n",
              " '.',\n",
              " 'Mr.',\n",
              " 'Smith',\n",
              " 'Goes',\n",
              " 'to',\n",
              " 'Washington',\n",
              " 'Doogie',\n",
              " 'Howser',\n",
              " 'M.D',\n",
              " '.']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = word_tokenize(text)\n",
        "\n",
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29SwWNxwmAFQ",
        "outputId": "c5d82565-1c44-41d2-e0b0-81d4c5b5f741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'hand', 'worth', 'two', 'bush', '.', 'Good', 'things', 'come', 'wait', '.', 'These', 'watches', 'cost', '$', '1500', '!', 'There', 'fish', 'sea', '.', 'The', 'ball', 'court', '.', 'Mr.', 'Smith', 'Goes', 'Washington', 'Doogie', 'Howser', 'M.D', '.']\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_words = []\n",
        "\n",
        "for word in word_tokens:\n",
        "    if word not in stop_words:\n",
        "        filtered_words.append(word)\n",
        "\n",
        "print(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxOOAa16mAFR"
      },
      "outputs": [],
      "source": [
        "with open(\"./datasets/file.txt\", \"w\") as f:\n",
        "    for word in filtered_words:\n",
        "        f.write(word)\n",
        "        f.write(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-7ksK2amAFZ",
        "outputId": "77630b0f-c8b2-45e0-ace9-225236a739cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A bird hand worth two bush . Good things come wait . These watches cost $ 1500 ! There fish sea . The ball court . Mr. Smith Goes Washington Doogie Howser M.D . \n"
          ]
        }
      ],
      "source": [
        "with open(\"./datasets/file.txt\", \"r\") as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vbwj1WlmAFZ",
        "outputId": "7138aa55-7c19-4d3a-c881-73bdfbe63eb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit([file_contents])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfdHf4_hmAFa",
        "outputId": "8f2a2636-8f82-4249-b46a-306b6515f08a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 25)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector = count_vectorizer.transform(text_array)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFzLParqmAFa"
      },
      "outputs": [],
      "source": [
        "feature_names_nltk = count_vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrJaFIJbmAFb",
        "outputId": "04f9bcb9-ac92-4f40-8f92-8cccb843fb6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 2,\n",
              " 'hand': 11,\n",
              " 'worth': 24,\n",
              " 'two': 20,\n",
              " 'bush': 3,\n",
              " 'good': 10,\n",
              " 'things': 19,\n",
              " 'come': 4,\n",
              " 'wait': 21,\n",
              " 'these': 18,\n",
              " 'watches': 23,\n",
              " 'cost': 5,\n",
              " '1500': 0,\n",
              " 'there': 17,\n",
              " 'fish': 8,\n",
              " 'sea': 14,\n",
              " 'the': 16,\n",
              " 'ball': 1,\n",
              " 'court': 6,\n",
              " 'mr': 13,\n",
              " 'smith': 15,\n",
              " 'goes': 9,\n",
              " 'washington': 22,\n",
              " 'doogie': 7,\n",
              " 'howser': 12}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1_U0uhgmAFb",
        "outputId": "20ec3a5c-e3a5-4a49-b17f-07614a4f7b3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "        0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D8LDCpXmAFc",
        "outputId": "1cbf3f11-b4de-4cd2-afa3-28e41f33958b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['bird', 'bush', 'hand', 'the', 'two', 'worth'], dtype='<U10'),\n",
              " array(['come', 'good', 'things', 'wait'], dtype='<U10'),\n",
              " array(['1500', 'cost', 'these', 'watches'], dtype='<U10'),\n",
              " array(['fish', 'sea', 'the', 'there'], dtype='<U10'),\n",
              " array(['ball', 'court', 'the'], dtype='<U10'),\n",
              " array(['goes', 'mr', 'smith', 'washington'], dtype='<U10'),\n",
              " array(['doogie', 'howser'], dtype='<U10')]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.inverse_transform(transformed_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFJa17edmAFc"
      },
      "source": [
        "## Remove Stop Words Using sklearn\n",
        "\n",
        "The stop_words='english' parameter is not recommended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3Ext-nBmAFd",
        "outputId": "4e926e68-f214-4869-d0f6-6b353637310a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 21)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(text_array)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hILX2dIDmAFd"
      },
      "outputs": [],
      "source": [
        "feature_names_sklearn = count_vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDyss5LmmAFe",
        "outputId": "8485c9f5-8b37-40c5-b07b-1a993ffcf38f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa7FLrdWmAFe",
        "outputId": "a687e18d-61eb-4f1b-d9b1-f6eb0f9e3033"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['bush', 'worth', 'hand', 'bird'], dtype='<U10'),\n",
              " array(['wait', 'come', 'things', 'good'], dtype='<U10'),\n",
              " array(['1500', 'cost', 'watches'], dtype='<U10'),\n",
              " array(['sea', 'fish'], dtype='<U10'),\n",
              " array(['court', 'ball'], dtype='<U10'),\n",
              " array(['washington', 'goes', 'smith', 'mr'], dtype='<U10'),\n",
              " array(['howser', 'doogie'], dtype='<U10')]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.inverse_transform(transformed_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4giz4LgimAFf"
      },
      "source": [
        "## Set difference of both"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00_PyMPJmAFf"
      },
      "outputs": [],
      "source": [
        "def set_diff(first, second):\n",
        "        second = set(second)\n",
        "        return [item for item in first if item not in second]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7Shj-qdmAFg",
        "outputId": "e4940773-2300-46d8-c4d5-da49972b7e45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_diff(feature_names_sklearn, feature_names_nltk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFxUhGhymAFg",
        "outputId": "af2a34ab-0e1e-47c0-e739-731eea1cf8bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the', 'there', 'these', 'two']"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_diff(feature_names_nltk, feature_names_sklearn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijQnXGMSmAFh"
      },
      "source": [
        "## Filtering words based on frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rtbLjm2mAFh"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups = fetch_20newsgroups(subset='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnPr2ZxtmAFh",
        "outputId": "22f50305-8d34-4098-d980-a6cf4bf16736"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newsgroups.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szZZ_z7kmAFi",
        "outputId": "5d05d63c-7262-4ec2-fdb8-43d1e5254910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(newsgroups.data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ccp97kbmAFi",
        "outputId": "15970caf-5552-4540-f84f-6df618125057"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newsgroups.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uPe2V3WmAFj"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn-feature-extraction-text-countvectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jRd7DnfmAFj",
        "outputId": "18f90f50-ff06-46dc-85a7-659bcde36e1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHqJoitImAFj",
        "outputId": "e421af09-40c7-44d5-e828-ca1c52c82350"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 130094)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0.0, max_df=0.7)\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YM-TiZMmAFk",
        "outputId": "8980dc83-ff16-44da-ea77-1722753afb35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 2155)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0.01, max_df=0.7)\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WxZcLp3mAFl",
        "outputId": "82b7b372-e616-4047-d0b0-a3b4f7039f76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 127701)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0, max_df=100)\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMPpj-aNmAFl",
        "outputId": "7bc39037-3911-4e48-9082-6f4b6d6fda4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 54030)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=2, max_df=100)\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuxUvrvBmAFl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijm6PcJ2mAFm"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 06-Stemming</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CNR9THimAFm"
      },
      "source": [
        "# Stemming Words with NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4hx8PZkmAFm"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.stem import *\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1oFCuM_mAFn"
      },
      "source": [
        "### PorterStemmer\n",
        "* PorterStemmer uses Suffix Stripping to produce stems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeYVx8YOmAFn"
      },
      "outputs": [],
      "source": [
        "input_tokens = ['overwhelming', 'overwhelmingly',\n",
        "                'hushed', 'hush',\n",
        "                'functional', 'functionally',\n",
        "                'lying', 'lied',\n",
        "                'fairly',\n",
        "                'destabilize', 'stability',\n",
        "                'friendship', 'friendships', 'friendly', 'friendless',\n",
        "                'connect', 'connections', 'connected',\n",
        "                'the', 'these', 'those',\n",
        "                'motivational', 'motivate', 'motivating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-cbA2pWmAFo"
      },
      "outputs": [],
      "source": [
        "ps = PorterStemmer()\n",
        "\n",
        "ps_stemmed_tokens = []\n",
        "for token in input_tokens:\n",
        "    ps_stemmed_tokens.append(ps.stem(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRwaxvqimAFo",
        "outputId": "912d9910-5eaf-4add-fcf9-1c5cf98edd9b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Porter Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelmingli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fairli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>destabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friendli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words  Porter Stemmer\n",
              "0     overwhelming       overwhelm\n",
              "1   overwhelmingly  overwhelmingli\n",
              "2           hushed            hush\n",
              "3             hush            hush\n",
              "4       functional        function\n",
              "5     functionally        function\n",
              "6            lying             lie\n",
              "7             lied             lie\n",
              "8           fairly          fairli\n",
              "9      destabilize        destabil\n",
              "10       stability          stabil\n",
              "11      friendship      friendship\n",
              "12     friendships      friendship\n",
              "13        friendly        friendli\n",
              "14      friendless      friendless\n",
              "15         connect         connect\n",
              "16     connections         connect\n",
              "17       connected         connect\n",
              "18             the             the\n",
              "19           these           these\n",
              "20           those           those\n",
              "21    motivational           motiv\n",
              "22        motivate           motiv\n",
              "23      motivating           motiv"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Porter Stemmer': ps_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v32xnMkmAFo"
      },
      "source": [
        "### LancasterStemmer\n",
        "* The LancasterStemmer (Paice-Husk stemmer) is an iterative algorithm with rules saved externally.\n",
        "* LancasterStemmer is simple, but heavy stemming due to iterations and over-stemming may occur.\n",
        "* Over-stemming causes the stems to be not linguistic, or they may have no meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWWHcxe9mAFp"
      },
      "outputs": [],
      "source": [
        "ls = LancasterStemmer()\n",
        "\n",
        "ls_stemmed_tokens = []\n",
        "for token in input_tokens:\n",
        "    ls_stemmed_tokens.append(ls.stem(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1kkkmnmAFp",
        "outputId": "69bc2e3d-e9b9-42f7-ecdc-8fa635e6a3ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Lancaster Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>funct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>funct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>dest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>thes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>thos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words Lancaster Stemmer\n",
              "0     overwhelming         overwhelm\n",
              "1   overwhelmingly         overwhelm\n",
              "2           hushed              hush\n",
              "3             hush              hush\n",
              "4       functional             funct\n",
              "5     functionally             funct\n",
              "6            lying             lying\n",
              "7             lied              lied\n",
              "8           fairly              fair\n",
              "9      destabilize              dest\n",
              "10       stability             stabl\n",
              "11      friendship            friend\n",
              "12     friendships            friend\n",
              "13        friendly            friend\n",
              "14      friendless        friendless\n",
              "15         connect           connect\n",
              "16     connections           connect\n",
              "17       connected           connect\n",
              "18             the               the\n",
              "19           these              thes\n",
              "20           those              thos\n",
              "21    motivational               mot\n",
              "22        motivate               mot\n",
              "23      motivating               mot"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Lancaster Stemmer': ls_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtw31OiEmAFq",
        "outputId": "ca151e20-a35c-4fa6-e169-51c153b75598"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Porter Stemmer</th>\n",
              "      <th>Lancaster Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelmingli</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "      <td>funct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "      <td>funct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "      <td>lying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "      <td>lied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fairli</td>\n",
              "      <td>fair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>destabil</td>\n",
              "      <td>dest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabil</td>\n",
              "      <td>stabl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friendli</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "      <td>thes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "      <td>thos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words  Porter Stemmer Lancaster Stemmer\n",
              "0     overwhelming       overwhelm         overwhelm\n",
              "1   overwhelmingly  overwhelmingli         overwhelm\n",
              "2           hushed            hush              hush\n",
              "3             hush            hush              hush\n",
              "4       functional        function             funct\n",
              "5     functionally        function             funct\n",
              "6            lying             lie             lying\n",
              "7             lied             lie              lied\n",
              "8           fairly          fairli              fair\n",
              "9      destabilize        destabil              dest\n",
              "10       stability          stabil             stabl\n",
              "11      friendship      friendship            friend\n",
              "12     friendships      friendship            friend\n",
              "13        friendly        friendli            friend\n",
              "14      friendless      friendless        friendless\n",
              "15         connect         connect           connect\n",
              "16     connections         connect           connect\n",
              "17       connected         connect           connect\n",
              "18             the             the               the\n",
              "19           these           these              thes\n",
              "20           those           those              thos\n",
              "21    motivational           motiv               mot\n",
              "22        motivate           motiv               mot\n",
              "23      motivating           motiv               mot"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Porter Stemmer': ps_stemmed_tokens,\n",
        "    'Lancaster Stemmer': ls_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvpCEO7qmAFq"
      },
      "source": [
        "### SnowballStemmer\n",
        "* One can generate its own set of rules for any language that is why Python nltk introduced SnowballStemmers that are used to create non-English Stemmers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srJbDd_wmAFr",
        "outputId": "39a57454-75cc-470a-82b9-290bc0944d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
          ]
        }
      ],
      "source": [
        "print(SnowballStemmer.languages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VOfz86KmAFr"
      },
      "outputs": [],
      "source": [
        "ss =  SnowballStemmer('english')\n",
        "\n",
        "ss_stemmed_tokens = []\n",
        "for token in input_tokens:\n",
        "    ss_stemmed_tokens.append(ss.stem(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KzquFhFmAFr",
        "outputId": "2943b900-2232-4ed4-b039-ce31b127038d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Snowball Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>destabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words Snowball Stemmer\n",
              "0     overwhelming        overwhelm\n",
              "1   overwhelmingly        overwhelm\n",
              "2           hushed             hush\n",
              "3             hush             hush\n",
              "4       functional         function\n",
              "5     functionally         function\n",
              "6            lying              lie\n",
              "7             lied              lie\n",
              "8           fairly             fair\n",
              "9      destabilize         destabil\n",
              "10       stability           stabil\n",
              "11      friendship       friendship\n",
              "12     friendships       friendship\n",
              "13        friendly           friend\n",
              "14      friendless       friendless\n",
              "15         connect          connect\n",
              "16     connections          connect\n",
              "17       connected          connect\n",
              "18             the              the\n",
              "19           these            these\n",
              "20           those            those\n",
              "21    motivational            motiv\n",
              "22        motivate            motiv\n",
              "23      motivating            motiv"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Snowball Stemmer': ss_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gEuNZYdmAFs",
        "outputId": "352a6996-2e0f-4b1f-9cd5-e733abdb8a01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Porter Stemmer</th>\n",
              "      <th>Lancaster Stemmer</th>\n",
              "      <th>Snowball Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "      <td>overwhelm</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelmingli</td>\n",
              "      <td>overwhelm</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "      <td>funct</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "      <td>funct</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fairli</td>\n",
              "      <td>fair</td>\n",
              "      <td>fair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>destabil</td>\n",
              "      <td>dest</td>\n",
              "      <td>destabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabil</td>\n",
              "      <td>stabl</td>\n",
              "      <td>stabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friendli</td>\n",
              "      <td>friend</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "      <td>thes</td>\n",
              "      <td>these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "      <td>thos</td>\n",
              "      <td>those</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words  Porter Stemmer Lancaster Stemmer Snowball Stemmer\n",
              "0     overwhelming       overwhelm         overwhelm        overwhelm\n",
              "1   overwhelmingly  overwhelmingli         overwhelm        overwhelm\n",
              "2           hushed            hush              hush             hush\n",
              "3             hush            hush              hush             hush\n",
              "4       functional        function             funct         function\n",
              "5     functionally        function             funct         function\n",
              "6            lying             lie             lying              lie\n",
              "7             lied             lie              lied              lie\n",
              "8           fairly          fairli              fair             fair\n",
              "9      destabilize        destabil              dest         destabil\n",
              "10       stability          stabil             stabl           stabil\n",
              "11      friendship      friendship            friend       friendship\n",
              "12     friendships      friendship            friend       friendship\n",
              "13        friendly        friendli            friend           friend\n",
              "14      friendless      friendless        friendless       friendless\n",
              "15         connect         connect           connect          connect\n",
              "16     connections         connect           connect          connect\n",
              "17       connected         connect           connect          connect\n",
              "18             the             the               the              the\n",
              "19           these           these              thes            these\n",
              "20           those           those              thos            those\n",
              "21    motivational           motiv               mot            motiv\n",
              "22        motivate           motiv               mot            motiv\n",
              "23      motivating           motiv               mot            motiv"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Porter Stemmer': ps_stemmed_tokens,\n",
        "    'Lancaster Stemmer': ls_stemmed_tokens,\n",
        "    'Snowball Stemmer': ss_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtRX0jY6mAFs",
        "outputId": "99749061-7c91-49a5-8ef0-fc2f283201bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Suffix stripping algorithms may differ in results for a variety of reasons. One such reason is whether the algorithm constrains whether the output word must be a real word in the given language. Some approaches do not require the word to actually exist in the language lexicon (the set of all words in the language). Alternatively, some suffix stripping approaches maintain a database (a large list) of all known morphological word roots that exist as real words. These approaches check the list for the existence of the term prior to making a decision. Typically, if the term does not exist, alternate action is taken. This alternate action may involve several other criteria. The non-existence of an output term may serve to cause the algorithm to try alternate suffix stripping rules.\n",
            "\n",
            "It can be the case that two or more suffix stripping rules apply to the same input term, which creates an ambiguity as to which rule to apply. The algorithm may assign (by human hand or stochastically) a priority to one rule or another. Or the algorithm may reject one rule application because it results in a non-existent term whereas the other overlapping rule does not. For example, given the English term friendlies, the algorithm may identify the ies suffix and apply the appropriate rule and achieve the result of friendl. friendl is likely not found in the lexicon, and therefore the rule is rejected.\n",
            "\n",
            "One improvement upon basic suffix stripping is the use of suffix substitution. Similar to a stripping rule, a substitution rule replaces a suffix with an alternate suffix. For example, there could exist a rule that replaces ies with y. How this affects the algorithm varies on the algorithm's design. To illustrate, the algorithm may identify that both the ies suffix stripping rule as well as the suffix substitution rule apply. Since the stripping rule results in a non-existent term in the lexicon, but the substitution rule does not, the substitution rule is applied instead. In this example, friendlies becomes friendly instead of friendl.\n",
            "\n",
            "Diving further into the details, a common technique is to apply rules in a cyclical fashion (recursively, as computer scientists would say). After applying the suffix substitution rule in this example scenario, a second pass is made to identify matching rules on the term friendly, where the ly stripping rule is likely identified and accepted. In summary, friendlies becomes (via substitution) friendly which becomes (via stripping) friend.\n",
            "\n",
            "This example also helps illustrate the difference between a rule-based approach and a brute force approach. In a brute force approach, the algorithm would search for friendlies in the set of hundreds of thousands of inflected word forms and ideally find the corresponding root form friend. In the rule-based approach, the three rules mentioned above would be applied in succession to converge on the same solution. Chances are that the rule-based approach would be slower, as lookup algorithms have a direct access to the solution, while rule-based should try several options, and combinations of them, and then choose which result seems to be the best.\n",
            "\n",
            "There are two error measurements in stemming algorithms, overstemming and understemming. Overstemming is an error where two separate inflected words are stemmed to the same root, but should not have been—a false positive. Understemming is an error where two separate inflected words should be stemmed to the same root, but are not—a false negative. Stemming algorithms attempt to minimize each type of error, although reducing one type can lead to increasing the other.\n",
            "\n",
            "For example, the widely used Porter stemmer stems \"universal\", \"university\", and \"universe\" to \"univers\". This is a case of overstemming: though these three words are etymologically related, their modern meanings are in widely different domains, so treating them as synonyms in a search engine will likely reduce the relevance of the search results.\n",
            "\n",
            "An example of understemming in the Porter stemmer is \"alumnus\" → \"alumnu\", \"alumni\" → \"alumni\", \"alumna\"/\"alumnae\" → \"alumna\". This English word keeps Latin morphology, and so these near-synonyms are not conflated.\n",
            "\n",
            "Stochastic algorithms involve using probability to identify the root form of a word. Stochastic algorithms are trained (they \"learn\") on a table of root form to inflected form relations to develop a probabilistic model. This model is typically expressed in the form of complex linguistic rules, similar in nature to those in suffix stripping or lemmatisation. Stemming is performed by inputting an inflected form to the trained model and having the model produce the root form according to its internal ruleset, which again is similar to suffix stripping and lemmatisation, except that the decisions involved in applying the most appropriate rule, or whether or not to stem the word and just return the same word, or whether to apply two different rules sequentially, are applied on the grounds that the output word will have the highest probability of being correct (which is to say, the smallest probability of being incorrect, which is how it is typically measured).\n",
            "\n",
            "Some lemmatisation algorithms are stochastic in that, given a word which may belong to multiple parts of speech, a probability is assigned to each possible part. This may take into account the surrounding words, called the context, or not. Context-free grammars do not take into account any additional information. In either case, after assigning the probabilities to each possible part of speech, the most likely part of speech is chosen, and from there the appropriate normalization rules are applied to the input word to produce the normalized (root) form.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/stemming.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PXL8862mAFt"
      },
      "outputs": [],
      "source": [
        "word_tokens = word_tokenize(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGrwzek5mAFt"
      },
      "outputs": [],
      "source": [
        "ss =  SnowballStemmer('english', ignore_stopwords=True)\n",
        "\n",
        "ss_stemmed_words = []\n",
        "for word in word_tokens:\n",
        "    ss_stemmed_words.append(ss.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb5qqYpkmAFu",
        "outputId": "a102282f-4eda-4ed8-e007-6458897f45f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"suffix strip algorithm may differ in result for a varieti of reason . one such reason is whether the algorithm constrain whether the output word must be a real word in the given languag . some approach do not requir the word to actual exist in the languag lexicon ( the set of all word in the languag ) . altern , some suffix strip approach maintain a databas ( a larg list ) of all known morpholog word root that exist as real word . these approach check the list for the exist of the term prior to make a decis . typic , if the term does not exist , altern action is taken . this altern action may involv sever other criteria . the non-exist of an output term may serv to caus the algorithm to tri altern suffix strip rule . it can be the case that two or more suffix strip rule appli to the same input term , which creat an ambigu as to which rule to appli . the algorithm may assign ( by human hand or stochast ) a prioriti to one rule or anoth . or the algorithm may reject one rule applic because it result in a non-exist term wherea the other overlap rule does not . for exampl , given the english term friend , the algorithm may identifi the ie suffix and appli the appropri rule and achiev the result of friendl . friendl is like not found in the lexicon , and therefor the rule is reject . one improv upon basic suffix strip is the use of suffix substitut . similar to a strip rule , a substitut rule replac a suffix with an altern suffix . for exampl , there could exist a rule that replac ie with y . how this affect the algorithm vari on the algorithm 's design . to illustr , the algorithm may identifi that both the ie suffix strip rule as well as the suffix substitut rule appli . sinc the strip rule result in a non-exist term in the lexicon , but the substitut rule does not , the substitut rule is appli instead . in this exampl , friend becom friend instead of friendl . dive further into the detail , a common techniqu is to appli rule in a cyclic fashion ( recurs , as comput scientist would say ) . after appli the suffix substitut rule in this exampl scenario , a second pass is made to identifi match rule on the term friend , where the ly strip rule is like identifi and accept . in summari , friend becom ( via substitut ) friend which becom ( via strip ) friend . this exampl also help illustr the differ between a rule-bas approach and a brute forc approach . in a brute forc approach , the algorithm would search for friend in the set of hundr of thousand of inflect word form and ideal find the correspond root form friend . in the rule-bas approach , the three rule mention above would be appli in success to converg on the same solut . chanc are that the rule-bas approach would be slower , as lookup algorithm have a direct access to the solut , while rule-bas should tri sever option , and combin of them , and then choos which result seem to be the best . there are two error measur in stem algorithm , overstem and understem . overstem is an error where two separ inflect word are stem to the same root , but should not have been—a fals posit . understem is an error where two separ inflect word should be stem to the same root , but are not—a fals negat . stem algorithm attempt to minim each type of error , although reduc one type can lead to increas the other . for exampl , the wide use porter stemmer stem `` univers '' , `` univers '' , and `` univers '' to `` univ '' . this is a case of overstem : though these three word are etymolog relat , their modern mean are in wide differ domain , so treat them as synonym in a search engin will like reduc the relev of the search result . an exampl of understem in the porter stemmer is `` alumnus '' → `` alumnu '' , `` alumni '' → `` alumni '' , `` alumna '' / '' alumna '' → `` alumna '' . this english word keep latin morpholog , and so these near-synonym are not conflat . stochast algorithm involv use probabl to identifi the root form of a word . stochast algorithm are train ( they `` learn '' ) on a tabl of root form to inflect form relat to develop a probabilist model . this model is typic express in the form of complex linguist rule , similar in natur to those in suffix strip or lemmatis . stem is perform by input an inflect form to the train model and having the model produc the root form accord to its intern ruleset , which again is similar to suffix strip and lemmatis , except that the decis involv in appli the most appropri rule , or whether or not to stem the word and just return the same word , or whether to appli two differ rule sequenti , are appli on the ground that the output word will have the highest probabl of being correct ( which is to say , the smallest probabl of being incorrect , which is how it is typic measur ) . some lemmatis algorithm are stochast in that , given a word which may belong to multipl part of speech , a probabl is assign to each possibl part . this may take into account the surround word , call the context , or not . context-fre grammar do not take into account any addit inform . in either case , after assign the probabl to each possibl part of speech , the most like part of speech is chosen , and from there the appropri normal rule are appli to the input word to produc the normal ( root ) form .\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\" \".join(ss_stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g36czpuvmAFu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1u-m37umAFv"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 07-Lemmatization</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_-PxNLqmAFv"
      },
      "source": [
        "## Lemmatizing Words Using WordNet\n",
        "* Part-of-speech constants:\n",
        "* ADJ: a\n",
        "* ADV: r\n",
        "* NOUN: n\n",
        "* VERB: v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRI-awtLmAFv"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.stem import *\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqfyyh7WmAFw"
      },
      "source": [
        "### Stemming words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeotqoxtmAFw",
        "outputId": "c8b0228e-9742-4940-9bfa-b588c7645e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "definit\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "print(stemmer.stem('definitions'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhQsMFoMmAFw",
        "outputId": "e60c23c1-5911-4495-c44d-2d8d913f5ec7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LusRfWTNmAFx"
      },
      "source": [
        "### Lemmatizing Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2vyfkX9mAFx",
        "outputId": "82ed17c1-c47a-4ca5-8468-29a80b666227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "definition\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wnl = WordNetLemmatizer()\n",
        "print(wnl.lemmatize('definitions'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjUC5tH_mAFy"
      },
      "source": [
        "### Lemmatizing words by specifying parts-of-speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trE-JkLZmAFy",
        "outputId": "93d5652b-73d2-4dba-a2ac-e1292177f78b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjective:  running\n",
            "Adverb:  running\n",
            "Noun:  running\n",
            "Verb:  run\n"
          ]
        }
      ],
      "source": [
        "print('Adjective: ', wnl.lemmatize('running', pos='a'))\n",
        "print('Adverb: ', wnl.lemmatize('running', pos='r'))\n",
        "print('Noun: ', wnl.lemmatize('running', pos='n'))\n",
        "print('Verb: ', wnl.lemmatize('running', pos='v'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfP_Rh_tmAFz"
      },
      "outputs": [],
      "source": [
        "input_tokens = ['dictionaries', 'dictionary',\n",
        "                'hushed', 'hush', 'hushing',\n",
        "                'functional', 'functionally',\n",
        "                'lying', 'lied', 'lies',\n",
        "                'flawed', 'flaws', 'flawless',\n",
        "                'friendship', 'friendships', 'friendly', 'friendless',\n",
        "                'definitions', 'definition', 'definitely',\n",
        "                'the', 'these', 'those',\n",
        "                'motivational', 'motivate', 'motivating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwGdnQU0mAFz"
      },
      "outputs": [],
      "source": [
        "ss =  SnowballStemmer('english')\n",
        "\n",
        "ss_stemmed_tokens = []\n",
        "for token in input_tokens:\n",
        "    ss_stemmed_tokens.append(ss.stem(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B--4VadmAF0"
      },
      "outputs": [],
      "source": [
        "wnl_lemmatized_tokens = []\n",
        "for token in input_tokens:\n",
        "    wnl_lemmatized_tokens.append(wnl.lemmatize(token, pos='v'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xjl9IlHmAF0",
        "outputId": "90d40283-b642-4fad-db19-504918a07226"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Snowball Stemmer</th>\n",
              "      <th>WordNet Lemmatizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dictionaries</td>\n",
              "      <td>dictionari</td>\n",
              "      <td>dictionaries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dictionary</td>\n",
              "      <td>dictionari</td>\n",
              "      <td>dictionary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hushing</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "      <td>functionally</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>lies</td>\n",
              "      <td>lie</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>flawed</td>\n",
              "      <td>flaw</td>\n",
              "      <td>flaw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>flaws</td>\n",
              "      <td>flaw</td>\n",
              "      <td>flaw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>flawless</td>\n",
              "      <td>flawless</td>\n",
              "      <td>flawless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friendships</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friend</td>\n",
              "      <td>friendly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>definitions</td>\n",
              "      <td>definit</td>\n",
              "      <td>definitions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>definition</td>\n",
              "      <td>definit</td>\n",
              "      <td>definition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>definitely</td>\n",
              "      <td>definit</td>\n",
              "      <td>definitely</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "      <td>motivational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "      <td>motivate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "      <td>motivate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           words Snowball Stemmer WordNet Lemmatizer\n",
              "0   dictionaries       dictionari       dictionaries\n",
              "1     dictionary       dictionari         dictionary\n",
              "2         hushed             hush               hush\n",
              "3           hush             hush               hush\n",
              "4        hushing             hush               hush\n",
              "5     functional         function         functional\n",
              "6   functionally         function       functionally\n",
              "7          lying              lie                lie\n",
              "8           lied              lie                lie\n",
              "9           lies              lie                lie\n",
              "10        flawed             flaw               flaw\n",
              "11         flaws             flaw               flaw\n",
              "12      flawless         flawless           flawless\n",
              "13    friendship       friendship         friendship\n",
              "14   friendships       friendship        friendships\n",
              "15      friendly           friend           friendly\n",
              "16    friendless       friendless         friendless\n",
              "17   definitions          definit        definitions\n",
              "18    definition          definit         definition\n",
              "19    definitely          definit         definitely\n",
              "20           the              the                the\n",
              "21         these            these              these\n",
              "22         those            those              those\n",
              "23  motivational            motiv       motivational\n",
              "24      motivate            motiv           motivate\n",
              "25    motivating            motiv           motivate"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_lemmas_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Snowball Stemmer': ss_stemmed_tokens,\n",
        "    'WordNet Lemmatizer': wnl_lemmatized_tokens\n",
        "})\n",
        "\n",
        "stems_lemmas_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az-0zEhemAF1",
        "outputId": "99d1bd94-ee8c-4acc-cf56-e05438ec84e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI68fF89mAF1"
      },
      "outputs": [],
      "source": [
        "word_tokens = word_tokenize(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_14tsOL2mAF2"
      },
      "outputs": [],
      "source": [
        "wnl = WordNetLemmatizer()\n",
        "lemmatized_words = []\n",
        "\n",
        "for word in word_tokens:\n",
        "    lemmatized_words.append(wnl.lemmatize(word, pos=\"v\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMiYkMASmAF2",
        "outputId": "fadfa0ba-f2b0-4ed4-a489-64bd3c665b21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Marie Curie be a Polish-born physicist and chemist and one of the most famous scientists of her time . Together with her husband Pierre , she be award the Nobel Prize in 1903 , and she go on to win another in 1911 . Marie Sklodowska be bear in Warsaw on 7 November 1867 , the daughter of a teacher . In 1891 , she go to Paris to study physics and mathematics at the Sorbonne where she meet Pierre Curie , professor of the School of Physics . They be marry in 1895 . The Curies work together investigate radioactivity , build on the work of the German physicist Roentgen and the French physicist Becquerel . In July 1898 , the Curies announce the discovery of a new chemical element , polonium . At the end of the year , they announce the discovery of another , radium . The Curies , along with Becquerel , be award the Nobel Prize for Physics in 1903 . Pierre 's life be cut short in 1906 when he be knock down and kill by a carriage . Marie take over his teach post , become the first woman to teach at the Sorbonne , and devote herself to continue the work that they have begin together . She receive a second Nobel Prize , for Chemistry , in 1911 . The Curie 's research be crucial in the development of x-ray in surgery . During World War One Curie help to equip ambulances with x-ray equipment , which she herself drive to the front line . The International Red Cross make her head of its radiological service and she hold train course for medical orderlies and doctor in the new techniques . Despite her success , Marie continue to face great opposition from male scientists in France , and she never receive significant financial benefit from her work . By the late 1920s her health be begin to deteriorate . She die on 4 July 1934 from leukaemia , cause by exposure to high-energy radiation from her research . The Curies ' eldest daughter Irene be herself a scientist and winner of the Nobel Prize for Chemistry .\""
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\" \".join(lemmatized_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpRByEI4mAF3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUuA5FLpmAF3"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 08-PartOfSpeechTagging</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qmg4kvEmAF4"
      },
      "source": [
        "# Part-of-Speech Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yUqozxAmAF4"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUgcp15PmAF4",
        "outputId": "39710615-899e-4094-c7ab-8dc54f912e8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package tagsets to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('tagsets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxDTLqexmAF5",
        "outputId": "e742826f-0984-4eac-8459-6e0259d4cb74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x09QG-2bmAF5",
        "outputId": "db3e1e98-54cf-45e5-d26b-2f869c58d058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n"
          ]
        }
      ],
      "source": [
        "nltk.help.upenn_tagset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkWQmw-EmAF6",
        "outputId": "b765edd3-2202-4c9c-b26f-d828439a8b0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('refuse', 'VBP'),\n",
              " ('to', 'TO'),\n",
              " ('let', 'VB'),\n",
              " ('this', 'DT'),\n",
              " ('refuse', 'NN'),\n",
              " ('get', 'VB'),\n",
              " ('me', 'PRP'),\n",
              " ('down', 'RP')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I refuse to let this refuse get me down\"\n",
        "\n",
        "tokenized_words = word_tokenize(text)\n",
        "tagged_words = nltk.pos_tag(tokenized_words)\n",
        "tagged_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oigs6AalmAF6",
        "outputId": "31218a28-477e-42fd-fbbd-bf4729fb2a2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Bear', 'NNP'),\n",
              " ('with', 'IN'),\n",
              " ('me', 'PRP'),\n",
              " (',', ','),\n",
              " ('this', 'DT'),\n",
              " ('effort', 'NN'),\n",
              " ('with', 'IN'),\n",
              " ('soon', 'RB'),\n",
              " ('bear', 'JJ'),\n",
              " ('fruit', 'NN'),\n",
              " (',', ','),\n",
              " ('otherwise', 'RB'),\n",
              " ('we', 'PRP'),\n",
              " (\"'ll\", 'MD'),\n",
              " ('have', 'VB'),\n",
              " ('to', 'TO'),\n",
              " ('run', 'VB'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('bear', 'NN')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"\"\"Bear with me, this effort with soon bear fruit,\n",
        "          otherwise we'll have to run from the bear\"\"\"\n",
        "\n",
        "tokenized_words = word_tokenize(text)\n",
        "tagged_words = nltk.pos_tag(tokenized_words)\n",
        "tagged_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9zOBiYDmAF7",
        "outputId": "71c5b700-3464-444e-ce6a-408c46a66b6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'DT'),\n",
              " ('bird', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('hand', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('worth', 'JJ'),\n",
              " ('two', 'CD'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('bush', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Good', 'JJ'),\n",
              " ('things', 'NNS'),\n",
              " ('come', 'VBP'),\n",
              " ('to', 'TO'),\n",
              " ('those', 'DT'),\n",
              " ('who', 'WP'),\n",
              " ('wait', 'VBP'),\n",
              " ('.', '.'),\n",
              " ('There', 'EX'),\n",
              " ('are', 'VBP'),\n",
              " ('other', 'JJ'),\n",
              " ('fish', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('sea', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('ball', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('in', 'IN'),\n",
              " ('your', 'PRP$'),\n",
              " ('court', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"A bird in hand is worth two in the bush. \" +\\\n",
        "       \"Good things come to those who wait. \" +\\\n",
        "       \"There are other fish in the sea. \" +\\\n",
        "       \"The ball is in your court.\"\n",
        "\n",
        "tokenized_words = word_tokenize(text)\n",
        "tagged_words = nltk.pos_tag(tokenized_words)\n",
        "tagged_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xNyRilsmAF7",
        "outputId": "8cc10f35-10c2-4191-b914-552938af0512"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('NN', 7),\n",
              " ('DT', 5),\n",
              " ('IN', 4),\n",
              " ('.', 4),\n",
              " ('JJ', 3),\n",
              " ('VBP', 3),\n",
              " ('VBZ', 2),\n",
              " ('CD', 1),\n",
              " ('NNS', 1),\n",
              " ('TO', 1)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "fd = FreqDist(tagged_words)\n",
        "fd_tagged = FreqDist(tag for (word, tag) in tagged_words)\n",
        "fd_tagged.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTXBfs98mAF8"
      },
      "source": [
        "The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University. This corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, and so on. 1.1 gives an example of each genre (for a complete list, see http://icame.uib.no/brown/bcm-los.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sKDNBPImAF8",
        "outputId": "b4a5543c-f09e-473a-f0ce-7af509c50e1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h5ILSjOmAF8",
        "outputId": "20828367-fb9d-47c3-e65d-662b48a7b0cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'Grand',\n",
              " 'Jury',\n",
              " 'said',\n",
              " 'Friday',\n",
              " 'an',\n",
              " 'investigation',\n",
              " 'of']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.corpus.brown.words()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlTPxuNVmAF9"
      },
      "outputs": [],
      "source": [
        "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQU3l5LGmAF9"
      },
      "source": [
        "Lexical categories like \"noun\" and part-of-speech tags like NN seem to have their uses, but the details will be obscure to many readers. You might wonder what justification there is for introducing this extra level of information. Many of these categories arise from superficial analysis the distribution of words in text. Consider the following analysis involving woman (a noun), bought (a verb), over (a preposition), and the (a determiner). The text.similar() method takes a word w, finds all contexts w1w w2, then finds all words w' that appear in the same context, i.e. w1w'w2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AqV78-TmAF9"
      },
      "source": [
        "#### Similar words here belong to the same part of speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP6f2mHYmAF-",
        "outputId": "4729d5b1-22a5-4030-d0fc-f7126212d435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "man time day way girl year house people world city family state room\n",
            "country car woman program church government job\n"
          ]
        }
      ],
      "source": [
        "text.similar('boy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SEBYMGImAF_",
        "outputId": "475019ec-b1b4-4b51-ee27-606fae419e8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get be do in see work go have take make put and find time look day say\n",
            "use come show\n"
          ]
        }
      ],
      "source": [
        "text.similar('run')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fElpTxHgmAF_",
        "outputId": "699f6825-3fdc-4936-edaf-872b9c87b07f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in on to of and for with from at by that into as up out down through\n",
            "is all about\n"
          ]
        }
      ],
      "source": [
        "text.similar('over')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs6fSMWrmAGA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlTXX4ZPmAGA"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 09-ReduceDimensionsInText_HashingTrick</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBU3j2BSmAGA"
      },
      "source": [
        "## Hashing trick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM9PusfCmAGB"
      },
      "source": [
        "Instead of building a hash table of the features encountered in training, as the vectorizers do, instances of FeatureHasher apply a hash function to the features to determine their column index in sample matrices directly. The result is increased speed and reduced memory usage, at the expense of inspectability; the hasher does not remember what the input features looked like and has no inverse_transform method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRGGNzqumAGB"
      },
      "source": [
        "* https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html\n",
        "* https://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCuLuvGzmAGB",
        "outputId": "56216feb-dc02-4fd1-8b94-a36ef8187af6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 8)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "text = [\"A bird in hand is worth two in the bush.\",\n",
        "        \"Good things come to those who wait.\",\n",
        "        \"These watches cost $1500! \",\n",
        "        \"These are other fish in the sea.\",\n",
        "        \"The ball is in your court.\",\n",
        "        \"Mr. Smith Goes to Washington \",\n",
        "        \"Doogie Howser M.D.\"]\n",
        "\n",
        "hasher = FeatureHasher(n_features=8, input_type='string')\n",
        "hashed_features = hasher.fit_transform(text)\n",
        "\n",
        "hashed_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHhGj778mAGC",
        "outputId": "da516f91-25aa-4e34-b592-278ec68dd53b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 10.,   0.,   1.,   1.,  -3., -11.,   1.,  -1.],\n",
              "       [  6.,  -2.,   0.,   3.,   0.,  -6.,   0.,   0.],\n",
              "       [  4.,  -5.,   1.,  -1.,   2.,  -3.,   0.,   0.],\n",
              "       [  6.,   2.,   2.,   0.,  -1.,  -8.,   0.,   3.],\n",
              "       [  7.,   1.,   1.,   1.,   1.,  -6.,   1.,   0.],\n",
              "       [  4.,   2.,   1.,   0.,  -2.,  -5.,   0.,  -1.],\n",
              "       [  2.,   1.,   0.,   3.,   0.,  -3.,   2.,   1.]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hashed_features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SJ-jPPCmAGC",
        "outputId": "39f33232-06c1-47c0-bf89-e5b193e383d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 16)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasher = FeatureHasher(n_features=16, input_type='string')\n",
        "hashed_features = hasher.fit_transform(text)\n",
        "\n",
        "hashed_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX_5SzthmAGD",
        "outputId": "479c7322-1f24-4b58-a2fc-f4f950a9080e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.,  0.,  1.,  1., -3., -4.,  0.,  1.,  9.,  0.,  0.,  0.,  0.,\n",
              "        -7.,  1., -2.],\n",
              "       [ 0., -3.,  1.,  3., -1., -2.,  0.,  2.,  6.,  1., -1.,  0.,  1.,\n",
              "        -4.,  0., -2.],\n",
              "       [ 0., -5.,  1., -1.,  2.,  1.,  0.,  3.,  4.,  0.,  0.,  0.,  0.,\n",
              "        -4.,  0., -3.],\n",
              "       [ 0.,  2.,  2., -1., -1., -2.,  0.,  6.,  6.,  0.,  0.,  1.,  0.,\n",
              "        -6.,  0., -3.],\n",
              "       [ 2.,  1.,  1.,  1., -1., -2.,  1.,  1.,  5.,  0.,  0.,  0.,  2.,\n",
              "        -4.,  0., -1.],\n",
              "       [-1.,  1.,  1.,  0., -2., -2.,  0.,  1.,  5.,  1.,  0.,  0.,  0.,\n",
              "        -3.,  0., -2.],\n",
              "       [ 0.,  0.,  0.,  3.,  0., -1.,  2.,  2.,  2.,  1.,  0.,  0.,  0.,\n",
              "        -2.,  0., -1.]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hashed_features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG4b934gmAGD",
        "outputId": "2f86468e-4525-4d17-a04d-a2ec736f41da"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'FeatureHasher' object has no attribute 'inverse_transform'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-acc2ce62ec0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashed_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'FeatureHasher' object has no attribute 'inverse_transform'"
          ]
        }
      ],
      "source": [
        "hasher.inverse_transform(hashed_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svoEk1SYmAGE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48hjKGKSmAGE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7CV1vAimAGE"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 10-VectorizingTextData_HashingVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7lg7kBWmAGF"
      },
      "source": [
        "## HashingVectorizer\n",
        "* <b>HashingVectorizer</b> is the combination of <b>FeatureHasher</b> and <b>CountVectorizer</b> i.e, we get the Term frequency of words as well as the reduced dimension\n",
        "* When we used FeatureHasher the dimension of vector reduced but we couldn't get any understandable format in output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbDveHPxmAGF"
      },
      "source": [
        "#### If we have large vocabulary of words we can choose to use the HashingVectorizer rather than the CountVectorizer\n",
        "* The use of hashing buckets to represent words allows us to scale large data sets when we use the HashingVectorizer.\n",
        "* The input argument to the vectorizer is the number of hash buckets (n_features)\n",
        "* Result : numeric representation of all the words in documents.\n",
        "* Word ids are from 0 to (n_features - 1) because total of n_features buckets.\n",
        "* Because the size of vocabulary is larger than the number of buckets, multiple words can hash to the same bucket.\n",
        "* No way to get back to the original value from the hash bucket value.\n",
        "* Frequencies of each is represented in normalized from\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html#vectorizing-a-large-text-corpus-with-the-hashing-trick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7rKs9IcmAGF"
      },
      "source": [
        "##### words are mapped directly to indices with a hashing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NtmCacjmAGG",
        "outputId": "54b80154-db31-4a47-a3e0-668ff13173ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 27)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text_array = [\"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"These are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "feature_vector = count_vectorizer.fit_transform(text_array)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhkk2AhImAGG",
        "outputId": "591112dc-a620-401e-e44c-8927b5ff6398"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        1, 0, 0, 1, 0],\n",
              "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "        0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZHdUTX-mAGH",
        "outputId": "ba2a29d3-fd8a-4459-e6d4-72d0946178ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'good': 9,\n",
              " 'things': 19,\n",
              " 'come': 3,\n",
              " 'to': 21,\n",
              " 'those': 20,\n",
              " 'who': 25,\n",
              " 'wait': 22,\n",
              " 'these': 18,\n",
              " 'watches': 24,\n",
              " 'cost': 4,\n",
              " '1500': 0,\n",
              " 'are': 1,\n",
              " 'other': 14,\n",
              " 'fish': 7,\n",
              " 'in': 11,\n",
              " 'the': 17,\n",
              " 'sea': 15,\n",
              " 'ball': 2,\n",
              " 'is': 12,\n",
              " 'your': 26,\n",
              " 'court': 5,\n",
              " 'mr': 13,\n",
              " 'smith': 16,\n",
              " 'goes': 8,\n",
              " 'washington': 23,\n",
              " 'doogie': 6,\n",
              " 'howser': 10}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6FPWD-0mAGH"
      },
      "outputs": [],
      "source": [
        "analyzer = count_vectorizer.build_analyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT_QARpPmAGI",
        "outputId": "81d8d228-c7a2-4b9a-c973-afa39c11969a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['good', 'things', 'come', 'to', 'those', 'who', 'wait']"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = analyzer(text_array[0])\n",
        "\n",
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl5MkVximAGI"
      },
      "outputs": [],
      "source": [
        "frequency_list = []\n",
        "\n",
        "for i, text in enumerate(text_array):\n",
        "    tokens = analyzer(text)\n",
        "\n",
        "    word_frequency = {}\n",
        "\n",
        "    for token in tokens:\n",
        "        word_idx = count_vectorizer.vocabulary_[token]\n",
        "\n",
        "        word_frequency[token] = feature_vector[i, word_idx]\n",
        "\n",
        "    frequency_list.append(word_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWmqTV9VmAGJ",
        "outputId": "488a0a01-3547-4212-a034-35b5360439d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'good': 1, 'things': 1, 'come': 1, 'to': 1, 'those': 1, 'who': 1, 'wait': 1},\n",
              " {'these': 1, 'watches': 1, 'cost': 1, '1500': 1},\n",
              " {'these': 1, 'are': 1, 'other': 1, 'fish': 1, 'in': 1, 'the': 1, 'sea': 1},\n",
              " {'the': 1, 'ball': 1, 'is': 1, 'in': 1, 'your': 1, 'court': 1},\n",
              " {'mr': 1, 'smith': 1, 'goes': 1, 'to': 1, 'washington': 1},\n",
              " {'doogie': 1, 'howser': 1}]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ7W-O5rmAGJ",
        "outputId": "a8b38a84-eb22-4295-81bb-c6bef37222b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 8)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "hasher = FeatureHasher(n_features=8, input_type='string')\n",
        "hashed_features = hasher.fit_transform(frequency_list)\n",
        "\n",
        "hashed_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiQ-2ESvmAGK",
        "outputId": "40d79130-32a1-46c7-ad66-a7bd60a27c24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.,  3.,  0.,  1., -2., -1.,  0.,  0.],\n",
              "       [ 0.,  0., -1.,  0., -1.,  0.,  2.,  0.],\n",
              "       [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  1.],\n",
              "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
              "       [ 0., -1.,  0.,  1.,  0., -1.,  0.,  0.],\n",
              "       [ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.]])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hashed_features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9sGqFXymAGK",
        "outputId": "9f493a9f-bac1-449c-8d83-4848c4c35200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 8)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "vectorizer = HashingVectorizer(n_features=8, norm=None)\n",
        "feature_vector = vectorizer.transform(text_array)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A4xBnIumAGL",
        "outputId": "b04f48fd-caf8-4629-af81-5cbba8313b6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.,  3.,  0.,  1., -2., -1.,  0.,  0.],\n",
              "       [ 0.,  0., -1.,  0., -1.,  0.,  2.,  0.],\n",
              "       [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  1.],\n",
              "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
              "       [ 0., -1.,  0.,  1.,  0., -1.,  0.,  0.],\n",
              "       [ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.]])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vonPpJlgmAGL",
        "outputId": "37fb7e24-f285-4cf2-a20a-e565b145360d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 8)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = HashingVectorizer(n_features=8, norm='l1')\n",
        "feature_vector = vectorizer.transform(text_array)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGthE4RUmAGM",
        "outputId": "eb0741a3-08a3-47be-ed95-94d53124defc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.42857143,  0.        ,  0.14285714, -0.28571429,\n",
              "        -0.14285714,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        , -0.25      ,  0.        , -0.25      ,\n",
              "         0.        ,  0.5       ,  0.        ],\n",
              "       [ 0.        ,  0.33333333, -0.33333333,  0.        ,  0.        ,\n",
              "         0.        ,  0.        ,  0.33333333],\n",
              "       [ 0.        ,  0.5       ,  0.        ,  0.        ,  0.        ,\n",
              "         0.5       ,  0.        ,  0.        ],\n",
              "       [ 0.        , -0.33333333,  0.        ,  0.33333333,  0.        ,\n",
              "        -0.33333333,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.5       ,  0.        ,  0.        ,  0.5       ,\n",
              "         0.        ,  0.        ,  0.        ]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EInewfI1mAGN",
        "outputId": "9f9c0806-1b8a-4b05-85ae-07c522395e16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 8)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = HashingVectorizer(n_features=8, norm='l2')\n",
        "feature_vector = vectorizer.transform(text_array)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS3V6VOvmAGN",
        "outputId": "ac8467ab-65b2-4138-d22b-ffe284798049"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.77459667,  0.        ,  0.25819889, -0.51639778,\n",
              "        -0.25819889,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        , -0.40824829,  0.        , -0.40824829,\n",
              "         0.        ,  0.81649658,  0.        ],\n",
              "       [ 0.        ,  0.57735027, -0.57735027,  0.        ,  0.        ,\n",
              "         0.        ,  0.        ,  0.57735027],\n",
              "       [ 0.        ,  0.70710678,  0.        ,  0.        ,  0.        ,\n",
              "         0.70710678,  0.        ,  0.        ],\n",
              "       [ 0.        , -0.57735027,  0.        ,  0.57735027,  0.        ,\n",
              "        -0.57735027,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.70710678,  0.        ,  0.        ,  0.70710678,\n",
              "         0.        ,  0.        ,  0.        ]])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhXRla4dmAGO",
        "outputId": "e1c2d471-261d-4169-fd4b-bd3ba18252ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 3., 0., 1., 2., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 1., 0., 2., 0.],\n",
              "       [2., 1., 1., 0., 0., 0., 2., 1.],\n",
              "       [0., 1., 0., 0., 2., 1., 2., 0.],\n",
              "       [0., 1., 0., 3., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 1., 0., 0., 0.]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = HashingVectorizer(n_features=8, norm=None, alternate_sign=False)\n",
        "feature_vector = vectorizer.transform(text_array)\n",
        "\n",
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-K9RrvMmAGW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ymiuHWmAG1"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 11-SimplifyTextDataUsingLocallySensitiveHashing </h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVf5O4-YmAG3"
      },
      "source": [
        "### Datasketch\n",
        "https://pypi.org/project/datasketch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U0MUjOFmAG4",
        "outputId": "30ee33d6-264f-4e99-f7f3-f87bbfef4426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasketch in /anaconda3/lib/python3.7/site-packages (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.11 in /anaconda3/lib/python3.7/site-packages (from datasketch) (1.16.1)\n",
            "Requirement already satisfied: redis>=2.10.0 in /anaconda3/lib/python3.7/site-packages (from datasketch) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasketch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0HHkoiRmAG6"
      },
      "outputs": [],
      "source": [
        "from datasketch import MinHash, MinHashLSH\n",
        "\n",
        "from nltk import ngrams\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzS1tF8gmAG7"
      },
      "outputs": [],
      "source": [
        "text_array = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GJlH2wxmAG8",
        "outputId": "e9495ea5-93b5-4591-bc31-c972768d741a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.'],\n",
              " ['Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.'],\n",
              " ['There', 'are', 'other', 'fish', 'in', 'the', 'sea', '.'],\n",
              " ['The', 'ball', 'is', 'in', 'your', 'court', '.']]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_token_array = [word_tokenize(text) for text in text_array]\n",
        "\n",
        "word_token_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd8la6tnmAHK",
        "outputId": "e3e17845-cef3-482d-ed8c-3a6dab6c1f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 ('A', 'bird', 'in')\n",
            "0 ('bird', 'in', 'hand')\n",
            "0 ('in', 'hand', 'is')\n",
            "0 ('hand', 'is', 'worth')\n",
            "0 ('is', 'worth', 'two')\n",
            "0 ('worth', 'two', 'in')\n",
            "0 ('two', 'in', 'the')\n",
            "0 ('in', 'the', 'bush')\n",
            "0 ('the', 'bush', '.')\n",
            "1 ('Good', 'things', 'come')\n",
            "1 ('things', 'come', 'to')\n",
            "1 ('come', 'to', 'those')\n",
            "1 ('to', 'those', 'who')\n",
            "1 ('those', 'who', 'wait')\n",
            "1 ('who', 'wait', '.')\n",
            "2 ('There', 'are', 'other')\n",
            "2 ('are', 'other', 'fish')\n",
            "2 ('other', 'fish', 'in')\n",
            "2 ('fish', 'in', 'the')\n",
            "2 ('in', 'the', 'sea')\n",
            "2 ('the', 'sea', '.')\n",
            "3 ('The', 'ball', 'is')\n",
            "3 ('ball', 'is', 'in')\n",
            "3 ('is', 'in', 'your')\n",
            "3 ('in', 'your', 'court')\n",
            "3 ('your', 'court', '.')\n"
          ]
        }
      ],
      "source": [
        "for index, word_tokens in enumerate(word_token_array):\n",
        "    for n_gram in ngrams(word_tokens, 3):\n",
        "        print(index, n_gram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3W0QILDmAHL"
      },
      "outputs": [],
      "source": [
        "min_hash_lsh = MinHashLSH(threshold=0.5, num_perm=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O0FIOBUmAHM"
      },
      "outputs": [],
      "source": [
        "min_hashes = {}\n",
        "\n",
        "for index, text in enumerate(text_array):\n",
        "    min_hash = MinHash(num_perm=128)\n",
        "\n",
        "    for n_gram in ngrams(text, 3):\n",
        "        min_hash.update(\"\".join(n_gram).encode('utf-8'))\n",
        "\n",
        "    min_hash_lsh.insert(index, min_hash)\n",
        "    min_hashes[index] = min_hash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKQ9LNoEmAHS",
        "outputId": "677d366b-4259-41a6-c5b8-fe6e4bccba72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: <datasketch.minhash.MinHash at 0x11bc3a9b0>,\n",
              " 1: <datasketch.minhash.MinHash at 0x11bc3ab00>,\n",
              " 2: <datasketch.minhash.MinHash at 0x11bc392e8>,\n",
              " 3: <datasketch.minhash.MinHash at 0x11bc39320>}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "min_hashes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqaW8LBjmAHT",
        "outputId": "4fe5210a-75eb-41d9-c7f9-501e38b6fd29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidate pairs with Jaccard similarity > 0.5 for input 0 : [0]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 1 : [1]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 2 : [2]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 3 : [3]\n"
          ]
        }
      ],
      "source": [
        "for i in min_hashes.keys():\n",
        "    result = min_hash_lsh.query(min_hashes[i])\n",
        "    print(\"Candidate pairs with Jaccard similarity > 0.5 for input\", i, \":\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2UcUW5BmAHV"
      },
      "outputs": [],
      "source": [
        "text_array = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"A bird in hands is worth three in the bushes.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"Good tpings cxme to those who wait long.\",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\"\n",
        "             ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qln6FjBSmAHX"
      },
      "outputs": [],
      "source": [
        "min_hash_lsh = MinHashLSH(threshold=0.5, num_perm=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV0ZWF4QmAHY"
      },
      "outputs": [],
      "source": [
        "min_hashes = {}\n",
        "\n",
        "for index, text in enumerate(text_array):\n",
        "    min_hash = MinHash(num_perm=128)\n",
        "\n",
        "    for n_gram in ngrams(text, 3):\n",
        "        min_hash.update(\"\".join(n_gram).encode('utf-8'))\n",
        "\n",
        "    min_hash_lsh.insert(index, min_hash)\n",
        "    min_hashes[index] = min_hash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbjzA37XmAHb",
        "outputId": "a0146be0-c698-47df-b2d1-6a46e9e89c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidate pairs with Jaccard similarity > 0.5 for input 0 : [0, 1]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 1 : [0, 1]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 2 : [2, 3]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 3 : [2, 3]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 4 : [4]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 5 : [5]\n"
          ]
        }
      ],
      "source": [
        "for i in min_hashes.keys():\n",
        "    result = min_hash_lsh.query(min_hashes[i])\n",
        "    print(\"Candidate pairs with Jaccard similarity > 0.5 for input\", i, \":\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtJqn0DKmAHc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0aw-JnGmAHc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsZImo0dmAHd"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 12a-HashingVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa3jC7JnmAHe"
      },
      "source": [
        "Dataset link : https://github.com/pyk/dbpedia_csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO_B1GuMmAHe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDs7oiJGmAHf"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc3z_DpwmAHg",
        "outputId": "f4c365eb-19d3-437f-f707-89fbcf81f57c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkFTg9Z6mAHi"
      },
      "source": [
        "### DBPedia classes\n",
        "\n",
        "- Company\n",
        "- EducationalInstitution\n",
        "- Artist\n",
        "- Athlete\n",
        "- OfficeHolder\n",
        "- MeanOfTransportation\n",
        "- Building\n",
        "- NaturalPlace\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- WrittenWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b6SjwjsmAHk",
        "outputId": "ae07a24d-5cdb-4eb1-e814-b4c70c7411bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moj3oTKgmAHl"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Yfyqj_CmAHm",
        "outputId": "4a225ccc-5054-438b-c348-58a296247f7d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>494483</th>\n",
              "      <td>13</td>\n",
              "      <td>A Wedding Suit</td>\n",
              "      <td>A Wedding Suit (Persian: لباسی برای عروسی‎ Le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548491</th>\n",
              "      <td>14</td>\n",
              "      <td>Into Thin Air</td>\n",
              "      <td>Into Thin Air: A Personal Account of the Mt. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339369</th>\n",
              "      <td>9</td>\n",
              "      <td>Banavchan</td>\n",
              "      <td>Banavchan (Persian: بناوچان‎ also Romanized a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295828</th>\n",
              "      <td>8</td>\n",
              "      <td>Icalma Lake</td>\n",
              "      <td>Icalma Lake is a lake located in the Andes of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416552</th>\n",
              "      <td>11</td>\n",
              "      <td>Pouteria sandwicensis</td>\n",
              "      <td>Pouteria sandwicensis is a species of floweri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503849</th>\n",
              "      <td>13</td>\n",
              "      <td>Pepo (film)</td>\n",
              "      <td>Pepo (Armenian: Պեպո) is a 1935 Soviet film d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364384</th>\n",
              "      <td>10</td>\n",
              "      <td>Puebla deer mouse</td>\n",
              "      <td>The Puebla deer mouse (Peromyscus mekisturus)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265465</th>\n",
              "      <td>7</td>\n",
              "      <td>Waleffe Castle</td>\n",
              "      <td>Waleffe Castle is a castle in Belgium.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528364</th>\n",
              "      <td>14</td>\n",
              "      <td>Through the Arc of the Rain Forest</td>\n",
              "      <td>Through the Arc of the Rain Forest is a novel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423816</th>\n",
              "      <td>11</td>\n",
              "      <td>Guarianthe</td>\n",
              "      <td>Guarianthe abbreviated Gur. in the horticultu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                                Name  \\\n",
              "494483     13                      A Wedding Suit   \n",
              "548491     14                       Into Thin Air   \n",
              "339369      9                           Banavchan   \n",
              "295828      8                         Icalma Lake   \n",
              "416552     11               Pouteria sandwicensis   \n",
              "503849     13                         Pepo (film)   \n",
              "364384     10                   Puebla deer mouse   \n",
              "265465      7                      Waleffe Castle   \n",
              "528364     14  Through the Arc of the Rain Forest   \n",
              "423816     11                          Guarianthe   \n",
              "\n",
              "                                                     Text  \n",
              "494483   A Wedding Suit (Persian: لباسی برای عروسی‎ Le...  \n",
              "548491   Into Thin Air: A Personal Account of the Mt. ...  \n",
              "339369   Banavchan (Persian: بناوچان‎ also Romanized a...  \n",
              "295828   Icalma Lake is a lake located in the Andes of...  \n",
              "416552   Pouteria sandwicensis is a species of floweri...  \n",
              "503849   Pepo (Armenian: Պեպո) is a 1935 Soviet film d...  \n",
              "364384   The Puebla deer mouse (Peromyscus mekisturus)...  \n",
              "265465             Waleffe Castle is a castle in Belgium.  \n",
              "528364   Through the Arc of the Rain Forest is a novel...  \n",
              "423816   Guarianthe abbreviated Gur. in the horticultu...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmW6wFEomAHn",
        "outputId": "2c2bd249-7a20-4f6a-a624-69f465addcea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC8ZekxmmAHn"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVNGWL68mAHo",
        "outputId": "cce5fb23-355d-44ee-cd31-43c68d18fcf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "187313     Bruce Cameron Young is an Australian Liberal ...\n",
              "94935      Daniel Douglas Orlando (born May 29 1981) als...\n",
              "93329      John Hultberg (February 8 1922 – April 15 200...\n",
              "530642     The Oxford University Commonwealth Law Journa...\n",
              "361874     Stensioella heintzi (Heintz's Little Stensio)...\n",
              "Name: Text, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcRpS8xlmAHp",
        "outputId": "7370fb6b-a3fe-4bc9-a7fe-3de9adc45973"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "187313     5\n",
              "94935      3\n",
              "93329      3\n",
              "530642    14\n",
              "361874    10\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrmBBT2hmAHq"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ayxrmg4mAH-",
        "outputId": "e685f3c7-e13f-4845-caa9-84beba9d4761"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 1024)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = HashingVectorizer(n_features=2**10, norm='l2')\n",
        "\n",
        "feature_vector = vectorizer.transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eDKQVWXmAH_",
        "outputId": "7d5af6a1-49c3-46ae-956d-f1dd567edbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 39)\t0.15811388300841897\n",
            "  (0, 53)\t-0.15811388300841897\n",
            "  (0, 54)\t0.15811388300841897\n",
            "  (0, 61)\t-0.15811388300841897\n",
            "  (0, 152)\t0.15811388300841897\n",
            "  (0, 158)\t-0.4743416490252569\n",
            "  (0, 175)\t-0.15811388300841897\n",
            "  (0, 203)\t-0.15811388300841897\n",
            "  (0, 300)\t0.31622776601683794\n",
            "  (0, 308)\t-0.15811388300841897\n",
            "  (0, 311)\t-0.15811388300841897\n",
            "  (0, 352)\t-0.15811388300841897\n",
            "  (0, 362)\t-0.15811388300841897\n",
            "  (0, 363)\t0.15811388300841897\n",
            "  (0, 365)\t0.31622776601683794\n",
            "  (0, 399)\t0.15811388300841897\n",
            "  (0, 426)\t0.15811388300841897\n",
            "  (0, 470)\t0.15811388300841897\n",
            "  (0, 513)\t-0.15811388300841897\n",
            "  (0, 534)\t0.15811388300841897\n",
            "  (0, 540)\t-0.15811388300841897\n",
            "  (0, 663)\t-0.15811388300841897\n",
            "  (0, 665)\t-0.15811388300841897\n",
            "  (0, 819)\t-0.15811388300841897\n",
            "  (0, 1002)\t-0.15811388300841897\n",
            "  (0, 1011)\t-0.15811388300841897\n"
          ]
        }
      ],
      "source": [
        "print(feature_vector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF6YveVcmAIB"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFmgT6Y4mAIC",
        "outputId": "0e804a6a-4bd4-45bd-f3f6-4ffe2ee8328f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 1024)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8dlr1yNmAID"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgIa29s9mAIG",
        "outputId": "dc67d160-5eb3-4132-b90d-9d806cb2ecb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 1024), (2000, 1024))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfYlFhUCmAIH",
        "outputId": "bda8bada-3790-4819-f4d9-d02bab2c5a9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000,), (2000,))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJsiyWo7mAII"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyTfyL9zmAII",
        "outputId": "36b326b8-e5ad-4a55-d4fe-6eb90ff1a27e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7, 11, 13, ...,  5,  6,  7])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi8LBU94mAIJ",
        "outputId": "290d44cf-2441-453a-a237-4d5b625c8887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1153\n",
            "accuracy_score :  0.5765\n",
            "precision_score :  0.5891110304184962\n",
            "recall_score :  0.5765\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js48Ox8qmAIJ",
        "outputId": "b3e3be5e-949a-41e2-dd81-2fa07037d6c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "267097     7\n",
              "364326    10\n",
              "509624    13\n",
              "466990    12\n",
              "145918     4\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCWnXxCgmAIK"
      },
      "outputs": [],
      "source": [
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfHB8pR7mAIK",
        "outputId": "d2455ffa-2c2a-4709-876a-8bcdf683edb2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1746</th>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1851</th>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      y_test  y_pred\n",
              "1486       1       1\n",
              "494        9       8\n",
              "1039       3       3\n",
              "985        9       9\n",
              "711        8      10\n",
              "532        1       1\n",
              "1249      11      10\n",
              "1746       8      11\n",
              "766        1       7\n",
              "1851      12       4"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_results = pd.DataFrame({'y_test': pd.Series(y_test),\n",
        "                             'y_pred': pd.Series(y_pred)})\n",
        "\n",
        "pred_results.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRcejY1ZmAIK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ1JpkXomAIL"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 12b-Stemmer_HashingVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flz0kFYvmAIL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNP8U9iUmAIL"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY8nwFZImAIM",
        "outputId": "c3445b0d-4f83-4b39-eb64-67c1e470ccdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KEF7005mAIM"
      },
      "source": [
        "### DBPedia classes\n",
        "\n",
        "- Company\n",
        "- EducationalInstitution\n",
        "- Artist\n",
        "- Athlete\n",
        "- OfficeHolder\n",
        "- MeanOfTransportation\n",
        "- Building\n",
        "- NaturalPlace\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- WrittenWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGFNNeDqmAIM",
        "outputId": "d2eee719-8792-471b-e84c-af7b8022abfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwmvCfHLmAIN"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB8L603mmAIN",
        "outputId": "c59880b3-d545-48b7-a261-f00aabc27c60"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>328754</th>\n",
              "      <td>9</td>\n",
              "      <td>Sadabad-e Sofla</td>\n",
              "      <td>Sadabad-e Sofla (Persian: سعدابادسفلي‎ also R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268204</th>\n",
              "      <td>7</td>\n",
              "      <td>Westgate Mall (Spartanburg)</td>\n",
              "      <td>Westgate Mall is a shopping mall in Spartanbu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53524</th>\n",
              "      <td>2</td>\n",
              "      <td>North Rockland High School</td>\n",
              "      <td>North Rockland High School is a high school l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435646</th>\n",
              "      <td>11</td>\n",
              "      <td>Tillandsia diguetii</td>\n",
              "      <td>Tillandsia diguetii is a species of the genus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254752</th>\n",
              "      <td>7</td>\n",
              "      <td>Palais Wilczek</td>\n",
              "      <td>Palais Wilczek is a palace in Vienna Austria....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29074</th>\n",
              "      <td>1</td>\n",
              "      <td>Canfor</td>\n",
              "      <td>Canfor Corporation is a Canadian integrated f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155059</th>\n",
              "      <td>4</td>\n",
              "      <td>Gerry Rioux</td>\n",
              "      <td>Gerard Rioux (born February 17 1959) is a Can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137451</th>\n",
              "      <td>4</td>\n",
              "      <td>Jerry DePoyster</td>\n",
              "      <td>Jerry Dean DePoyster (born July 6 1946 in Oma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363022</th>\n",
              "      <td>10</td>\n",
              "      <td>Pieris (butterfly)</td>\n",
              "      <td>Pieris the whites or garden whites is a wides...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499846</th>\n",
              "      <td>13</td>\n",
              "      <td>Gunah Aur Kanoon</td>\n",
              "      <td>Gunah Aur Kanoon is a 1970 Bollywood drama fi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                         Name  \\\n",
              "328754      9              Sadabad-e Sofla   \n",
              "268204      7  Westgate Mall (Spartanburg)   \n",
              "53524       2   North Rockland High School   \n",
              "435646     11          Tillandsia diguetii   \n",
              "254752      7               Palais Wilczek   \n",
              "29074       1                       Canfor   \n",
              "155059      4                  Gerry Rioux   \n",
              "137451      4              Jerry DePoyster   \n",
              "363022     10           Pieris (butterfly)   \n",
              "499846     13             Gunah Aur Kanoon   \n",
              "\n",
              "                                                     Text  \n",
              "328754   Sadabad-e Sofla (Persian: سعدابادسفلي‎ also R...  \n",
              "268204   Westgate Mall is a shopping mall in Spartanbu...  \n",
              "53524    North Rockland High School is a high school l...  \n",
              "435646   Tillandsia diguetii is a species of the genus...  \n",
              "254752   Palais Wilczek is a palace in Vienna Austria....  \n",
              "29074    Canfor Corporation is a Canadian integrated f...  \n",
              "155059   Gerard Rioux (born February 17 1959) is a Can...  \n",
              "137451   Jerry Dean DePoyster (born July 6 1946 in Oma...  \n",
              "363022   Pieris the whites or garden whites is a wides...  \n",
              "499846   Gunah Aur Kanoon is a 1970 Bollywood drama fi...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TfT6iGDmAIN",
        "outputId": "886f862a-eaf6-4acb-99a0-118cb7a26793"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xswT0oqpmAIO"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhDMbajkmAIT",
        "outputId": "105d6a76-593c-48b8-c493-63b185afc985"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "346354     Hoseynabad-e Sarzeh (Persian: حسين ابادسرزه‎ ...\n",
              "198538     Milton Berkes (born September 29 1924) is a f...\n",
              "550592     R.M. Williams Outback (or simply Outback) is ...\n",
              "387637     Metasia carnealis is a species of moth in the...\n",
              "366618     The Father Basilio's Striped Mouse or Bioko H...\n",
              "Name: Text, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqppZnZQmAIU",
        "outputId": "b89899e0-977a-46c8-8473-d21f7a46d756"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "346354     9\n",
              "198538     5\n",
              "550592    14\n",
              "387637    10\n",
              "366618    10\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ughVFiEmAIV"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiC_sFpTmAIW"
      },
      "outputs": [],
      "source": [
        "stemmer =  SnowballStemmer('english')\n",
        "analyzer = HashingVectorizer().build_analyzer()\n",
        "\n",
        "def stemmed_words(doc):\n",
        "    return (stemmer.stem(w) for w in analyzer(doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tw_iOlC2mAIW",
        "outputId": "0c123b53-cc19-49fb-941e-eb9c5a560f67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 1024)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stem_vectorizer = HashingVectorizer(n_features=2**10, norm='l2', analyzer=stemmed_words)\n",
        "\n",
        "feature_vector = stem_vectorizer.transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwNCGUwqmAIX",
        "outputId": "c538c8b6-c031-4d0c-8bcd-ac36f740a7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 21)\t0.25607375986579195\n",
            "  (0, 24)\t-0.12803687993289598\n",
            "  (0, 27)\t0.12803687993289598\n",
            "  (0, 61)\t-0.12803687993289598\n",
            "  (0, 62)\t0.12803687993289598\n",
            "  (0, 69)\t-0.12803687993289598\n",
            "  (0, 71)\t-0.25607375986579195\n",
            "  (0, 145)\t-0.12803687993289598\n",
            "  (0, 158)\t-0.12803687993289598\n",
            "  (0, 215)\t0.12803687993289598\n",
            "  (0, 273)\t0.25607375986579195\n",
            "  (0, 301)\t-0.12803687993289598\n",
            "  (0, 304)\t0.12803687993289598\n",
            "  (0, 355)\t0.12803687993289598\n",
            "  (0, 365)\t0.12803687993289598\n",
            "  (0, 424)\t-0.12803687993289598\n",
            "  (0, 540)\t0.25607375986579195\n",
            "  (0, 550)\t-0.12803687993289598\n",
            "  (0, 569)\t0.12803687993289598\n",
            "  (0, 595)\t-0.3841106397986879\n",
            "  (0, 643)\t0.12803687993289598\n",
            "  (0, 659)\t0.12803687993289598\n",
            "  (0, 697)\t0.12803687993289598\n",
            "  (0, 745)\t-0.12803687993289598\n",
            "  (0, 758)\t-0.12803687993289598\n",
            "  (0, 799)\t0.12803687993289598\n",
            "  (0, 832)\t-0.12803687993289598\n",
            "  (0, 877)\t0.12803687993289598\n",
            "  (0, 883)\t0.12803687993289598\n",
            "  (0, 884)\t-0.12803687993289598\n",
            "  (0, 885)\t0.25607375986579195\n",
            "  (0, 913)\t0.12803687993289598\n",
            "  (0, 914)\t-0.12803687993289598\n",
            "  (0, 971)\t-0.25607375986579195\n",
            "  (0, 983)\t-0.12803687993289598\n"
          ]
        }
      ],
      "source": [
        "print(feature_vector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xJHOmSomAIX"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9ljxUlNmAIY",
        "outputId": "0e251aaf-d33c-44db-cffb-6c36c20d75d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 1024)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W07eVK9GmAIY"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1CS3MtRmAIZ",
        "outputId": "ba96d741-8615-473c-fb71-20d2efe6fca3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 1024), (2000, 1024))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdEcfNXjmAIZ",
        "outputId": "b89138be-887f-4282-ed3a-89f5e7349a6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000,), (2000,))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwTpyvtImAIa"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1Jje0hrmAIa",
        "outputId": "a47f01ce-4a36-4f2d-cdbf-4eb286f1ca39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3,  3, 11, ...,  2,  2,  4])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-9eB1bOmAIb",
        "outputId": "ab0d1c30-c268-4759-80de-be48b5f369c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1120\n",
            "accuracy_score :  0.56\n",
            "precision_score :  0.5663465185830068\n",
            "recall_score :  0.56\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHxukba6mAIb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OzF_mAbmAIb"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 13a-CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfPNexVnmAIc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFeFeL2UmAIc"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np6KsLi4mAId",
        "outputId": "929f6061-1a7e-4850-f427-12d92eb98e08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGNh1S6AmAId"
      },
      "source": [
        "### DBPedia classes\n",
        "\n",
        "- Company\n",
        "- EducationalInstitution\n",
        "- Artist\n",
        "- Athlete\n",
        "- OfficeHolder\n",
        "- MeanOfTransportation\n",
        "- Building\n",
        "- NaturalPlace\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- WrittenWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9gGmsznmAIe",
        "outputId": "dd591089-7721-4318-dcb0-8475b21b32d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wnFGOmQmAJF"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cL1qBhJmAJH",
        "outputId": "7f4714f9-0922-446f-e985-5327fed969b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>500996</th>\n",
              "      <td>13</td>\n",
              "      <td>The County Chairman</td>\n",
              "      <td>The County Chairman is a 1935 comedy film dir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40795</th>\n",
              "      <td>2</td>\n",
              "      <td>Our Lady of Mount Carmel High School (Baltimor...</td>\n",
              "      <td>Our Lady of Mount Carmel High School (OLMC HS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131453</th>\n",
              "      <td>4</td>\n",
              "      <td>Jim Kleinsasser</td>\n",
              "      <td>Jimmy Carter Kleinsasser (/ˈklaɪnsɑːsər/; bor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122291</th>\n",
              "      <td>4</td>\n",
              "      <td>August Klingler</td>\n",
              "      <td>August Klingler (24 February 1918 – 23 Novemb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38965</th>\n",
              "      <td>1</td>\n",
              "      <td>Fine Fare</td>\n",
              "      <td>Fine Fare was the name of a chain of supermar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89852</th>\n",
              "      <td>3</td>\n",
              "      <td>Desmond Devlin</td>\n",
              "      <td>Desmond Devlin is an American comedy writer. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481930</th>\n",
              "      <td>13</td>\n",
              "      <td>A Sister to Assist 'Er (1938 film)</td>\n",
              "      <td>A Sister to Assist 'Er is a 1938 British come...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95008</th>\n",
              "      <td>3</td>\n",
              "      <td>Megumi Makihara</td>\n",
              "      <td>Megumi Makihara (槇原めぐみ or 槙原めぐみ or 慎原めぐみ Maki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543571</th>\n",
              "      <td>14</td>\n",
              "      <td>Annals of Science</td>\n",
              "      <td>Annals of Science is a peer-reviewed academic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356791</th>\n",
              "      <td>9</td>\n",
              "      <td>Dula Gavabar</td>\n",
              "      <td>Dula Gavabar (Persian: دولاگوابر‎ also Romani...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                                               Name  \\\n",
              "500996     13                                The County Chairman   \n",
              "40795       2  Our Lady of Mount Carmel High School (Baltimor...   \n",
              "131453      4                                    Jim Kleinsasser   \n",
              "122291      4                                    August Klingler   \n",
              "38965       1                                          Fine Fare   \n",
              "89852       3                                     Desmond Devlin   \n",
              "481930     13                 A Sister to Assist 'Er (1938 film)   \n",
              "95008       3                                    Megumi Makihara   \n",
              "543571     14                                  Annals of Science   \n",
              "356791      9                                       Dula Gavabar   \n",
              "\n",
              "                                                     Text  \n",
              "500996   The County Chairman is a 1935 comedy film dir...  \n",
              "40795    Our Lady of Mount Carmel High School (OLMC HS...  \n",
              "131453   Jimmy Carter Kleinsasser (/ˈklaɪnsɑːsər/; bor...  \n",
              "122291   August Klingler (24 February 1918 – 23 Novemb...  \n",
              "38965    Fine Fare was the name of a chain of supermar...  \n",
              "89852    Desmond Devlin is an American comedy writer. ...  \n",
              "481930   A Sister to Assist 'Er is a 1938 British come...  \n",
              "95008    Megumi Makihara (槇原めぐみ or 槙原めぐみ or 慎原めぐみ Maki...  \n",
              "543571   Annals of Science is a peer-reviewed academic...  \n",
              "356791   Dula Gavabar (Persian: دولاگوابر‎ also Romani...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asXoyGOMmAJI",
        "outputId": "eb841727-4d88-4137-d068-0c05ef58b70c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTWaOGFomAJI"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5_JQVGCmAJJ",
        "outputId": "157f689b-ec13-44ae-bcce-6e7a29acc609"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "113209     Eisuke Yoshiyuki (吉行 エイスケ Yoshiyuki Eisuke Ma...\n",
              "10443      Schroders plc is a British multinational asse...\n",
              "152897     Patrice Ferri is a retired French association...\n",
              "485929     Honey 2 is a dance film which is a sequel to ...\n",
              "312910     Marjanah is an impact crater in the northern ...\n",
              "Name: Text, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFaj32vymAJK",
        "outputId": "f89dc769-9993-4651-d3ae-1d08b8ee778f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "113209     3\n",
              "10443      1\n",
              "152897     4\n",
              "485929    13\n",
              "312910     8\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkP0RJzimAJK"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2uvLW6dmAJL",
        "outputId": "b7e61782-011d-4c14-983b-9f051f38b381"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48133)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrL9aYxVmAJM",
        "outputId": "80bb3202-321a-4432-9144-5f844ab3ac5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 44965)\t1\n",
            "  (0, 45159)\t1\n",
            "  (0, 24477)\t1\n",
            "  (0, 30174)\t1\n",
            "  (0, 5353)\t1\n",
            "  (0, 2617)\t2\n",
            "  (0, 4213)\t1\n",
            "  (0, 29184)\t1\n",
            "  (0, 770)\t1\n",
            "  (0, 41370)\t1\n",
            "  (0, 2229)\t1\n",
            "  (0, 22994)\t1\n",
            "  (0, 44731)\t1\n",
            "  (0, 22447)\t1\n",
            "  (0, 11806)\t1\n",
            "  (0, 3406)\t1\n",
            "  (0, 29564)\t1\n",
            "  (0, 3087)\t1\n",
            "  (0, 21905)\t1\n",
            "  (0, 38741)\t1\n",
            "  (0, 19410)\t3\n",
            "  (0, 32904)\t1\n",
            "  (0, 30043)\t1\n",
            "  (0, 20446)\t1\n",
            "  (0, 6733)\t1\n",
            "  (0, 18881)\t1\n",
            "  (0, 4662)\t2\n",
            "  (0, 21408)\t1\n",
            "  (0, 44526)\t4\n",
            "  (0, 696)\t1\n",
            "  (0, 21879)\t1\n",
            "  (0, 653)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 26417)\t1\n",
            "  (0, 47763)\t1\n",
            "  (0, 47850)\t1\n",
            "  (0, 45736)\t4\n",
            "  (0, 13969)\t3\n"
          ]
        }
      ],
      "source": [
        "print(feature_vector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq3XdcpImAJM"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL9WNl5zmAJN",
        "outputId": "931d2568-fb57-4115-8a80-7a60c9339eb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48133)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrVZKIMJmAJN"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBBhh9zumAJN",
        "outputId": "ba8f402b-a739-4c36-82cf-b92defc2a21e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 48133), (2000, 48133))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY7YhijTmAJO",
        "outputId": "3486c0ab-8ca1-497b-80da-2291f26b4658"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000,), (2000,))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU52hlfmmAJO"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG7ku_b5mAJO",
        "outputId": "5e5b8dc7-4327-4fd1-9d30-317f9796471d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 5, 10,  4, ...,  5,  1, 14])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WtdgStXmAJP",
        "outputId": "e3c12bbe-dea0-48bf-ab39-62d911c78be6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1464\n",
            "accuracy_score :  0.732\n",
            "precision_score :  0.7480649828741391\n",
            "recall_score :  0.732\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il5zMOh8mAJP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GRfWiaUmAJQ"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 13b-StopwordRemoval_CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibnJbFuMmAJQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReFBpSFRmAJR"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gruBGGJtmAJR",
        "outputId": "d8654c68-f6d3-4315-a5f6-dd8316df9fa0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pKsJcYbmAJS"
      },
      "source": [
        "### DBPedia classes\n",
        "\n",
        "- Company\n",
        "- EducationalInstitution\n",
        "- Artist\n",
        "- Athlete\n",
        "- OfficeHolder\n",
        "- MeanOfTransportation\n",
        "- Building\n",
        "- NaturalPlace\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- WrittenWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OmsHUatmAJS",
        "outputId": "03342c00-c5b4-4ba5-b816-c3215e488431"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP1DbhLrmAJT"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EurS5BLcmAJU",
        "outputId": "d054d387-af4d-4002-b5c9-8273529f644b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>524463</th>\n",
              "      <td>14</td>\n",
              "      <td>Open Sesame (manga)</td>\n",
              "      <td>Open Sesame is a Japanese manga series writte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214954</th>\n",
              "      <td>6</td>\n",
              "      <td>USS Porter (DDG-78)</td>\n",
              "      <td>USS Porter (DDG-78) is an Arleigh Burke-class...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369188</th>\n",
              "      <td>10</td>\n",
              "      <td>Chionodes luctuella</td>\n",
              "      <td>Chionodes luctuella is a moth of the Gelechii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15537</th>\n",
              "      <td>1</td>\n",
              "      <td>Rashtriya Chemicals &amp; Fertilizers</td>\n",
              "      <td>Rashtriya Chemicals &amp; Fertilizers Ltd. (RCF) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434426</th>\n",
              "      <td>11</td>\n",
              "      <td>Salix gilgiana</td>\n",
              "      <td>Salix gilgiana is a species of willow native ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315086</th>\n",
              "      <td>8</td>\n",
              "      <td>Devlins Creek</td>\n",
              "      <td>Devlins Creek an urban watercourse that is pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133194</th>\n",
              "      <td>4</td>\n",
              "      <td>Warren Donald</td>\n",
              "      <td>Warren Donald (born 7 October 1964) is an Eng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138090</th>\n",
              "      <td>4</td>\n",
              "      <td>Chris Hatcher (outfielder)</td>\n",
              "      <td>Christopher Kenneth Hatcher (born January 7 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358873</th>\n",
              "      <td>9</td>\n",
              "      <td>Królewskie Ostrzeszów County</td>\n",
              "      <td>Królewskie [kruˈlɛfskʲɛ] is a village in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108048</th>\n",
              "      <td>3</td>\n",
              "      <td>Hamuera Tamahau Mahupuku</td>\n",
              "      <td>Hamuera Tamahau Mahupuku (c.1842 – 14 January...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                               Name  \\\n",
              "524463     14                Open Sesame (manga)   \n",
              "214954      6                USS Porter (DDG-78)   \n",
              "369188     10                Chionodes luctuella   \n",
              "15537       1  Rashtriya Chemicals & Fertilizers   \n",
              "434426     11                     Salix gilgiana   \n",
              "315086      8                      Devlins Creek   \n",
              "133194      4                      Warren Donald   \n",
              "138090      4         Chris Hatcher (outfielder)   \n",
              "358873      9       Królewskie Ostrzeszów County   \n",
              "108048      3           Hamuera Tamahau Mahupuku   \n",
              "\n",
              "                                                     Text  \n",
              "524463   Open Sesame is a Japanese manga series writte...  \n",
              "214954   USS Porter (DDG-78) is an Arleigh Burke-class...  \n",
              "369188   Chionodes luctuella is a moth of the Gelechii...  \n",
              "15537    Rashtriya Chemicals & Fertilizers Ltd. (RCF) ...  \n",
              "434426   Salix gilgiana is a species of willow native ...  \n",
              "315086   Devlins Creek an urban watercourse that is pa...  \n",
              "133194   Warren Donald (born 7 October 1964) is an Eng...  \n",
              "138090   Christopher Kenneth Hatcher (born January 7 1...  \n",
              "358873   Królewskie [kruˈlɛfskʲɛ] is a village in the ...  \n",
              "108048   Hamuera Tamahau Mahupuku (c.1842 – 14 January...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX7DDklRmAJU",
        "outputId": "3f67cf5d-a273-4b43-c959-b18d3f11bfae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qglAohZFmAJV"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M8hpgHSmAJV",
        "outputId": "e0fe820f-70ba-4098-da69-77503458ad83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77514      Phillips University was a private coeducation...\n",
              "341059     Nowiny [nɔˈvinɨ] is a village in the administ...\n",
              "517834     Capricious Summer (Czech: Rozmarné léto) is a...\n",
              "215388     Maumelle Ordnance Works Locomotive 1 is a gas...\n",
              "250923     Grace Reformed Church is a historic church lo...\n",
              "Name: Text, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z8lSE39mAJW",
        "outputId": "a630688b-73f2-4d81-d7d1-2a40c634f0ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77514      2\n",
              "341059     9\n",
              "517834    13\n",
              "215388     6\n",
              "250923     7\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySc3v8SSmAJX"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKLHP690mAJX",
        "outputId": "32cb3988-1172-4aac-a5e1-c33c3e88c4ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47886)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOXk5HwPmAJY",
        "outputId": "f9612a34-c81a-4659-dafd-5912fc2ba6b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 15329)\t1\n",
            "  (0, 28116)\t1\n",
            "  (0, 39106)\t1\n",
            "  (0, 42005)\t1\n",
            "  (0, 14627)\t1\n",
            "  (0, 19453)\t1\n",
            "  (0, 34423)\t1\n",
            "  (0, 7888)\t1\n",
            "  (0, 30095)\t1\n",
            "  (0, 40200)\t1\n",
            "  (0, 19281)\t1\n",
            "  (0, 36984)\t1\n",
            "  (0, 17534)\t1\n",
            "  (0, 9770)\t1\n",
            "  (0, 42720)\t1\n",
            "  (0, 20178)\t1\n",
            "  (0, 9116)\t1\n",
            "  (0, 12475)\t1\n",
            "  (0, 9188)\t1\n",
            "  (0, 9127)\t1\n",
            "  (0, 2428)\t1\n",
            "  (0, 786)\t1\n",
            "  (0, 666)\t1\n",
            "  (0, 39115)\t1\n",
            "  (0, 42819)\t1\n",
            "  (0, 29834)\t1\n",
            "  (0, 14115)\t2\n",
            "  (0, 24524)\t1\n",
            "  (0, 13596)\t1\n",
            "  (0, 19001)\t1\n",
            "  (0, 20458)\t1\n",
            "  (0, 9679)\t1\n",
            "  (0, 32870)\t1\n",
            "  (0, 42838)\t2\n",
            "  (0, 31628)\t2\n"
          ]
        }
      ],
      "source": [
        "print(feature_vector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcyIHognmAJY"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlUyWqV_mAJZ",
        "outputId": "86f11224-23bf-40ac-d8ac-260b9467e035"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47886)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQR_KcGwmAJa"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKw05sPYmAJa",
        "outputId": "c133f0b7-7fd7-421e-a24e-8e93acb2654c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 47886), (2000, 47886))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpdjvhXXmAJb",
        "outputId": "8565d44e-9e06-418d-fd62-a0f3f9c25de1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000,), (2000,))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f91TdrQbmAJb"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2djkpgHmAJc",
        "outputId": "b307968a-acdf-462f-971b-83b6b3757b1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 8, 13,  4, ...,  6,  4, 13])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwIKGnRimAJd",
        "outputId": "f217445c-273f-440b-9526-f19500047f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1472\n",
            "accuracy_score :  0.736\n",
            "precision_score :  0.746912711601029\n",
            "recall_score :  0.736\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stdsFAYmmAJi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI1oA11omAJj"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 13c-StopwordRemoval_FrequencyFiltering_CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUouk2IhmAJk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiWo5TOtmAJk"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO-I7lPgmAJl",
        "outputId": "58c1d08f-4dd6-4c13-ae48-0067f476d184"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_0pmMpTmAJl",
        "outputId": "9526c781-8fea-47f0-f3aa-bc11d8c44eeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcTNxq9ZmAJm"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EIKZsxxmAJm",
        "outputId": "2796dc69-caa9-403e-d5eb-c5b49849463b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>293816</th>\n",
              "      <td>8</td>\n",
              "      <td>Sheep Mountain (Flathead County Montana)</td>\n",
              "      <td>Sheep Mountain (8530 feet (2600 m)) is locate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379389</th>\n",
              "      <td>10</td>\n",
              "      <td>Argyropelecus hemigymnus</td>\n",
              "      <td>Argyropelecus hemigymnus the half-naked hatch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553602</th>\n",
              "      <td>14</td>\n",
              "      <td>Double Identity (novel)</td>\n",
              "      <td>Double Identity is a 2005 young adult novel b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104503</th>\n",
              "      <td>3</td>\n",
              "      <td>Picaflor de los Andes</td>\n",
              "      <td>Víctor Alberto Gil Mallma (1930; Huancayo - J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338288</th>\n",
              "      <td>9</td>\n",
              "      <td>Jerry City Ohio</td>\n",
              "      <td>Jerry City is a village in Wood County Ohio U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244140</th>\n",
              "      <td>7</td>\n",
              "      <td>John Hosford House</td>\n",
              "      <td>The John Hosford House built in 1860 is an hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182565</th>\n",
              "      <td>5</td>\n",
              "      <td>Hunt Downer</td>\n",
              "      <td>Major General Huntington Blair Downer Jr. kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252037</th>\n",
              "      <td>7</td>\n",
              "      <td>Brea City Hall and Park</td>\n",
              "      <td>Brea City Hall and Park in Brea California wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98721</th>\n",
              "      <td>3</td>\n",
              "      <td>Christian Jacob (musician)</td>\n",
              "      <td>Christian Jacob is a lyrical jazz pianist. He...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188815</th>\n",
              "      <td>5</td>\n",
              "      <td>George Forbes (New Zealand politician)</td>\n",
              "      <td>George William Forbes (12 March 1869 – 17 May...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                                      Name  \\\n",
              "293816      8  Sheep Mountain (Flathead County Montana)   \n",
              "379389     10                  Argyropelecus hemigymnus   \n",
              "553602     14                   Double Identity (novel)   \n",
              "104503      3                     Picaflor de los Andes   \n",
              "338288      9                           Jerry City Ohio   \n",
              "244140      7                        John Hosford House   \n",
              "182565      5                               Hunt Downer   \n",
              "252037      7                   Brea City Hall and Park   \n",
              "98721       3                Christian Jacob (musician)   \n",
              "188815      5    George Forbes (New Zealand politician)   \n",
              "\n",
              "                                                     Text  \n",
              "293816   Sheep Mountain (8530 feet (2600 m)) is locate...  \n",
              "379389   Argyropelecus hemigymnus the half-naked hatch...  \n",
              "553602   Double Identity is a 2005 young adult novel b...  \n",
              "104503   Víctor Alberto Gil Mallma (1930; Huancayo - J...  \n",
              "338288   Jerry City is a village in Wood County Ohio U...  \n",
              "244140   The John Hosford House built in 1860 is an hi...  \n",
              "182565   Major General Huntington Blair Downer Jr. kno...  \n",
              "252037   Brea City Hall and Park in Brea California wa...  \n",
              "98721    Christian Jacob is a lyrical jazz pianist. He...  \n",
              "188815   George William Forbes (12 March 1869 – 17 May...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcRyFEPfmAJn",
        "outputId": "1c384a99-db9c-4cfe-9a37-94adb649bbfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2RVFJqrmAJo"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bBD4DpomAJp"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6g9oG_emAJp",
        "outputId": "b53579c0-4aa1-46e0-9698-68e44ad55efd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "503033"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = word_tokenize(\"\\n\".join(X.values))\n",
        "\n",
        "len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q44Z9YBHmAJq",
        "outputId": "5b4c6246-8a93-40a6-f4e1-9716285b72fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FreqDist({'the': 23584, '.': 23365, 'in': 16237, 'of': 15558, 'is': 13472, 'a': 13075, 'and': 12741, '(': 7078, ')': 7048, 'was': 6816, ...})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq = FreqDist(tokens)\n",
        "freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UOBShfZmAJr",
        "outputId": "6dd1b6b3-44ab-49f3-8109-e3665e9a8fe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "491"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequent_words = []\n",
        "\n",
        "for key, value in freq.items():\n",
        "    if value >= 100:\n",
        "        frequent_words.append(key.lower())\n",
        "\n",
        "len(frequent_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zCwC4rKmAJs",
        "outputId": "5b583584-4529-4d16-e1f2-0b8739536c57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['columbia',\n",
              " '(',\n",
              " ')',\n",
              " 'was',\n",
              " 'an',\n",
              " 'american',\n",
              " 'company',\n",
              " 'that',\n",
              " 'from',\n",
              " '1994',\n",
              " 'to',\n",
              " '2002',\n",
              " '.',\n",
              " 'it',\n",
              " 'operated',\n",
              " 'as',\n",
              " 'the',\n",
              " 'third',\n",
              " 'name',\n",
              " 'of',\n",
              " 'early',\n",
              " 'studio',\n",
              " 'and',\n",
              " 'part',\n",
              " 'second']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequent_words[:25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56f1PehHmAJt"
      },
      "outputs": [],
      "source": [
        "stop_words = text.ENGLISH_STOP_WORDS.union(frequent_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBiiFD9gmAJu",
        "outputId": "4080a397-f037-4094-9694-26643e717473"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['st'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(10000, 47434)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(stop_words=stop_words)\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnoTyb7_mAJv"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YoP534zmAJv",
        "outputId": "0eb64902-d7aa-4afa-f526-7fcc15f6b2cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47434)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaa4IoEKmAJw"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZVDa41tmAJx"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2eaKuzjmAJy",
        "outputId": "c87ba51f-fcaf-4f6d-f3c4-f41e5fbbec45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([13,  9, 13, ...,  7, 11,  5])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRxTT-kzmAJz",
        "outputId": "0356900f-2352-4bf8-bf62-135271ab946e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1397\n",
            "accuracy_score :  0.6985\n",
            "precision_score :  0.7009864007615241\n",
            "recall_score :  0.6985\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMuQ1LF_mAJz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y2gCz1ZmAJ0"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 13d-Bigrams_CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahSfEwucmAJ1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtKCzBQpmAJ2"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxnZJXcimAJ2",
        "outputId": "3938cad9-46c9-4407-d0bc-a76a696a4d71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdL2hiFSmAJ3",
        "outputId": "5d16ba08-6cc6-44e6-f1c0-9e898bed6e5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdnLXiMnmAJ4"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AckSonzFmAJ5",
        "outputId": "b2d5b0cb-0ee7-4a82-f5a1-c9c4226572aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>427520</th>\n",
              "      <td>11</td>\n",
              "      <td>Guzmania remyi</td>\n",
              "      <td>Guzmania remyi is a species of plant in the B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522145</th>\n",
              "      <td>14</td>\n",
              "      <td>Villa Aurore</td>\n",
              "      <td>Villa Aurore is a novel written in French by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462552</th>\n",
              "      <td>12</td>\n",
              "      <td>Monk's Casino</td>\n",
              "      <td>Monk's Casino is a live album by German free ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2460</th>\n",
              "      <td>1</td>\n",
              "      <td>Kiss Technology</td>\n",
              "      <td>Kiss Technology is an entertainment technolog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83743</th>\n",
              "      <td>3</td>\n",
              "      <td>S.M. Zakir</td>\n",
              "      <td>S.M. Zakir (born 4 February 1969 in Kota Bhar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554887</th>\n",
              "      <td>14</td>\n",
              "      <td>New York Law Journal</td>\n",
              "      <td>The New York Law Journal founded in 1888 is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270857</th>\n",
              "      <td>7</td>\n",
              "      <td>Latham United Methodist Church</td>\n",
              "      <td>Latham United Methodist Church is a historic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323989</th>\n",
              "      <td>9</td>\n",
              "      <td>Nalavadi</td>\n",
              "      <td>Nalavadi is a village in Dharwad district in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193352</th>\n",
              "      <td>5</td>\n",
              "      <td>Richard Ottley (judge)</td>\n",
              "      <td>Sir Richard Ottley was the 5th Chief Justice ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78104</th>\n",
              "      <td>2</td>\n",
              "      <td>Umatilla High School (Oregon)</td>\n",
              "      <td>Umatilla High School is a public high school ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                            Name  \\\n",
              "427520     11                  Guzmania remyi   \n",
              "522145     14                    Villa Aurore   \n",
              "462552     12                   Monk's Casino   \n",
              "2460        1                 Kiss Technology   \n",
              "83743       3                      S.M. Zakir   \n",
              "554887     14            New York Law Journal   \n",
              "270857      7  Latham United Methodist Church   \n",
              "323989      9                        Nalavadi   \n",
              "193352      5          Richard Ottley (judge)   \n",
              "78104       2   Umatilla High School (Oregon)   \n",
              "\n",
              "                                                     Text  \n",
              "427520   Guzmania remyi is a species of plant in the B...  \n",
              "522145   Villa Aurore is a novel written in French by ...  \n",
              "462552   Monk's Casino is a live album by German free ...  \n",
              "2460     Kiss Technology is an entertainment technolog...  \n",
              "83743    S.M. Zakir (born 4 February 1969 in Kota Bhar...  \n",
              "554887   The New York Law Journal founded in 1888 is a...  \n",
              "270857   Latham United Methodist Church is a historic ...  \n",
              "323989   Nalavadi is a village in Dharwad district in ...  \n",
              "193352   Sir Richard Ottley was the 5th Chief Justice ...  \n",
              "78104    Umatilla High School is a public high school ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzUFZnLtmAJ6",
        "outputId": "34432f2b-a85d-48a4-842a-3a8771ed9e72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE0v99Q1mAJ6"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UebzmgN-mAJ7"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5MM1xc-mAJ8",
        "outputId": "b58e2c58-97b9-4fe0-fb8a-0eac192c9613"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217709)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN6FjjLXmAJ9"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwc1uG12mAJ9",
        "outputId": "c47f8355-6983-4894-e510-2276e87eec4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217709)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EITFB3e1mAJ-"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f03f8XGsmAJ-"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D32xsAipmAJ_",
        "outputId": "7beacf49-9c6d-40d9-b8f1-fdc0f41557ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 1, 5, ..., 4, 7, 8])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc-HRm9SmAJ_",
        "outputId": "6c263dcd-bff7-4c7b-d007-81a658a65cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1812\n",
            "accuracy_score :  0.906\n",
            "precision_score :  0.9071432275572098\n",
            "recall_score :  0.906\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWq8AwSVmAKA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An6tO65qmAKA"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 14-TfidfVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wte9gA5CmAKB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67Y2ynWmmAKB"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5bEuH5OmAKC",
        "outputId": "7e1ec12a-52a4-4694-cb93-9715c25872b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOcOTkt3mAKC",
        "outputId": "c91d3a3a-427f-47f2-e442-1aeff23bb6d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtuJAJoMmAKD"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVPYeBN3mAKD",
        "outputId": "22c33335-ec26-4db8-8a11-9b79a6d30254"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>252405</th>\n",
              "      <td>7</td>\n",
              "      <td>Prowers Bridge</td>\n",
              "      <td>The Prowers Bridge over the Arkansas River ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504457</th>\n",
              "      <td>13</td>\n",
              "      <td>Que sera sera (film)</td>\n",
              "      <td>Que sera sera (Portuguese: Seja o que Deus Qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270494</th>\n",
              "      <td>7</td>\n",
              "      <td>The Esplanade (Kenner Louisiana)</td>\n",
              "      <td>The Esplanade also known as the Esplanade Mal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546058</th>\n",
              "      <td>14</td>\n",
              "      <td>The 1974 Annual World's Best SF</td>\n",
              "      <td>The 1974 Annual World's Best SF is an antholo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461279</th>\n",
              "      <td>12</td>\n",
              "      <td>Just Go (album)</td>\n",
              "      <td>Just Go is the ninth studio album by American...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277143</th>\n",
              "      <td>7</td>\n",
              "      <td>Steyning Methodist Church</td>\n",
              "      <td>Steyning Methodist Church is a Methodist plac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266867</th>\n",
              "      <td>7</td>\n",
              "      <td>Smith Estate (Ridge New York)</td>\n",
              "      <td>Smith Estate also known as Longwood Estate - ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283712</th>\n",
              "      <td>8</td>\n",
              "      <td>Yr Eifl</td>\n",
              "      <td>Yr Eifl is a mountain on the north coast of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33861</th>\n",
              "      <td>1</td>\n",
              "      <td>IBM India</td>\n",
              "      <td>IBM India Private Limited is the Indian subsi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70953</th>\n",
              "      <td>2</td>\n",
              "      <td>Loreto College of Rose-Hill</td>\n",
              "      <td>Loreto College Rose Hill is a private seconda...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                              Name  \\\n",
              "252405      7                    Prowers Bridge   \n",
              "504457     13              Que sera sera (film)   \n",
              "270494      7  The Esplanade (Kenner Louisiana)   \n",
              "546058     14   The 1974 Annual World's Best SF   \n",
              "461279     12                   Just Go (album)   \n",
              "277143      7         Steyning Methodist Church   \n",
              "266867      7     Smith Estate (Ridge New York)   \n",
              "283712      8                           Yr Eifl   \n",
              "33861       1                         IBM India   \n",
              "70953       2       Loreto College of Rose-Hill   \n",
              "\n",
              "                                                     Text  \n",
              "252405   The Prowers Bridge over the Arkansas River ne...  \n",
              "504457   Que sera sera (Portuguese: Seja o que Deus Qu...  \n",
              "270494   The Esplanade also known as the Esplanade Mal...  \n",
              "546058   The 1974 Annual World's Best SF is an antholo...  \n",
              "461279   Just Go is the ninth studio album by American...  \n",
              "277143   Steyning Methodist Church is a Methodist plac...  \n",
              "266867   Smith Estate also known as Longwood Estate - ...  \n",
              "283712   Yr Eifl is a mountain on the north coast of t...  \n",
              "33861    IBM India Private Limited is the Indian subsi...  \n",
              "70953    Loreto College Rose Hill is a private seconda...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5BAedPImAKE",
        "outputId": "be2fb5f4-64ae-429b-9264-9df841484bbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5sk0wDVmAKE"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVGrzxdJmAKF"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8IPujEUmAKF",
        "outputId": "53f87d23-a450-4219-992c-dcec6907d2e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48401)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "feature_vector = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxMlF6yfmAKG"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii1Fp7XLmAKH",
        "outputId": "8ca6c46f-6272-4641-c525-53112e06e0ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48401)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sicXSjWmAKH"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR2en5hqmAKH"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXN41eU8mAKH",
        "outputId": "7b08b92c-79e4-4840-9c6f-b3db41ab2cee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10,  7,  7, ...,  7,  4, 12])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGxHO03emAKL",
        "outputId": "6c11ddaf-cdff-4014-92ca-29c30d8e3227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1398\n",
            "accuracy_score :  0.699\n",
            "precision_score :  0.7100351307095724\n",
            "recall_score :  0.699\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i28nTDPmAKM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcWnwghPmAKO"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 15a-CountVectorizer_TfidfTransformer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Eac03rmAKP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o43iXlGymAKP"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFsnfsmkmAKQ",
        "outputId": "0ae8555d-c835-4af5-f1b9-b50fc4c4afe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKnRlk3SmAKQ",
        "outputId": "6cb00c50-10da-435d-a1fd-94d9c61ec179"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhF6_U2WmAKR"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhymYNwemAKR",
        "outputId": "fc2cfb88-b3d7-406d-8af4-286f71eb0ccc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>445879</th>\n",
              "      <td>12</td>\n",
              "      <td>Lucas (album)</td>\n",
              "      <td>Lucas is the second album by Ghostly Internat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120854</th>\n",
              "      <td>4</td>\n",
              "      <td>Pat McGehee</td>\n",
              "      <td>Patrick Henry McGehee (July 2 1888 – December...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449608</th>\n",
              "      <td>12</td>\n",
              "      <td>One Too Many Hearts</td>\n",
              "      <td>One Too Many Hearts is the third EP by Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171512</th>\n",
              "      <td>5</td>\n",
              "      <td>Arken Arystanov</td>\n",
              "      <td>Arkén Kenesbékovich Arystánov (Kazakh: Аркен ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26868</th>\n",
              "      <td>1</td>\n",
              "      <td>Cineplex Odeon Films</td>\n",
              "      <td>Cineplex Odeon Films (also known as Cineplex ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402498</th>\n",
              "      <td>11</td>\n",
              "      <td>Steirachne</td>\n",
              "      <td>Steirachne is a genus of grass in the Poaceae...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102353</th>\n",
              "      <td>3</td>\n",
              "      <td>Harry Thumann</td>\n",
              "      <td>Harry Thumann (28 February 1952 – 2001) was a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337385</th>\n",
              "      <td>9</td>\n",
              "      <td>Chah Sheykh</td>\n",
              "      <td>Chah Sheykh (Persian: چاه شيخ‎ also Romanized...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485176</th>\n",
              "      <td>13</td>\n",
              "      <td>Emmtan-Magan</td>\n",
              "      <td>Em Magan is a 2006 Tamil drama film directed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295129</th>\n",
              "      <td>8</td>\n",
              "      <td>Hot Springs Range</td>\n",
              "      <td>The Hot Springs Range is a mountain range in ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                  Name  \\\n",
              "445879     12         Lucas (album)   \n",
              "120854      4           Pat McGehee   \n",
              "449608     12   One Too Many Hearts   \n",
              "171512      5       Arken Arystanov   \n",
              "26868       1  Cineplex Odeon Films   \n",
              "402498     11            Steirachne   \n",
              "102353      3         Harry Thumann   \n",
              "337385      9           Chah Sheykh   \n",
              "485176     13          Emmtan-Magan   \n",
              "295129      8     Hot Springs Range   \n",
              "\n",
              "                                                     Text  \n",
              "445879   Lucas is the second album by Ghostly Internat...  \n",
              "120854   Patrick Henry McGehee (July 2 1888 – December...  \n",
              "449608   One Too Many Hearts is the third EP by Americ...  \n",
              "171512   Arkén Kenesbékovich Arystánov (Kazakh: Аркен ...  \n",
              "26868    Cineplex Odeon Films (also known as Cineplex ...  \n",
              "402498   Steirachne is a genus of grass in the Poaceae...  \n",
              "102353   Harry Thumann (28 February 1952 – 2001) was a...  \n",
              "337385   Chah Sheykh (Persian: چاه شيخ‎ also Romanized...  \n",
              "485176   Em Magan is a 2006 Tamil drama film directed ...  \n",
              "295129   The Hot Springs Range is a mountain range in ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x2LzfRTmAKS",
        "outputId": "f945c8dd-7f31-46d1-8797-a7125a6fd37b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycgR4ikAmAKS"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QODo8n1hmAKT"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLh9ejVemAKU",
        "outputId": "3a289bc2-813e-4754-b2b6-bc907c5b5f52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48318)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vfqwu_VjmAKV",
        "outputId": "ef844f73-8d03-4406-9035-0087b997c4ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48318)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "feature_vector = tfidf_transformer.fit_transform(feature_vector)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRYa04iqmAKW"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ti7_J4dmAKX",
        "outputId": "5b909ee6-bef9-416e-c5b8-463c3d51a4a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48318)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1Dny1TlmAKY"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwrWuJyqmAKY"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fKd5loYmAKZ",
        "outputId": "5e335f6f-c7ca-4491-8dab-ad43b820bc70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  1,  3, ..., 12, 10,  5])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e4OrdjLmAKZ",
        "outputId": "2b33f4c2-cda7-47ae-fed7-8136a0425389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1438\n",
            "accuracy_score :  0.719\n",
            "precision_score :  0.7284791775245764\n",
            "recall_score :  0.719\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx023HrpmAKa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMuhHcIYmAKa"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 15b-FrequencyFiltering_CountVectorizer_TfidfTransformer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXEVSyvTmAKa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvzh1HlumAKb"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70VdhttsmAKb",
        "outputId": "1b6da5e2-3bba-4fe8-ce33-b3ca3a40443d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9YHAdH7mAKb",
        "outputId": "c113e879-036a-4a4e-93c4-3f33c14cf976"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duB5IBp_mAKc"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhe1vbScmAKc",
        "outputId": "0663b8d9-759e-456e-822d-30716d9bca5b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>510378</th>\n",
              "      <td>13</td>\n",
              "      <td>Unknown (2006 film)</td>\n",
              "      <td>Unknown is a 2006 American crime-thriller fil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510665</th>\n",
              "      <td>13</td>\n",
              "      <td>World Without Sun</td>\n",
              "      <td>World Without Sun (French: Le Monde sans sole...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392655</th>\n",
              "      <td>10</td>\n",
              "      <td>Argyresthia pseudotsuga</td>\n",
              "      <td>Argyresthia pseudotsuga is a moth of the Ypon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419827</th>\n",
              "      <td>11</td>\n",
              "      <td>Erythronium multiscapoideum</td>\n",
              "      <td>Erythronium multiscapoideum is a species of f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217867</th>\n",
              "      <td>6</td>\n",
              "      <td>Simca 5</td>\n",
              "      <td>The Simca 5 is a small Franco-Italian passeng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377408</th>\n",
              "      <td>10</td>\n",
              "      <td>Bucculatrix zophopasta</td>\n",
              "      <td>Bucculatrix zophopasta is a moth in the Buccu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232485</th>\n",
              "      <td>6</td>\n",
              "      <td>HMS Ajax (F114)</td>\n",
              "      <td>HMS Ajax was a Leander-class frigate of the R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327195</th>\n",
              "      <td>9</td>\n",
              "      <td>Ruś Ostróda County</td>\n",
              "      <td>Ruś [ruɕ] (German Reussen) is a village in th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478293</th>\n",
              "      <td>12</td>\n",
              "      <td>Mortal Kombat: The Album</td>\n",
              "      <td>Mortal Kombat: The Album is an album by The I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533360</th>\n",
              "      <td>14</td>\n",
              "      <td>Makers (novel)</td>\n",
              "      <td>Makers is a novel by Cory Doctorow. It was re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                         Name  \\\n",
              "510378     13          Unknown (2006 film)   \n",
              "510665     13            World Without Sun   \n",
              "392655     10      Argyresthia pseudotsuga   \n",
              "419827     11  Erythronium multiscapoideum   \n",
              "217867      6                      Simca 5   \n",
              "377408     10       Bucculatrix zophopasta   \n",
              "232485      6              HMS Ajax (F114)   \n",
              "327195      9           Ruś Ostróda County   \n",
              "478293     12     Mortal Kombat: The Album   \n",
              "533360     14               Makers (novel)   \n",
              "\n",
              "                                                     Text  \n",
              "510378   Unknown is a 2006 American crime-thriller fil...  \n",
              "510665   World Without Sun (French: Le Monde sans sole...  \n",
              "392655   Argyresthia pseudotsuga is a moth of the Ypon...  \n",
              "419827   Erythronium multiscapoideum is a species of f...  \n",
              "217867   The Simca 5 is a small Franco-Italian passeng...  \n",
              "377408   Bucculatrix zophopasta is a moth in the Buccu...  \n",
              "232485   HMS Ajax was a Leander-class frigate of the R...  \n",
              "327195   Ruś [ruɕ] (German Reussen) is a village in th...  \n",
              "478293   Mortal Kombat: The Album is an album by The I...  \n",
              "533360   Makers is a novel by Cory Doctorow. It was re...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccrdYfiamAKd",
        "outputId": "b1d0b3d7-8efa-4cfa-d929-3d1f908c6cf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S5J0Pq-mAKd"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYlsvTgZmAKe"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NX2GxiaXmAKe",
        "outputId": "230b8ea4-836a-4013-ef29-be8f22cef822"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47544)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0, max_df=80)\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzDmKuzSmAKf",
        "outputId": "7b15a8fa-a8be-486d-d515-0fe457268321"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47544)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "feature_vector = tfidf_transformer.fit_transform(feature_vector)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_CwVqpZmAKg"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzqLrDmQmAKh",
        "outputId": "5e4342ee-0a8a-4e2d-94f8-000ca5eb5d17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47544)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZesuKO-mAKi"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2YcFd51mAKi"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut_5xodRmAKj",
        "outputId": "342da337-c9f6-407b-8697-a30f30a17231"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10,  4,  1, ..., 13,  6,  2])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym5IIVIXmAKj",
        "outputId": "aac8bdfe-189c-42ac-fd25-0598da478adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1316\n",
            "accuracy_score :  0.658\n",
            "precision_score :  0.6650727642789968\n",
            "recall_score :  0.658\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcQTJYu3mAKk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xirkLjtWmAKk"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 15c-StopwordRemoval_FrequencyFiltering_CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LscAAKQpmAKl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2FJYuS2mAKl"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaXYPD1ImAKm",
        "outputId": "34223762-28b0-418c-dbac-8ca1799d80d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIu3sS4VmAKm",
        "outputId": "edad97c8-8c41-48f8-dc6b-a877eabd3abd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3U7a1cxmAKn"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o7tK2GNmAKn",
        "outputId": "41c52c29-ee1f-4910-a9a0-44de96bd1b3c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>179975</th>\n",
              "      <td>5</td>\n",
              "      <td>Ramreddy Damodar Reddy</td>\n",
              "      <td>Ramreddy Damodar Reddy (Telugu: రాంరెడ్డి దామ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558672</th>\n",
              "      <td>14</td>\n",
              "      <td>Sonora Review</td>\n",
              "      <td>Sonora Review is a biannual graduate student-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503492</th>\n",
              "      <td>13</td>\n",
              "      <td>Luz en el páramo</td>\n",
              "      <td>Luz en el páramo is a 1953 Venezuelan film di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40980</th>\n",
              "      <td>2</td>\n",
              "      <td>Oswaldo Cruz Foundation</td>\n",
              "      <td>The Oswaldo Cruz Foundation (Portuguese Funda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199065</th>\n",
              "      <td>5</td>\n",
              "      <td>Tate Reeves</td>\n",
              "      <td>Jonathon Tate Reeves (born June 5 1974) a Rep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20373</th>\n",
              "      <td>1</td>\n",
              "      <td>Indie Boyz</td>\n",
              "      <td>Indie Boyz is a European company based in Lon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131192</th>\n",
              "      <td>4</td>\n",
              "      <td>Hanna Mazgunova</td>\n",
              "      <td>Hanna Mazgunova (Belarusian: Ганна Мазгунова;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438389</th>\n",
              "      <td>11</td>\n",
              "      <td>Platystemon</td>\n",
              "      <td>Platystemon is a monotypic genus of flowering...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295233</th>\n",
              "      <td>8</td>\n",
              "      <td>Paddys River (South West Slopes New South Wales)</td>\n",
              "      <td>Paddys River a watercourse of the Murray catc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481401</th>\n",
              "      <td>13</td>\n",
              "      <td>The Ragged Edge (film)</td>\n",
              "      <td>The Ragged Edge is a lost 1923 silent film So...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                                              Name  \\\n",
              "179975      5                            Ramreddy Damodar Reddy   \n",
              "558672     14                                     Sonora Review   \n",
              "503492     13                                  Luz en el páramo   \n",
              "40980       2                           Oswaldo Cruz Foundation   \n",
              "199065      5                                       Tate Reeves   \n",
              "20373       1                                        Indie Boyz   \n",
              "131192      4                                   Hanna Mazgunova   \n",
              "438389     11                                       Platystemon   \n",
              "295233      8  Paddys River (South West Slopes New South Wales)   \n",
              "481401     13                            The Ragged Edge (film)   \n",
              "\n",
              "                                                     Text  \n",
              "179975   Ramreddy Damodar Reddy (Telugu: రాంరెడ్డి దామ...  \n",
              "558672   Sonora Review is a biannual graduate student-...  \n",
              "503492   Luz en el páramo is a 1953 Venezuelan film di...  \n",
              "40980    The Oswaldo Cruz Foundation (Portuguese Funda...  \n",
              "199065   Jonathon Tate Reeves (born June 5 1974) a Rep...  \n",
              "20373    Indie Boyz is a European company based in Lon...  \n",
              "131192   Hanna Mazgunova (Belarusian: Ганна Мазгунова;...  \n",
              "438389   Platystemon is a monotypic genus of flowering...  \n",
              "295233   Paddys River a watercourse of the Murray catc...  \n",
              "481401   The Ragged Edge is a lost 1923 silent film So...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu63ER2XmAKn",
        "outputId": "c6519208-00d5-46e7-c852-4b06fef51739"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ot1Wf50mAKo"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40keOnpzmAKo"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBYeE3ZMmAKp",
        "outputId": "79a1041c-778e-4697-b910-a2c1a0bbdf5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "504495"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = word_tokenize(\"\\n\".join(X.values))\n",
        "\n",
        "len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeXJgWeQmAKp",
        "outputId": "184aebf1-e767-4428-f2a4-8f3d825e0111"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FreqDist({'the': 23494, '.': 23437, 'in': 16379, 'of': 15332, 'is': 13499, 'and': 12934, 'a': 12862, '(': 7204, ')': 7199, 'was': 6950, ...})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq = FreqDist(tokens)\n",
        "freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLWPim3mmAKq",
        "outputId": "78e2d002-5fd8-407f-d549-fbb91f5ac21b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "487"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequent_words = []\n",
        "\n",
        "for key, value in freq.items():\n",
        "    if value >= 100:\n",
        "        frequent_words.append(key.lower())\n",
        "\n",
        "len(frequent_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCxuMWXUmAKr",
        "outputId": "22605467-ecd1-4f45-dee2-fa3af6763692"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['(',\n",
              " ':',\n",
              " '[',\n",
              " ']',\n",
              " '.',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'lake',\n",
              " 'in',\n",
              " 'located',\n",
              " 'north',\n",
              " 'of',\n",
              " 'the',\n",
              " 'town',\n",
              " 'district',\n",
              " 'not',\n",
              " '1',\n",
              " 'the',\n",
              " 'area',\n",
              " 'by',\n",
              " 'including',\n",
              " '2001',\n",
              " 'was',\n",
              " 'international']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequent_words[:25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezi7r4pymAKs"
      },
      "outputs": [],
      "source": [
        "stop_words = text.ENGLISH_STOP_WORDS.union(frequent_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4oCzawrmAKt",
        "outputId": "4b6d7896-aafa-459b-deca-bf2fcad7d788"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47573)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(stop_words=stop_words)\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqjakT2imAKy",
        "outputId": "7e8a8d30-8514-4479-fd9a-8ae5d6f3c496"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47573)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "feature_vector = tfidf_transformer.fit_transform(feature_vector)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yob4FvJHmAKz"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH7ak5u3mAKz",
        "outputId": "cbdca348-731b-4193-dc8f-e189e985f5a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47573)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsOlQPfvmAK0"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPk-PPjomAK1"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu8XlU1RmAK2",
        "outputId": "1c8d359a-e51f-4a76-927b-b943c1ec730c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7,  7,  1, ..., 13, 14, 11])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5079JnrFmAK2",
        "outputId": "1469f448-6ed7-471d-b474-fe9c8065e42a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1335\n",
            "accuracy_score :  0.6675\n",
            "precision_score :  0.6803619205404001\n",
            "recall_score :  0.6675\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fVNOWeAmAK3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvC58JPfmAK3"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 15d-Bigrams_CountVectorizer_TfidfTransformer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXNW6LzWmAK4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64ZZNggAmAK5"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpwEVXstmAK5",
        "outputId": "9d472548-63ab-47c3-ef3e-56644fbadbd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnB_0EAvmAK6",
        "outputId": "02bb187c-5971-4855-f40a-4915611b78c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0u7dnsomAK6"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxHGYnCJmAK7",
        "outputId": "4f9faa98-cf8f-4efe-93b7-fa0af67665f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>521705</th>\n",
              "      <td>14</td>\n",
              "      <td>Woodstock (novel)</td>\n",
              "      <td>Woodstock or The Cavalier. A Tale of the Year...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373693</th>\n",
              "      <td>10</td>\n",
              "      <td>Cryptophagidae</td>\n",
              "      <td>Cryptophagidae is a family of beetles with re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333934</th>\n",
              "      <td>9</td>\n",
              "      <td>Dehliz-e Yek</td>\n",
              "      <td>Dehliz-e Yek (Persian: دهليزيك‎ also Romanize...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125305</th>\n",
              "      <td>4</td>\n",
              "      <td>Roland Osabutey</td>\n",
              "      <td>Roland Osabutey (born 11 March 1980) is a Gha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100866</th>\n",
              "      <td>3</td>\n",
              "      <td>Ann Voskamp</td>\n",
              "      <td>Ann Voskamp (born August 10 1973 in Listowel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58320</th>\n",
              "      <td>2</td>\n",
              "      <td>Robert Bateman High School</td>\n",
              "      <td>Robert Bateman High School (also known as Rob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419470</th>\n",
              "      <td>11</td>\n",
              "      <td>Vriesea languida</td>\n",
              "      <td>Vriesea languida is a species of the genus Vr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164430</th>\n",
              "      <td>5</td>\n",
              "      <td>Gilbert Wellington Ostrom</td>\n",
              "      <td>Gilbert Wellington Ostrom (June 1837 – Decemb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426098</th>\n",
              "      <td>11</td>\n",
              "      <td>Banara regia</td>\n",
              "      <td>Banara regia is a species of plant in the Sal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281236</th>\n",
              "      <td>8</td>\n",
              "      <td>Calder River (Western Australia)</td>\n",
              "      <td>For other Rivers Calder see River Calder (dis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                              Name  \\\n",
              "521705     14                 Woodstock (novel)   \n",
              "373693     10                    Cryptophagidae   \n",
              "333934      9                      Dehliz-e Yek   \n",
              "125305      4                   Roland Osabutey   \n",
              "100866      3                       Ann Voskamp   \n",
              "58320       2        Robert Bateman High School   \n",
              "419470     11                  Vriesea languida   \n",
              "164430      5         Gilbert Wellington Ostrom   \n",
              "426098     11                      Banara regia   \n",
              "281236      8  Calder River (Western Australia)   \n",
              "\n",
              "                                                     Text  \n",
              "521705   Woodstock or The Cavalier. A Tale of the Year...  \n",
              "373693   Cryptophagidae is a family of beetles with re...  \n",
              "333934   Dehliz-e Yek (Persian: دهليزيك‎ also Romanize...  \n",
              "125305   Roland Osabutey (born 11 March 1980) is a Gha...  \n",
              "100866   Ann Voskamp (born August 10 1973 in Listowel ...  \n",
              "58320    Robert Bateman High School (also known as Rob...  \n",
              "419470   Vriesea languida is a species of the genus Vr...  \n",
              "164430   Gilbert Wellington Ostrom (June 1837 – Decemb...  \n",
              "426098   Banara regia is a species of plant in the Sal...  \n",
              "281236   For other Rivers Calder see River Calder (dis...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_X5EyfcmAK8",
        "outputId": "d3eff541-b557-4289-c497-a8ecd4e65cc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OaqRbjamAK8"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKi4DjHNmAK9"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR_XLU0lmAK-",
        "outputId": "991cf6ab-e757-4962-869f-f5e17f5f2b23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217434)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0, max_df=80, ngram_range=(2, 2))\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vPK2umVmAK_",
        "outputId": "c35d019f-344f-4d2c-b5d0-6baf143e9e2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217434)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "feature_vector = tfidf_transformer.fit_transform(feature_vector)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtpZDc33mAK_"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1NXs78DmALA",
        "outputId": "55d6671f-d95b-40c9-d2a9-fc8f299e5cb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217434)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhNxxRw_mALB"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbFtgqi6mALB"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyWUta5KmALC",
        "outputId": "77ac2935-2cf1-403a-902e-5c855043b58a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7, 12,  6, ...,  1, 12,  3])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAb2uWhxmALD",
        "outputId": "b9a27540-98aa-4bd0-ca52-0009cefa6ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1778\n",
            "accuracy_score :  0.889\n",
            "precision_score :  0.8902761517734769\n",
            "recall_score :  0.889\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8Zm8QbsmALE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_OBo82tmALE"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: baseFile</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2heOERSpmALF"
      },
      "source": [
        "# *Merged Jupyter Notebook*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmSfiWjYmALF"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 01-TokenizingTextIntoSentencesAndWords</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOKZs5EimALG"
      },
      "source": [
        "## Tokenize text into words and sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-r49GFrmALG",
        "outputId": "fc2d6d68-845a-4b6f-be92-b61a7ed92d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.16.1\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "print(numpy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl0TxJCgmALH",
        "outputId": "35f9db50-a8f6-4253-b056-68d77ff06f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.4\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "print(nltk.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py1ihsIsmALH"
      },
      "source": [
        "#### Uses NLTK's recommended sentence tokenizer, the PunktSentenceTokenizer\n",
        "#### Uses NLTK's recommended word tokenizer, the TreebankWordTokenizer and the PunktSentencetokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egmrdklimALI"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAd7jnFHmALJ",
        "outputId": "f515410e-f2bc-4a84-81da-e2b119378ab9"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-27d5e78d663c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Does this tokenizer work? These are two different sentences'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = sent_tokenize('Does this tokenizer work? These are two different sentences')\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVi3ld9cmALK",
        "outputId": "6162e3e8-9bc6-4dad-81a9-9980c256e002"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-42e4b9771e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Does this tokenizer work?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     return [\n\u001b[1;32m    145\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize('Does this tokenizer work?')\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcK7w3Y3mALK"
      },
      "source": [
        "#### Punkt tokenizer\n",
        "\n",
        "https://www.nltk.org/_modules/nltk/tokenize/punkt.html\n",
        "http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt\n",
        "\n",
        "A sentence tokenizer which uses an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences; and then uses that model to find sentence boundaries. This approach has been shown to work well for many European languages.\n",
        "\n",
        "It must be trained on a large collection of plaintext in the target language before it can be used.\n",
        "\n",
        "The NLTK data package includes a pre-trained Punkt tokenizer for English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTfhiD2gmALL",
        "outputId": "ddb88146-04e3-430c-b8d7-76258a7a23d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOvmIUFMmALM",
        "outputId": "9eb35536-8d7b-428f-b04a-1fd0c25bf99a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does this tokenizer work?', 'These are two different sentences']\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = sent_tokenize('Does this tokenizer work? These are two different sentences')\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8HJJRhimALN",
        "outputId": "9f0f8956-8e51-4371-c26f-a6be222a6576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does', 'this', 'tokenizer', 'work', '?']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize('Does this tokenizer work?')\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAYJA6HomALN",
        "outputId": "1f1ad8cc-44d4-4941-ee87-14865b6b0445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.', 'Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.', 'These', 'watches', 'cost', '$', '1500', '!', 'The', 'ball', 'is', 'in', 'your', 'court', '.', 'Mr.', 'Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D', '.']\n"
          ]
        }
      ],
      "source": [
        "text = \"A bird in hand is worth two in the bush. \" +\\\n",
        "       \"Good things come to those who wait. \" +\\\n",
        "       \"These watches cost $1500! \" +\\\n",
        "       \"The ball is in your court. \" +\\\n",
        "       \"Mr. Smith Goes to Washington \" +\\\n",
        "       \"Doogie Howser M.D.\"\n",
        "\n",
        "word_tokens = word_tokenize(text, language='english')\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f25RIlQmALO",
        "outputId": "0ef6f296-f478-44cf-c708-cfe76cbafa6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMTgGmUumALP",
        "outputId": "f1c08686-9907-4934-abae-e6c9a515ff35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hand', 'is', 'worth', 'two', 'in']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens[3:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXL-HdpvmALQ"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize.punkt import PunktSentenceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXKJU-uOmALR"
      },
      "outputs": [],
      "source": [
        "pst = PunktSentenceTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHa8wz2jmALR",
        "outputId": "5b4b1151-bf8a-48da-afc1-2fc61569ecdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A bird in hand is worth two in the bush.', 'Good things come to those who wait.', 'These watches cost $1500!', 'The ball is in your court.', 'Mr.', 'Smith Goes to Washington Doogie Howser M.D.']\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = pst.tokenize(text)\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-YEVCqwmALS",
        "outputId": "b50bcd1b-d416-48f5-c656-253e4399118f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 40), (41, 76), (77, 102), (103, 129), (130, 133), (134, 177)]\n"
          ]
        }
      ],
      "source": [
        "span_tokens = pst.span_tokenize(text)\n",
        "\n",
        "print(list(span_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpDHdKwBmALT",
        "outputId": "9ce6a944-9b5f-4216-af01-c43e5daaf333"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.'],\n",
              " ['Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.'],\n",
              " ['These', 'watches', 'cost', '$', '1500', '!'],\n",
              " ['The', 'ball', 'is', 'in', 'your', 'court', '.'],\n",
              " ['Mr.'],\n",
              " ['Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D', '.']]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences = pst.sentences_from_tokens(word_tokens)\n",
        "\n",
        "list(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCQJAch9mALU"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri1Y587ImALU"
      },
      "outputs": [],
      "source": [
        "wt = WhitespaceTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJvcXdeZmALV",
        "outputId": "8a2c5f17-4c4d-476f-9981-3c6768e3503c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush.', 'Good', 'things', 'come', 'to', 'those', 'who', 'wait.', 'These', 'watches', 'cost', '$1500!', 'The', 'ball', 'is', 'in', 'your', 'court.', 'Mr.', 'Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D.']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = wt.tokenize(text)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r2l80xXmALW"
      },
      "source": [
        "### Reading Local Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQPUkUNVmALX",
        "outputId": "51bea908-9f86-4309-e247-ec32af220726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U7eDLGpmALY",
        "outputId": "a224c578-067b-4fcd-a48d-fd6ab3539099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie', 'Curie', 'was', 'a', 'Polish-born', 'physicist', 'and', 'chemist', 'and', 'one', 'of', 'the', 'most', 'famous', 'scientists', 'of', 'her', 'time', '.', 'Together', 'with', 'her', 'husband', 'Pierre', ',', 'she', 'was', 'awarded', 'the', 'Nobel', 'Prize', 'in', '1903', ',', 'and', 'she', 'went', 'on', 'to', 'win', 'another', 'in', '1911', '.', 'Marie', 'Sklodowska', 'was', 'born', 'in', 'Warsaw', 'on', '7', 'November', '1867', ',', 'the', 'daughter', 'of', 'a', 'teacher', '.', 'In', '1891', ',', 'she', 'went', 'to', 'Paris', 'to', 'study', 'physics', 'and', 'mathematics', 'at', 'the', 'Sorbonne', 'where', 'she', 'met', 'Pierre', 'Curie', ',', 'professor', 'of', 'the', 'School', 'of', 'Physics', '.', 'They', 'were', 'married', 'in', '1895', '.', 'The', 'Curies', 'worked', 'together', 'investigating', 'radioactivity', ',', 'building', 'on', 'the', 'work', 'of', 'the', 'German', 'physicist', 'Roentgen', 'and', 'the', 'French', 'physicist', 'Becquerel', '.', 'In', 'July', '1898', ',', 'the', 'Curies', 'announced', 'the', 'discovery', 'of', 'a', 'new', 'chemical', 'element', ',', 'polonium', '.', 'At', 'the', 'end', 'of', 'the', 'year', ',', 'they', 'announced', 'the', 'discovery', 'of', 'another', ',', 'radium', '.', 'The', 'Curies', ',', 'along', 'with', 'Becquerel', ',', 'were', 'awarded', 'the', 'Nobel', 'Prize', 'for', 'Physics', 'in', '1903', '.', 'Pierre', \"'s\", 'life', 'was', 'cut', 'short', 'in', '1906', 'when', 'he', 'was', 'knocked', 'down', 'and', 'killed', 'by', 'a', 'carriage', '.', 'Marie', 'took', 'over', 'his', 'teaching', 'post', ',', 'becoming', 'the', 'first', 'woman', 'to', 'teach', 'at', 'the', 'Sorbonne', ',', 'and', 'devoted', 'herself', 'to', 'continuing', 'the', 'work', 'that', 'they', 'had', 'begun', 'together', '.', 'She', 'received', 'a', 'second', 'Nobel', 'Prize', ',', 'for', 'Chemistry', ',', 'in', '1911', '.', 'The', 'Curie', \"'s\", 'research', 'was', 'crucial', 'in', 'the', 'development', 'of', 'x-rays', 'in', 'surgery', '.', 'During', 'World', 'War', 'One', 'Curie', 'helped', 'to', 'equip', 'ambulances', 'with', 'x-ray', 'equipment', ',', 'which', 'she', 'herself', 'drove', 'to', 'the', 'front', 'lines', '.', 'The', 'International', 'Red', 'Cross', 'made', 'her', 'head', 'of', 'its', 'radiological', 'service', 'and', 'she', 'held', 'training', 'courses', 'for', 'medical', 'orderlies', 'and', 'doctors', 'in', 'the', 'new', 'techniques', '.', 'Despite', 'her', 'success', ',', 'Marie', 'continued', 'to', 'face', 'great', 'opposition', 'from', 'male', 'scientists', 'in', 'France', ',', 'and', 'she', 'never', 'received', 'significant', 'financial', 'benefits', 'from', 'her', 'work', '.', 'By', 'the', 'late', '1920s', 'her', 'health', 'was', 'beginning', 'to', 'deteriorate', '.', 'She', 'died', 'on', '4', 'July', '1934', 'from', 'leukaemia', ',', 'caused', 'by', 'exposure', 'to', 'high-energy', 'radiation', 'from', 'her', 'research', '.', 'The', 'Curies', \"'\", 'eldest', 'daughter', 'Irene', 'was', 'herself', 'a', 'scientist', 'and', 'winner', 'of', 'the', 'Nobel', 'Prize', 'for', 'Chemistry', '.']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize(file_contents)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWtiWBT6mALZ"
      },
      "source": [
        "### Frequency distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXrj4RjOmALZ"
      },
      "outputs": [],
      "source": [
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Oguf-OnmALc",
        "outputId": "fde9b5ed-3128-4061-dfa5-29570b748190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FreqDist with 182 samples and 367 outcomes>\n"
          ]
        }
      ],
      "source": [
        "freq_dist = FreqDist(word_tokens)\n",
        "\n",
        "print(freq_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQaKW1YTmALe",
        "outputId": "ef283c8d-510f-401a-e59a-3f3459e274f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 22),\n",
              " (',', 20),\n",
              " ('.', 19),\n",
              " ('of', 12),\n",
              " ('and', 11),\n",
              " ('in', 11),\n",
              " ('to', 10),\n",
              " ('was', 8),\n",
              " ('her', 7),\n",
              " ('she', 7),\n",
              " ('a', 6),\n",
              " ('The', 5),\n",
              " ('Marie', 4),\n",
              " ('Curie', 4),\n",
              " ('Nobel', 4),\n",
              " ('Prize', 4),\n",
              " ('on', 4),\n",
              " ('Curies', 4),\n",
              " ('for', 4),\n",
              " ('from', 4)]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prn_z1qrmALf"
      },
      "source": [
        "Return the frequency of a given sample. The frequency of a sample is defined as the count of that sample divided by the total number of sample outcomes that have been recorded by this FreqDist. The count of a sample is defined as the number of times that sample outcome was recorded by this FreqDist. Frequencies are always real numbers in the range [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTIige2umALg",
        "outputId": "e8b66a17-2c7a-4fb0-c1a0-f1715c69fe3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.05994550408719346"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.freq('the')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZbXKvSvmALh",
        "outputId": "dd147020-ff5b-47dc-a58a-f8f762529dff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0027247956403269754"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.freq('exposure')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nRZdgMcmALi",
        "outputId": "0cd54e32-9fc4-4967-8a78-3ce0b2f02f7b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "freq_dist.plot(20, cumulative=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEoQXcXLmALj",
        "outputId": "6ea9e298-6db9-4d9d-85ad-f12836c9ddc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['marie', 'curie', 'was', 'a', 'polish-born', 'physicist', 'and', 'chemist', 'and', 'one', 'of', 'the', 'most', 'famous', 'scientists', 'of', 'her', 'time.', 'together', 'with', 'her', 'husband', 'pierre,', 'she', 'was', 'awarded', 'the', 'nobel', 'prize', 'in', '1903,', 'and', 'she', 'went', 'on', 'to', 'win', 'another', 'in', '1911.', 'marie', 'sklodowska', 'was', 'born', 'in', 'warsaw', 'on', '7', 'november', '1867,', 'the', 'daughter', 'of', 'a', 'teacher.', 'in', '1891,', 'she', 'went', 'to', 'paris', 'to', 'study', 'physics', 'and', 'mathematics', 'at', 'the', 'sorbonne', 'where', 'she', 'met', 'pierre', 'curie,', 'professor', 'of', 'the', 'school', 'of', 'physics.', 'they', 'were', 'married', 'in', '1895.', 'the', 'curies', 'worked', 'together', 'investigating', 'radioactivity,', 'building', 'on', 'the', 'work', 'of', 'the', 'german', 'physicist', 'roentgen', 'and', 'the', 'french', 'physicist', 'becquerel.', 'in', 'july', '1898,', 'the', 'curies', 'announced', 'the', 'discovery', 'of', 'a', 'new', 'chemical', 'element,', 'polonium.', 'at', 'the', 'end', 'of', 'the', 'year,', 'they', 'announced', 'the', 'discovery', 'of', 'another,', 'radium.', 'the', 'curies,', 'along', 'with', 'becquerel,', 'were', 'awarded', 'the', 'nobel', 'prize', 'for', 'physics', 'in', '1903.', \"pierre's\", 'life', 'was', 'cut', 'short', 'in', '1906', 'when', 'he', 'was', 'knocked', 'down', 'and', 'killed', 'by', 'a', 'carriage.', 'marie', 'took', 'over', 'his', 'teaching', 'post,', 'becoming', 'the', 'first', 'woman', 'to', 'teach', 'at', 'the', 'sorbonne,', 'and', 'devoted', 'herself', 'to', 'continuing', 'the', 'work', 'that', 'they', 'had', 'begun', 'together.', 'she', 'received', 'a', 'second', 'nobel', 'prize,', 'for', 'chemistry,', 'in', '1911.', 'the', \"curie's\", 'research', 'was', 'crucial', 'in', 'the', 'development', 'of', 'x-rays', 'in', 'surgery.', 'during', 'world', 'war', 'one', 'curie', 'helped', 'to', 'equip', 'ambulances', 'with', 'x-ray', 'equipment,', 'which', 'she', 'herself', 'drove', 'to', 'the', 'front', 'lines.', 'the', 'international', 'red', 'cross', 'made', 'her', 'head', 'of', 'its', 'radiological', 'service', 'and', 'she', 'held', 'training', 'courses', 'for', 'medical', 'orderlies', 'and', 'doctors', 'in', 'the', 'new', 'techniques.', 'despite', 'her', 'success,', 'marie', 'continued', 'to', 'face', 'great', 'opposition', 'from', 'male', 'scientists', 'in', 'france,', 'and', 'she', 'never', 'received', 'significant', 'financial', 'benefits', 'from', 'her', 'work.', 'by', 'the', 'late', '1920s', 'her', 'health', 'was', 'beginning', 'to', 'deteriorate.', 'she', 'died', 'on', '4', 'july', '1934', 'from', 'leukaemia,', 'caused', 'by', 'exposure', 'to', 'high-energy', 'radiation', 'from', 'her', 'research.', 'the', \"curies'\", 'eldest', 'daughter', 'irene', 'was', 'herself', 'a', 'scientist', 'and', 'winner', 'of', 'the', 'nobel', 'prize', 'for', 'chemistry.']\n"
          ]
        }
      ],
      "source": [
        "file_contents = file_contents.lower()\n",
        "\n",
        "word_tokens = wt.tokenize(file_contents)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCQCLo6NmALs",
        "outputId": "4e3cc75c-dd75-4e28-9ec0-6b61a2bb8e24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXRL3jD6mALu",
        "outputId": "299864b0-d926-4d61-ad07-3f3f622bbdd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'an', 'should', \"needn't\", 'o', 'ours', 'yourselves', 'am', 't', 'd', 'our', 'yourself', 'himself', 'wasn', 'above', 'you', 'me', 'did', \"hasn't\", 'shan', 'about', 'wouldn', 'shouldn', 'because', 'myself', 'where', 'hasn', 'hadn', 'own', 'hers', 'at', \"mightn't\", 'now', 'with', 'how', 'some', 'or', 'had', 'having', 'aren', 'm', \"shouldn't\", 'was', 'don', 'same', \"didn't\", 'against', 'why', 'y', 'any', 'do', 'being', 'll', 'up', 'doesn', 'which', 'again', 'as', 'in', 'mightn', \"you'll\", \"that'll\", 'can', 'for', 'haven', 's', 'him', 'ain', 'from', 'then', 'once', 'that', \"you're\", 'such', 'does', '.', 'these', 'be', 'only', 'just', 'will', 'into', 'she', \"aren't\", 'and', 'they', 'isn', 'been', 'until', 'theirs', \"don't\", \"couldn't\", 'we', 'ourselves', 'under', 'is', 'by', 'what', \"hadn't\", \"weren't\", 'too', 'ma', 'needn', 'those', 'are', 'more', 'there', 'to', 'between', 'herself', 'has', 'a', 'the', 'yours', 'who', 'than', 'not', 'of', 'nor', \"isn't\", 'when', 'whom', \"it's\", 'i', 'my', 'were', 'mustn', 'doing', 'down', \"won't\", 'all', 'have', \"you'd\", 'his', 'other', 'but', 'if', 'very', 'off', 'before', 'both', 'each', 'didn', 'further', 'no', 'most', \"doesn't\", 'couldn', 'them', 'through', 'weren', 'won', \"wouldn't\", 'The', 're', \"wasn't\", 'few', 'here', 'so', ',', 'its', 'their', 'below', \"shan't\", 'out', \"mustn't\", 'it', 'over', 'itself', 'while', \"you've\", 'themselves', 'after', 'your', 'her', \"should've\", \"haven't\", 'this', 'on', 've', \"she's\", 'he', 'during'}\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(['.', ',', 'The'])\n",
        "\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVyiX62WmALv",
        "outputId": "76c89a9a-4430-4fbb-996d-b4baef66c282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['marie', 'curie', 'polish-born', 'physicist', 'chemist', 'one', 'famous', 'scientists', 'time.', 'together', 'husband', 'pierre,', 'awarded', 'nobel', 'prize', '1903,', 'went', 'win', 'another', '1911.', 'marie', 'sklodowska', 'born', 'warsaw', '7', 'november', '1867,', 'daughter', 'teacher.', '1891,', 'went', 'paris', 'study', 'physics', 'mathematics', 'sorbonne', 'met', 'pierre', 'curie,', 'professor', 'school', 'physics.', 'married', '1895.', 'curies', 'worked', 'together', 'investigating', 'radioactivity,', 'building', 'work', 'german', 'physicist', 'roentgen', 'french', 'physicist', 'becquerel.', 'july', '1898,', 'curies', 'announced', 'discovery', 'new', 'chemical', 'element,', 'polonium.', 'end', 'year,', 'announced', 'discovery', 'another,', 'radium.', 'curies,', 'along', 'becquerel,', 'awarded', 'nobel', 'prize', 'physics', '1903.', \"pierre's\", 'life', 'cut', 'short', '1906', 'knocked', 'killed', 'carriage.', 'marie', 'took', 'teaching', 'post,', 'becoming', 'first', 'woman', 'teach', 'sorbonne,', 'devoted', 'continuing', 'work', 'begun', 'together.', 'received', 'second', 'nobel', 'prize,', 'chemistry,', '1911.', \"curie's\", 'research', 'crucial', 'development', 'x-rays', 'surgery.', 'world', 'war', 'one', 'curie', 'helped', 'equip', 'ambulances', 'x-ray', 'equipment,', 'drove', 'front', 'lines.', 'international', 'red', 'cross', 'made', 'head', 'radiological', 'service', 'held', 'training', 'courses', 'medical', 'orderlies', 'doctors', 'new', 'techniques.', 'despite', 'success,', 'marie', 'continued', 'face', 'great', 'opposition', 'male', 'scientists', 'france,', 'never', 'received', 'significant', 'financial', 'benefits', 'work.', 'late', '1920s', 'health', 'beginning', 'deteriorate.', 'died', '4', 'july', '1934', 'leukaemia,', 'caused', 'exposure', 'high-energy', 'radiation', 'research.', \"curies'\", 'eldest', 'daughter', 'irene', 'scientist', 'winner', 'nobel', 'prize', 'chemistry.']\n"
          ]
        }
      ],
      "source": [
        "filtered_words = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_words.append(w)\n",
        "\n",
        "print(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4wHDdrqmALy"
      },
      "outputs": [],
      "source": [
        "freq_dist = FreqDist(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Uxd1cU4mALz",
        "outputId": "e0402e14-1c23-4fe5-8477-4ad9cffba8e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('marie', 4),\n",
              " ('nobel', 4),\n",
              " ('physicist', 3),\n",
              " ('prize', 3),\n",
              " ('curie', 2),\n",
              " ('one', 2),\n",
              " ('scientists', 2),\n",
              " ('together', 2),\n",
              " ('awarded', 2),\n",
              " ('went', 2),\n",
              " ('1911.', 2),\n",
              " ('daughter', 2),\n",
              " ('physics', 2),\n",
              " ('curies', 2),\n",
              " ('work', 2),\n",
              " ('july', 2),\n",
              " ('announced', 2),\n",
              " ('discovery', 2),\n",
              " ('new', 2),\n",
              " ('received', 2)]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJdGcudzmAL0",
        "outputId": "c48e3860-79f8-4aeb-8e2c-cab78597cac4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "freq_dist.plot(20, cumulative=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yplaH6KRmAL1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DssQ22fPmAL1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J0JKgqpmAL2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtWJ4kaomAL2"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 02-VectorizeTextAsABagOfWords_CountVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bla6XtMMmAL2"
      },
      "source": [
        "## Vectorize text as a bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHo2mEw5mAL3",
        "outputId": "672898d8-4bff-4150-d5f4-14873ca303f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.20.3\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oIY7m-3mAL5"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_plcnMAmAL6"
      },
      "outputs": [],
      "source": [
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]\n",
        "\n",
        "count_vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tae-sKodmAL7",
        "outputId": "463c1d1a-848e-4232-c752-a66700887990"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.fit(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jIo1JWEmAL9",
        "outputId": "e8e22b21-97ec-4aa9-fc71-e6ebf90b61b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1500',\n",
              " 'are',\n",
              " 'ball',\n",
              " 'bird',\n",
              " 'bush',\n",
              " 'come',\n",
              " 'cost',\n",
              " 'court',\n",
              " 'doogie',\n",
              " 'fish',\n",
              " 'goes',\n",
              " 'good',\n",
              " 'hand',\n",
              " 'howser',\n",
              " 'in',\n",
              " 'is',\n",
              " 'mr',\n",
              " 'other',\n",
              " 'sea',\n",
              " 'smith',\n",
              " 'the',\n",
              " 'there',\n",
              " 'these',\n",
              " 'things',\n",
              " 'those',\n",
              " 'to',\n",
              " 'two',\n",
              " 'wait',\n",
              " 'washington',\n",
              " 'watches',\n",
              " 'who',\n",
              " 'worth',\n",
              " 'your']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufp-OmTcmAL9"
      },
      "outputs": [],
      "source": [
        "count_vectorizer.get_stop_words()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdd_tNrSmAL_",
        "outputId": "796669f2-8078-462b-dab3-2cf656803c5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 3,\n",
              " 'in': 14,\n",
              " 'hand': 12,\n",
              " 'is': 15,\n",
              " 'worth': 31,\n",
              " 'two': 26,\n",
              " 'the': 20,\n",
              " 'bush': 4,\n",
              " 'good': 11,\n",
              " 'things': 23,\n",
              " 'come': 5,\n",
              " 'to': 25,\n",
              " 'those': 24,\n",
              " 'who': 30,\n",
              " 'wait': 27,\n",
              " 'these': 22,\n",
              " 'watches': 29,\n",
              " 'cost': 6,\n",
              " '1500': 0,\n",
              " 'there': 21,\n",
              " 'are': 1,\n",
              " 'other': 17,\n",
              " 'fish': 9,\n",
              " 'sea': 18,\n",
              " 'ball': 2,\n",
              " 'your': 32,\n",
              " 'court': 7,\n",
              " 'mr': 16,\n",
              " 'smith': 19,\n",
              " 'goes': 10,\n",
              " 'washington': 28,\n",
              " 'doogie': 8,\n",
              " 'howser': 13}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4mc_-X9mAL_",
        "outputId": "73387653-a7d3-4630-ce4f-c32c69aa92d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_.get('things')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGyz3FXAmAMA",
        "outputId": "179a2412-44bd-41c3-ab68-af0c86b902f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A bird in hand is worth two in the bush.',\n",
              " 'Good things come to those who wait.',\n",
              " 'These watches cost $1500! ',\n",
              " 'There are other fish in the sea.',\n",
              " 'The ball is in your court.',\n",
              " 'Mr. Smith Goes to Washington ',\n",
              " 'Doogie Howser M.D.']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRmmCYoBmAMB"
      },
      "outputs": [],
      "source": [
        "transformed_vector = count_vectorizer.transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPf3Mh4HmAMB",
        "outputId": "54b166c3-968d-42c0-96f6-39fcc28b721b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 33)\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_FFzrGkmAMC",
        "outputId": "0d08a735-672e-47e9-d857-347941026a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 1 0 0 0 0 0 0 0 1 0 2 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haOtEISkmAMD",
        "outputId": "1bc41d88-798a-47c1-9698-c2728b33ebea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_text = [\"Every cloud has a silver lining.\"]\n",
        "\n",
        "count_vectorizer.transform(test_text).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwsfeu1YmAMD",
        "outputId": "a8ee5a32-963d-40e2-b277-381d1c1985ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.fit(train_text + test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fUCr_UrmAME",
        "outputId": "60395ab0-82c6-44c8-bfb8-6138245b0545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bird': 3, 'in': 17, 'hand': 14, 'is': 18, 'worth': 36, 'two': 31, 'the': 25, 'bush': 4, 'good': 13, 'things': 28, 'come': 6, 'to': 30, 'those': 29, 'who': 35, 'wait': 32, 'these': 27, 'watches': 34, 'cost': 7, '1500': 0, 'there': 26, 'are': 1, 'other': 21, 'fish': 11, 'sea': 22, 'ball': 2, 'your': 37, 'court': 8, 'mr': 20, 'smith': 24, 'goes': 12, 'washington': 33, 'doogie': 9, 'howser': 16, 'every': 10, 'cloud': 5, 'has': 15, 'silver': 23, 'lining': 19}\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAprCoRfmAME",
        "outputId": "d8329b8b-55c7-49b5-ed7b-67aca10a3e71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.transform(test_text).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgZmSyxWmAMF",
        "outputId": "49770473-a0d8-4cd6-ade5-d792cfb3f509"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<3x38 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 9 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = [\"That bird is sitting in the bush and this bird is in hand.\",\n",
        "        \"Wait and then walk\",\n",
        "        \"Watches are cool \"]\n",
        "\n",
        "transformed_vector = count_vectorizer.transform(text)\n",
        "\n",
        "transformed_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-igiA4rmAMG",
        "outputId": "2fcbaaf4-0aae-41ff-d023-ef227cea108e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3)\t2\n",
            "  (0, 4)\t1\n",
            "  (0, 14)\t1\n",
            "  (0, 17)\t2\n",
            "  (0, 18)\t2\n",
            "  (0, 25)\t1\n",
            "  (1, 32)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 34)\t1\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QPQdKEjmAMG",
        "outputId": "e7c901dc-e4b7-43fc-d3a6-76b24ab2dde5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 38)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCu8VLptmAMH",
        "outputId": "5c91e034-ca88-403d-fa0d-c38dbd979d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 2 1 0 0 0 0 0 0 0 0 0 1 0 0 2 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            "  0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzFhmyubmAMH"
      },
      "source": [
        "### CountVectorizer on text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2heV3FEmAMI",
        "outputId": "4b676907-ccf8-42ec-fd22-066d9e442ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMrtgAfImAMI",
        "outputId": "6e512d4b-3fb6-4a49-cc7a-6f5d3c0035a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.', 'Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.', 'Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.', 'In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.', 'They were married in 1895.', 'The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.', 'In July 1898, the Curies announced the discovery of a new chemical element, polonium.', 'At the end of the year, they announced the discovery of another, radium.', 'The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.', \"Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\", 'Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.', 'She received a second Nobel Prize, for Chemistry, in 1911.', \"The Curie's research was crucial in the development of x-rays in surgery.\", 'During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.', 'The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.', 'Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.', 'By the late 1920s her health was beginning to deteriorate.', 'She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.', \"The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\"]\n"
          ]
        }
      ],
      "source": [
        "sentences = file_contents.split('\\n')\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ9mgTrCmAMJ",
        "outputId": "51140572-6784-4dbd-8583-11eabe47117d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19, 167)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector = count_vectorizer.fit_transform(sentences)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJjtRFmCmAMJ",
        "outputId": "c6c9c6f3-fcde-439c-9a65-690180f4ead8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 146)\t1\n",
            "  (0, 72)\t1\n",
            "  (0, 128)\t1\n",
            "  (0, 56)\t1\n",
            "  (0, 96)\t1\n",
            "  (0, 144)\t1\n",
            "  (0, 101)\t2\n",
            "  (0, 103)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 11)\t2\n",
            "  (0, 108)\t1\n",
            "  (0, 21)\t1\n",
            "  (0, 111)\t1\n",
            "  (0, 153)\t1\n",
            "  (0, 34)\t1\n",
            "  (0, 91)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 13)\t1\n",
            "  (1, 159)\t1\n",
            "  (1, 147)\t1\n",
            "  (1, 102)\t1\n",
            "  (1, 154)\t1\n",
            "  (1, 4)\t1\n",
            "  (1, 77)\t2\n",
            "  (1, 114)\t1\n",
            "  :\t:\n",
            "  (17, 8)\t1\n",
            "  (17, 42)\t1\n",
            "  (17, 62)\t2\n",
            "  (17, 124)\t1\n",
            "  (17, 23)\t1\n",
            "  (17, 82)\t1\n",
            "  (17, 147)\t1\n",
            "  (17, 102)\t1\n",
            "  (17, 131)\t1\n",
            "  (17, 72)\t1\n",
            "  (18, 160)\t1\n",
            "  (18, 127)\t1\n",
            "  (18, 80)\t1\n",
            "  (18, 48)\t1\n",
            "  (18, 28)\t1\n",
            "  (18, 73)\t1\n",
            "  (18, 59)\t1\n",
            "  (18, 35)\t1\n",
            "  (18, 37)\t1\n",
            "  (18, 114)\t1\n",
            "  (18, 99)\t1\n",
            "  (18, 144)\t2\n",
            "  (18, 101)\t1\n",
            "  (18, 11)\t1\n",
            "  (18, 153)\t1\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZbZGciTmAMJ",
        "outputId": "6f00249a-2dc4-4981-8cb5-d507fc1d3117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'marie': 91, 'curie': 34, 'was': 153, 'polish': 111, 'born': 21, 'physicist': 108, 'and': 11, 'chemist': 27, 'one': 103, 'of': 101, 'the': 144, 'most': 96, 'famous': 56, 'scientists': 128, 'her': 72, 'time': 146, 'together': 148, 'with': 161, 'husband': 76, 'pierre': 110, 'she': 131, 'awarded': 15, 'nobel': 99, 'prize': 114, 'in': 77, '1903': 4, 'went': 154, 'on': 102, 'to': 147, 'win': 159, 'another': 13, '1911': 6, 'sklodowska': 134, 'warsaw': 152, 'november': 100, '1867': 0, 'daughter': 37, 'teacher': 140, '1891': 1, 'paris': 107, 'study': 136, 'physics': 109, 'mathematics': 93, 'at': 14, 'sorbonne': 135, 'where': 157, 'met': 95, 'professor': 115, 'school': 126, 'they': 145, 'were': 155, 'married': 92, '1895': 2, 'curies': 35, 'worked': 164, 'investigating': 79, 'radioactivity': 117, 'building': 22, 'work': 163, 'german': 64, 'roentgen': 125, 'french': 61, 'becquerel': 17, 'july': 82, '1898': 3, 'announced': 12, 'discovery': 43, 'new': 98, 'chemical': 26, 'element': 49, 'polonium': 112, 'end': 50, 'year': 166, 'radium': 119, 'along': 9, 'for': 59, 'life': 87, 'cut': 36, 'short': 132, '1906': 5, 'when': 156, 'he': 67, 'knocked': 84, 'down': 45, 'killed': 83, 'by': 23, 'carriage': 24, 'took': 149, 'over': 106, 'his': 75, 'teaching': 141, 'post': 113, 'becoming': 16, 'first': 58, 'woman': 162, 'teach': 139, 'devoted': 41, 'herself': 73, 'continuing': 30, 'that': 143, 'had': 66, 'begun': 19, 'received': 122, 'second': 129, 'chemistry': 28, 'research': 124, 'crucial': 33, 'development': 40, 'rays': 121, 'surgery': 138, 'during': 47, 'world': 165, 'war': 151, 'helped': 71, 'equip': 52, 'ambulances': 10, 'ray': 120, 'equipment': 53, 'which': 158, 'drove': 46, 'front': 63, 'lines': 88, 'international': 78, 'red': 123, 'cross': 32, 'made': 89, 'head': 68, 'its': 81, 'radiological': 118, 'service': 130, 'held': 70, 'training': 150, 'courses': 31, 'medical': 94, 'orderlies': 105, 'doctors': 44, 'techniques': 142, 'despite': 38, 'success': 137, 'continued': 29, 'face': 55, 'great': 65, 'opposition': 104, 'from': 62, 'male': 90, 'france': 60, 'never': 97, 'significant': 133, 'financial': 57, 'benefits': 20, 'late': 85, '1920s': 7, 'health': 69, 'beginning': 18, 'deteriorate': 39, 'died': 42, '1934': 8, 'leukaemia': 86, 'caused': 25, 'exposure': 54, 'high': 74, 'energy': 51, 'radiation': 116, 'eldest': 48, 'irene': 80, 'scientist': 127, 'winner': 160}\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rVMJEE7mAMJ"
      },
      "source": [
        "We lost:\n",
        "\n",
        "* The meaning of text corpus\n",
        "* The ordering of the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jONaGooUmAMK",
        "outputId": "44134228-0b31-443a-ffa5-4014fb25e3a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['time', 'her', 'scientists', 'famous', 'most', 'the', 'of', 'one',\n",
              "        'chemist', 'and', 'physicist', 'born', 'polish', 'was', 'curie',\n",
              "        'marie'], dtype='<U13'),\n",
              " array(['1911', 'another', 'win', 'to', 'on', 'went', '1903', 'in',\n",
              "        'prize', 'nobel', 'awarded', 'she', 'pierre', 'husband', 'with',\n",
              "        'together', 'her', 'the', 'and', 'was'], dtype='<U13'),\n",
              " array(['teacher', 'daughter', '1867', 'november', 'warsaw', 'sklodowska',\n",
              "        'on', 'in', 'the', 'of', 'born', 'was', 'marie'], dtype='<U13'),\n",
              " array(['school', 'professor', 'met', 'where', 'sorbonne', 'at',\n",
              "        'mathematics', 'physics', 'study', 'paris', '1891', 'to', 'went',\n",
              "        'in', 'she', 'pierre', 'the', 'of', 'and', 'curie'], dtype='<U13'),\n",
              " array(['1895', 'married', 'were', 'they', 'in'], dtype='<U13'),\n",
              " array(['becquerel', 'french', 'roentgen', 'german', 'work', 'building',\n",
              "        'radioactivity', 'investigating', 'worked', 'curies', 'on',\n",
              "        'together', 'the', 'of', 'and', 'physicist'], dtype='<U13'),\n",
              " array(['polonium', 'element', 'chemical', 'new', 'discovery', 'announced',\n",
              "        '1898', 'july', 'curies', 'in', 'the', 'of'], dtype='<U13'),\n",
              " array(['radium', 'year', 'end', 'discovery', 'announced', 'they', 'at',\n",
              "        'another', 'the', 'of'], dtype='<U13'),\n",
              " array(['for', 'along', 'becquerel', 'curies', 'were', 'physics', '1903',\n",
              "        'in', 'prize', 'nobel', 'awarded', 'with', 'the'], dtype='<U13'),\n",
              " array(['carriage', 'by', 'killed', 'down', 'knocked', 'he', 'when',\n",
              "        '1906', 'short', 'cut', 'life', 'in', 'pierre', 'and', 'was'],\n",
              "       dtype='<U13'),\n",
              " array(['begun', 'had', 'that', 'continuing', 'herself', 'devoted',\n",
              "        'teach', 'woman', 'first', 'becoming', 'post', 'teaching', 'his',\n",
              "        'over', 'took', 'work', 'they', 'sorbonne', 'at', 'to', 'together',\n",
              "        'the', 'and', 'marie'], dtype='<U13'),\n",
              " array(['chemistry', 'second', 'received', 'for', '1911', 'in', 'prize',\n",
              "        'nobel', 'she'], dtype='<U13'),\n",
              " array(['surgery', 'rays', 'development', 'crucial', 'research', 'in',\n",
              "        'the', 'of', 'was', 'curie'], dtype='<U13'),\n",
              " array(['lines', 'front', 'drove', 'which', 'equipment', 'ray',\n",
              "        'ambulances', 'equip', 'helped', 'war', 'world', 'during',\n",
              "        'herself', 'to', 'she', 'with', 'the', 'one', 'curie'],\n",
              "       dtype='<U13'),\n",
              " array(['techniques', 'doctors', 'orderlies', 'medical', 'courses',\n",
              "        'training', 'held', 'service', 'radiological', 'its', 'head',\n",
              "        'made', 'cross', 'red', 'international', 'for', 'new', 'in', 'she',\n",
              "        'her', 'the', 'of', 'and'], dtype='<U13'),\n",
              " array(['benefits', 'financial', 'significant', 'never', 'france', 'male',\n",
              "        'from', 'opposition', 'great', 'face', 'continued', 'success',\n",
              "        'despite', 'received', 'work', 'to', 'in', 'she', 'her',\n",
              "        'scientists', 'and', 'marie'], dtype='<U13'),\n",
              " array(['deteriorate', 'beginning', 'health', '1920s', 'late', 'by', 'to',\n",
              "        'her', 'the', 'was'], dtype='<U13'),\n",
              " array(['radiation', 'energy', 'high', 'exposure', 'caused', 'leukaemia',\n",
              "        '1934', 'died', 'from', 'research', 'by', 'july', 'to', 'on',\n",
              "        'she', 'her'], dtype='<U13'),\n",
              " array(['winner', 'scientist', 'irene', 'eldest', 'chemistry', 'herself',\n",
              "        'for', 'curies', 'daughter', 'prize', 'nobel', 'the', 'of', 'and',\n",
              "        'was'], dtype='<U13')]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.inverse_transform(transformed_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drm71R-CmAMK"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 03-VectorizeTextAsABagOfNGrams_CountVectorizer_Nltk</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiE988PumAMK"
      },
      "source": [
        "## Vectorize text as a bag-of-n-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hkPrec8mAML"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJD7vwVumAML"
      },
      "outputs": [],
      "source": [
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2HpxkUZmAML"
      },
      "outputs": [],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-H9lSmBmAMM"
      },
      "outputs": [],
      "source": [
        "transformed_vector = n_gram_vectorizer.fit_transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmB8WyUimAMN",
        "outputId": "76b5dd9a-78c3-4bf2-d734-c51e57a5c17e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird in': 2,\n",
              " 'in hand': 10,\n",
              " 'hand is': 9,\n",
              " 'is worth': 14,\n",
              " 'worth two': 30,\n",
              " 'two in': 27,\n",
              " 'in the': 11,\n",
              " 'the bush': 19,\n",
              " 'good things': 8,\n",
              " 'things come': 23,\n",
              " 'come to': 3,\n",
              " 'to those': 25,\n",
              " 'those who': 24,\n",
              " 'who wait': 29,\n",
              " 'these watches': 22,\n",
              " 'watches cost': 28,\n",
              " 'cost 1500': 4,\n",
              " 'there are': 21,\n",
              " 'are other': 0,\n",
              " 'other fish': 16,\n",
              " 'fish in': 6,\n",
              " 'the sea': 20,\n",
              " 'the ball': 18,\n",
              " 'ball is': 1,\n",
              " 'is in': 13,\n",
              " 'in your': 12,\n",
              " 'your court': 31,\n",
              " 'mr smith': 15,\n",
              " 'smith goes': 17,\n",
              " 'goes to': 7,\n",
              " 'to washington': 26,\n",
              " 'doogie howser': 5}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYW3r1-rmAMN",
        "outputId": "3ae7b058-9cad-4eb6-952f-4658cd61b0d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdSYp8u0mAMO",
        "outputId": "c185f46a-4ded-4952-a192-83f660ee4d84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 5,\n",
              " 'in': 24,\n",
              " 'hand': 21,\n",
              " 'is': 28,\n",
              " 'worth': 61,\n",
              " 'two': 53,\n",
              " 'the': 38,\n",
              " 'bush': 7,\n",
              " 'bird in': 6,\n",
              " 'in hand': 25,\n",
              " 'hand is': 22,\n",
              " 'is worth': 30,\n",
              " 'worth two': 62,\n",
              " 'two in': 54,\n",
              " 'in the': 26,\n",
              " 'the bush': 40,\n",
              " 'good': 19,\n",
              " 'things': 46,\n",
              " 'come': 8,\n",
              " 'to': 50,\n",
              " 'those': 48,\n",
              " 'who': 59,\n",
              " 'wait': 55,\n",
              " 'good things': 20,\n",
              " 'things come': 47,\n",
              " 'come to': 9,\n",
              " 'to those': 51,\n",
              " 'those who': 49,\n",
              " 'who wait': 60,\n",
              " 'these': 44,\n",
              " 'watches': 57,\n",
              " 'cost': 10,\n",
              " '1500': 0,\n",
              " 'these watches': 45,\n",
              " 'watches cost': 58,\n",
              " 'cost 1500': 11,\n",
              " 'there': 42,\n",
              " 'are': 1,\n",
              " 'other': 33,\n",
              " 'fish': 15,\n",
              " 'sea': 35,\n",
              " 'there are': 43,\n",
              " 'are other': 2,\n",
              " 'other fish': 34,\n",
              " 'fish in': 16,\n",
              " 'the sea': 41,\n",
              " 'ball': 3,\n",
              " 'your': 63,\n",
              " 'court': 12,\n",
              " 'the ball': 39,\n",
              " 'ball is': 4,\n",
              " 'is in': 29,\n",
              " 'in your': 27,\n",
              " 'your court': 64,\n",
              " 'mr': 31,\n",
              " 'smith': 36,\n",
              " 'goes': 17,\n",
              " 'washington': 56,\n",
              " 'mr smith': 32,\n",
              " 'smith goes': 37,\n",
              " 'goes to': 18,\n",
              " 'to washington': 52,\n",
              " 'doogie': 13,\n",
              " 'howser': 23,\n",
              " 'doogie howser': 14}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "transformed_vector = n_gram_vectorizer.fit_transform(train_text)\n",
        "\n",
        "n_gram_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9i7dmEImAMO",
        "outputId": "c3be0afe-f7b6-4c31-b164-9791cba30864"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        1, 0, 2, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu8modvemAMP"
      },
      "source": [
        "#### Bigram and Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w6VtmoUmAMP",
        "outputId": "d22e66df-2603-49ce-d99e-9fa7df888df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok2zB-UMmAMP",
        "outputId": "69bdcfe3-9704-41ba-e316-6f57b9a43a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.', 'Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.', 'Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.', 'In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.', 'They were married in 1895.', 'The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.', 'In July 1898, the Curies announced the discovery of a new chemical element, polonium.', 'At the end of the year, they announced the discovery of another, radium.', 'The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.', \"Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\", 'Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.', 'She received a second Nobel Prize, for Chemistry, in 1911.', \"The Curie's research was crucial in the development of x-rays in surgery.\", 'During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.', 'The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.', 'Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.', 'By the late 1920s her health was beginning to deteriorate.', 'She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.', \"The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\"]\n"
          ]
        }
      ],
      "source": [
        "sentences = file_contents.split('\\n')\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opimGrXsmAMQ"
      },
      "outputs": [],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-xOCcZemAMQ"
      },
      "outputs": [],
      "source": [
        "transformed_vector = n_gram_vectorizer.fit_transform(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce9rmoKimAMQ",
        "outputId": "29af9337-0b0a-41ed-e9b9-8864ed5b27f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'marie curie': 251,\n",
              " 'curie was': 92,\n",
              " 'was polish': 504,\n",
              " 'polish born': 330,\n",
              " 'born physicist': 59,\n",
              " 'physicist and': 315,\n",
              " 'and chemist': 18,\n",
              " 'chemist and': 72,\n",
              " 'and one': 28,\n",
              " 'one of': 305,\n",
              " 'of the': 289,\n",
              " 'the most': 437,\n",
              " 'most famous': 265,\n",
              " 'famous scientists': 142,\n",
              " 'scientists of': 367,\n",
              " 'of her': 279,\n",
              " 'her time': 191,\n",
              " 'marie curie was': 252,\n",
              " 'curie was polish': 93,\n",
              " 'was polish born': 505,\n",
              " 'polish born physicist': 331,\n",
              " 'born physicist and': 60,\n",
              " 'physicist and chemist': 316,\n",
              " 'and chemist and': 19,\n",
              " 'chemist and one': 73,\n",
              " 'and one of': 29,\n",
              " 'one of the': 306,\n",
              " 'of the most': 291,\n",
              " 'the most famous': 438,\n",
              " 'most famous scientists': 266,\n",
              " 'famous scientists of': 143,\n",
              " 'scientists of her': 368,\n",
              " 'of her time': 280,\n",
              " 'together with': 480,\n",
              " 'with her': 526,\n",
              " 'her husband': 186,\n",
              " 'husband pierre': 203,\n",
              " 'pierre she': 328,\n",
              " 'she was': 385,\n",
              " 'was awarded': 490,\n",
              " 'awarded the': 46,\n",
              " 'the nobel': 441,\n",
              " 'nobel prize': 272,\n",
              " 'prize in': 337,\n",
              " 'in 1903': 208,\n",
              " '1903 and': 6,\n",
              " 'and she': 30,\n",
              " 'she went': 387,\n",
              " 'went on': 506,\n",
              " 'on to': 301,\n",
              " 'to win': 476,\n",
              " 'win another': 520,\n",
              " 'another in': 40,\n",
              " 'in 1911': 212,\n",
              " 'together with her': 481,\n",
              " 'with her husband': 527,\n",
              " 'her husband pierre': 187,\n",
              " 'husband pierre she': 204,\n",
              " 'pierre she was': 329,\n",
              " 'she was awarded': 386,\n",
              " 'was awarded the': 491,\n",
              " 'awarded the nobel': 47,\n",
              " 'the nobel prize': 442,\n",
              " 'nobel prize in': 274,\n",
              " 'prize in 1903': 338,\n",
              " 'in 1903 and': 209,\n",
              " '1903 and she': 7,\n",
              " 'and she went': 33,\n",
              " 'she went on': 388,\n",
              " 'went on to': 507,\n",
              " 'on to win': 302,\n",
              " 'to win another': 477,\n",
              " 'win another in': 521,\n",
              " 'another in 1911': 41,\n",
              " 'marie sklodowska': 253,\n",
              " 'sklodowska was': 394,\n",
              " 'was born': 494,\n",
              " 'born in': 57,\n",
              " 'in warsaw': 221,\n",
              " 'warsaw on': 488,\n",
              " 'on november': 297,\n",
              " 'november 1867': 275,\n",
              " '1867 the': 0,\n",
              " 'the daughter': 417,\n",
              " 'daughter of': 106,\n",
              " 'of teacher': 288,\n",
              " 'marie sklodowska was': 254,\n",
              " 'sklodowska was born': 395,\n",
              " 'was born in': 495,\n",
              " 'born in warsaw': 58,\n",
              " 'in warsaw on': 222,\n",
              " 'warsaw on november': 489,\n",
              " 'on november 1867': 298,\n",
              " 'november 1867 the': 276,\n",
              " '1867 the daughter': 1,\n",
              " 'the daughter of': 418,\n",
              " 'daughter of teacher': 107,\n",
              " 'in 1891': 205,\n",
              " '1891 she': 2,\n",
              " 'went to': 508,\n",
              " 'to paris': 468,\n",
              " 'paris to': 313,\n",
              " 'to study': 470,\n",
              " 'study physics': 400,\n",
              " 'physics and': 320,\n",
              " 'and mathematics': 26,\n",
              " 'mathematics at': 259,\n",
              " 'at the': 43,\n",
              " 'the sorbonne': 445,\n",
              " 'sorbonne where': 398,\n",
              " 'where she': 516,\n",
              " 'she met': 379,\n",
              " 'met pierre': 263,\n",
              " 'pierre curie': 324,\n",
              " 'curie professor': 88,\n",
              " 'professor of': 339,\n",
              " 'the school': 443,\n",
              " 'school of': 361,\n",
              " 'of physics': 285,\n",
              " 'in 1891 she': 206,\n",
              " '1891 she went': 3,\n",
              " 'she went to': 389,\n",
              " 'went to paris': 509,\n",
              " 'to paris to': 469,\n",
              " 'paris to study': 314,\n",
              " 'to study physics': 471,\n",
              " 'study physics and': 401,\n",
              " 'physics and mathematics': 321,\n",
              " 'and mathematics at': 27,\n",
              " 'mathematics at the': 260,\n",
              " 'at the sorbonne': 45,\n",
              " 'the sorbonne where': 447,\n",
              " 'sorbonne where she': 399,\n",
              " 'where she met': 517,\n",
              " 'she met pierre': 380,\n",
              " 'met pierre curie': 264,\n",
              " 'pierre curie professor': 325,\n",
              " 'curie professor of': 89,\n",
              " 'professor of the': 340,\n",
              " 'of the school': 293,\n",
              " 'the school of': 444,\n",
              " 'school of physics': 362,\n",
              " 'they were': 457,\n",
              " 'were married': 512,\n",
              " 'married in': 257,\n",
              " 'in 1895': 207,\n",
              " 'they were married': 458,\n",
              " 'were married in': 513,\n",
              " 'married in 1895': 258,\n",
              " 'the curies': 412,\n",
              " 'curies worked': 100,\n",
              " 'worked together': 536,\n",
              " 'together investigating': 478,\n",
              " 'investigating radioactivity': 225,\n",
              " 'radioactivity building': 343,\n",
              " 'building on': 61,\n",
              " 'on the': 299,\n",
              " 'the work': 448,\n",
              " 'work of': 532,\n",
              " 'the german': 431,\n",
              " 'german physicist': 166,\n",
              " 'physicist roentgen': 318,\n",
              " 'roentgen and': 359,\n",
              " 'and the': 34,\n",
              " 'the french': 427,\n",
              " 'french physicist': 156,\n",
              " 'physicist becquerel': 317,\n",
              " 'the curies worked': 416,\n",
              " 'curies worked together': 101,\n",
              " 'worked together investigating': 537,\n",
              " 'together investigating radioactivity': 479,\n",
              " 'investigating radioactivity building': 226,\n",
              " 'radioactivity building on': 344,\n",
              " 'building on the': 62,\n",
              " 'on the work': 300,\n",
              " 'the work of': 449,\n",
              " 'work of the': 533,\n",
              " 'of the german': 290,\n",
              " 'the german physicist': 432,\n",
              " 'german physicist roentgen': 167,\n",
              " 'physicist roentgen and': 319,\n",
              " 'roentgen and the': 360,\n",
              " 'and the french': 35,\n",
              " 'the french physicist': 428,\n",
              " 'french physicist becquerel': 157,\n",
              " 'in july': 215,\n",
              " 'july 1898': 231,\n",
              " '1898 the': 4,\n",
              " 'curies announced': 96,\n",
              " 'announced the': 38,\n",
              " 'the discovery': 421,\n",
              " 'discovery of': 116,\n",
              " 'of new': 283,\n",
              " 'new chemical': 269,\n",
              " 'chemical element': 70,\n",
              " 'element polonium': 129,\n",
              " 'in july 1898': 216,\n",
              " 'july 1898 the': 232,\n",
              " '1898 the curies': 5,\n",
              " 'the curies announced': 414,\n",
              " 'curies announced the': 97,\n",
              " 'announced the discovery': 39,\n",
              " 'the discovery of': 422,\n",
              " 'discovery of new': 118,\n",
              " 'of new chemical': 284,\n",
              " 'new chemical element': 270,\n",
              " 'chemical element polonium': 71,\n",
              " 'the end': 423,\n",
              " 'end of': 130,\n",
              " 'the year': 451,\n",
              " 'year they': 540,\n",
              " 'they announced': 453,\n",
              " 'of another': 277,\n",
              " 'another radium': 42,\n",
              " 'at the end': 44,\n",
              " 'the end of': 424,\n",
              " 'end of the': 131,\n",
              " 'of the year': 294,\n",
              " 'the year they': 452,\n",
              " 'year they announced': 541,\n",
              " 'they announced the': 454,\n",
              " 'discovery of another': 117,\n",
              " 'of another radium': 278,\n",
              " 'curies along': 94,\n",
              " 'along with': 14,\n",
              " 'with becquerel': 524,\n",
              " 'becquerel were': 50,\n",
              " 'were awarded': 510,\n",
              " 'prize for': 334,\n",
              " 'for physics': 152,\n",
              " 'physics in': 322,\n",
              " 'the curies along': 413,\n",
              " 'curies along with': 95,\n",
              " 'along with becquerel': 15,\n",
              " 'with becquerel were': 525,\n",
              " 'becquerel were awarded': 51,\n",
              " 'were awarded the': 511,\n",
              " 'nobel prize for': 273,\n",
              " 'prize for physics': 336,\n",
              " 'for physics in': 153,\n",
              " 'physics in 1903': 323,\n",
              " 'pierre life': 326,\n",
              " 'life was': 243,\n",
              " 'was cut': 498,\n",
              " 'cut short': 102,\n",
              " 'short in': 390,\n",
              " 'in 1906': 210,\n",
              " '1906 when': 8,\n",
              " 'when he': 514,\n",
              " 'he was': 172,\n",
              " 'was knocked': 502,\n",
              " 'knocked down': 237,\n",
              " 'down and': 121,\n",
              " 'and killed': 24,\n",
              " 'killed by': 235,\n",
              " 'by carriage': 63,\n",
              " 'pierre life was': 327,\n",
              " 'life was cut': 244,\n",
              " 'was cut short': 499,\n",
              " 'cut short in': 103,\n",
              " 'short in 1906': 391,\n",
              " 'in 1906 when': 211,\n",
              " '1906 when he': 9,\n",
              " 'when he was': 515,\n",
              " 'he was knocked': 173,\n",
              " 'was knocked down': 503,\n",
              " 'knocked down and': 238,\n",
              " 'down and killed': 122,\n",
              " 'and killed by': 25,\n",
              " 'killed by carriage': 236,\n",
              " 'marie took': 255,\n",
              " 'took over': 482,\n",
              " 'over his': 311,\n",
              " 'his teaching': 201,\n",
              " 'teaching post': 406,\n",
              " 'post becoming': 332,\n",
              " 'becoming the': 48,\n",
              " 'the first': 425,\n",
              " 'first woman': 146,\n",
              " 'woman to': 530,\n",
              " 'to teach': 472,\n",
              " 'teach at': 404,\n",
              " 'sorbonne and': 396,\n",
              " 'and devoted': 20,\n",
              " 'devoted herself': 112,\n",
              " 'herself to': 197,\n",
              " 'to continuing': 459,\n",
              " 'continuing the': 78,\n",
              " 'work that': 534,\n",
              " 'that they': 408,\n",
              " 'they had': 455,\n",
              " 'had begun': 170,\n",
              " 'begun together': 54,\n",
              " 'marie took over': 256,\n",
              " 'took over his': 483,\n",
              " 'over his teaching': 312,\n",
              " 'his teaching post': 202,\n",
              " 'teaching post becoming': 407,\n",
              " 'post becoming the': 333,\n",
              " 'becoming the first': 49,\n",
              " 'the first woman': 426,\n",
              " 'first woman to': 147,\n",
              " 'woman to teach': 531,\n",
              " 'to teach at': 473,\n",
              " 'teach at the': 405,\n",
              " 'the sorbonne and': 446,\n",
              " 'sorbonne and devoted': 397,\n",
              " 'and devoted herself': 21,\n",
              " 'devoted herself to': 113,\n",
              " 'herself to continuing': 198,\n",
              " 'to continuing the': 460,\n",
              " 'continuing the work': 79,\n",
              " 'the work that': 450,\n",
              " 'work that they': 535,\n",
              " 'that they had': 409,\n",
              " 'they had begun': 456,\n",
              " 'had begun together': 171,\n",
              " 'she received': 383,\n",
              " 'received second': 351,\n",
              " 'second nobel': 369,\n",
              " 'for chemistry': 148,\n",
              " 'chemistry in': 74,\n",
              " 'she received second': 384,\n",
              " 'received second nobel': 352,\n",
              " 'second nobel prize': 370,\n",
              " 'prize for chemistry': 335,\n",
              " 'for chemistry in': 149,\n",
              " 'chemistry in 1911': 75,\n",
              " 'the curie': 410,\n",
              " 'curie research': 90,\n",
              " 'research was': 357,\n",
              " 'was crucial': 496,\n",
              " 'crucial in': 84,\n",
              " 'in the': 218,\n",
              " 'the development': 419,\n",
              " 'development of': 110,\n",
              " 'of rays': 286,\n",
              " 'rays in': 349,\n",
              " 'in surgery': 217,\n",
              " 'the curie research': 411,\n",
              " 'curie research was': 91,\n",
              " 'research was crucial': 358,\n",
              " 'was crucial in': 497,\n",
              " 'crucial in the': 85,\n",
              " 'in the development': 219,\n",
              " 'the development of': 420,\n",
              " 'development of rays': 111,\n",
              " 'of rays in': 287,\n",
              " 'rays in surgery': 350,\n",
              " 'during world': 125,\n",
              " 'world war': 538,\n",
              " 'war one': 486,\n",
              " 'one curie': 303,\n",
              " 'curie helped': 86,\n",
              " 'helped to': 180,\n",
              " 'to equip': 462,\n",
              " 'equip ambulances': 134,\n",
              " 'ambulances with': 16,\n",
              " 'with ray': 528,\n",
              " 'ray equipment': 347,\n",
              " 'equipment which': 136,\n",
              " 'which she': 518,\n",
              " 'she herself': 377,\n",
              " 'herself drove': 193,\n",
              " 'drove to': 123,\n",
              " 'to the': 474,\n",
              " 'the front': 429,\n",
              " 'front lines': 165,\n",
              " 'during world war': 126,\n",
              " 'world war one': 539,\n",
              " 'war one curie': 487,\n",
              " 'one curie helped': 304,\n",
              " 'curie helped to': 87,\n",
              " 'helped to equip': 181,\n",
              " 'to equip ambulances': 463,\n",
              " 'equip ambulances with': 135,\n",
              " 'ambulances with ray': 17,\n",
              " 'with ray equipment': 529,\n",
              " 'ray equipment which': 348,\n",
              " 'equipment which she': 137,\n",
              " 'which she herself': 519,\n",
              " 'she herself drove': 378,\n",
              " 'herself drove to': 194,\n",
              " 'drove to the': 124,\n",
              " 'to the front': 475,\n",
              " 'the front lines': 430,\n",
              " 'the international': 433,\n",
              " 'international red': 223,\n",
              " 'red cross': 355,\n",
              " 'cross made': 82,\n",
              " 'made her': 245,\n",
              " 'her head': 182,\n",
              " 'head of': 174,\n",
              " 'of its': 281,\n",
              " 'its radiological': 229,\n",
              " 'radiological service': 345,\n",
              " 'service and': 371,\n",
              " 'she held': 375,\n",
              " 'held training': 178,\n",
              " 'training courses': 484,\n",
              " 'courses for': 80,\n",
              " 'for medical': 150,\n",
              " 'medical orderlies': 261,\n",
              " 'orderlies and': 309,\n",
              " 'and doctors': 22,\n",
              " 'doctors in': 119,\n",
              " 'the new': 439,\n",
              " 'new techniques': 271,\n",
              " 'the international red': 434,\n",
              " 'international red cross': 224,\n",
              " 'red cross made': 356,\n",
              " 'cross made her': 83,\n",
              " 'made her head': 246,\n",
              " 'her head of': 183,\n",
              " 'head of its': 175,\n",
              " 'of its radiological': 282,\n",
              " 'its radiological service': 230,\n",
              " 'radiological service and': 346,\n",
              " 'service and she': 372,\n",
              " 'and she held': 31,\n",
              " 'she held training': 376,\n",
              " 'held training courses': 179,\n",
              " 'training courses for': 485,\n",
              " 'courses for medical': 81,\n",
              " 'for medical orderlies': 151,\n",
              " 'medical orderlies and': 262,\n",
              " 'orderlies and doctors': 310,\n",
              " 'and doctors in': 23,\n",
              " 'doctors in the': 120,\n",
              " 'in the new': 220,\n",
              " 'the new techniques': 440,\n",
              " 'despite her': 108,\n",
              " 'her success': 189,\n",
              " 'success marie': 402,\n",
              " 'marie continued': 249,\n",
              " 'continued to': 76,\n",
              " 'to face': 464,\n",
              " 'face great': 140,\n",
              " 'great opposition': 168,\n",
              " 'opposition from': 307,\n",
              " 'from male': 163,\n",
              " 'male scientists': 247,\n",
              " 'scientists in': 365,\n",
              " 'in france': 213,\n",
              " 'france and': 154,\n",
              " 'she never': 381,\n",
              " 'never received': 267,\n",
              " 'received significant': 353,\n",
              " 'significant financial': 392,\n",
              " 'financial benefits': 144,\n",
              " 'benefits from': 55,\n",
              " 'from her': 158,\n",
              " 'her work': 192,\n",
              " 'despite her success': 109,\n",
              " 'her success marie': 190,\n",
              " 'success marie continued': 403,\n",
              " 'marie continued to': 250,\n",
              " 'continued to face': 77,\n",
              " 'to face great': 465,\n",
              " 'face great opposition': 141,\n",
              " 'great opposition from': 169,\n",
              " 'opposition from male': 308,\n",
              " 'from male scientists': 164,\n",
              " 'male scientists in': 248,\n",
              " 'scientists in france': 366,\n",
              " 'in france and': 214,\n",
              " 'france and she': 155,\n",
              " 'and she never': 32,\n",
              " 'she never received': 382,\n",
              " 'never received significant': 268,\n",
              " 'received significant financial': 354,\n",
              " 'significant financial benefits': 393,\n",
              " 'financial benefits from': 145,\n",
              " 'benefits from her': 56,\n",
              " 'from her work': 160,\n",
              " 'by the': 66,\n",
              " 'the late': 435,\n",
              " 'late 1920s': 239,\n",
              " '1920s her': 10,\n",
              " 'her health': 184,\n",
              " 'health was': 176,\n",
              " 'was beginning': 492,\n",
              " 'beginning to': 52,\n",
              " 'to deteriorate': 461,\n",
              " 'by the late': 67,\n",
              " 'the late 1920s': 436,\n",
              " 'late 1920s her': 240,\n",
              " '1920s her health': 11,\n",
              " 'her health was': 185,\n",
              " 'health was beginning': 177,\n",
              " 'was beginning to': 493,\n",
              " 'beginning to deteriorate': 53,\n",
              " 'she died': 373,\n",
              " 'died on': 114,\n",
              " 'on july': 295,\n",
              " 'july 1934': 233,\n",
              " '1934 from': 12,\n",
              " 'from leukaemia': 161,\n",
              " 'leukaemia caused': 241,\n",
              " 'caused by': 68,\n",
              " 'by exposure': 64,\n",
              " 'exposure to': 138,\n",
              " 'to high': 466,\n",
              " 'high energy': 199,\n",
              " 'energy radiation': 132,\n",
              " 'radiation from': 341,\n",
              " 'her research': 188,\n",
              " 'she died on': 374,\n",
              " 'died on july': 115,\n",
              " 'on july 1934': 296,\n",
              " 'july 1934 from': 234,\n",
              " '1934 from leukaemia': 13,\n",
              " 'from leukaemia caused': 162,\n",
              " 'leukaemia caused by': 242,\n",
              " 'caused by exposure': 69,\n",
              " 'by exposure to': 65,\n",
              " 'exposure to high': 139,\n",
              " 'to high energy': 467,\n",
              " 'high energy radiation': 200,\n",
              " 'energy radiation from': 133,\n",
              " 'radiation from her': 342,\n",
              " 'from her research': 159,\n",
              " 'curies eldest': 98,\n",
              " 'eldest daughter': 127,\n",
              " 'daughter irene': 104,\n",
              " 'irene was': 227,\n",
              " 'was herself': 500,\n",
              " 'herself scientist': 195,\n",
              " 'scientist and': 363,\n",
              " 'and winner': 36,\n",
              " 'winner of': 522,\n",
              " 'the curies eldest': 415,\n",
              " 'curies eldest daughter': 99,\n",
              " 'eldest daughter irene': 128,\n",
              " 'daughter irene was': 105,\n",
              " 'irene was herself': 228,\n",
              " 'was herself scientist': 501,\n",
              " 'herself scientist and': 196,\n",
              " 'scientist and winner': 364,\n",
              " 'and winner of': 37,\n",
              " 'winner of the': 523,\n",
              " 'of the nobel': 292}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary = n_gram_vectorizer.vocabulary_\n",
        "\n",
        "vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjvnVkNEmAMR",
        "outputId": "ba16794c-1174-4cfe-9f6b-caaea4a9fcbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_.get('marie curie')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dU9kx8rvmAMR",
        "outputId": "57c3b6b9-eb32-41b7-c88d-d4f75ae9429b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "279"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_.get('of her')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXnI7WEPmAMR"
      },
      "source": [
        "* https://stackoverflow.com/questions/11763613/python-list-of-ngrams-with-frequencies\n",
        "* https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4IxakLmmAMS"
      },
      "source": [
        "word_count is a vector that contains the sum of each word occurrence in all texts in the corpus. In other words, we are adding the elements for each column of vector matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LmLpXNAmAMS",
        "outputId": "19d06c76-f17f-479c-aa11-e628a64b695a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyNnuyXHmAMS",
        "outputId": "a429a2c1-df7a-4b32-f9aa-3debedf41361"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3,\n",
              "       1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 3, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_count = transformed_vector.toarray().sum(axis=0)\n",
        "\n",
        "word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlZwdSnhmAMS",
        "outputId": "4c037b6f-e999-4fcb-974d-659feca0e117"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_items([('marie curie', 251), ('curie was', 92), ('was polish', 504), ('polish born', 330), ('born physicist', 59), ('physicist and', 315), ('and chemist', 18), ('chemist and', 72), ('and one', 28), ('one of', 305), ('of the', 289), ('the most', 437), ('most famous', 265), ('famous scientists', 142), ('scientists of', 367), ('of her', 279), ('her time', 191), ('marie curie was', 252), ('curie was polish', 93), ('was polish born', 505), ('polish born physicist', 331), ('born physicist and', 60), ('physicist and chemist', 316), ('and chemist and', 19), ('chemist and one', 73), ('and one of', 29), ('one of the', 306), ('of the most', 291), ('the most famous', 438), ('most famous scientists', 266), ('famous scientists of', 143), ('scientists of her', 368), ('of her time', 280), ('together with', 480), ('with her', 526), ('her husband', 186), ('husband pierre', 203), ('pierre she', 328), ('she was', 385), ('was awarded', 490), ('awarded the', 46), ('the nobel', 441), ('nobel prize', 272), ('prize in', 337), ('in 1903', 208), ('1903 and', 6), ('and she', 30), ('she went', 387), ('went on', 506), ('on to', 301), ('to win', 476), ('win another', 520), ('another in', 40), ('in 1911', 212), ('together with her', 481), ('with her husband', 527), ('her husband pierre', 187), ('husband pierre she', 204), ('pierre she was', 329), ('she was awarded', 386), ('was awarded the', 491), ('awarded the nobel', 47), ('the nobel prize', 442), ('nobel prize in', 274), ('prize in 1903', 338), ('in 1903 and', 209), ('1903 and she', 7), ('and she went', 33), ('she went on', 388), ('went on to', 507), ('on to win', 302), ('to win another', 477), ('win another in', 521), ('another in 1911', 41), ('marie sklodowska', 253), ('sklodowska was', 394), ('was born', 494), ('born in', 57), ('in warsaw', 221), ('warsaw on', 488), ('on november', 297), ('november 1867', 275), ('1867 the', 0), ('the daughter', 417), ('daughter of', 106), ('of teacher', 288), ('marie sklodowska was', 254), ('sklodowska was born', 395), ('was born in', 495), ('born in warsaw', 58), ('in warsaw on', 222), ('warsaw on november', 489), ('on november 1867', 298), ('november 1867 the', 276), ('1867 the daughter', 1), ('the daughter of', 418), ('daughter of teacher', 107), ('in 1891', 205), ('1891 she', 2), ('went to', 508), ('to paris', 468), ('paris to', 313), ('to study', 470), ('study physics', 400), ('physics and', 320), ('and mathematics', 26), ('mathematics at', 259), ('at the', 43), ('the sorbonne', 445), ('sorbonne where', 398), ('where she', 516), ('she met', 379), ('met pierre', 263), ('pierre curie', 324), ('curie professor', 88), ('professor of', 339), ('the school', 443), ('school of', 361), ('of physics', 285), ('in 1891 she', 206), ('1891 she went', 3), ('she went to', 389), ('went to paris', 509), ('to paris to', 469), ('paris to study', 314), ('to study physics', 471), ('study physics and', 401), ('physics and mathematics', 321), ('and mathematics at', 27), ('mathematics at the', 260), ('at the sorbonne', 45), ('the sorbonne where', 447), ('sorbonne where she', 399), ('where she met', 517), ('she met pierre', 380), ('met pierre curie', 264), ('pierre curie professor', 325), ('curie professor of', 89), ('professor of the', 340), ('of the school', 293), ('the school of', 444), ('school of physics', 362), ('they were', 457), ('were married', 512), ('married in', 257), ('in 1895', 207), ('they were married', 458), ('were married in', 513), ('married in 1895', 258), ('the curies', 412), ('curies worked', 100), ('worked together', 536), ('together investigating', 478), ('investigating radioactivity', 225), ('radioactivity building', 343), ('building on', 61), ('on the', 299), ('the work', 448), ('work of', 532), ('the german', 431), ('german physicist', 166), ('physicist roentgen', 318), ('roentgen and', 359), ('and the', 34), ('the french', 427), ('french physicist', 156), ('physicist becquerel', 317), ('the curies worked', 416), ('curies worked together', 101), ('worked together investigating', 537), ('together investigating radioactivity', 479), ('investigating radioactivity building', 226), ('radioactivity building on', 344), ('building on the', 62), ('on the work', 300), ('the work of', 449), ('work of the', 533), ('of the german', 290), ('the german physicist', 432), ('german physicist roentgen', 167), ('physicist roentgen and', 319), ('roentgen and the', 360), ('and the french', 35), ('the french physicist', 428), ('french physicist becquerel', 157), ('in july', 215), ('july 1898', 231), ('1898 the', 4), ('curies announced', 96), ('announced the', 38), ('the discovery', 421), ('discovery of', 116), ('of new', 283), ('new chemical', 269), ('chemical element', 70), ('element polonium', 129), ('in july 1898', 216), ('july 1898 the', 232), ('1898 the curies', 5), ('the curies announced', 414), ('curies announced the', 97), ('announced the discovery', 39), ('the discovery of', 422), ('discovery of new', 118), ('of new chemical', 284), ('new chemical element', 270), ('chemical element polonium', 71), ('the end', 423), ('end of', 130), ('the year', 451), ('year they', 540), ('they announced', 453), ('of another', 277), ('another radium', 42), ('at the end', 44), ('the end of', 424), ('end of the', 131), ('of the year', 294), ('the year they', 452), ('year they announced', 541), ('they announced the', 454), ('discovery of another', 117), ('of another radium', 278), ('curies along', 94), ('along with', 14), ('with becquerel', 524), ('becquerel were', 50), ('were awarded', 510), ('prize for', 334), ('for physics', 152), ('physics in', 322), ('the curies along', 413), ('curies along with', 95), ('along with becquerel', 15), ('with becquerel were', 525), ('becquerel were awarded', 51), ('were awarded the', 511), ('nobel prize for', 273), ('prize for physics', 336), ('for physics in', 153), ('physics in 1903', 323), ('pierre life', 326), ('life was', 243), ('was cut', 498), ('cut short', 102), ('short in', 390), ('in 1906', 210), ('1906 when', 8), ('when he', 514), ('he was', 172), ('was knocked', 502), ('knocked down', 237), ('down and', 121), ('and killed', 24), ('killed by', 235), ('by carriage', 63), ('pierre life was', 327), ('life was cut', 244), ('was cut short', 499), ('cut short in', 103), ('short in 1906', 391), ('in 1906 when', 211), ('1906 when he', 9), ('when he was', 515), ('he was knocked', 173), ('was knocked down', 503), ('knocked down and', 238), ('down and killed', 122), ('and killed by', 25), ('killed by carriage', 236), ('marie took', 255), ('took over', 482), ('over his', 311), ('his teaching', 201), ('teaching post', 406), ('post becoming', 332), ('becoming the', 48), ('the first', 425), ('first woman', 146), ('woman to', 530), ('to teach', 472), ('teach at', 404), ('sorbonne and', 396), ('and devoted', 20), ('devoted herself', 112), ('herself to', 197), ('to continuing', 459), ('continuing the', 78), ('work that', 534), ('that they', 408), ('they had', 455), ('had begun', 170), ('begun together', 54), ('marie took over', 256), ('took over his', 483), ('over his teaching', 312), ('his teaching post', 202), ('teaching post becoming', 407), ('post becoming the', 333), ('becoming the first', 49), ('the first woman', 426), ('first woman to', 147), ('woman to teach', 531), ('to teach at', 473), ('teach at the', 405), ('the sorbonne and', 446), ('sorbonne and devoted', 397), ('and devoted herself', 21), ('devoted herself to', 113), ('herself to continuing', 198), ('to continuing the', 460), ('continuing the work', 79), ('the work that', 450), ('work that they', 535), ('that they had', 409), ('they had begun', 456), ('had begun together', 171), ('she received', 383), ('received second', 351), ('second nobel', 369), ('for chemistry', 148), ('chemistry in', 74), ('she received second', 384), ('received second nobel', 352), ('second nobel prize', 370), ('prize for chemistry', 335), ('for chemistry in', 149), ('chemistry in 1911', 75), ('the curie', 410), ('curie research', 90), ('research was', 357), ('was crucial', 496), ('crucial in', 84), ('in the', 218), ('the development', 419), ('development of', 110), ('of rays', 286), ('rays in', 349), ('in surgery', 217), ('the curie research', 411), ('curie research was', 91), ('research was crucial', 358), ('was crucial in', 497), ('crucial in the', 85), ('in the development', 219), ('the development of', 420), ('development of rays', 111), ('of rays in', 287), ('rays in surgery', 350), ('during world', 125), ('world war', 538), ('war one', 486), ('one curie', 303), ('curie helped', 86), ('helped to', 180), ('to equip', 462), ('equip ambulances', 134), ('ambulances with', 16), ('with ray', 528), ('ray equipment', 347), ('equipment which', 136), ('which she', 518), ('she herself', 377), ('herself drove', 193), ('drove to', 123), ('to the', 474), ('the front', 429), ('front lines', 165), ('during world war', 126), ('world war one', 539), ('war one curie', 487), ('one curie helped', 304), ('curie helped to', 87), ('helped to equip', 181), ('to equip ambulances', 463), ('equip ambulances with', 135), ('ambulances with ray', 17), ('with ray equipment', 529), ('ray equipment which', 348), ('equipment which she', 137), ('which she herself', 519), ('she herself drove', 378), ('herself drove to', 194), ('drove to the', 124), ('to the front', 475), ('the front lines', 430), ('the international', 433), ('international red', 223), ('red cross', 355), ('cross made', 82), ('made her', 245), ('her head', 182), ('head of', 174), ('of its', 281), ('its radiological', 229), ('radiological service', 345), ('service and', 371), ('she held', 375), ('held training', 178), ('training courses', 484), ('courses for', 80), ('for medical', 150), ('medical orderlies', 261), ('orderlies and', 309), ('and doctors', 22), ('doctors in', 119), ('the new', 439), ('new techniques', 271), ('the international red', 434), ('international red cross', 224), ('red cross made', 356), ('cross made her', 83), ('made her head', 246), ('her head of', 183), ('head of its', 175), ('of its radiological', 282), ('its radiological service', 230), ('radiological service and', 346), ('service and she', 372), ('and she held', 31), ('she held training', 376), ('held training courses', 179), ('training courses for', 485), ('courses for medical', 81), ('for medical orderlies', 151), ('medical orderlies and', 262), ('orderlies and doctors', 310), ('and doctors in', 23), ('doctors in the', 120), ('in the new', 220), ('the new techniques', 440), ('despite her', 108), ('her success', 189), ('success marie', 402), ('marie continued', 249), ('continued to', 76), ('to face', 464), ('face great', 140), ('great opposition', 168), ('opposition from', 307), ('from male', 163), ('male scientists', 247), ('scientists in', 365), ('in france', 213), ('france and', 154), ('she never', 381), ('never received', 267), ('received significant', 353), ('significant financial', 392), ('financial benefits', 144), ('benefits from', 55), ('from her', 158), ('her work', 192), ('despite her success', 109), ('her success marie', 190), ('success marie continued', 403), ('marie continued to', 250), ('continued to face', 77), ('to face great', 465), ('face great opposition', 141), ('great opposition from', 169), ('opposition from male', 308), ('from male scientists', 164), ('male scientists in', 248), ('scientists in france', 366), ('in france and', 214), ('france and she', 155), ('and she never', 32), ('she never received', 382), ('never received significant', 268), ('received significant financial', 354), ('significant financial benefits', 393), ('financial benefits from', 145), ('benefits from her', 56), ('from her work', 160), ('by the', 66), ('the late', 435), ('late 1920s', 239), ('1920s her', 10), ('her health', 184), ('health was', 176), ('was beginning', 492), ('beginning to', 52), ('to deteriorate', 461), ('by the late', 67), ('the late 1920s', 436), ('late 1920s her', 240), ('1920s her health', 11), ('her health was', 185), ('health was beginning', 177), ('was beginning to', 493), ('beginning to deteriorate', 53), ('she died', 373), ('died on', 114), ('on july', 295), ('july 1934', 233), ('1934 from', 12), ('from leukaemia', 161), ('leukaemia caused', 241), ('caused by', 68), ('by exposure', 64), ('exposure to', 138), ('to high', 466), ('high energy', 199), ('energy radiation', 132), ('radiation from', 341), ('her research', 188), ('she died on', 374), ('died on july', 115), ('on july 1934', 296), ('july 1934 from', 234), ('1934 from leukaemia', 13), ('from leukaemia caused', 162), ('leukaemia caused by', 242), ('caused by exposure', 69), ('by exposure to', 65), ('exposure to high', 139), ('to high energy', 467), ('high energy radiation', 200), ('energy radiation from', 133), ('radiation from her', 342), ('from her research', 159), ('curies eldest', 98), ('eldest daughter', 127), ('daughter irene', 104), ('irene was', 227), ('was herself', 500), ('herself scientist', 195), ('scientist and', 363), ('and winner', 36), ('winner of', 522), ('the curies eldest', 415), ('curies eldest daughter', 99), ('eldest daughter irene', 128), ('daughter irene was', 105), ('irene was herself', 228), ('was herself scientist', 501), ('herself scientist and', 196), ('scientist and winner', 364), ('and winner of', 37), ('winner of the', 523), ('of the nobel', 292)])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18ngSebRmAMT",
        "outputId": "36ff1c07-4d2b-4d15-e785-7ff6495e403d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(5, 'of the'),\n",
              " (4, 'the curies'),\n",
              " (4, 'nobel prize'),\n",
              " (3, 'the nobel prize'),\n",
              " (3, 'the nobel'),\n",
              " (3, 'prize for'),\n",
              " (3, 'nobel prize for'),\n",
              " (3, 'at the'),\n",
              " (3, 'and she'),\n",
              " (2, 'the work'),\n",
              " (2, 'the sorbonne'),\n",
              " (2, 'the discovery of'),\n",
              " (2, 'the discovery'),\n",
              " (2, 'she went'),\n",
              " (2, 'prize for chemistry'),\n",
              " (2, 'in the'),\n",
              " (2, 'in 1911'),\n",
              " (2, 'in 1903'),\n",
              " (2, 'from her'),\n",
              " (2, 'for chemistry'),\n",
              " (2, 'discovery of'),\n",
              " (2, 'awarded the nobel'),\n",
              " (2, 'awarded the'),\n",
              " (2, 'at the sorbonne'),\n",
              " (2, 'announced the discovery'),\n",
              " (2, 'announced the'),\n",
              " (1, 'year they announced'),\n",
              " (1, 'year they'),\n",
              " (1, 'world war one'),\n",
              " (1, 'world war'),\n",
              " (1, 'worked together investigating'),\n",
              " (1, 'worked together'),\n",
              " (1, 'work that they'),\n",
              " (1, 'work that'),\n",
              " (1, 'work of the'),\n",
              " (1, 'work of'),\n",
              " (1, 'woman to teach'),\n",
              " (1, 'woman to'),\n",
              " (1, 'with ray equipment'),\n",
              " (1, 'with ray'),\n",
              " (1, 'with her husband'),\n",
              " (1, 'with her'),\n",
              " (1, 'with becquerel were'),\n",
              " (1, 'with becquerel'),\n",
              " (1, 'winner of the'),\n",
              " (1, 'winner of'),\n",
              " (1, 'win another in'),\n",
              " (1, 'win another'),\n",
              " (1, 'which she herself'),\n",
              " (1, 'which she'),\n",
              " (1, 'where she met'),\n",
              " (1, 'where she'),\n",
              " (1, 'when he was'),\n",
              " (1, 'when he'),\n",
              " (1, 'were married in'),\n",
              " (1, 'were married'),\n",
              " (1, 'were awarded the'),\n",
              " (1, 'were awarded'),\n",
              " (1, 'went to paris'),\n",
              " (1, 'went to'),\n",
              " (1, 'went on to'),\n",
              " (1, 'went on'),\n",
              " (1, 'was polish born'),\n",
              " (1, 'was polish'),\n",
              " (1, 'was knocked down'),\n",
              " (1, 'was knocked'),\n",
              " (1, 'was herself scientist'),\n",
              " (1, 'was herself'),\n",
              " (1, 'was cut short'),\n",
              " (1, 'was cut'),\n",
              " (1, 'was crucial in'),\n",
              " (1, 'was crucial'),\n",
              " (1, 'was born in'),\n",
              " (1, 'was born'),\n",
              " (1, 'was beginning to'),\n",
              " (1, 'was beginning'),\n",
              " (1, 'was awarded the'),\n",
              " (1, 'was awarded'),\n",
              " (1, 'warsaw on november'),\n",
              " (1, 'warsaw on'),\n",
              " (1, 'war one curie'),\n",
              " (1, 'war one'),\n",
              " (1, 'training courses for'),\n",
              " (1, 'training courses'),\n",
              " (1, 'took over his'),\n",
              " (1, 'took over'),\n",
              " (1, 'together with her'),\n",
              " (1, 'together with'),\n",
              " (1, 'together investigating radioactivity'),\n",
              " (1, 'together investigating'),\n",
              " (1, 'to win another'),\n",
              " (1, 'to win'),\n",
              " (1, 'to the front'),\n",
              " (1, 'to the'),\n",
              " (1, 'to teach at'),\n",
              " (1, 'to teach'),\n",
              " (1, 'to study physics'),\n",
              " (1, 'to study'),\n",
              " (1, 'to paris to'),\n",
              " (1, 'to paris'),\n",
              " (1, 'to high energy'),\n",
              " (1, 'to high'),\n",
              " (1, 'to face great'),\n",
              " (1, 'to face'),\n",
              " (1, 'to equip ambulances'),\n",
              " (1, 'to equip'),\n",
              " (1, 'to deteriorate'),\n",
              " (1, 'to continuing the'),\n",
              " (1, 'to continuing'),\n",
              " (1, 'they were married'),\n",
              " (1, 'they were'),\n",
              " (1, 'they had begun'),\n",
              " (1, 'they had'),\n",
              " (1, 'they announced the'),\n",
              " (1, 'they announced'),\n",
              " (1, 'the year they'),\n",
              " (1, 'the year'),\n",
              " (1, 'the work that'),\n",
              " (1, 'the work of'),\n",
              " (1, 'the sorbonne where'),\n",
              " (1, 'the sorbonne and'),\n",
              " (1, 'the school of'),\n",
              " (1, 'the school'),\n",
              " (1, 'the new techniques'),\n",
              " (1, 'the new'),\n",
              " (1, 'the most famous'),\n",
              " (1, 'the most'),\n",
              " (1, 'the late 1920s'),\n",
              " (1, 'the late'),\n",
              " (1, 'the international red'),\n",
              " (1, 'the international'),\n",
              " (1, 'the german physicist'),\n",
              " (1, 'the german'),\n",
              " (1, 'the front lines'),\n",
              " (1, 'the front'),\n",
              " (1, 'the french physicist'),\n",
              " (1, 'the french'),\n",
              " (1, 'the first woman'),\n",
              " (1, 'the first'),\n",
              " (1, 'the end of'),\n",
              " (1, 'the end'),\n",
              " (1, 'the development of'),\n",
              " (1, 'the development'),\n",
              " (1, 'the daughter of'),\n",
              " (1, 'the daughter'),\n",
              " (1, 'the curies worked'),\n",
              " (1, 'the curies eldest'),\n",
              " (1, 'the curies announced'),\n",
              " (1, 'the curies along'),\n",
              " (1, 'the curie research'),\n",
              " (1, 'the curie'),\n",
              " (1, 'that they had'),\n",
              " (1, 'that they'),\n",
              " (1, 'teaching post becoming'),\n",
              " (1, 'teaching post'),\n",
              " (1, 'teach at the'),\n",
              " (1, 'teach at'),\n",
              " (1, 'success marie continued'),\n",
              " (1, 'success marie'),\n",
              " (1, 'study physics and'),\n",
              " (1, 'study physics'),\n",
              " (1, 'sorbonne where she'),\n",
              " (1, 'sorbonne where'),\n",
              " (1, 'sorbonne and devoted'),\n",
              " (1, 'sorbonne and'),\n",
              " (1, 'sklodowska was born'),\n",
              " (1, 'sklodowska was'),\n",
              " (1, 'significant financial benefits'),\n",
              " (1, 'significant financial'),\n",
              " (1, 'short in 1906'),\n",
              " (1, 'short in'),\n",
              " (1, 'she went to'),\n",
              " (1, 'she went on'),\n",
              " (1, 'she was awarded'),\n",
              " (1, 'she was'),\n",
              " (1, 'she received second'),\n",
              " (1, 'she received'),\n",
              " (1, 'she never received'),\n",
              " (1, 'she never'),\n",
              " (1, 'she met pierre'),\n",
              " (1, 'she met'),\n",
              " (1, 'she herself drove'),\n",
              " (1, 'she herself'),\n",
              " (1, 'she held training'),\n",
              " (1, 'she held'),\n",
              " (1, 'she died on'),\n",
              " (1, 'she died'),\n",
              " (1, 'service and she'),\n",
              " (1, 'service and'),\n",
              " (1, 'second nobel prize'),\n",
              " (1, 'second nobel'),\n",
              " (1, 'scientists of her'),\n",
              " (1, 'scientists of'),\n",
              " (1, 'scientists in france'),\n",
              " (1, 'scientists in'),\n",
              " (1, 'scientist and winner'),\n",
              " (1, 'scientist and'),\n",
              " (1, 'school of physics'),\n",
              " (1, 'school of'),\n",
              " (1, 'roentgen and the'),\n",
              " (1, 'roentgen and'),\n",
              " (1, 'research was crucial'),\n",
              " (1, 'research was'),\n",
              " (1, 'red cross made'),\n",
              " (1, 'red cross'),\n",
              " (1, 'received significant financial'),\n",
              " (1, 'received significant'),\n",
              " (1, 'received second nobel'),\n",
              " (1, 'received second'),\n",
              " (1, 'rays in surgery'),\n",
              " (1, 'rays in'),\n",
              " (1, 'ray equipment which'),\n",
              " (1, 'ray equipment'),\n",
              " (1, 'radiological service and'),\n",
              " (1, 'radiological service'),\n",
              " (1, 'radioactivity building on'),\n",
              " (1, 'radioactivity building'),\n",
              " (1, 'radiation from her'),\n",
              " (1, 'radiation from'),\n",
              " (1, 'professor of the'),\n",
              " (1, 'professor of'),\n",
              " (1, 'prize in 1903'),\n",
              " (1, 'prize in'),\n",
              " (1, 'prize for physics'),\n",
              " (1, 'post becoming the'),\n",
              " (1, 'post becoming'),\n",
              " (1, 'polish born physicist'),\n",
              " (1, 'polish born'),\n",
              " (1, 'pierre she was'),\n",
              " (1, 'pierre she'),\n",
              " (1, 'pierre life was'),\n",
              " (1, 'pierre life'),\n",
              " (1, 'pierre curie professor'),\n",
              " (1, 'pierre curie'),\n",
              " (1, 'physics in 1903'),\n",
              " (1, 'physics in'),\n",
              " (1, 'physics and mathematics'),\n",
              " (1, 'physics and'),\n",
              " (1, 'physicist roentgen and'),\n",
              " (1, 'physicist roentgen'),\n",
              " (1, 'physicist becquerel'),\n",
              " (1, 'physicist and chemist'),\n",
              " (1, 'physicist and'),\n",
              " (1, 'paris to study'),\n",
              " (1, 'paris to'),\n",
              " (1, 'over his teaching'),\n",
              " (1, 'over his'),\n",
              " (1, 'orderlies and doctors'),\n",
              " (1, 'orderlies and'),\n",
              " (1, 'opposition from male'),\n",
              " (1, 'opposition from'),\n",
              " (1, 'one of the'),\n",
              " (1, 'one of'),\n",
              " (1, 'one curie helped'),\n",
              " (1, 'one curie'),\n",
              " (1, 'on to win'),\n",
              " (1, 'on to'),\n",
              " (1, 'on the work'),\n",
              " (1, 'on the'),\n",
              " (1, 'on november 1867'),\n",
              " (1, 'on november'),\n",
              " (1, 'on july 1934'),\n",
              " (1, 'on july'),\n",
              " (1, 'of the year'),\n",
              " (1, 'of the school'),\n",
              " (1, 'of the nobel'),\n",
              " (1, 'of the most'),\n",
              " (1, 'of the german'),\n",
              " (1, 'of teacher'),\n",
              " (1, 'of rays in'),\n",
              " (1, 'of rays'),\n",
              " (1, 'of physics'),\n",
              " (1, 'of new chemical'),\n",
              " (1, 'of new'),\n",
              " (1, 'of its radiological'),\n",
              " (1, 'of its'),\n",
              " (1, 'of her time'),\n",
              " (1, 'of her'),\n",
              " (1, 'of another radium'),\n",
              " (1, 'of another'),\n",
              " (1, 'november 1867 the'),\n",
              " (1, 'november 1867'),\n",
              " (1, 'nobel prize in'),\n",
              " (1, 'new techniques'),\n",
              " (1, 'new chemical element'),\n",
              " (1, 'new chemical'),\n",
              " (1, 'never received significant'),\n",
              " (1, 'never received'),\n",
              " (1, 'most famous scientists'),\n",
              " (1, 'most famous'),\n",
              " (1, 'met pierre curie'),\n",
              " (1, 'met pierre'),\n",
              " (1, 'medical orderlies and'),\n",
              " (1, 'medical orderlies'),\n",
              " (1, 'mathematics at the'),\n",
              " (1, 'mathematics at'),\n",
              " (1, 'married in 1895'),\n",
              " (1, 'married in'),\n",
              " (1, 'marie took over'),\n",
              " (1, 'marie took'),\n",
              " (1, 'marie sklodowska was'),\n",
              " (1, 'marie sklodowska'),\n",
              " (1, 'marie curie was'),\n",
              " (1, 'marie curie'),\n",
              " (1, 'marie continued to'),\n",
              " (1, 'marie continued'),\n",
              " (1, 'male scientists in'),\n",
              " (1, 'male scientists'),\n",
              " (1, 'made her head'),\n",
              " (1, 'made her'),\n",
              " (1, 'life was cut'),\n",
              " (1, 'life was'),\n",
              " (1, 'leukaemia caused by'),\n",
              " (1, 'leukaemia caused'),\n",
              " (1, 'late 1920s her'),\n",
              " (1, 'late 1920s'),\n",
              " (1, 'knocked down and'),\n",
              " (1, 'knocked down'),\n",
              " (1, 'killed by carriage'),\n",
              " (1, 'killed by'),\n",
              " (1, 'july 1934 from'),\n",
              " (1, 'july 1934'),\n",
              " (1, 'july 1898 the'),\n",
              " (1, 'july 1898'),\n",
              " (1, 'its radiological service'),\n",
              " (1, 'its radiological'),\n",
              " (1, 'irene was herself'),\n",
              " (1, 'irene was'),\n",
              " (1, 'investigating radioactivity building'),\n",
              " (1, 'investigating radioactivity'),\n",
              " (1, 'international red cross'),\n",
              " (1, 'international red'),\n",
              " (1, 'in warsaw on'),\n",
              " (1, 'in warsaw'),\n",
              " (1, 'in the new'),\n",
              " (1, 'in the development'),\n",
              " (1, 'in surgery'),\n",
              " (1, 'in july 1898'),\n",
              " (1, 'in july'),\n",
              " (1, 'in france and'),\n",
              " (1, 'in france'),\n",
              " (1, 'in 1906 when'),\n",
              " (1, 'in 1906'),\n",
              " (1, 'in 1903 and'),\n",
              " (1, 'in 1895'),\n",
              " (1, 'in 1891 she'),\n",
              " (1, 'in 1891'),\n",
              " (1, 'husband pierre she'),\n",
              " (1, 'husband pierre'),\n",
              " (1, 'his teaching post'),\n",
              " (1, 'his teaching'),\n",
              " (1, 'high energy radiation'),\n",
              " (1, 'high energy'),\n",
              " (1, 'herself to continuing'),\n",
              " (1, 'herself to'),\n",
              " (1, 'herself scientist and'),\n",
              " (1, 'herself scientist'),\n",
              " (1, 'herself drove to'),\n",
              " (1, 'herself drove'),\n",
              " (1, 'her work'),\n",
              " (1, 'her time'),\n",
              " (1, 'her success marie'),\n",
              " (1, 'her success'),\n",
              " (1, 'her research'),\n",
              " (1, 'her husband pierre'),\n",
              " (1, 'her husband'),\n",
              " (1, 'her health was'),\n",
              " (1, 'her health'),\n",
              " (1, 'her head of'),\n",
              " (1, 'her head'),\n",
              " (1, 'helped to equip'),\n",
              " (1, 'helped to'),\n",
              " (1, 'held training courses'),\n",
              " (1, 'held training'),\n",
              " (1, 'health was beginning'),\n",
              " (1, 'health was'),\n",
              " (1, 'head of its'),\n",
              " (1, 'head of'),\n",
              " (1, 'he was knocked'),\n",
              " (1, 'he was'),\n",
              " (1, 'had begun together'),\n",
              " (1, 'had begun'),\n",
              " (1, 'great opposition from'),\n",
              " (1, 'great opposition'),\n",
              " (1, 'german physicist roentgen'),\n",
              " (1, 'german physicist'),\n",
              " (1, 'front lines'),\n",
              " (1, 'from male scientists'),\n",
              " (1, 'from male'),\n",
              " (1, 'from leukaemia caused'),\n",
              " (1, 'from leukaemia'),\n",
              " (1, 'from her work'),\n",
              " (1, 'from her research'),\n",
              " (1, 'french physicist becquerel'),\n",
              " (1, 'french physicist'),\n",
              " (1, 'france and she'),\n",
              " (1, 'france and'),\n",
              " (1, 'for physics in'),\n",
              " (1, 'for physics'),\n",
              " (1, 'for medical orderlies'),\n",
              " (1, 'for medical'),\n",
              " (1, 'for chemistry in'),\n",
              " (1, 'first woman to'),\n",
              " (1, 'first woman'),\n",
              " (1, 'financial benefits from'),\n",
              " (1, 'financial benefits'),\n",
              " (1, 'famous scientists of'),\n",
              " (1, 'famous scientists'),\n",
              " (1, 'face great opposition'),\n",
              " (1, 'face great'),\n",
              " (1, 'exposure to high'),\n",
              " (1, 'exposure to'),\n",
              " (1, 'equipment which she'),\n",
              " (1, 'equipment which'),\n",
              " (1, 'equip ambulances with'),\n",
              " (1, 'equip ambulances'),\n",
              " (1, 'energy radiation from'),\n",
              " (1, 'energy radiation'),\n",
              " (1, 'end of the'),\n",
              " (1, 'end of'),\n",
              " (1, 'element polonium'),\n",
              " (1, 'eldest daughter irene'),\n",
              " (1, 'eldest daughter'),\n",
              " (1, 'during world war'),\n",
              " (1, 'during world'),\n",
              " (1, 'drove to the'),\n",
              " (1, 'drove to'),\n",
              " (1, 'down and killed'),\n",
              " (1, 'down and'),\n",
              " (1, 'doctors in the'),\n",
              " (1, 'doctors in'),\n",
              " (1, 'discovery of new'),\n",
              " (1, 'discovery of another'),\n",
              " (1, 'died on july'),\n",
              " (1, 'died on'),\n",
              " (1, 'devoted herself to'),\n",
              " (1, 'devoted herself'),\n",
              " (1, 'development of rays'),\n",
              " (1, 'development of'),\n",
              " (1, 'despite her success'),\n",
              " (1, 'despite her'),\n",
              " (1, 'daughter of teacher'),\n",
              " (1, 'daughter of'),\n",
              " (1, 'daughter irene was'),\n",
              " (1, 'daughter irene'),\n",
              " (1, 'cut short in'),\n",
              " (1, 'cut short'),\n",
              " (1, 'curies worked together'),\n",
              " (1, 'curies worked'),\n",
              " (1, 'curies eldest daughter'),\n",
              " (1, 'curies eldest'),\n",
              " (1, 'curies announced the'),\n",
              " (1, 'curies announced'),\n",
              " (1, 'curies along with'),\n",
              " (1, 'curies along'),\n",
              " (1, 'curie was polish'),\n",
              " (1, 'curie was'),\n",
              " (1, 'curie research was'),\n",
              " (1, 'curie research'),\n",
              " (1, 'curie professor of'),\n",
              " (1, 'curie professor'),\n",
              " (1, 'curie helped to'),\n",
              " (1, 'curie helped'),\n",
              " (1, 'crucial in the'),\n",
              " (1, 'crucial in'),\n",
              " (1, 'cross made her'),\n",
              " (1, 'cross made'),\n",
              " (1, 'courses for medical'),\n",
              " (1, 'courses for'),\n",
              " (1, 'continuing the work'),\n",
              " (1, 'continuing the'),\n",
              " (1, 'continued to face'),\n",
              " (1, 'continued to'),\n",
              " (1, 'chemistry in 1911'),\n",
              " (1, 'chemistry in'),\n",
              " (1, 'chemist and one'),\n",
              " (1, 'chemist and'),\n",
              " (1, 'chemical element polonium'),\n",
              " (1, 'chemical element'),\n",
              " (1, 'caused by exposure'),\n",
              " (1, 'caused by'),\n",
              " (1, 'by the late'),\n",
              " (1, 'by the'),\n",
              " (1, 'by exposure to'),\n",
              " (1, 'by exposure'),\n",
              " (1, 'by carriage'),\n",
              " (1, 'building on the'),\n",
              " (1, 'building on'),\n",
              " (1, 'born physicist and'),\n",
              " (1, 'born physicist'),\n",
              " (1, 'born in warsaw'),\n",
              " (1, 'born in'),\n",
              " (1, 'benefits from her'),\n",
              " (1, 'benefits from'),\n",
              " (1, 'begun together'),\n",
              " (1, 'beginning to deteriorate'),\n",
              " (1, 'beginning to'),\n",
              " (1, 'becquerel were awarded'),\n",
              " (1, 'becquerel were'),\n",
              " (1, 'becoming the first'),\n",
              " (1, 'becoming the'),\n",
              " (1, 'at the end'),\n",
              " (1, 'another radium'),\n",
              " (1, 'another in 1911'),\n",
              " (1, 'another in'),\n",
              " (1, 'and winner of'),\n",
              " (1, 'and winner'),\n",
              " (1, 'and the french'),\n",
              " (1, 'and the'),\n",
              " (1, 'and she went'),\n",
              " (1, 'and she never'),\n",
              " (1, 'and she held'),\n",
              " (1, 'and one of'),\n",
              " (1, 'and one'),\n",
              " (1, 'and mathematics at'),\n",
              " (1, 'and mathematics'),\n",
              " (1, 'and killed by'),\n",
              " (1, 'and killed'),\n",
              " (1, 'and doctors in'),\n",
              " (1, 'and doctors'),\n",
              " (1, 'and devoted herself'),\n",
              " (1, 'and devoted'),\n",
              " (1, 'and chemist and'),\n",
              " (1, 'and chemist'),\n",
              " (1, 'ambulances with ray'),\n",
              " (1, 'ambulances with'),\n",
              " (1, 'along with becquerel'),\n",
              " (1, 'along with'),\n",
              " (1, '1934 from leukaemia'),\n",
              " (1, '1934 from'),\n",
              " (1, '1920s her health'),\n",
              " (1, '1920s her'),\n",
              " (1, '1906 when he'),\n",
              " (1, '1906 when'),\n",
              " (1, '1903 and she'),\n",
              " (1, '1903 and'),\n",
              " (1, '1898 the curies'),\n",
              " (1, '1898 the'),\n",
              " (1, '1891 she went'),\n",
              " (1, '1891 she'),\n",
              " (1, '1867 the daughter'),\n",
              " (1, '1867 the')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_word_list = sorted([(word_count[i], n_gram) for n_gram, i in vocabulary.items()], reverse=True)\n",
        "\n",
        "sorted_word_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuggxPwVmAMT"
      },
      "source": [
        "### Using nltk to find ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYfl9g4KmAMT",
        "outputId": "aba22ed5-5b9b-4fe4-980b-13aebec3fe2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A bird in hand is worth two in the bush.',\n",
              " 'Good things come to those who wait.',\n",
              " 'These watches cost $1500! ',\n",
              " 'There are other fish in the sea.',\n",
              " 'The ball is in your court.',\n",
              " 'Mr. Smith Goes to Washington ',\n",
              " 'Doogie Howser M.D.']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4rbKb5ymAMT"
      },
      "outputs": [],
      "source": [
        "from nltk import bigrams\n",
        "from nltk import trigrams\n",
        "\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF_zco1YmAMT",
        "outputId": "0fe7ef11-2ef8-443c-e805-854ebe83e2f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A',\n",
              " 'bird',\n",
              " 'in',\n",
              " 'hand',\n",
              " 'is',\n",
              " 'worth',\n",
              " 'two',\n",
              " 'in',\n",
              " 'the',\n",
              " 'bush',\n",
              " '.',\n",
              " 'Good',\n",
              " 'things',\n",
              " 'come',\n",
              " 'to',\n",
              " 'those',\n",
              " 'who',\n",
              " 'wait',\n",
              " '.',\n",
              " 'These',\n",
              " 'watches',\n",
              " 'cost',\n",
              " '$',\n",
              " '1500',\n",
              " '!',\n",
              " 'There',\n",
              " 'are',\n",
              " 'other',\n",
              " 'fish',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sea',\n",
              " '.',\n",
              " 'The',\n",
              " 'ball',\n",
              " 'is',\n",
              " 'in',\n",
              " 'your',\n",
              " 'court',\n",
              " '.',\n",
              " 'Mr.',\n",
              " 'Smith',\n",
              " 'Goes',\n",
              " 'to',\n",
              " 'Washington',\n",
              " 'Doogie',\n",
              " 'Howser',\n",
              " 'M.D',\n",
              " '.']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = word_tokenize(\" \".join(train_text))\n",
        "\n",
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEeNqdTYmAMU",
        "outputId": "b57032c7-8dc5-4296-c5bc-3d2e242aec16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'bird'),\n",
              " ('bird', 'in'),\n",
              " ('in', 'hand'),\n",
              " ('hand', 'is'),\n",
              " ('is', 'worth'),\n",
              " ('worth', 'two'),\n",
              " ('two', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'bush'),\n",
              " ('bush', '.'),\n",
              " ('.', 'Good'),\n",
              " ('Good', 'things'),\n",
              " ('things', 'come'),\n",
              " ('come', 'to'),\n",
              " ('to', 'those'),\n",
              " ('those', 'who'),\n",
              " ('who', 'wait'),\n",
              " ('wait', '.'),\n",
              " ('.', 'These'),\n",
              " ('These', 'watches'),\n",
              " ('watches', 'cost'),\n",
              " ('cost', '$'),\n",
              " ('$', '1500'),\n",
              " ('1500', '!'),\n",
              " ('!', 'There'),\n",
              " ('There', 'are'),\n",
              " ('are', 'other'),\n",
              " ('other', 'fish'),\n",
              " ('fish', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'sea'),\n",
              " ('sea', '.'),\n",
              " ('.', 'The'),\n",
              " ('The', 'ball'),\n",
              " ('ball', 'is'),\n",
              " ('is', 'in'),\n",
              " ('in', 'your'),\n",
              " ('your', 'court'),\n",
              " ('court', '.'),\n",
              " ('.', 'Mr.'),\n",
              " ('Mr.', 'Smith'),\n",
              " ('Smith', 'Goes'),\n",
              " ('Goes', 'to'),\n",
              " ('to', 'Washington'),\n",
              " ('Washington', 'Doogie'),\n",
              " ('Doogie', 'Howser'),\n",
              " ('Howser', 'M.D'),\n",
              " ('M.D', '.')]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_bigrams = bigrams(word_tokens)\n",
        "\n",
        "list(nltk_bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKbrTAWumAMU",
        "outputId": "f6793ea0-d08f-48dd-efab-042d4bc8d52d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'bird', 'in'),\n",
              " ('bird', 'in', 'hand'),\n",
              " ('in', 'hand', 'is'),\n",
              " ('hand', 'is', 'worth'),\n",
              " ('is', 'worth', 'two'),\n",
              " ('worth', 'two', 'in'),\n",
              " ('two', 'in', 'the'),\n",
              " ('in', 'the', 'bush'),\n",
              " ('the', 'bush', '.'),\n",
              " ('bush', '.', 'Good'),\n",
              " ('.', 'Good', 'things'),\n",
              " ('Good', 'things', 'come'),\n",
              " ('things', 'come', 'to'),\n",
              " ('come', 'to', 'those'),\n",
              " ('to', 'those', 'who'),\n",
              " ('those', 'who', 'wait'),\n",
              " ('who', 'wait', '.'),\n",
              " ('wait', '.', 'These'),\n",
              " ('.', 'These', 'watches'),\n",
              " ('These', 'watches', 'cost'),\n",
              " ('watches', 'cost', '$'),\n",
              " ('cost', '$', '1500'),\n",
              " ('$', '1500', '!'),\n",
              " ('1500', '!', 'There'),\n",
              " ('!', 'There', 'are'),\n",
              " ('There', 'are', 'other'),\n",
              " ('are', 'other', 'fish'),\n",
              " ('other', 'fish', 'in'),\n",
              " ('fish', 'in', 'the'),\n",
              " ('in', 'the', 'sea'),\n",
              " ('the', 'sea', '.'),\n",
              " ('sea', '.', 'The'),\n",
              " ('.', 'The', 'ball'),\n",
              " ('The', 'ball', 'is'),\n",
              " ('ball', 'is', 'in'),\n",
              " ('is', 'in', 'your'),\n",
              " ('in', 'your', 'court'),\n",
              " ('your', 'court', '.'),\n",
              " ('court', '.', 'Mr.'),\n",
              " ('.', 'Mr.', 'Smith'),\n",
              " ('Mr.', 'Smith', 'Goes'),\n",
              " ('Smith', 'Goes', 'to'),\n",
              " ('Goes', 'to', 'Washington'),\n",
              " ('to', 'Washington', 'Doogie'),\n",
              " ('Washington', 'Doogie', 'Howser'),\n",
              " ('Doogie', 'Howser', 'M.D'),\n",
              " ('Howser', 'M.D', '.')]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_trigrams = trigrams(word_tokens)\n",
        "\n",
        "list(nltk_trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRcgAEppmAMU",
        "outputId": "c2668e57-0ecb-4890-ad15-dd88a9ce9c52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('A', 'bird', 'in', 'hand', 'is')\n",
            "('bird', 'in', 'hand', 'is', 'worth')\n",
            "('in', 'hand', 'is', 'worth', 'two')\n",
            "('hand', 'is', 'worth', 'two', 'in')\n",
            "('is', 'worth', 'two', 'in', 'the')\n",
            "('worth', 'two', 'in', 'the', 'bush')\n",
            "('two', 'in', 'the', 'bush', '.')\n",
            "('in', 'the', 'bush', '.', 'Good')\n",
            "('the', 'bush', '.', 'Good', 'things')\n",
            "('bush', '.', 'Good', 'things', 'come')\n",
            "('.', 'Good', 'things', 'come', 'to')\n",
            "('Good', 'things', 'come', 'to', 'those')\n",
            "('things', 'come', 'to', 'those', 'who')\n",
            "('come', 'to', 'those', 'who', 'wait')\n",
            "('to', 'those', 'who', 'wait', '.')\n",
            "('those', 'who', 'wait', '.', 'These')\n",
            "('who', 'wait', '.', 'These', 'watches')\n",
            "('wait', '.', 'These', 'watches', 'cost')\n",
            "('.', 'These', 'watches', 'cost', '$')\n",
            "('These', 'watches', 'cost', '$', '1500')\n",
            "('watches', 'cost', '$', '1500', '!')\n",
            "('cost', '$', '1500', '!', 'There')\n",
            "('$', '1500', '!', 'There', 'are')\n",
            "('1500', '!', 'There', 'are', 'other')\n",
            "('!', 'There', 'are', 'other', 'fish')\n",
            "('There', 'are', 'other', 'fish', 'in')\n",
            "('are', 'other', 'fish', 'in', 'the')\n",
            "('other', 'fish', 'in', 'the', 'sea')\n",
            "('fish', 'in', 'the', 'sea', '.')\n",
            "('in', 'the', 'sea', '.', 'The')\n",
            "('the', 'sea', '.', 'The', 'ball')\n",
            "('sea', '.', 'The', 'ball', 'is')\n",
            "('.', 'The', 'ball', 'is', 'in')\n",
            "('The', 'ball', 'is', 'in', 'your')\n",
            "('ball', 'is', 'in', 'your', 'court')\n",
            "('is', 'in', 'your', 'court', '.')\n",
            "('in', 'your', 'court', '.', 'Mr.')\n",
            "('your', 'court', '.', 'Mr.', 'Smith')\n",
            "('court', '.', 'Mr.', 'Smith', 'Goes')\n",
            "('.', 'Mr.', 'Smith', 'Goes', 'to')\n",
            "('Mr.', 'Smith', 'Goes', 'to', 'Washington')\n",
            "('Smith', 'Goes', 'to', 'Washington', 'Doogie')\n",
            "('Goes', 'to', 'Washington', 'Doogie', 'Howser')\n",
            "('to', 'Washington', 'Doogie', 'Howser', 'M.D')\n",
            "('Washington', 'Doogie', 'Howser', 'M.D', '.')\n"
          ]
        }
      ],
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "fivegrams = ngrams(word_tokens, 5)\n",
        "\n",
        "for grams in fivegrams:\n",
        "    print(grams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMivAZQrmAMU"
      },
      "source": [
        "* https://tedboy.github.io/nlps/generated/generated/nltk.BigramAssocMeasures\n",
        "* http://www.nltk.org/_modules/nltk/collocations.html#BigramCollocationFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI088pSemAMV"
      },
      "outputs": [],
      "source": [
        "from nltk.collocations import BigramAssocMeasures\n",
        "from nltk.collocations import BigramCollocationFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1yX5b1GmAMV"
      },
      "outputs": [],
      "source": [
        "word_tokens = word_tokenize(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ss6yI8scmAMV",
        "outputId": "460d1c11-b177-49c0-cf2c-c045a1e0c192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('.', 'The'),\n",
              " ('of', 'the'),\n",
              " ('Nobel', 'Prize'),\n",
              " (',', 'and'),\n",
              " ('The', 'Curies'),\n",
              " ('and', 'she'),\n",
              " ('the', 'Nobel')]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_measures = BigramAssocMeasures()\n",
        "\n",
        "finder = BigramCollocationFinder.from_words(word_tokens)\n",
        "\n",
        "finder.apply_freq_filter(3)\n",
        "\n",
        "matches = finder.nbest(bigram_measures.raw_freq, 15)\n",
        "\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59HubgWzmAMV",
        "outputId": "7ec03e36-f5ec-4ee1-8fa8-fe641b8abd10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('.', 'The'),\n",
              " ('of', 'the'),\n",
              " ('Nobel', 'Prize'),\n",
              " (',', 'and'),\n",
              " ('The', 'Curies'),\n",
              " ('and', 'she'),\n",
              " ('the', 'Nobel'),\n",
              " (',', 'she'),\n",
              " (',', 'the'),\n",
              " ('.', 'In'),\n",
              " ('.', 'Marie'),\n",
              " ('.', 'She'),\n",
              " ('1911', '.'),\n",
              " ('Prize', 'for'),\n",
              " ('announced', 'the')]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_measures = BigramAssocMeasures()\n",
        "\n",
        "finder = BigramCollocationFinder.from_words(word_tokens)\n",
        "\n",
        "finder.apply_freq_filter(2)\n",
        "\n",
        "matches = finder.nbest(bigram_measures.raw_freq, 15)\n",
        "\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1GZi4gxmAMV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glHIW30emAMW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3zqaLIHmAMW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPE2-5gumAMW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6XnYijImAMW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-QnIaArmAMW"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 04-VectorizeText_TfidfTransformer_TfidfVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQKlIOJ4mAMW"
      },
      "source": [
        "<b>TfidfTransformer</b> :\n",
        "\n",
        "* Transform a count matrix to a normalized tf or tf-idf representation\n",
        "* Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBh7cifkmAMX"
      },
      "source": [
        "* A <b>Term Frequency</b> is a count of how many times a word occurs in a given document (synonymous with bag of words).\n",
        "* The <b>Inverse Document Frequency</b> is the the number of times a word occurs in a corpus of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAda4ZzAmAMX"
      },
      "source": [
        "The first step is to create our training and testing document set and computing the term frequency matrix\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrC1qShZmAMX"
      },
      "source": [
        "### Creating a count vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RRTjYOQmAMX"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-se-D6AmAMX"
      },
      "outputs": [],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "frequency_term_matrix = count_vectorizer.fit_transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "775z03_TmAMY",
        "outputId": "853b8180-3551-43dd-f931-0cc995ade837"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx3H6otwmAMZ",
        "outputId": "8eb60048-1b82-4cb4-f543-4e0c9281a805"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_term_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RMJL20gmAMZ",
        "outputId": "569720ef-2bfa-468f-a4d9-fd806b199bd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_term_matrix.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJecOuKdmAMa"
      },
      "source": [
        "### Building the tf-idf matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI5TDQuwmAMb"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq59cjiSmAMb",
        "outputId": "2e1e3b6a-0f25-4522-af2d-9001a3230562"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector1 = tfidf_transformer.fit_transform(frequency_term_matrix)\n",
        "\n",
        "tfidf_vector1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw_qaXKwmAMc",
        "outputId": "c70192de-7662-438f-f436-88fe64a7325e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.34908308, 0.34908308,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34908308, 0.        , 0.49536976,\n",
              "        0.28976893, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24768488, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38665001, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.38665001, 0.38665001,\n",
              "        0.32095271, 0.        , 0.38665001, 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.40801493,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28949879,\n",
              "        0.        , 0.        , 0.40801493, 0.40801493, 0.        ,\n",
              "        0.28949879, 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.3274243 ,\n",
              "        0.38305686, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3274243 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46180424, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46180424, 0.        , 0.        , 0.46180424,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38333718, 0.        , 0.        , 0.46180424, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector1.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vinE4YUNmAMd",
        "outputId": "84996fc7-ebcd-404a-a840-b00ef5a0b5f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.34908308 0.34908308 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.34908308 0.         0.49536976 0.28976893 0.         0.\n",
            "  0.         0.         0.24768488 0.         0.         0.\n",
            "  0.         0.         0.34908308 0.         0.         0.\n",
            "  0.         0.34908308 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.38665001\n",
            "  0.         0.         0.         0.         0.         0.38665001\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.38665001\n",
            "  0.38665001 0.32095271 0.         0.38665001 0.         0.\n",
            "  0.38665001 0.         0.        ]\n",
            " [0.5        0.         0.         0.         0.         0.\n",
            "  0.5        0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.5        0.\n",
            "  0.         0.         0.         0.         0.         0.5\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.40801493 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.40801493 0.         0.\n",
            "  0.         0.         0.28949879 0.         0.         0.40801493\n",
            "  0.40801493 0.         0.28949879 0.40801493 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.46146654 0.         0.         0.\n",
            "  0.         0.46146654 0.         0.         0.         0.\n",
            "  0.         0.         0.3274243  0.38305686 0.         0.\n",
            "  0.         0.         0.3274243  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.46146654]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.46180424 0.\n",
            "  0.         0.         0.         0.         0.46180424 0.\n",
            "  0.         0.46180424 0.         0.         0.         0.\n",
            "  0.         0.38333718 0.         0.         0.46180424 0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.70710678 0.         0.         0.\n",
            "  0.         0.70710678 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector1.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkhAxMVamAMe"
      },
      "source": [
        "## TfidfVectorizer = CountVectorizer + TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4GvFfeFmAMe"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P73XTmremAMf",
        "outputId": "e9cdc488-d5ea-4c53-d2e1-28f76e70af05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 3,\n",
              " 'in': 14,\n",
              " 'hand': 12,\n",
              " 'is': 15,\n",
              " 'worth': 31,\n",
              " 'two': 26,\n",
              " 'the': 20,\n",
              " 'bush': 4,\n",
              " 'good': 11,\n",
              " 'things': 23,\n",
              " 'come': 5,\n",
              " 'to': 25,\n",
              " 'those': 24,\n",
              " 'who': 30,\n",
              " 'wait': 27,\n",
              " 'these': 22,\n",
              " 'watches': 29,\n",
              " 'cost': 6,\n",
              " '1500': 0,\n",
              " 'there': 21,\n",
              " 'are': 1,\n",
              " 'other': 17,\n",
              " 'fish': 9,\n",
              " 'sea': 18,\n",
              " 'ball': 2,\n",
              " 'your': 32,\n",
              " 'court': 7,\n",
              " 'mr': 16,\n",
              " 'smith': 19,\n",
              " 'goes': 10,\n",
              " 'washington': 28,\n",
              " 'doogie': 8,\n",
              " 'howser': 13}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2 = tfidf_vectorizer.fit_transform(train_text)\n",
        "\n",
        "tfidf_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-yI2W-ImAMg",
        "outputId": "2332bbc3-ff3b-4df3-a16f-6e642a44d34d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXRgQsafmAMg",
        "outputId": "5f75a42c-64e2-4dc7-d4cb-b5d0f768e3cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.38629436, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436, 2.38629436, 1.69314718,\n",
              "       1.98082925, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       1.69314718, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       1.98082925, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer.idf_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lsvr8cgmAMh",
        "outputId": "82c5cf23-3ece-4c6c-db5b-37bd37c65614"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'1500': 2.386294361119891,\n",
              " 'are': 2.386294361119891,\n",
              " 'ball': 2.386294361119891,\n",
              " 'bird': 2.386294361119891,\n",
              " 'bush': 2.386294361119891,\n",
              " 'come': 2.386294361119891,\n",
              " 'cost': 2.386294361119891,\n",
              " 'court': 2.386294361119891,\n",
              " 'doogie': 2.386294361119891,\n",
              " 'fish': 2.386294361119891,\n",
              " 'goes': 2.386294361119891,\n",
              " 'good': 2.386294361119891,\n",
              " 'hand': 2.386294361119891,\n",
              " 'howser': 2.386294361119891,\n",
              " 'in': 1.6931471805599454,\n",
              " 'is': 1.9808292530117262,\n",
              " 'mr': 2.386294361119891,\n",
              " 'other': 2.386294361119891,\n",
              " 'sea': 2.386294361119891,\n",
              " 'smith': 2.386294361119891,\n",
              " 'the': 1.6931471805599454,\n",
              " 'there': 2.386294361119891,\n",
              " 'these': 2.386294361119891,\n",
              " 'things': 2.386294361119891,\n",
              " 'those': 2.386294361119891,\n",
              " 'to': 1.9808292530117262,\n",
              " 'two': 2.386294361119891,\n",
              " 'wait': 2.386294361119891,\n",
              " 'washington': 2.386294361119891,\n",
              " 'watches': 2.386294361119891,\n",
              " 'who': 2.386294361119891,\n",
              " 'worth': 2.386294361119891,\n",
              " 'your': 2.386294361119891}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnD6929cmAMi"
      },
      "source": [
        "### Final scorings of each word from the other words in the vocabulary.\n",
        "* The scores are normalized to values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxSePjAmmAMi",
        "outputId": "8fe296aa-9d37-4a38-bcdb-94cdd3aaf2b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.34908308, 0.34908308,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34908308, 0.        , 0.49536976,\n",
              "        0.28976893, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24768488, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38665001, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.38665001, 0.38665001,\n",
              "        0.32095271, 0.        , 0.38665001, 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.40801493,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28949879,\n",
              "        0.        , 0.        , 0.40801493, 0.40801493, 0.        ,\n",
              "        0.28949879, 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.3274243 ,\n",
              "        0.38305686, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3274243 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46180424, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46180424, 0.        , 0.        , 0.46180424,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38333718, 0.        , 0.        , 0.46180424, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X54F7lURmAMi",
        "outputId": "3bc2f56d-090b-4456-b8e5-f54d1578362f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3)\t0.3490830767264469\n",
            "  (0, 14)\t0.49536975552604884\n",
            "  (0, 12)\t0.3490830767264469\n",
            "  (0, 15)\t0.2897689326921819\n",
            "  (0, 31)\t0.3490830767264469\n",
            "  (0, 26)\t0.3490830767264469\n",
            "  (0, 20)\t0.24768487776302442\n",
            "  (0, 4)\t0.3490830767264469\n",
            "  (1, 11)\t0.386650005027498\n",
            "  (1, 23)\t0.386650005027498\n",
            "  (1, 5)\t0.386650005027498\n",
            "  (1, 25)\t0.32095270940344806\n",
            "  (1, 24)\t0.386650005027498\n",
            "  (1, 30)\t0.386650005027498\n",
            "  (1, 27)\t0.386650005027498\n",
            "  (2, 22)\t0.5\n",
            "  (2, 29)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (2, 0)\t0.5\n",
            "  (3, 14)\t0.2894987873064995\n",
            "  (3, 20)\t0.2894987873064995\n",
            "  (3, 21)\t0.40801492725049476\n",
            "  (3, 1)\t0.40801492725049476\n",
            "  (3, 17)\t0.40801492725049476\n",
            "  (3, 9)\t0.40801492725049476\n",
            "  (3, 18)\t0.40801492725049476\n",
            "  (4, 14)\t0.3274243027464032\n",
            "  (4, 15)\t0.38305685676572565\n",
            "  (4, 20)\t0.3274243027464032\n",
            "  (4, 2)\t0.4614665377636916\n",
            "  (4, 32)\t0.4614665377636916\n",
            "  (4, 7)\t0.4614665377636916\n",
            "  (5, 25)\t0.38333717539523177\n",
            "  (5, 16)\t0.4618042361109319\n",
            "  (5, 19)\t0.4618042361109319\n",
            "  (5, 10)\t0.4618042361109319\n",
            "  (5, 28)\t0.4618042361109319\n",
            "  (6, 8)\t0.7071067811865476\n",
            "  (6, 13)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB7PkSA4mAMj",
        "outputId": "2cfea365-1fa1-4a50-f989-804b60976f4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 31)\t0.34908307672644684\n",
            "  (0, 26)\t0.34908307672644684\n",
            "  (0, 20)\t0.2476848777630244\n",
            "  (0, 15)\t0.2897689326921819\n",
            "  (0, 14)\t0.4953697555260488\n",
            "  (0, 12)\t0.34908307672644684\n",
            "  (0, 4)\t0.34908307672644684\n",
            "  (0, 3)\t0.34908307672644684\n",
            "  (1, 30)\t0.386650005027498\n",
            "  (1, 27)\t0.386650005027498\n",
            "  (1, 25)\t0.32095270940344806\n",
            "  (1, 24)\t0.386650005027498\n",
            "  (1, 23)\t0.386650005027498\n",
            "  (1, 11)\t0.386650005027498\n",
            "  (1, 5)\t0.386650005027498\n",
            "  (2, 29)\t0.5\n",
            "  (2, 22)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (2, 0)\t0.5\n",
            "  (3, 21)\t0.40801492725049476\n",
            "  (3, 20)\t0.2894987873064995\n",
            "  (3, 18)\t0.40801492725049476\n",
            "  (3, 17)\t0.40801492725049476\n",
            "  (3, 14)\t0.2894987873064995\n",
            "  (3, 9)\t0.40801492725049476\n",
            "  (3, 1)\t0.40801492725049476\n",
            "  (4, 32)\t0.4614665377636916\n",
            "  (4, 20)\t0.3274243027464032\n",
            "  (4, 15)\t0.38305685676572565\n",
            "  (4, 14)\t0.3274243027464032\n",
            "  (4, 7)\t0.4614665377636916\n",
            "  (4, 2)\t0.4614665377636916\n",
            "  (5, 28)\t0.4618042361109319\n",
            "  (5, 25)\t0.38333717539523177\n",
            "  (5, 19)\t0.4618042361109319\n",
            "  (5, 16)\t0.4618042361109319\n",
            "  (5, 10)\t0.4618042361109319\n",
            "  (6, 13)\t0.7071067811865476\n",
            "  (6, 8)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zdKqyyDmAMj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1BrXpfumAMk"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 01-TokenizingTextIntoSentencesAndWords</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDhwxUG9mAMl"
      },
      "source": [
        "## Tokenize text into words and sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfUKN3aImAMl",
        "outputId": "e4f5a678-5f27-49e4-a428-b98605a765df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.16.1\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "print(numpy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpM2rI17mAMm",
        "outputId": "ca7e6726-f37e-4e15-d6af-ee50586e14f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.4\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "print(nltk.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFW4B19jmAMm"
      },
      "source": [
        "#### Uses NLTK's recommended sentence tokenizer, the PunktSentenceTokenizer\n",
        "#### Uses NLTK's recommended word tokenizer, the TreebankWordTokenizer and the PunktSentencetokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKwu6qLmmAMn"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1oQju9wmAMn",
        "outputId": "a28cc12f-f370-4a93-9b8c-1789d51a69aa"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-27d5e78d663c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Does this tokenizer work? These are two different sentences'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = sent_tokenize('Does this tokenizer work? These are two different sentences')\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvkRqoaBmAMo",
        "outputId": "5a39fe91-1735-45d7-bd02-af30236cda4b"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-42e4b9771e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Does this tokenizer work?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     return [\n\u001b[1;32m    145\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/loonycorn/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize('Does this tokenizer work?')\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjn4hwrVmAMo"
      },
      "source": [
        "#### Punkt tokenizer\n",
        "\n",
        "https://www.nltk.org/_modules/nltk/tokenize/punkt.html\n",
        "http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt\n",
        "\n",
        "A sentence tokenizer which uses an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences; and then uses that model to find sentence boundaries. This approach has been shown to work well for many European languages.\n",
        "\n",
        "It must be trained on a large collection of plaintext in the target language before it can be used.\n",
        "\n",
        "The NLTK data package includes a pre-trained Punkt tokenizer for English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkAIb7demAMp",
        "outputId": "c92fd26a-e977-4b37-ba8d-2f88c4fb9703"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMqHn2vEmAMp",
        "outputId": "59d2e1f8-b0d7-4181-e7c6-c08e6873b04d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does this tokenizer work?', 'These are two different sentences']\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = sent_tokenize('Does this tokenizer work? These are two different sentences')\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfMRRkaNmAMq",
        "outputId": "10889922-5eff-4456-ad4a-4890f1b903e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Does', 'this', 'tokenizer', 'work', '?']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize('Does this tokenizer work?')\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJLPiG70mAMq",
        "outputId": "e4d57458-0d44-42db-e58c-9db7c7bbe339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.', 'Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.', 'These', 'watches', 'cost', '$', '1500', '!', 'The', 'ball', 'is', 'in', 'your', 'court', '.', 'Mr.', 'Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D', '.']\n"
          ]
        }
      ],
      "source": [
        "text = \"A bird in hand is worth two in the bush. \" +\\\n",
        "       \"Good things come to those who wait. \" +\\\n",
        "       \"These watches cost $1500! \" +\\\n",
        "       \"The ball is in your court. \" +\\\n",
        "       \"Mr. Smith Goes to Washington \" +\\\n",
        "       \"Doogie Howser M.D.\"\n",
        "\n",
        "word_tokens = word_tokenize(text, language='english')\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKnFr-0UmAMr",
        "outputId": "6318b48c-0931-4718-aae4-85cf7eca4b16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93Fg1QrAmAMr",
        "outputId": "17367428-e978-426e-e3bb-81d09b7cd86c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hand', 'is', 'worth', 'two', 'in']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens[3:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zdCuJfSmAMr"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize.punkt import PunktSentenceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMqSSLuImAMs"
      },
      "outputs": [],
      "source": [
        "pst = PunktSentenceTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUYz6kUnmAMs",
        "outputId": "990bb620-72f2-4a4a-ff11-687ccf983f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A bird in hand is worth two in the bush.', 'Good things come to those who wait.', 'These watches cost $1500!', 'The ball is in your court.', 'Mr.', 'Smith Goes to Washington Doogie Howser M.D.']\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = pst.tokenize(text)\n",
        "\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9pMpX1WmAMt",
        "outputId": "d8a1300a-6d5f-45c4-b6df-675029ea2110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 40), (41, 76), (77, 102), (103, 129), (130, 133), (134, 177)]\n"
          ]
        }
      ],
      "source": [
        "span_tokens = pst.span_tokenize(text)\n",
        "\n",
        "print(list(span_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffM4UFJCmAMu",
        "outputId": "17777072-012c-4344-d17f-a3e071b7e9eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.'],\n",
              " ['Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.'],\n",
              " ['These', 'watches', 'cost', '$', '1500', '!'],\n",
              " ['The', 'ball', 'is', 'in', 'your', 'court', '.'],\n",
              " ['Mr.'],\n",
              " ['Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D', '.']]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences = pst.sentences_from_tokens(word_tokens)\n",
        "\n",
        "list(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9fv9jBZmAMu"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3a-3fPPmAMv"
      },
      "outputs": [],
      "source": [
        "wt = WhitespaceTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K5oUzRLmAMv",
        "outputId": "036dc03f-e8d2-4d66-cdfe-40ac67dd72ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush.', 'Good', 'things', 'come', 'to', 'those', 'who', 'wait.', 'These', 'watches', 'cost', '$1500!', 'The', 'ball', 'is', 'in', 'your', 'court.', 'Mr.', 'Smith', 'Goes', 'to', 'Washington', 'Doogie', 'Howser', 'M.D.']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = wt.tokenize(text)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_enS1_qmAMw"
      },
      "source": [
        "### Reading Local Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsva5NpNmAMw",
        "outputId": "6325ab21-6bb6-452a-e7bb-c410afe1b6e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv6rbe8FmAMx",
        "outputId": "919f6a16-aa41-403a-fd3d-bfc7791dfa29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie', 'Curie', 'was', 'a', 'Polish-born', 'physicist', 'and', 'chemist', 'and', 'one', 'of', 'the', 'most', 'famous', 'scientists', 'of', 'her', 'time', '.', 'Together', 'with', 'her', 'husband', 'Pierre', ',', 'she', 'was', 'awarded', 'the', 'Nobel', 'Prize', 'in', '1903', ',', 'and', 'she', 'went', 'on', 'to', 'win', 'another', 'in', '1911', '.', 'Marie', 'Sklodowska', 'was', 'born', 'in', 'Warsaw', 'on', '7', 'November', '1867', ',', 'the', 'daughter', 'of', 'a', 'teacher', '.', 'In', '1891', ',', 'she', 'went', 'to', 'Paris', 'to', 'study', 'physics', 'and', 'mathematics', 'at', 'the', 'Sorbonne', 'where', 'she', 'met', 'Pierre', 'Curie', ',', 'professor', 'of', 'the', 'School', 'of', 'Physics', '.', 'They', 'were', 'married', 'in', '1895', '.', 'The', 'Curies', 'worked', 'together', 'investigating', 'radioactivity', ',', 'building', 'on', 'the', 'work', 'of', 'the', 'German', 'physicist', 'Roentgen', 'and', 'the', 'French', 'physicist', 'Becquerel', '.', 'In', 'July', '1898', ',', 'the', 'Curies', 'announced', 'the', 'discovery', 'of', 'a', 'new', 'chemical', 'element', ',', 'polonium', '.', 'At', 'the', 'end', 'of', 'the', 'year', ',', 'they', 'announced', 'the', 'discovery', 'of', 'another', ',', 'radium', '.', 'The', 'Curies', ',', 'along', 'with', 'Becquerel', ',', 'were', 'awarded', 'the', 'Nobel', 'Prize', 'for', 'Physics', 'in', '1903', '.', 'Pierre', \"'s\", 'life', 'was', 'cut', 'short', 'in', '1906', 'when', 'he', 'was', 'knocked', 'down', 'and', 'killed', 'by', 'a', 'carriage', '.', 'Marie', 'took', 'over', 'his', 'teaching', 'post', ',', 'becoming', 'the', 'first', 'woman', 'to', 'teach', 'at', 'the', 'Sorbonne', ',', 'and', 'devoted', 'herself', 'to', 'continuing', 'the', 'work', 'that', 'they', 'had', 'begun', 'together', '.', 'She', 'received', 'a', 'second', 'Nobel', 'Prize', ',', 'for', 'Chemistry', ',', 'in', '1911', '.', 'The', 'Curie', \"'s\", 'research', 'was', 'crucial', 'in', 'the', 'development', 'of', 'x-rays', 'in', 'surgery', '.', 'During', 'World', 'War', 'One', 'Curie', 'helped', 'to', 'equip', 'ambulances', 'with', 'x-ray', 'equipment', ',', 'which', 'she', 'herself', 'drove', 'to', 'the', 'front', 'lines', '.', 'The', 'International', 'Red', 'Cross', 'made', 'her', 'head', 'of', 'its', 'radiological', 'service', 'and', 'she', 'held', 'training', 'courses', 'for', 'medical', 'orderlies', 'and', 'doctors', 'in', 'the', 'new', 'techniques', '.', 'Despite', 'her', 'success', ',', 'Marie', 'continued', 'to', 'face', 'great', 'opposition', 'from', 'male', 'scientists', 'in', 'France', ',', 'and', 'she', 'never', 'received', 'significant', 'financial', 'benefits', 'from', 'her', 'work', '.', 'By', 'the', 'late', '1920s', 'her', 'health', 'was', 'beginning', 'to', 'deteriorate', '.', 'She', 'died', 'on', '4', 'July', '1934', 'from', 'leukaemia', ',', 'caused', 'by', 'exposure', 'to', 'high-energy', 'radiation', 'from', 'her', 'research', '.', 'The', 'Curies', \"'\", 'eldest', 'daughter', 'Irene', 'was', 'herself', 'a', 'scientist', 'and', 'winner', 'of', 'the', 'Nobel', 'Prize', 'for', 'Chemistry', '.']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize(file_contents)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S62j6NVOmAMx"
      },
      "source": [
        "### Frequency distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEXlPDdxmAMy"
      },
      "outputs": [],
      "source": [
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwjLWPvvmAMy",
        "outputId": "5d13d18d-3a99-4d31-f6cd-d7d2a592f721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FreqDist with 182 samples and 367 outcomes>\n"
          ]
        }
      ],
      "source": [
        "freq_dist = FreqDist(word_tokens)\n",
        "\n",
        "print(freq_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN5DIT0fmAMz",
        "outputId": "5dda17f0-4585-42e1-bce7-bb6ba1107595"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 22),\n",
              " (',', 20),\n",
              " ('.', 19),\n",
              " ('of', 12),\n",
              " ('and', 11),\n",
              " ('in', 11),\n",
              " ('to', 10),\n",
              " ('was', 8),\n",
              " ('her', 7),\n",
              " ('she', 7),\n",
              " ('a', 6),\n",
              " ('The', 5),\n",
              " ('Marie', 4),\n",
              " ('Curie', 4),\n",
              " ('Nobel', 4),\n",
              " ('Prize', 4),\n",
              " ('on', 4),\n",
              " ('Curies', 4),\n",
              " ('for', 4),\n",
              " ('from', 4)]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4GuDHTcmAMz"
      },
      "source": [
        "Return the frequency of a given sample. The frequency of a sample is defined as the count of that sample divided by the total number of sample outcomes that have been recorded by this FreqDist. The count of a sample is defined as the number of times that sample outcome was recorded by this FreqDist. Frequencies are always real numbers in the range [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZpvSPWYmAMz",
        "outputId": "655e68e1-cf4d-414d-fb55-1500b3b569fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.05994550408719346"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.freq('the')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUQFwlJ2mAM0",
        "outputId": "6f20f11d-6894-4dcf-c375-35b7664b08f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0027247956403269754"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.freq('exposure')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7cj20phmAM0",
        "outputId": "846e41f4-667f-42cb-fe15-749809c01d67"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "freq_dist.plot(20, cumulative=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISKg6fylmAM1",
        "outputId": "e18f40f4-d01c-46fe-c3dd-25303a745763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['marie', 'curie', 'was', 'a', 'polish-born', 'physicist', 'and', 'chemist', 'and', 'one', 'of', 'the', 'most', 'famous', 'scientists', 'of', 'her', 'time.', 'together', 'with', 'her', 'husband', 'pierre,', 'she', 'was', 'awarded', 'the', 'nobel', 'prize', 'in', '1903,', 'and', 'she', 'went', 'on', 'to', 'win', 'another', 'in', '1911.', 'marie', 'sklodowska', 'was', 'born', 'in', 'warsaw', 'on', '7', 'november', '1867,', 'the', 'daughter', 'of', 'a', 'teacher.', 'in', '1891,', 'she', 'went', 'to', 'paris', 'to', 'study', 'physics', 'and', 'mathematics', 'at', 'the', 'sorbonne', 'where', 'she', 'met', 'pierre', 'curie,', 'professor', 'of', 'the', 'school', 'of', 'physics.', 'they', 'were', 'married', 'in', '1895.', 'the', 'curies', 'worked', 'together', 'investigating', 'radioactivity,', 'building', 'on', 'the', 'work', 'of', 'the', 'german', 'physicist', 'roentgen', 'and', 'the', 'french', 'physicist', 'becquerel.', 'in', 'july', '1898,', 'the', 'curies', 'announced', 'the', 'discovery', 'of', 'a', 'new', 'chemical', 'element,', 'polonium.', 'at', 'the', 'end', 'of', 'the', 'year,', 'they', 'announced', 'the', 'discovery', 'of', 'another,', 'radium.', 'the', 'curies,', 'along', 'with', 'becquerel,', 'were', 'awarded', 'the', 'nobel', 'prize', 'for', 'physics', 'in', '1903.', \"pierre's\", 'life', 'was', 'cut', 'short', 'in', '1906', 'when', 'he', 'was', 'knocked', 'down', 'and', 'killed', 'by', 'a', 'carriage.', 'marie', 'took', 'over', 'his', 'teaching', 'post,', 'becoming', 'the', 'first', 'woman', 'to', 'teach', 'at', 'the', 'sorbonne,', 'and', 'devoted', 'herself', 'to', 'continuing', 'the', 'work', 'that', 'they', 'had', 'begun', 'together.', 'she', 'received', 'a', 'second', 'nobel', 'prize,', 'for', 'chemistry,', 'in', '1911.', 'the', \"curie's\", 'research', 'was', 'crucial', 'in', 'the', 'development', 'of', 'x-rays', 'in', 'surgery.', 'during', 'world', 'war', 'one', 'curie', 'helped', 'to', 'equip', 'ambulances', 'with', 'x-ray', 'equipment,', 'which', 'she', 'herself', 'drove', 'to', 'the', 'front', 'lines.', 'the', 'international', 'red', 'cross', 'made', 'her', 'head', 'of', 'its', 'radiological', 'service', 'and', 'she', 'held', 'training', 'courses', 'for', 'medical', 'orderlies', 'and', 'doctors', 'in', 'the', 'new', 'techniques.', 'despite', 'her', 'success,', 'marie', 'continued', 'to', 'face', 'great', 'opposition', 'from', 'male', 'scientists', 'in', 'france,', 'and', 'she', 'never', 'received', 'significant', 'financial', 'benefits', 'from', 'her', 'work.', 'by', 'the', 'late', '1920s', 'her', 'health', 'was', 'beginning', 'to', 'deteriorate.', 'she', 'died', 'on', '4', 'july', '1934', 'from', 'leukaemia,', 'caused', 'by', 'exposure', 'to', 'high-energy', 'radiation', 'from', 'her', 'research.', 'the', \"curies'\", 'eldest', 'daughter', 'irene', 'was', 'herself', 'a', 'scientist', 'and', 'winner', 'of', 'the', 'nobel', 'prize', 'for', 'chemistry.']\n"
          ]
        }
      ],
      "source": [
        "file_contents = file_contents.lower()\n",
        "\n",
        "word_tokens = wt.tokenize(file_contents)\n",
        "\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsOl0bslmAM2",
        "outputId": "b2194eac-2193-4567-f45f-d72ff5578cd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK0BB1uImAM2",
        "outputId": "74f5e9e2-1981-42fe-f7ea-659cb3a18fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'an', 'should', \"needn't\", 'o', 'ours', 'yourselves', 'am', 't', 'd', 'our', 'yourself', 'himself', 'wasn', 'above', 'you', 'me', 'did', \"hasn't\", 'shan', 'about', 'wouldn', 'shouldn', 'because', 'myself', 'where', 'hasn', 'hadn', 'own', 'hers', 'at', \"mightn't\", 'now', 'with', 'how', 'some', 'or', 'had', 'having', 'aren', 'm', \"shouldn't\", 'was', 'don', 'same', \"didn't\", 'against', 'why', 'y', 'any', 'do', 'being', 'll', 'up', 'doesn', 'which', 'again', 'as', 'in', 'mightn', \"you'll\", \"that'll\", 'can', 'for', 'haven', 's', 'him', 'ain', 'from', 'then', 'once', 'that', \"you're\", 'such', 'does', '.', 'these', 'be', 'only', 'just', 'will', 'into', 'she', \"aren't\", 'and', 'they', 'isn', 'been', 'until', 'theirs', \"don't\", \"couldn't\", 'we', 'ourselves', 'under', 'is', 'by', 'what', \"hadn't\", \"weren't\", 'too', 'ma', 'needn', 'those', 'are', 'more', 'there', 'to', 'between', 'herself', 'has', 'a', 'the', 'yours', 'who', 'than', 'not', 'of', 'nor', \"isn't\", 'when', 'whom', \"it's\", 'i', 'my', 'were', 'mustn', 'doing', 'down', \"won't\", 'all', 'have', \"you'd\", 'his', 'other', 'but', 'if', 'very', 'off', 'before', 'both', 'each', 'didn', 'further', 'no', 'most', \"doesn't\", 'couldn', 'them', 'through', 'weren', 'won', \"wouldn't\", 'The', 're', \"wasn't\", 'few', 'here', 'so', ',', 'its', 'their', 'below', \"shan't\", 'out', \"mustn't\", 'it', 'over', 'itself', 'while', \"you've\", 'themselves', 'after', 'your', 'her', \"should've\", \"haven't\", 'this', 'on', 've', \"she's\", 'he', 'during'}\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(['.', ',', 'The'])\n",
        "\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDUvlTHimAM3",
        "outputId": "1f69117a-e086-4898-afe4-1de554e8fc83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['marie', 'curie', 'polish-born', 'physicist', 'chemist', 'one', 'famous', 'scientists', 'time.', 'together', 'husband', 'pierre,', 'awarded', 'nobel', 'prize', '1903,', 'went', 'win', 'another', '1911.', 'marie', 'sklodowska', 'born', 'warsaw', '7', 'november', '1867,', 'daughter', 'teacher.', '1891,', 'went', 'paris', 'study', 'physics', 'mathematics', 'sorbonne', 'met', 'pierre', 'curie,', 'professor', 'school', 'physics.', 'married', '1895.', 'curies', 'worked', 'together', 'investigating', 'radioactivity,', 'building', 'work', 'german', 'physicist', 'roentgen', 'french', 'physicist', 'becquerel.', 'july', '1898,', 'curies', 'announced', 'discovery', 'new', 'chemical', 'element,', 'polonium.', 'end', 'year,', 'announced', 'discovery', 'another,', 'radium.', 'curies,', 'along', 'becquerel,', 'awarded', 'nobel', 'prize', 'physics', '1903.', \"pierre's\", 'life', 'cut', 'short', '1906', 'knocked', 'killed', 'carriage.', 'marie', 'took', 'teaching', 'post,', 'becoming', 'first', 'woman', 'teach', 'sorbonne,', 'devoted', 'continuing', 'work', 'begun', 'together.', 'received', 'second', 'nobel', 'prize,', 'chemistry,', '1911.', \"curie's\", 'research', 'crucial', 'development', 'x-rays', 'surgery.', 'world', 'war', 'one', 'curie', 'helped', 'equip', 'ambulances', 'x-ray', 'equipment,', 'drove', 'front', 'lines.', 'international', 'red', 'cross', 'made', 'head', 'radiological', 'service', 'held', 'training', 'courses', 'medical', 'orderlies', 'doctors', 'new', 'techniques.', 'despite', 'success,', 'marie', 'continued', 'face', 'great', 'opposition', 'male', 'scientists', 'france,', 'never', 'received', 'significant', 'financial', 'benefits', 'work.', 'late', '1920s', 'health', 'beginning', 'deteriorate.', 'died', '4', 'july', '1934', 'leukaemia,', 'caused', 'exposure', 'high-energy', 'radiation', 'research.', \"curies'\", 'eldest', 'daughter', 'irene', 'scientist', 'winner', 'nobel', 'prize', 'chemistry.']\n"
          ]
        }
      ],
      "source": [
        "filtered_words = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_words.append(w)\n",
        "\n",
        "print(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_7PNMirmAM4"
      },
      "outputs": [],
      "source": [
        "freq_dist = FreqDist(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2i-0mY9dmAM4",
        "outputId": "a60a0f87-fab8-4eec-d80b-02a7637e180f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('marie', 4),\n",
              " ('nobel', 4),\n",
              " ('physicist', 3),\n",
              " ('prize', 3),\n",
              " ('curie', 2),\n",
              " ('one', 2),\n",
              " ('scientists', 2),\n",
              " ('together', 2),\n",
              " ('awarded', 2),\n",
              " ('went', 2),\n",
              " ('1911.', 2),\n",
              " ('daughter', 2),\n",
              " ('physics', 2),\n",
              " ('curies', 2),\n",
              " ('work', 2),\n",
              " ('july', 2),\n",
              " ('announced', 2),\n",
              " ('discovery', 2),\n",
              " ('new', 2),\n",
              " ('received', 2)]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_dist.most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMbLLAeNmAM5",
        "outputId": "85997342-6441-411a-8c6d-f7f9f855ae55"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "freq_dist.plot(20, cumulative=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE7VmhE4mAM5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23ksz3zUmAM6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNsO46eHmAM6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpEYiPiWmAM6"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 02-VectorizeTextAsABagOfWords_CountVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaGkgJoumAM6"
      },
      "source": [
        "## Vectorize text as a bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzrkKW1BmAM7",
        "outputId": "eacc4455-8760-49e3-ca2c-95c452135e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.20.3\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dJbnuFpmAM7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MeG5PODmAM8"
      },
      "outputs": [],
      "source": [
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]\n",
        "\n",
        "count_vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Feyi5M9mAM8",
        "outputId": "0da7276c-e9cf-49e0-b902-429e8c1dd939"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.fit(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl88Faz9mAM9",
        "outputId": "9f8e70d1-8e11-4c03-abeb-3359b3f38fa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1500',\n",
              " 'are',\n",
              " 'ball',\n",
              " 'bird',\n",
              " 'bush',\n",
              " 'come',\n",
              " 'cost',\n",
              " 'court',\n",
              " 'doogie',\n",
              " 'fish',\n",
              " 'goes',\n",
              " 'good',\n",
              " 'hand',\n",
              " 'howser',\n",
              " 'in',\n",
              " 'is',\n",
              " 'mr',\n",
              " 'other',\n",
              " 'sea',\n",
              " 'smith',\n",
              " 'the',\n",
              " 'there',\n",
              " 'these',\n",
              " 'things',\n",
              " 'those',\n",
              " 'to',\n",
              " 'two',\n",
              " 'wait',\n",
              " 'washington',\n",
              " 'watches',\n",
              " 'who',\n",
              " 'worth',\n",
              " 'your']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3vzkllMmANC"
      },
      "outputs": [],
      "source": [
        "count_vectorizer.get_stop_words()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaky7byUmAND",
        "outputId": "4df65440-ea40-4d22-b879-41c9c7565333"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 3,\n",
              " 'in': 14,\n",
              " 'hand': 12,\n",
              " 'is': 15,\n",
              " 'worth': 31,\n",
              " 'two': 26,\n",
              " 'the': 20,\n",
              " 'bush': 4,\n",
              " 'good': 11,\n",
              " 'things': 23,\n",
              " 'come': 5,\n",
              " 'to': 25,\n",
              " 'those': 24,\n",
              " 'who': 30,\n",
              " 'wait': 27,\n",
              " 'these': 22,\n",
              " 'watches': 29,\n",
              " 'cost': 6,\n",
              " '1500': 0,\n",
              " 'there': 21,\n",
              " 'are': 1,\n",
              " 'other': 17,\n",
              " 'fish': 9,\n",
              " 'sea': 18,\n",
              " 'ball': 2,\n",
              " 'your': 32,\n",
              " 'court': 7,\n",
              " 'mr': 16,\n",
              " 'smith': 19,\n",
              " 'goes': 10,\n",
              " 'washington': 28,\n",
              " 'doogie': 8,\n",
              " 'howser': 13}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdpfqmrNmANE",
        "outputId": "28b9771f-3bd7-4b15-e27d-a233afd8c8fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_.get('things')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QPrArltmANE",
        "outputId": "17aa8324-67d9-4ca7-9341-2fd4328f2ae0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A bird in hand is worth two in the bush.',\n",
              " 'Good things come to those who wait.',\n",
              " 'These watches cost $1500! ',\n",
              " 'There are other fish in the sea.',\n",
              " 'The ball is in your court.',\n",
              " 'Mr. Smith Goes to Washington ',\n",
              " 'Doogie Howser M.D.']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRos86EImANF"
      },
      "outputs": [],
      "source": [
        "transformed_vector = count_vectorizer.transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Abq2d59umANG",
        "outputId": "bccadaf5-9035-4ba9-d713-ce96e5871521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 33)\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAnNPtOYmANG",
        "outputId": "4bea56ca-6b6e-4a0e-b2d7-9f1ad7d52352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 1 0 0 0 0 0 0 0 1 0 2 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYerBn1QmANH",
        "outputId": "3502fbf5-c81f-427c-b08b-23c12376e959"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_text = [\"Every cloud has a silver lining.\"]\n",
        "\n",
        "count_vectorizer.transform(test_text).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_MdH79PmANH",
        "outputId": "6da36238-c2db-4990-8875-1753100422f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.fit(train_text + test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBKehdWMmANI",
        "outputId": "840f78a0-73e2-48fc-8f18-a042398b3c18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bird': 3, 'in': 17, 'hand': 14, 'is': 18, 'worth': 36, 'two': 31, 'the': 25, 'bush': 4, 'good': 13, 'things': 28, 'come': 6, 'to': 30, 'those': 29, 'who': 35, 'wait': 32, 'these': 27, 'watches': 34, 'cost': 7, '1500': 0, 'there': 26, 'are': 1, 'other': 21, 'fish': 11, 'sea': 22, 'ball': 2, 'your': 37, 'court': 8, 'mr': 20, 'smith': 24, 'goes': 12, 'washington': 33, 'doogie': 9, 'howser': 16, 'every': 10, 'cloud': 5, 'has': 15, 'silver': 23, 'lining': 19}\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPDTcQf4mANI",
        "outputId": "f49ab8c4-b1ae-418a-a3c4-945beb53cb8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.transform(test_text).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OFlJg--mANJ",
        "outputId": "c134a91f-3cc2-45ac-9084-44e72afa0997"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<3x38 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 9 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = [\"That bird is sitting in the bush and this bird is in hand.\",\n",
        "        \"Wait and then walk\",\n",
        "        \"Watches are cool \"]\n",
        "\n",
        "transformed_vector = count_vectorizer.transform(text)\n",
        "\n",
        "transformed_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPgM_K8WmANJ",
        "outputId": "aee53966-69e2-4dd2-e0fb-b9ff38e22dde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3)\t2\n",
            "  (0, 4)\t1\n",
            "  (0, 14)\t1\n",
            "  (0, 17)\t2\n",
            "  (0, 18)\t2\n",
            "  (0, 25)\t1\n",
            "  (1, 32)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 34)\t1\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfVYkUN9mANJ",
        "outputId": "bd56b75a-a7de-4927-8745-f0217b811c13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 38)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsTTIpJzmANK",
        "outputId": "84202863-d95f-4358-f96a-30425b527ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 2 1 0 0 0 0 0 0 0 0 0 1 0 0 2 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            "  0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2CjVtA-mANK"
      },
      "source": [
        "### CountVectorizer on text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I6A77SbmANL",
        "outputId": "3d7bcbc2-c314-4986-e0ec-f0009fee15bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjMJjSACmANL",
        "outputId": "3b59f3ef-f364-45e3-d01e-9fa40d6bd261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.', 'Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.', 'Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.', 'In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.', 'They were married in 1895.', 'The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.', 'In July 1898, the Curies announced the discovery of a new chemical element, polonium.', 'At the end of the year, they announced the discovery of another, radium.', 'The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.', \"Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\", 'Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.', 'She received a second Nobel Prize, for Chemistry, in 1911.', \"The Curie's research was crucial in the development of x-rays in surgery.\", 'During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.', 'The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.', 'Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.', 'By the late 1920s her health was beginning to deteriorate.', 'She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.', \"The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\"]\n"
          ]
        }
      ],
      "source": [
        "sentences = file_contents.split('\\n')\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJKTf8kWmANM",
        "outputId": "51687454-687f-4f16-eec8-19c837a8193d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19, 167)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector = count_vectorizer.fit_transform(sentences)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTohgpBVmANM",
        "outputId": "d891ebfb-1966-482b-c829-8dc543dcd09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 146)\t1\n",
            "  (0, 72)\t1\n",
            "  (0, 128)\t1\n",
            "  (0, 56)\t1\n",
            "  (0, 96)\t1\n",
            "  (0, 144)\t1\n",
            "  (0, 101)\t2\n",
            "  (0, 103)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 11)\t2\n",
            "  (0, 108)\t1\n",
            "  (0, 21)\t1\n",
            "  (0, 111)\t1\n",
            "  (0, 153)\t1\n",
            "  (0, 34)\t1\n",
            "  (0, 91)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 13)\t1\n",
            "  (1, 159)\t1\n",
            "  (1, 147)\t1\n",
            "  (1, 102)\t1\n",
            "  (1, 154)\t1\n",
            "  (1, 4)\t1\n",
            "  (1, 77)\t2\n",
            "  (1, 114)\t1\n",
            "  :\t:\n",
            "  (17, 8)\t1\n",
            "  (17, 42)\t1\n",
            "  (17, 62)\t2\n",
            "  (17, 124)\t1\n",
            "  (17, 23)\t1\n",
            "  (17, 82)\t1\n",
            "  (17, 147)\t1\n",
            "  (17, 102)\t1\n",
            "  (17, 131)\t1\n",
            "  (17, 72)\t1\n",
            "  (18, 160)\t1\n",
            "  (18, 127)\t1\n",
            "  (18, 80)\t1\n",
            "  (18, 48)\t1\n",
            "  (18, 28)\t1\n",
            "  (18, 73)\t1\n",
            "  (18, 59)\t1\n",
            "  (18, 35)\t1\n",
            "  (18, 37)\t1\n",
            "  (18, 114)\t1\n",
            "  (18, 99)\t1\n",
            "  (18, 144)\t2\n",
            "  (18, 101)\t1\n",
            "  (18, 11)\t1\n",
            "  (18, 153)\t1\n"
          ]
        }
      ],
      "source": [
        "print(transformed_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6x9T2OMmANN",
        "outputId": "09272584-4f65-4c45-80b2-4729aa0a688c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'marie': 91, 'curie': 34, 'was': 153, 'polish': 111, 'born': 21, 'physicist': 108, 'and': 11, 'chemist': 27, 'one': 103, 'of': 101, 'the': 144, 'most': 96, 'famous': 56, 'scientists': 128, 'her': 72, 'time': 146, 'together': 148, 'with': 161, 'husband': 76, 'pierre': 110, 'she': 131, 'awarded': 15, 'nobel': 99, 'prize': 114, 'in': 77, '1903': 4, 'went': 154, 'on': 102, 'to': 147, 'win': 159, 'another': 13, '1911': 6, 'sklodowska': 134, 'warsaw': 152, 'november': 100, '1867': 0, 'daughter': 37, 'teacher': 140, '1891': 1, 'paris': 107, 'study': 136, 'physics': 109, 'mathematics': 93, 'at': 14, 'sorbonne': 135, 'where': 157, 'met': 95, 'professor': 115, 'school': 126, 'they': 145, 'were': 155, 'married': 92, '1895': 2, 'curies': 35, 'worked': 164, 'investigating': 79, 'radioactivity': 117, 'building': 22, 'work': 163, 'german': 64, 'roentgen': 125, 'french': 61, 'becquerel': 17, 'july': 82, '1898': 3, 'announced': 12, 'discovery': 43, 'new': 98, 'chemical': 26, 'element': 49, 'polonium': 112, 'end': 50, 'year': 166, 'radium': 119, 'along': 9, 'for': 59, 'life': 87, 'cut': 36, 'short': 132, '1906': 5, 'when': 156, 'he': 67, 'knocked': 84, 'down': 45, 'killed': 83, 'by': 23, 'carriage': 24, 'took': 149, 'over': 106, 'his': 75, 'teaching': 141, 'post': 113, 'becoming': 16, 'first': 58, 'woman': 162, 'teach': 139, 'devoted': 41, 'herself': 73, 'continuing': 30, 'that': 143, 'had': 66, 'begun': 19, 'received': 122, 'second': 129, 'chemistry': 28, 'research': 124, 'crucial': 33, 'development': 40, 'rays': 121, 'surgery': 138, 'during': 47, 'world': 165, 'war': 151, 'helped': 71, 'equip': 52, 'ambulances': 10, 'ray': 120, 'equipment': 53, 'which': 158, 'drove': 46, 'front': 63, 'lines': 88, 'international': 78, 'red': 123, 'cross': 32, 'made': 89, 'head': 68, 'its': 81, 'radiological': 118, 'service': 130, 'held': 70, 'training': 150, 'courses': 31, 'medical': 94, 'orderlies': 105, 'doctors': 44, 'techniques': 142, 'despite': 38, 'success': 137, 'continued': 29, 'face': 55, 'great': 65, 'opposition': 104, 'from': 62, 'male': 90, 'france': 60, 'never': 97, 'significant': 133, 'financial': 57, 'benefits': 20, 'late': 85, '1920s': 7, 'health': 69, 'beginning': 18, 'deteriorate': 39, 'died': 42, '1934': 8, 'leukaemia': 86, 'caused': 25, 'exposure': 54, 'high': 74, 'energy': 51, 'radiation': 116, 'eldest': 48, 'irene': 80, 'scientist': 127, 'winner': 160}\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuEb7a_xmANN"
      },
      "source": [
        "We lost:\n",
        "\n",
        "* The meaning of text corpus\n",
        "* The ordering of the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7XSD5bwmANO",
        "outputId": "85a276f9-02fa-40e3-9247-069307515805"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['time', 'her', 'scientists', 'famous', 'most', 'the', 'of', 'one',\n",
              "        'chemist', 'and', 'physicist', 'born', 'polish', 'was', 'curie',\n",
              "        'marie'], dtype='<U13'),\n",
              " array(['1911', 'another', 'win', 'to', 'on', 'went', '1903', 'in',\n",
              "        'prize', 'nobel', 'awarded', 'she', 'pierre', 'husband', 'with',\n",
              "        'together', 'her', 'the', 'and', 'was'], dtype='<U13'),\n",
              " array(['teacher', 'daughter', '1867', 'november', 'warsaw', 'sklodowska',\n",
              "        'on', 'in', 'the', 'of', 'born', 'was', 'marie'], dtype='<U13'),\n",
              " array(['school', 'professor', 'met', 'where', 'sorbonne', 'at',\n",
              "        'mathematics', 'physics', 'study', 'paris', '1891', 'to', 'went',\n",
              "        'in', 'she', 'pierre', 'the', 'of', 'and', 'curie'], dtype='<U13'),\n",
              " array(['1895', 'married', 'were', 'they', 'in'], dtype='<U13'),\n",
              " array(['becquerel', 'french', 'roentgen', 'german', 'work', 'building',\n",
              "        'radioactivity', 'investigating', 'worked', 'curies', 'on',\n",
              "        'together', 'the', 'of', 'and', 'physicist'], dtype='<U13'),\n",
              " array(['polonium', 'element', 'chemical', 'new', 'discovery', 'announced',\n",
              "        '1898', 'july', 'curies', 'in', 'the', 'of'], dtype='<U13'),\n",
              " array(['radium', 'year', 'end', 'discovery', 'announced', 'they', 'at',\n",
              "        'another', 'the', 'of'], dtype='<U13'),\n",
              " array(['for', 'along', 'becquerel', 'curies', 'were', 'physics', '1903',\n",
              "        'in', 'prize', 'nobel', 'awarded', 'with', 'the'], dtype='<U13'),\n",
              " array(['carriage', 'by', 'killed', 'down', 'knocked', 'he', 'when',\n",
              "        '1906', 'short', 'cut', 'life', 'in', 'pierre', 'and', 'was'],\n",
              "       dtype='<U13'),\n",
              " array(['begun', 'had', 'that', 'continuing', 'herself', 'devoted',\n",
              "        'teach', 'woman', 'first', 'becoming', 'post', 'teaching', 'his',\n",
              "        'over', 'took', 'work', 'they', 'sorbonne', 'at', 'to', 'together',\n",
              "        'the', 'and', 'marie'], dtype='<U13'),\n",
              " array(['chemistry', 'second', 'received', 'for', '1911', 'in', 'prize',\n",
              "        'nobel', 'she'], dtype='<U13'),\n",
              " array(['surgery', 'rays', 'development', 'crucial', 'research', 'in',\n",
              "        'the', 'of', 'was', 'curie'], dtype='<U13'),\n",
              " array(['lines', 'front', 'drove', 'which', 'equipment', 'ray',\n",
              "        'ambulances', 'equip', 'helped', 'war', 'world', 'during',\n",
              "        'herself', 'to', 'she', 'with', 'the', 'one', 'curie'],\n",
              "       dtype='<U13'),\n",
              " array(['techniques', 'doctors', 'orderlies', 'medical', 'courses',\n",
              "        'training', 'held', 'service', 'radiological', 'its', 'head',\n",
              "        'made', 'cross', 'red', 'international', 'for', 'new', 'in', 'she',\n",
              "        'her', 'the', 'of', 'and'], dtype='<U13'),\n",
              " array(['benefits', 'financial', 'significant', 'never', 'france', 'male',\n",
              "        'from', 'opposition', 'great', 'face', 'continued', 'success',\n",
              "        'despite', 'received', 'work', 'to', 'in', 'she', 'her',\n",
              "        'scientists', 'and', 'marie'], dtype='<U13'),\n",
              " array(['deteriorate', 'beginning', 'health', '1920s', 'late', 'by', 'to',\n",
              "        'her', 'the', 'was'], dtype='<U13'),\n",
              " array(['radiation', 'energy', 'high', 'exposure', 'caused', 'leukaemia',\n",
              "        '1934', 'died', 'from', 'research', 'by', 'july', 'to', 'on',\n",
              "        'she', 'her'], dtype='<U13'),\n",
              " array(['winner', 'scientist', 'irene', 'eldest', 'chemistry', 'herself',\n",
              "        'for', 'curies', 'daughter', 'prize', 'nobel', 'the', 'of', 'and',\n",
              "        'was'], dtype='<U13')]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.inverse_transform(transformed_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffLzG1aImANO"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 03-VectorizeTextAsABagOfNGrams_CountVectorizer_Nltk</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVzqVyqQmANO"
      },
      "source": [
        "## Vectorize text as a bag-of-n-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNOsOTgymANP"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjoxa6yOmANP"
      },
      "outputs": [],
      "source": [
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rotLqXQnmANQ"
      },
      "outputs": [],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoiMYxyfmANQ"
      },
      "outputs": [],
      "source": [
        "transformed_vector = n_gram_vectorizer.fit_transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4sN1pHqmANR",
        "outputId": "5d45286f-c73d-44bd-bd40-1c7ba0b18ad8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird in': 2,\n",
              " 'in hand': 10,\n",
              " 'hand is': 9,\n",
              " 'is worth': 14,\n",
              " 'worth two': 30,\n",
              " 'two in': 27,\n",
              " 'in the': 11,\n",
              " 'the bush': 19,\n",
              " 'good things': 8,\n",
              " 'things come': 23,\n",
              " 'come to': 3,\n",
              " 'to those': 25,\n",
              " 'those who': 24,\n",
              " 'who wait': 29,\n",
              " 'these watches': 22,\n",
              " 'watches cost': 28,\n",
              " 'cost 1500': 4,\n",
              " 'there are': 21,\n",
              " 'are other': 0,\n",
              " 'other fish': 16,\n",
              " 'fish in': 6,\n",
              " 'the sea': 20,\n",
              " 'the ball': 18,\n",
              " 'ball is': 1,\n",
              " 'is in': 13,\n",
              " 'in your': 12,\n",
              " 'your court': 31,\n",
              " 'mr smith': 15,\n",
              " 'smith goes': 17,\n",
              " 'goes to': 7,\n",
              " 'to washington': 26,\n",
              " 'doogie howser': 5}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MukUNkjGmANR",
        "outputId": "1856ae3e-6d60-431d-ab15-afc2d4da6716"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IornAmXjmANS",
        "outputId": "2d2b4808-f3c2-4386-d268-b4a7d289f8d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 5,\n",
              " 'in': 24,\n",
              " 'hand': 21,\n",
              " 'is': 28,\n",
              " 'worth': 61,\n",
              " 'two': 53,\n",
              " 'the': 38,\n",
              " 'bush': 7,\n",
              " 'bird in': 6,\n",
              " 'in hand': 25,\n",
              " 'hand is': 22,\n",
              " 'is worth': 30,\n",
              " 'worth two': 62,\n",
              " 'two in': 54,\n",
              " 'in the': 26,\n",
              " 'the bush': 40,\n",
              " 'good': 19,\n",
              " 'things': 46,\n",
              " 'come': 8,\n",
              " 'to': 50,\n",
              " 'those': 48,\n",
              " 'who': 59,\n",
              " 'wait': 55,\n",
              " 'good things': 20,\n",
              " 'things come': 47,\n",
              " 'come to': 9,\n",
              " 'to those': 51,\n",
              " 'those who': 49,\n",
              " 'who wait': 60,\n",
              " 'these': 44,\n",
              " 'watches': 57,\n",
              " 'cost': 10,\n",
              " '1500': 0,\n",
              " 'these watches': 45,\n",
              " 'watches cost': 58,\n",
              " 'cost 1500': 11,\n",
              " 'there': 42,\n",
              " 'are': 1,\n",
              " 'other': 33,\n",
              " 'fish': 15,\n",
              " 'sea': 35,\n",
              " 'there are': 43,\n",
              " 'are other': 2,\n",
              " 'other fish': 34,\n",
              " 'fish in': 16,\n",
              " 'the sea': 41,\n",
              " 'ball': 3,\n",
              " 'your': 63,\n",
              " 'court': 12,\n",
              " 'the ball': 39,\n",
              " 'ball is': 4,\n",
              " 'is in': 29,\n",
              " 'in your': 27,\n",
              " 'your court': 64,\n",
              " 'mr': 31,\n",
              " 'smith': 36,\n",
              " 'goes': 17,\n",
              " 'washington': 56,\n",
              " 'mr smith': 32,\n",
              " 'smith goes': 37,\n",
              " 'goes to': 18,\n",
              " 'to washington': 52,\n",
              " 'doogie': 13,\n",
              " 'howser': 23,\n",
              " 'doogie howser': 14}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "transformed_vector = n_gram_vectorizer.fit_transform(train_text)\n",
        "\n",
        "n_gram_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WY2oVpjmANS",
        "outputId": "f6e66f32-db3a-4c32-fb7a-935b47856001"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        1, 0, 2, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efNTkBp5mANT"
      },
      "source": [
        "#### Bigram and Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNq1OANWmANU",
        "outputId": "2ecdbffa-a069-46e3-d685-debebbd81b45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBGPOW4MmANU",
        "outputId": "f286709d-6c5d-4e31-c91f-dff2c2f3a7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.', 'Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.', 'Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.', 'In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.', 'They were married in 1895.', 'The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.', 'In July 1898, the Curies announced the discovery of a new chemical element, polonium.', 'At the end of the year, they announced the discovery of another, radium.', 'The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.', \"Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\", 'Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.', 'She received a second Nobel Prize, for Chemistry, in 1911.', \"The Curie's research was crucial in the development of x-rays in surgery.\", 'During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.', 'The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.', 'Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.', 'By the late 1920s her health was beginning to deteriorate.', 'She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.', \"The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\"]\n"
          ]
        }
      ],
      "source": [
        "sentences = file_contents.split('\\n')\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWO4AADomANV"
      },
      "outputs": [],
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ5V3zM_mANW"
      },
      "outputs": [],
      "source": [
        "transformed_vector = n_gram_vectorizer.fit_transform(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHz4Z1aHmANW",
        "outputId": "02113820-98be-4f89-862b-fe9f02d666ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'marie curie': 251,\n",
              " 'curie was': 92,\n",
              " 'was polish': 504,\n",
              " 'polish born': 330,\n",
              " 'born physicist': 59,\n",
              " 'physicist and': 315,\n",
              " 'and chemist': 18,\n",
              " 'chemist and': 72,\n",
              " 'and one': 28,\n",
              " 'one of': 305,\n",
              " 'of the': 289,\n",
              " 'the most': 437,\n",
              " 'most famous': 265,\n",
              " 'famous scientists': 142,\n",
              " 'scientists of': 367,\n",
              " 'of her': 279,\n",
              " 'her time': 191,\n",
              " 'marie curie was': 252,\n",
              " 'curie was polish': 93,\n",
              " 'was polish born': 505,\n",
              " 'polish born physicist': 331,\n",
              " 'born physicist and': 60,\n",
              " 'physicist and chemist': 316,\n",
              " 'and chemist and': 19,\n",
              " 'chemist and one': 73,\n",
              " 'and one of': 29,\n",
              " 'one of the': 306,\n",
              " 'of the most': 291,\n",
              " 'the most famous': 438,\n",
              " 'most famous scientists': 266,\n",
              " 'famous scientists of': 143,\n",
              " 'scientists of her': 368,\n",
              " 'of her time': 280,\n",
              " 'together with': 480,\n",
              " 'with her': 526,\n",
              " 'her husband': 186,\n",
              " 'husband pierre': 203,\n",
              " 'pierre she': 328,\n",
              " 'she was': 385,\n",
              " 'was awarded': 490,\n",
              " 'awarded the': 46,\n",
              " 'the nobel': 441,\n",
              " 'nobel prize': 272,\n",
              " 'prize in': 337,\n",
              " 'in 1903': 208,\n",
              " '1903 and': 6,\n",
              " 'and she': 30,\n",
              " 'she went': 387,\n",
              " 'went on': 506,\n",
              " 'on to': 301,\n",
              " 'to win': 476,\n",
              " 'win another': 520,\n",
              " 'another in': 40,\n",
              " 'in 1911': 212,\n",
              " 'together with her': 481,\n",
              " 'with her husband': 527,\n",
              " 'her husband pierre': 187,\n",
              " 'husband pierre she': 204,\n",
              " 'pierre she was': 329,\n",
              " 'she was awarded': 386,\n",
              " 'was awarded the': 491,\n",
              " 'awarded the nobel': 47,\n",
              " 'the nobel prize': 442,\n",
              " 'nobel prize in': 274,\n",
              " 'prize in 1903': 338,\n",
              " 'in 1903 and': 209,\n",
              " '1903 and she': 7,\n",
              " 'and she went': 33,\n",
              " 'she went on': 388,\n",
              " 'went on to': 507,\n",
              " 'on to win': 302,\n",
              " 'to win another': 477,\n",
              " 'win another in': 521,\n",
              " 'another in 1911': 41,\n",
              " 'marie sklodowska': 253,\n",
              " 'sklodowska was': 394,\n",
              " 'was born': 494,\n",
              " 'born in': 57,\n",
              " 'in warsaw': 221,\n",
              " 'warsaw on': 488,\n",
              " 'on november': 297,\n",
              " 'november 1867': 275,\n",
              " '1867 the': 0,\n",
              " 'the daughter': 417,\n",
              " 'daughter of': 106,\n",
              " 'of teacher': 288,\n",
              " 'marie sklodowska was': 254,\n",
              " 'sklodowska was born': 395,\n",
              " 'was born in': 495,\n",
              " 'born in warsaw': 58,\n",
              " 'in warsaw on': 222,\n",
              " 'warsaw on november': 489,\n",
              " 'on november 1867': 298,\n",
              " 'november 1867 the': 276,\n",
              " '1867 the daughter': 1,\n",
              " 'the daughter of': 418,\n",
              " 'daughter of teacher': 107,\n",
              " 'in 1891': 205,\n",
              " '1891 she': 2,\n",
              " 'went to': 508,\n",
              " 'to paris': 468,\n",
              " 'paris to': 313,\n",
              " 'to study': 470,\n",
              " 'study physics': 400,\n",
              " 'physics and': 320,\n",
              " 'and mathematics': 26,\n",
              " 'mathematics at': 259,\n",
              " 'at the': 43,\n",
              " 'the sorbonne': 445,\n",
              " 'sorbonne where': 398,\n",
              " 'where she': 516,\n",
              " 'she met': 379,\n",
              " 'met pierre': 263,\n",
              " 'pierre curie': 324,\n",
              " 'curie professor': 88,\n",
              " 'professor of': 339,\n",
              " 'the school': 443,\n",
              " 'school of': 361,\n",
              " 'of physics': 285,\n",
              " 'in 1891 she': 206,\n",
              " '1891 she went': 3,\n",
              " 'she went to': 389,\n",
              " 'went to paris': 509,\n",
              " 'to paris to': 469,\n",
              " 'paris to study': 314,\n",
              " 'to study physics': 471,\n",
              " 'study physics and': 401,\n",
              " 'physics and mathematics': 321,\n",
              " 'and mathematics at': 27,\n",
              " 'mathematics at the': 260,\n",
              " 'at the sorbonne': 45,\n",
              " 'the sorbonne where': 447,\n",
              " 'sorbonne where she': 399,\n",
              " 'where she met': 517,\n",
              " 'she met pierre': 380,\n",
              " 'met pierre curie': 264,\n",
              " 'pierre curie professor': 325,\n",
              " 'curie professor of': 89,\n",
              " 'professor of the': 340,\n",
              " 'of the school': 293,\n",
              " 'the school of': 444,\n",
              " 'school of physics': 362,\n",
              " 'they were': 457,\n",
              " 'were married': 512,\n",
              " 'married in': 257,\n",
              " 'in 1895': 207,\n",
              " 'they were married': 458,\n",
              " 'were married in': 513,\n",
              " 'married in 1895': 258,\n",
              " 'the curies': 412,\n",
              " 'curies worked': 100,\n",
              " 'worked together': 536,\n",
              " 'together investigating': 478,\n",
              " 'investigating radioactivity': 225,\n",
              " 'radioactivity building': 343,\n",
              " 'building on': 61,\n",
              " 'on the': 299,\n",
              " 'the work': 448,\n",
              " 'work of': 532,\n",
              " 'the german': 431,\n",
              " 'german physicist': 166,\n",
              " 'physicist roentgen': 318,\n",
              " 'roentgen and': 359,\n",
              " 'and the': 34,\n",
              " 'the french': 427,\n",
              " 'french physicist': 156,\n",
              " 'physicist becquerel': 317,\n",
              " 'the curies worked': 416,\n",
              " 'curies worked together': 101,\n",
              " 'worked together investigating': 537,\n",
              " 'together investigating radioactivity': 479,\n",
              " 'investigating radioactivity building': 226,\n",
              " 'radioactivity building on': 344,\n",
              " 'building on the': 62,\n",
              " 'on the work': 300,\n",
              " 'the work of': 449,\n",
              " 'work of the': 533,\n",
              " 'of the german': 290,\n",
              " 'the german physicist': 432,\n",
              " 'german physicist roentgen': 167,\n",
              " 'physicist roentgen and': 319,\n",
              " 'roentgen and the': 360,\n",
              " 'and the french': 35,\n",
              " 'the french physicist': 428,\n",
              " 'french physicist becquerel': 157,\n",
              " 'in july': 215,\n",
              " 'july 1898': 231,\n",
              " '1898 the': 4,\n",
              " 'curies announced': 96,\n",
              " 'announced the': 38,\n",
              " 'the discovery': 421,\n",
              " 'discovery of': 116,\n",
              " 'of new': 283,\n",
              " 'new chemical': 269,\n",
              " 'chemical element': 70,\n",
              " 'element polonium': 129,\n",
              " 'in july 1898': 216,\n",
              " 'july 1898 the': 232,\n",
              " '1898 the curies': 5,\n",
              " 'the curies announced': 414,\n",
              " 'curies announced the': 97,\n",
              " 'announced the discovery': 39,\n",
              " 'the discovery of': 422,\n",
              " 'discovery of new': 118,\n",
              " 'of new chemical': 284,\n",
              " 'new chemical element': 270,\n",
              " 'chemical element polonium': 71,\n",
              " 'the end': 423,\n",
              " 'end of': 130,\n",
              " 'the year': 451,\n",
              " 'year they': 540,\n",
              " 'they announced': 453,\n",
              " 'of another': 277,\n",
              " 'another radium': 42,\n",
              " 'at the end': 44,\n",
              " 'the end of': 424,\n",
              " 'end of the': 131,\n",
              " 'of the year': 294,\n",
              " 'the year they': 452,\n",
              " 'year they announced': 541,\n",
              " 'they announced the': 454,\n",
              " 'discovery of another': 117,\n",
              " 'of another radium': 278,\n",
              " 'curies along': 94,\n",
              " 'along with': 14,\n",
              " 'with becquerel': 524,\n",
              " 'becquerel were': 50,\n",
              " 'were awarded': 510,\n",
              " 'prize for': 334,\n",
              " 'for physics': 152,\n",
              " 'physics in': 322,\n",
              " 'the curies along': 413,\n",
              " 'curies along with': 95,\n",
              " 'along with becquerel': 15,\n",
              " 'with becquerel were': 525,\n",
              " 'becquerel were awarded': 51,\n",
              " 'were awarded the': 511,\n",
              " 'nobel prize for': 273,\n",
              " 'prize for physics': 336,\n",
              " 'for physics in': 153,\n",
              " 'physics in 1903': 323,\n",
              " 'pierre life': 326,\n",
              " 'life was': 243,\n",
              " 'was cut': 498,\n",
              " 'cut short': 102,\n",
              " 'short in': 390,\n",
              " 'in 1906': 210,\n",
              " '1906 when': 8,\n",
              " 'when he': 514,\n",
              " 'he was': 172,\n",
              " 'was knocked': 502,\n",
              " 'knocked down': 237,\n",
              " 'down and': 121,\n",
              " 'and killed': 24,\n",
              " 'killed by': 235,\n",
              " 'by carriage': 63,\n",
              " 'pierre life was': 327,\n",
              " 'life was cut': 244,\n",
              " 'was cut short': 499,\n",
              " 'cut short in': 103,\n",
              " 'short in 1906': 391,\n",
              " 'in 1906 when': 211,\n",
              " '1906 when he': 9,\n",
              " 'when he was': 515,\n",
              " 'he was knocked': 173,\n",
              " 'was knocked down': 503,\n",
              " 'knocked down and': 238,\n",
              " 'down and killed': 122,\n",
              " 'and killed by': 25,\n",
              " 'killed by carriage': 236,\n",
              " 'marie took': 255,\n",
              " 'took over': 482,\n",
              " 'over his': 311,\n",
              " 'his teaching': 201,\n",
              " 'teaching post': 406,\n",
              " 'post becoming': 332,\n",
              " 'becoming the': 48,\n",
              " 'the first': 425,\n",
              " 'first woman': 146,\n",
              " 'woman to': 530,\n",
              " 'to teach': 472,\n",
              " 'teach at': 404,\n",
              " 'sorbonne and': 396,\n",
              " 'and devoted': 20,\n",
              " 'devoted herself': 112,\n",
              " 'herself to': 197,\n",
              " 'to continuing': 459,\n",
              " 'continuing the': 78,\n",
              " 'work that': 534,\n",
              " 'that they': 408,\n",
              " 'they had': 455,\n",
              " 'had begun': 170,\n",
              " 'begun together': 54,\n",
              " 'marie took over': 256,\n",
              " 'took over his': 483,\n",
              " 'over his teaching': 312,\n",
              " 'his teaching post': 202,\n",
              " 'teaching post becoming': 407,\n",
              " 'post becoming the': 333,\n",
              " 'becoming the first': 49,\n",
              " 'the first woman': 426,\n",
              " 'first woman to': 147,\n",
              " 'woman to teach': 531,\n",
              " 'to teach at': 473,\n",
              " 'teach at the': 405,\n",
              " 'the sorbonne and': 446,\n",
              " 'sorbonne and devoted': 397,\n",
              " 'and devoted herself': 21,\n",
              " 'devoted herself to': 113,\n",
              " 'herself to continuing': 198,\n",
              " 'to continuing the': 460,\n",
              " 'continuing the work': 79,\n",
              " 'the work that': 450,\n",
              " 'work that they': 535,\n",
              " 'that they had': 409,\n",
              " 'they had begun': 456,\n",
              " 'had begun together': 171,\n",
              " 'she received': 383,\n",
              " 'received second': 351,\n",
              " 'second nobel': 369,\n",
              " 'for chemistry': 148,\n",
              " 'chemistry in': 74,\n",
              " 'she received second': 384,\n",
              " 'received second nobel': 352,\n",
              " 'second nobel prize': 370,\n",
              " 'prize for chemistry': 335,\n",
              " 'for chemistry in': 149,\n",
              " 'chemistry in 1911': 75,\n",
              " 'the curie': 410,\n",
              " 'curie research': 90,\n",
              " 'research was': 357,\n",
              " 'was crucial': 496,\n",
              " 'crucial in': 84,\n",
              " 'in the': 218,\n",
              " 'the development': 419,\n",
              " 'development of': 110,\n",
              " 'of rays': 286,\n",
              " 'rays in': 349,\n",
              " 'in surgery': 217,\n",
              " 'the curie research': 411,\n",
              " 'curie research was': 91,\n",
              " 'research was crucial': 358,\n",
              " 'was crucial in': 497,\n",
              " 'crucial in the': 85,\n",
              " 'in the development': 219,\n",
              " 'the development of': 420,\n",
              " 'development of rays': 111,\n",
              " 'of rays in': 287,\n",
              " 'rays in surgery': 350,\n",
              " 'during world': 125,\n",
              " 'world war': 538,\n",
              " 'war one': 486,\n",
              " 'one curie': 303,\n",
              " 'curie helped': 86,\n",
              " 'helped to': 180,\n",
              " 'to equip': 462,\n",
              " 'equip ambulances': 134,\n",
              " 'ambulances with': 16,\n",
              " 'with ray': 528,\n",
              " 'ray equipment': 347,\n",
              " 'equipment which': 136,\n",
              " 'which she': 518,\n",
              " 'she herself': 377,\n",
              " 'herself drove': 193,\n",
              " 'drove to': 123,\n",
              " 'to the': 474,\n",
              " 'the front': 429,\n",
              " 'front lines': 165,\n",
              " 'during world war': 126,\n",
              " 'world war one': 539,\n",
              " 'war one curie': 487,\n",
              " 'one curie helped': 304,\n",
              " 'curie helped to': 87,\n",
              " 'helped to equip': 181,\n",
              " 'to equip ambulances': 463,\n",
              " 'equip ambulances with': 135,\n",
              " 'ambulances with ray': 17,\n",
              " 'with ray equipment': 529,\n",
              " 'ray equipment which': 348,\n",
              " 'equipment which she': 137,\n",
              " 'which she herself': 519,\n",
              " 'she herself drove': 378,\n",
              " 'herself drove to': 194,\n",
              " 'drove to the': 124,\n",
              " 'to the front': 475,\n",
              " 'the front lines': 430,\n",
              " 'the international': 433,\n",
              " 'international red': 223,\n",
              " 'red cross': 355,\n",
              " 'cross made': 82,\n",
              " 'made her': 245,\n",
              " 'her head': 182,\n",
              " 'head of': 174,\n",
              " 'of its': 281,\n",
              " 'its radiological': 229,\n",
              " 'radiological service': 345,\n",
              " 'service and': 371,\n",
              " 'she held': 375,\n",
              " 'held training': 178,\n",
              " 'training courses': 484,\n",
              " 'courses for': 80,\n",
              " 'for medical': 150,\n",
              " 'medical orderlies': 261,\n",
              " 'orderlies and': 309,\n",
              " 'and doctors': 22,\n",
              " 'doctors in': 119,\n",
              " 'the new': 439,\n",
              " 'new techniques': 271,\n",
              " 'the international red': 434,\n",
              " 'international red cross': 224,\n",
              " 'red cross made': 356,\n",
              " 'cross made her': 83,\n",
              " 'made her head': 246,\n",
              " 'her head of': 183,\n",
              " 'head of its': 175,\n",
              " 'of its radiological': 282,\n",
              " 'its radiological service': 230,\n",
              " 'radiological service and': 346,\n",
              " 'service and she': 372,\n",
              " 'and she held': 31,\n",
              " 'she held training': 376,\n",
              " 'held training courses': 179,\n",
              " 'training courses for': 485,\n",
              " 'courses for medical': 81,\n",
              " 'for medical orderlies': 151,\n",
              " 'medical orderlies and': 262,\n",
              " 'orderlies and doctors': 310,\n",
              " 'and doctors in': 23,\n",
              " 'doctors in the': 120,\n",
              " 'in the new': 220,\n",
              " 'the new techniques': 440,\n",
              " 'despite her': 108,\n",
              " 'her success': 189,\n",
              " 'success marie': 402,\n",
              " 'marie continued': 249,\n",
              " 'continued to': 76,\n",
              " 'to face': 464,\n",
              " 'face great': 140,\n",
              " 'great opposition': 168,\n",
              " 'opposition from': 307,\n",
              " 'from male': 163,\n",
              " 'male scientists': 247,\n",
              " 'scientists in': 365,\n",
              " 'in france': 213,\n",
              " 'france and': 154,\n",
              " 'she never': 381,\n",
              " 'never received': 267,\n",
              " 'received significant': 353,\n",
              " 'significant financial': 392,\n",
              " 'financial benefits': 144,\n",
              " 'benefits from': 55,\n",
              " 'from her': 158,\n",
              " 'her work': 192,\n",
              " 'despite her success': 109,\n",
              " 'her success marie': 190,\n",
              " 'success marie continued': 403,\n",
              " 'marie continued to': 250,\n",
              " 'continued to face': 77,\n",
              " 'to face great': 465,\n",
              " 'face great opposition': 141,\n",
              " 'great opposition from': 169,\n",
              " 'opposition from male': 308,\n",
              " 'from male scientists': 164,\n",
              " 'male scientists in': 248,\n",
              " 'scientists in france': 366,\n",
              " 'in france and': 214,\n",
              " 'france and she': 155,\n",
              " 'and she never': 32,\n",
              " 'she never received': 382,\n",
              " 'never received significant': 268,\n",
              " 'received significant financial': 354,\n",
              " 'significant financial benefits': 393,\n",
              " 'financial benefits from': 145,\n",
              " 'benefits from her': 56,\n",
              " 'from her work': 160,\n",
              " 'by the': 66,\n",
              " 'the late': 435,\n",
              " 'late 1920s': 239,\n",
              " '1920s her': 10,\n",
              " 'her health': 184,\n",
              " 'health was': 176,\n",
              " 'was beginning': 492,\n",
              " 'beginning to': 52,\n",
              " 'to deteriorate': 461,\n",
              " 'by the late': 67,\n",
              " 'the late 1920s': 436,\n",
              " 'late 1920s her': 240,\n",
              " '1920s her health': 11,\n",
              " 'her health was': 185,\n",
              " 'health was beginning': 177,\n",
              " 'was beginning to': 493,\n",
              " 'beginning to deteriorate': 53,\n",
              " 'she died': 373,\n",
              " 'died on': 114,\n",
              " 'on july': 295,\n",
              " 'july 1934': 233,\n",
              " '1934 from': 12,\n",
              " 'from leukaemia': 161,\n",
              " 'leukaemia caused': 241,\n",
              " 'caused by': 68,\n",
              " 'by exposure': 64,\n",
              " 'exposure to': 138,\n",
              " 'to high': 466,\n",
              " 'high energy': 199,\n",
              " 'energy radiation': 132,\n",
              " 'radiation from': 341,\n",
              " 'her research': 188,\n",
              " 'she died on': 374,\n",
              " 'died on july': 115,\n",
              " 'on july 1934': 296,\n",
              " 'july 1934 from': 234,\n",
              " '1934 from leukaemia': 13,\n",
              " 'from leukaemia caused': 162,\n",
              " 'leukaemia caused by': 242,\n",
              " 'caused by exposure': 69,\n",
              " 'by exposure to': 65,\n",
              " 'exposure to high': 139,\n",
              " 'to high energy': 467,\n",
              " 'high energy radiation': 200,\n",
              " 'energy radiation from': 133,\n",
              " 'radiation from her': 342,\n",
              " 'from her research': 159,\n",
              " 'curies eldest': 98,\n",
              " 'eldest daughter': 127,\n",
              " 'daughter irene': 104,\n",
              " 'irene was': 227,\n",
              " 'was herself': 500,\n",
              " 'herself scientist': 195,\n",
              " 'scientist and': 363,\n",
              " 'and winner': 36,\n",
              " 'winner of': 522,\n",
              " 'the curies eldest': 415,\n",
              " 'curies eldest daughter': 99,\n",
              " 'eldest daughter irene': 128,\n",
              " 'daughter irene was': 105,\n",
              " 'irene was herself': 228,\n",
              " 'was herself scientist': 501,\n",
              " 'herself scientist and': 196,\n",
              " 'scientist and winner': 364,\n",
              " 'and winner of': 37,\n",
              " 'winner of the': 523,\n",
              " 'of the nobel': 292}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary = n_gram_vectorizer.vocabulary_\n",
        "\n",
        "vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naRAK2NimANX",
        "outputId": "2a21d3ff-8465-4cde-bebb-6723e248e121"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_.get('marie curie')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx7Kua7jmANY",
        "outputId": "fc23bd00-b16b-4593-aa86-1dd60409cdbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "279"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_gram_vectorizer.vocabulary_.get('of her')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN4RKoGZmANY"
      },
      "source": [
        "* https://stackoverflow.com/questions/11763613/python-list-of-ngrams-with-frequencies\n",
        "* https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD3ZMJVimANY"
      },
      "source": [
        "word_count is a vector that contains the sum of each word occurrence in all texts in the corpus. In other words, we are adding the elements for each column of vector matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR4JgAfimANZ",
        "outputId": "d8e570e8-e8f0-48b7-a579-80bf0a63190b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frUZsSp_mANZ",
        "outputId": "2b8e111e-e925-4ebe-be42-944539a2f84b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3,\n",
              "       1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 3, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_count = transformed_vector.toarray().sum(axis=0)\n",
        "\n",
        "word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0d95DwsmANa",
        "outputId": "fd6de684-826a-4005-c3ad-b5be683996e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_items([('marie curie', 251), ('curie was', 92), ('was polish', 504), ('polish born', 330), ('born physicist', 59), ('physicist and', 315), ('and chemist', 18), ('chemist and', 72), ('and one', 28), ('one of', 305), ('of the', 289), ('the most', 437), ('most famous', 265), ('famous scientists', 142), ('scientists of', 367), ('of her', 279), ('her time', 191), ('marie curie was', 252), ('curie was polish', 93), ('was polish born', 505), ('polish born physicist', 331), ('born physicist and', 60), ('physicist and chemist', 316), ('and chemist and', 19), ('chemist and one', 73), ('and one of', 29), ('one of the', 306), ('of the most', 291), ('the most famous', 438), ('most famous scientists', 266), ('famous scientists of', 143), ('scientists of her', 368), ('of her time', 280), ('together with', 480), ('with her', 526), ('her husband', 186), ('husband pierre', 203), ('pierre she', 328), ('she was', 385), ('was awarded', 490), ('awarded the', 46), ('the nobel', 441), ('nobel prize', 272), ('prize in', 337), ('in 1903', 208), ('1903 and', 6), ('and she', 30), ('she went', 387), ('went on', 506), ('on to', 301), ('to win', 476), ('win another', 520), ('another in', 40), ('in 1911', 212), ('together with her', 481), ('with her husband', 527), ('her husband pierre', 187), ('husband pierre she', 204), ('pierre she was', 329), ('she was awarded', 386), ('was awarded the', 491), ('awarded the nobel', 47), ('the nobel prize', 442), ('nobel prize in', 274), ('prize in 1903', 338), ('in 1903 and', 209), ('1903 and she', 7), ('and she went', 33), ('she went on', 388), ('went on to', 507), ('on to win', 302), ('to win another', 477), ('win another in', 521), ('another in 1911', 41), ('marie sklodowska', 253), ('sklodowska was', 394), ('was born', 494), ('born in', 57), ('in warsaw', 221), ('warsaw on', 488), ('on november', 297), ('november 1867', 275), ('1867 the', 0), ('the daughter', 417), ('daughter of', 106), ('of teacher', 288), ('marie sklodowska was', 254), ('sklodowska was born', 395), ('was born in', 495), ('born in warsaw', 58), ('in warsaw on', 222), ('warsaw on november', 489), ('on november 1867', 298), ('november 1867 the', 276), ('1867 the daughter', 1), ('the daughter of', 418), ('daughter of teacher', 107), ('in 1891', 205), ('1891 she', 2), ('went to', 508), ('to paris', 468), ('paris to', 313), ('to study', 470), ('study physics', 400), ('physics and', 320), ('and mathematics', 26), ('mathematics at', 259), ('at the', 43), ('the sorbonne', 445), ('sorbonne where', 398), ('where she', 516), ('she met', 379), ('met pierre', 263), ('pierre curie', 324), ('curie professor', 88), ('professor of', 339), ('the school', 443), ('school of', 361), ('of physics', 285), ('in 1891 she', 206), ('1891 she went', 3), ('she went to', 389), ('went to paris', 509), ('to paris to', 469), ('paris to study', 314), ('to study physics', 471), ('study physics and', 401), ('physics and mathematics', 321), ('and mathematics at', 27), ('mathematics at the', 260), ('at the sorbonne', 45), ('the sorbonne where', 447), ('sorbonne where she', 399), ('where she met', 517), ('she met pierre', 380), ('met pierre curie', 264), ('pierre curie professor', 325), ('curie professor of', 89), ('professor of the', 340), ('of the school', 293), ('the school of', 444), ('school of physics', 362), ('they were', 457), ('were married', 512), ('married in', 257), ('in 1895', 207), ('they were married', 458), ('were married in', 513), ('married in 1895', 258), ('the curies', 412), ('curies worked', 100), ('worked together', 536), ('together investigating', 478), ('investigating radioactivity', 225), ('radioactivity building', 343), ('building on', 61), ('on the', 299), ('the work', 448), ('work of', 532), ('the german', 431), ('german physicist', 166), ('physicist roentgen', 318), ('roentgen and', 359), ('and the', 34), ('the french', 427), ('french physicist', 156), ('physicist becquerel', 317), ('the curies worked', 416), ('curies worked together', 101), ('worked together investigating', 537), ('together investigating radioactivity', 479), ('investigating radioactivity building', 226), ('radioactivity building on', 344), ('building on the', 62), ('on the work', 300), ('the work of', 449), ('work of the', 533), ('of the german', 290), ('the german physicist', 432), ('german physicist roentgen', 167), ('physicist roentgen and', 319), ('roentgen and the', 360), ('and the french', 35), ('the french physicist', 428), ('french physicist becquerel', 157), ('in july', 215), ('july 1898', 231), ('1898 the', 4), ('curies announced', 96), ('announced the', 38), ('the discovery', 421), ('discovery of', 116), ('of new', 283), ('new chemical', 269), ('chemical element', 70), ('element polonium', 129), ('in july 1898', 216), ('july 1898 the', 232), ('1898 the curies', 5), ('the curies announced', 414), ('curies announced the', 97), ('announced the discovery', 39), ('the discovery of', 422), ('discovery of new', 118), ('of new chemical', 284), ('new chemical element', 270), ('chemical element polonium', 71), ('the end', 423), ('end of', 130), ('the year', 451), ('year they', 540), ('they announced', 453), ('of another', 277), ('another radium', 42), ('at the end', 44), ('the end of', 424), ('end of the', 131), ('of the year', 294), ('the year they', 452), ('year they announced', 541), ('they announced the', 454), ('discovery of another', 117), ('of another radium', 278), ('curies along', 94), ('along with', 14), ('with becquerel', 524), ('becquerel were', 50), ('were awarded', 510), ('prize for', 334), ('for physics', 152), ('physics in', 322), ('the curies along', 413), ('curies along with', 95), ('along with becquerel', 15), ('with becquerel were', 525), ('becquerel were awarded', 51), ('were awarded the', 511), ('nobel prize for', 273), ('prize for physics', 336), ('for physics in', 153), ('physics in 1903', 323), ('pierre life', 326), ('life was', 243), ('was cut', 498), ('cut short', 102), ('short in', 390), ('in 1906', 210), ('1906 when', 8), ('when he', 514), ('he was', 172), ('was knocked', 502), ('knocked down', 237), ('down and', 121), ('and killed', 24), ('killed by', 235), ('by carriage', 63), ('pierre life was', 327), ('life was cut', 244), ('was cut short', 499), ('cut short in', 103), ('short in 1906', 391), ('in 1906 when', 211), ('1906 when he', 9), ('when he was', 515), ('he was knocked', 173), ('was knocked down', 503), ('knocked down and', 238), ('down and killed', 122), ('and killed by', 25), ('killed by carriage', 236), ('marie took', 255), ('took over', 482), ('over his', 311), ('his teaching', 201), ('teaching post', 406), ('post becoming', 332), ('becoming the', 48), ('the first', 425), ('first woman', 146), ('woman to', 530), ('to teach', 472), ('teach at', 404), ('sorbonne and', 396), ('and devoted', 20), ('devoted herself', 112), ('herself to', 197), ('to continuing', 459), ('continuing the', 78), ('work that', 534), ('that they', 408), ('they had', 455), ('had begun', 170), ('begun together', 54), ('marie took over', 256), ('took over his', 483), ('over his teaching', 312), ('his teaching post', 202), ('teaching post becoming', 407), ('post becoming the', 333), ('becoming the first', 49), ('the first woman', 426), ('first woman to', 147), ('woman to teach', 531), ('to teach at', 473), ('teach at the', 405), ('the sorbonne and', 446), ('sorbonne and devoted', 397), ('and devoted herself', 21), ('devoted herself to', 113), ('herself to continuing', 198), ('to continuing the', 460), ('continuing the work', 79), ('the work that', 450), ('work that they', 535), ('that they had', 409), ('they had begun', 456), ('had begun together', 171), ('she received', 383), ('received second', 351), ('second nobel', 369), ('for chemistry', 148), ('chemistry in', 74), ('she received second', 384), ('received second nobel', 352), ('second nobel prize', 370), ('prize for chemistry', 335), ('for chemistry in', 149), ('chemistry in 1911', 75), ('the curie', 410), ('curie research', 90), ('research was', 357), ('was crucial', 496), ('crucial in', 84), ('in the', 218), ('the development', 419), ('development of', 110), ('of rays', 286), ('rays in', 349), ('in surgery', 217), ('the curie research', 411), ('curie research was', 91), ('research was crucial', 358), ('was crucial in', 497), ('crucial in the', 85), ('in the development', 219), ('the development of', 420), ('development of rays', 111), ('of rays in', 287), ('rays in surgery', 350), ('during world', 125), ('world war', 538), ('war one', 486), ('one curie', 303), ('curie helped', 86), ('helped to', 180), ('to equip', 462), ('equip ambulances', 134), ('ambulances with', 16), ('with ray', 528), ('ray equipment', 347), ('equipment which', 136), ('which she', 518), ('she herself', 377), ('herself drove', 193), ('drove to', 123), ('to the', 474), ('the front', 429), ('front lines', 165), ('during world war', 126), ('world war one', 539), ('war one curie', 487), ('one curie helped', 304), ('curie helped to', 87), ('helped to equip', 181), ('to equip ambulances', 463), ('equip ambulances with', 135), ('ambulances with ray', 17), ('with ray equipment', 529), ('ray equipment which', 348), ('equipment which she', 137), ('which she herself', 519), ('she herself drove', 378), ('herself drove to', 194), ('drove to the', 124), ('to the front', 475), ('the front lines', 430), ('the international', 433), ('international red', 223), ('red cross', 355), ('cross made', 82), ('made her', 245), ('her head', 182), ('head of', 174), ('of its', 281), ('its radiological', 229), ('radiological service', 345), ('service and', 371), ('she held', 375), ('held training', 178), ('training courses', 484), ('courses for', 80), ('for medical', 150), ('medical orderlies', 261), ('orderlies and', 309), ('and doctors', 22), ('doctors in', 119), ('the new', 439), ('new techniques', 271), ('the international red', 434), ('international red cross', 224), ('red cross made', 356), ('cross made her', 83), ('made her head', 246), ('her head of', 183), ('head of its', 175), ('of its radiological', 282), ('its radiological service', 230), ('radiological service and', 346), ('service and she', 372), ('and she held', 31), ('she held training', 376), ('held training courses', 179), ('training courses for', 485), ('courses for medical', 81), ('for medical orderlies', 151), ('medical orderlies and', 262), ('orderlies and doctors', 310), ('and doctors in', 23), ('doctors in the', 120), ('in the new', 220), ('the new techniques', 440), ('despite her', 108), ('her success', 189), ('success marie', 402), ('marie continued', 249), ('continued to', 76), ('to face', 464), ('face great', 140), ('great opposition', 168), ('opposition from', 307), ('from male', 163), ('male scientists', 247), ('scientists in', 365), ('in france', 213), ('france and', 154), ('she never', 381), ('never received', 267), ('received significant', 353), ('significant financial', 392), ('financial benefits', 144), ('benefits from', 55), ('from her', 158), ('her work', 192), ('despite her success', 109), ('her success marie', 190), ('success marie continued', 403), ('marie continued to', 250), ('continued to face', 77), ('to face great', 465), ('face great opposition', 141), ('great opposition from', 169), ('opposition from male', 308), ('from male scientists', 164), ('male scientists in', 248), ('scientists in france', 366), ('in france and', 214), ('france and she', 155), ('and she never', 32), ('she never received', 382), ('never received significant', 268), ('received significant financial', 354), ('significant financial benefits', 393), ('financial benefits from', 145), ('benefits from her', 56), ('from her work', 160), ('by the', 66), ('the late', 435), ('late 1920s', 239), ('1920s her', 10), ('her health', 184), ('health was', 176), ('was beginning', 492), ('beginning to', 52), ('to deteriorate', 461), ('by the late', 67), ('the late 1920s', 436), ('late 1920s her', 240), ('1920s her health', 11), ('her health was', 185), ('health was beginning', 177), ('was beginning to', 493), ('beginning to deteriorate', 53), ('she died', 373), ('died on', 114), ('on july', 295), ('july 1934', 233), ('1934 from', 12), ('from leukaemia', 161), ('leukaemia caused', 241), ('caused by', 68), ('by exposure', 64), ('exposure to', 138), ('to high', 466), ('high energy', 199), ('energy radiation', 132), ('radiation from', 341), ('her research', 188), ('she died on', 374), ('died on july', 115), ('on july 1934', 296), ('july 1934 from', 234), ('1934 from leukaemia', 13), ('from leukaemia caused', 162), ('leukaemia caused by', 242), ('caused by exposure', 69), ('by exposure to', 65), ('exposure to high', 139), ('to high energy', 467), ('high energy radiation', 200), ('energy radiation from', 133), ('radiation from her', 342), ('from her research', 159), ('curies eldest', 98), ('eldest daughter', 127), ('daughter irene', 104), ('irene was', 227), ('was herself', 500), ('herself scientist', 195), ('scientist and', 363), ('and winner', 36), ('winner of', 522), ('the curies eldest', 415), ('curies eldest daughter', 99), ('eldest daughter irene', 128), ('daughter irene was', 105), ('irene was herself', 228), ('was herself scientist', 501), ('herself scientist and', 196), ('scientist and winner', 364), ('and winner of', 37), ('winner of the', 523), ('of the nobel', 292)])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHUAdh55mANa",
        "outputId": "c01f7ac1-e181-4ea8-e074-c583459c1090"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(5, 'of the'),\n",
              " (4, 'the curies'),\n",
              " (4, 'nobel prize'),\n",
              " (3, 'the nobel prize'),\n",
              " (3, 'the nobel'),\n",
              " (3, 'prize for'),\n",
              " (3, 'nobel prize for'),\n",
              " (3, 'at the'),\n",
              " (3, 'and she'),\n",
              " (2, 'the work'),\n",
              " (2, 'the sorbonne'),\n",
              " (2, 'the discovery of'),\n",
              " (2, 'the discovery'),\n",
              " (2, 'she went'),\n",
              " (2, 'prize for chemistry'),\n",
              " (2, 'in the'),\n",
              " (2, 'in 1911'),\n",
              " (2, 'in 1903'),\n",
              " (2, 'from her'),\n",
              " (2, 'for chemistry'),\n",
              " (2, 'discovery of'),\n",
              " (2, 'awarded the nobel'),\n",
              " (2, 'awarded the'),\n",
              " (2, 'at the sorbonne'),\n",
              " (2, 'announced the discovery'),\n",
              " (2, 'announced the'),\n",
              " (1, 'year they announced'),\n",
              " (1, 'year they'),\n",
              " (1, 'world war one'),\n",
              " (1, 'world war'),\n",
              " (1, 'worked together investigating'),\n",
              " (1, 'worked together'),\n",
              " (1, 'work that they'),\n",
              " (1, 'work that'),\n",
              " (1, 'work of the'),\n",
              " (1, 'work of'),\n",
              " (1, 'woman to teach'),\n",
              " (1, 'woman to'),\n",
              " (1, 'with ray equipment'),\n",
              " (1, 'with ray'),\n",
              " (1, 'with her husband'),\n",
              " (1, 'with her'),\n",
              " (1, 'with becquerel were'),\n",
              " (1, 'with becquerel'),\n",
              " (1, 'winner of the'),\n",
              " (1, 'winner of'),\n",
              " (1, 'win another in'),\n",
              " (1, 'win another'),\n",
              " (1, 'which she herself'),\n",
              " (1, 'which she'),\n",
              " (1, 'where she met'),\n",
              " (1, 'where she'),\n",
              " (1, 'when he was'),\n",
              " (1, 'when he'),\n",
              " (1, 'were married in'),\n",
              " (1, 'were married'),\n",
              " (1, 'were awarded the'),\n",
              " (1, 'were awarded'),\n",
              " (1, 'went to paris'),\n",
              " (1, 'went to'),\n",
              " (1, 'went on to'),\n",
              " (1, 'went on'),\n",
              " (1, 'was polish born'),\n",
              " (1, 'was polish'),\n",
              " (1, 'was knocked down'),\n",
              " (1, 'was knocked'),\n",
              " (1, 'was herself scientist'),\n",
              " (1, 'was herself'),\n",
              " (1, 'was cut short'),\n",
              " (1, 'was cut'),\n",
              " (1, 'was crucial in'),\n",
              " (1, 'was crucial'),\n",
              " (1, 'was born in'),\n",
              " (1, 'was born'),\n",
              " (1, 'was beginning to'),\n",
              " (1, 'was beginning'),\n",
              " (1, 'was awarded the'),\n",
              " (1, 'was awarded'),\n",
              " (1, 'warsaw on november'),\n",
              " (1, 'warsaw on'),\n",
              " (1, 'war one curie'),\n",
              " (1, 'war one'),\n",
              " (1, 'training courses for'),\n",
              " (1, 'training courses'),\n",
              " (1, 'took over his'),\n",
              " (1, 'took over'),\n",
              " (1, 'together with her'),\n",
              " (1, 'together with'),\n",
              " (1, 'together investigating radioactivity'),\n",
              " (1, 'together investigating'),\n",
              " (1, 'to win another'),\n",
              " (1, 'to win'),\n",
              " (1, 'to the front'),\n",
              " (1, 'to the'),\n",
              " (1, 'to teach at'),\n",
              " (1, 'to teach'),\n",
              " (1, 'to study physics'),\n",
              " (1, 'to study'),\n",
              " (1, 'to paris to'),\n",
              " (1, 'to paris'),\n",
              " (1, 'to high energy'),\n",
              " (1, 'to high'),\n",
              " (1, 'to face great'),\n",
              " (1, 'to face'),\n",
              " (1, 'to equip ambulances'),\n",
              " (1, 'to equip'),\n",
              " (1, 'to deteriorate'),\n",
              " (1, 'to continuing the'),\n",
              " (1, 'to continuing'),\n",
              " (1, 'they were married'),\n",
              " (1, 'they were'),\n",
              " (1, 'they had begun'),\n",
              " (1, 'they had'),\n",
              " (1, 'they announced the'),\n",
              " (1, 'they announced'),\n",
              " (1, 'the year they'),\n",
              " (1, 'the year'),\n",
              " (1, 'the work that'),\n",
              " (1, 'the work of'),\n",
              " (1, 'the sorbonne where'),\n",
              " (1, 'the sorbonne and'),\n",
              " (1, 'the school of'),\n",
              " (1, 'the school'),\n",
              " (1, 'the new techniques'),\n",
              " (1, 'the new'),\n",
              " (1, 'the most famous'),\n",
              " (1, 'the most'),\n",
              " (1, 'the late 1920s'),\n",
              " (1, 'the late'),\n",
              " (1, 'the international red'),\n",
              " (1, 'the international'),\n",
              " (1, 'the german physicist'),\n",
              " (1, 'the german'),\n",
              " (1, 'the front lines'),\n",
              " (1, 'the front'),\n",
              " (1, 'the french physicist'),\n",
              " (1, 'the french'),\n",
              " (1, 'the first woman'),\n",
              " (1, 'the first'),\n",
              " (1, 'the end of'),\n",
              " (1, 'the end'),\n",
              " (1, 'the development of'),\n",
              " (1, 'the development'),\n",
              " (1, 'the daughter of'),\n",
              " (1, 'the daughter'),\n",
              " (1, 'the curies worked'),\n",
              " (1, 'the curies eldest'),\n",
              " (1, 'the curies announced'),\n",
              " (1, 'the curies along'),\n",
              " (1, 'the curie research'),\n",
              " (1, 'the curie'),\n",
              " (1, 'that they had'),\n",
              " (1, 'that they'),\n",
              " (1, 'teaching post becoming'),\n",
              " (1, 'teaching post'),\n",
              " (1, 'teach at the'),\n",
              " (1, 'teach at'),\n",
              " (1, 'success marie continued'),\n",
              " (1, 'success marie'),\n",
              " (1, 'study physics and'),\n",
              " (1, 'study physics'),\n",
              " (1, 'sorbonne where she'),\n",
              " (1, 'sorbonne where'),\n",
              " (1, 'sorbonne and devoted'),\n",
              " (1, 'sorbonne and'),\n",
              " (1, 'sklodowska was born'),\n",
              " (1, 'sklodowska was'),\n",
              " (1, 'significant financial benefits'),\n",
              " (1, 'significant financial'),\n",
              " (1, 'short in 1906'),\n",
              " (1, 'short in'),\n",
              " (1, 'she went to'),\n",
              " (1, 'she went on'),\n",
              " (1, 'she was awarded'),\n",
              " (1, 'she was'),\n",
              " (1, 'she received second'),\n",
              " (1, 'she received'),\n",
              " (1, 'she never received'),\n",
              " (1, 'she never'),\n",
              " (1, 'she met pierre'),\n",
              " (1, 'she met'),\n",
              " (1, 'she herself drove'),\n",
              " (1, 'she herself'),\n",
              " (1, 'she held training'),\n",
              " (1, 'she held'),\n",
              " (1, 'she died on'),\n",
              " (1, 'she died'),\n",
              " (1, 'service and she'),\n",
              " (1, 'service and'),\n",
              " (1, 'second nobel prize'),\n",
              " (1, 'second nobel'),\n",
              " (1, 'scientists of her'),\n",
              " (1, 'scientists of'),\n",
              " (1, 'scientists in france'),\n",
              " (1, 'scientists in'),\n",
              " (1, 'scientist and winner'),\n",
              " (1, 'scientist and'),\n",
              " (1, 'school of physics'),\n",
              " (1, 'school of'),\n",
              " (1, 'roentgen and the'),\n",
              " (1, 'roentgen and'),\n",
              " (1, 'research was crucial'),\n",
              " (1, 'research was'),\n",
              " (1, 'red cross made'),\n",
              " (1, 'red cross'),\n",
              " (1, 'received significant financial'),\n",
              " (1, 'received significant'),\n",
              " (1, 'received second nobel'),\n",
              " (1, 'received second'),\n",
              " (1, 'rays in surgery'),\n",
              " (1, 'rays in'),\n",
              " (1, 'ray equipment which'),\n",
              " (1, 'ray equipment'),\n",
              " (1, 'radiological service and'),\n",
              " (1, 'radiological service'),\n",
              " (1, 'radioactivity building on'),\n",
              " (1, 'radioactivity building'),\n",
              " (1, 'radiation from her'),\n",
              " (1, 'radiation from'),\n",
              " (1, 'professor of the'),\n",
              " (1, 'professor of'),\n",
              " (1, 'prize in 1903'),\n",
              " (1, 'prize in'),\n",
              " (1, 'prize for physics'),\n",
              " (1, 'post becoming the'),\n",
              " (1, 'post becoming'),\n",
              " (1, 'polish born physicist'),\n",
              " (1, 'polish born'),\n",
              " (1, 'pierre she was'),\n",
              " (1, 'pierre she'),\n",
              " (1, 'pierre life was'),\n",
              " (1, 'pierre life'),\n",
              " (1, 'pierre curie professor'),\n",
              " (1, 'pierre curie'),\n",
              " (1, 'physics in 1903'),\n",
              " (1, 'physics in'),\n",
              " (1, 'physics and mathematics'),\n",
              " (1, 'physics and'),\n",
              " (1, 'physicist roentgen and'),\n",
              " (1, 'physicist roentgen'),\n",
              " (1, 'physicist becquerel'),\n",
              " (1, 'physicist and chemist'),\n",
              " (1, 'physicist and'),\n",
              " (1, 'paris to study'),\n",
              " (1, 'paris to'),\n",
              " (1, 'over his teaching'),\n",
              " (1, 'over his'),\n",
              " (1, 'orderlies and doctors'),\n",
              " (1, 'orderlies and'),\n",
              " (1, 'opposition from male'),\n",
              " (1, 'opposition from'),\n",
              " (1, 'one of the'),\n",
              " (1, 'one of'),\n",
              " (1, 'one curie helped'),\n",
              " (1, 'one curie'),\n",
              " (1, 'on to win'),\n",
              " (1, 'on to'),\n",
              " (1, 'on the work'),\n",
              " (1, 'on the'),\n",
              " (1, 'on november 1867'),\n",
              " (1, 'on november'),\n",
              " (1, 'on july 1934'),\n",
              " (1, 'on july'),\n",
              " (1, 'of the year'),\n",
              " (1, 'of the school'),\n",
              " (1, 'of the nobel'),\n",
              " (1, 'of the most'),\n",
              " (1, 'of the german'),\n",
              " (1, 'of teacher'),\n",
              " (1, 'of rays in'),\n",
              " (1, 'of rays'),\n",
              " (1, 'of physics'),\n",
              " (1, 'of new chemical'),\n",
              " (1, 'of new'),\n",
              " (1, 'of its radiological'),\n",
              " (1, 'of its'),\n",
              " (1, 'of her time'),\n",
              " (1, 'of her'),\n",
              " (1, 'of another radium'),\n",
              " (1, 'of another'),\n",
              " (1, 'november 1867 the'),\n",
              " (1, 'november 1867'),\n",
              " (1, 'nobel prize in'),\n",
              " (1, 'new techniques'),\n",
              " (1, 'new chemical element'),\n",
              " (1, 'new chemical'),\n",
              " (1, 'never received significant'),\n",
              " (1, 'never received'),\n",
              " (1, 'most famous scientists'),\n",
              " (1, 'most famous'),\n",
              " (1, 'met pierre curie'),\n",
              " (1, 'met pierre'),\n",
              " (1, 'medical orderlies and'),\n",
              " (1, 'medical orderlies'),\n",
              " (1, 'mathematics at the'),\n",
              " (1, 'mathematics at'),\n",
              " (1, 'married in 1895'),\n",
              " (1, 'married in'),\n",
              " (1, 'marie took over'),\n",
              " (1, 'marie took'),\n",
              " (1, 'marie sklodowska was'),\n",
              " (1, 'marie sklodowska'),\n",
              " (1, 'marie curie was'),\n",
              " (1, 'marie curie'),\n",
              " (1, 'marie continued to'),\n",
              " (1, 'marie continued'),\n",
              " (1, 'male scientists in'),\n",
              " (1, 'male scientists'),\n",
              " (1, 'made her head'),\n",
              " (1, 'made her'),\n",
              " (1, 'life was cut'),\n",
              " (1, 'life was'),\n",
              " (1, 'leukaemia caused by'),\n",
              " (1, 'leukaemia caused'),\n",
              " (1, 'late 1920s her'),\n",
              " (1, 'late 1920s'),\n",
              " (1, 'knocked down and'),\n",
              " (1, 'knocked down'),\n",
              " (1, 'killed by carriage'),\n",
              " (1, 'killed by'),\n",
              " (1, 'july 1934 from'),\n",
              " (1, 'july 1934'),\n",
              " (1, 'july 1898 the'),\n",
              " (1, 'july 1898'),\n",
              " (1, 'its radiological service'),\n",
              " (1, 'its radiological'),\n",
              " (1, 'irene was herself'),\n",
              " (1, 'irene was'),\n",
              " (1, 'investigating radioactivity building'),\n",
              " (1, 'investigating radioactivity'),\n",
              " (1, 'international red cross'),\n",
              " (1, 'international red'),\n",
              " (1, 'in warsaw on'),\n",
              " (1, 'in warsaw'),\n",
              " (1, 'in the new'),\n",
              " (1, 'in the development'),\n",
              " (1, 'in surgery'),\n",
              " (1, 'in july 1898'),\n",
              " (1, 'in july'),\n",
              " (1, 'in france and'),\n",
              " (1, 'in france'),\n",
              " (1, 'in 1906 when'),\n",
              " (1, 'in 1906'),\n",
              " (1, 'in 1903 and'),\n",
              " (1, 'in 1895'),\n",
              " (1, 'in 1891 she'),\n",
              " (1, 'in 1891'),\n",
              " (1, 'husband pierre she'),\n",
              " (1, 'husband pierre'),\n",
              " (1, 'his teaching post'),\n",
              " (1, 'his teaching'),\n",
              " (1, 'high energy radiation'),\n",
              " (1, 'high energy'),\n",
              " (1, 'herself to continuing'),\n",
              " (1, 'herself to'),\n",
              " (1, 'herself scientist and'),\n",
              " (1, 'herself scientist'),\n",
              " (1, 'herself drove to'),\n",
              " (1, 'herself drove'),\n",
              " (1, 'her work'),\n",
              " (1, 'her time'),\n",
              " (1, 'her success marie'),\n",
              " (1, 'her success'),\n",
              " (1, 'her research'),\n",
              " (1, 'her husband pierre'),\n",
              " (1, 'her husband'),\n",
              " (1, 'her health was'),\n",
              " (1, 'her health'),\n",
              " (1, 'her head of'),\n",
              " (1, 'her head'),\n",
              " (1, 'helped to equip'),\n",
              " (1, 'helped to'),\n",
              " (1, 'held training courses'),\n",
              " (1, 'held training'),\n",
              " (1, 'health was beginning'),\n",
              " (1, 'health was'),\n",
              " (1, 'head of its'),\n",
              " (1, 'head of'),\n",
              " (1, 'he was knocked'),\n",
              " (1, 'he was'),\n",
              " (1, 'had begun together'),\n",
              " (1, 'had begun'),\n",
              " (1, 'great opposition from'),\n",
              " (1, 'great opposition'),\n",
              " (1, 'german physicist roentgen'),\n",
              " (1, 'german physicist'),\n",
              " (1, 'front lines'),\n",
              " (1, 'from male scientists'),\n",
              " (1, 'from male'),\n",
              " (1, 'from leukaemia caused'),\n",
              " (1, 'from leukaemia'),\n",
              " (1, 'from her work'),\n",
              " (1, 'from her research'),\n",
              " (1, 'french physicist becquerel'),\n",
              " (1, 'french physicist'),\n",
              " (1, 'france and she'),\n",
              " (1, 'france and'),\n",
              " (1, 'for physics in'),\n",
              " (1, 'for physics'),\n",
              " (1, 'for medical orderlies'),\n",
              " (1, 'for medical'),\n",
              " (1, 'for chemistry in'),\n",
              " (1, 'first woman to'),\n",
              " (1, 'first woman'),\n",
              " (1, 'financial benefits from'),\n",
              " (1, 'financial benefits'),\n",
              " (1, 'famous scientists of'),\n",
              " (1, 'famous scientists'),\n",
              " (1, 'face great opposition'),\n",
              " (1, 'face great'),\n",
              " (1, 'exposure to high'),\n",
              " (1, 'exposure to'),\n",
              " (1, 'equipment which she'),\n",
              " (1, 'equipment which'),\n",
              " (1, 'equip ambulances with'),\n",
              " (1, 'equip ambulances'),\n",
              " (1, 'energy radiation from'),\n",
              " (1, 'energy radiation'),\n",
              " (1, 'end of the'),\n",
              " (1, 'end of'),\n",
              " (1, 'element polonium'),\n",
              " (1, 'eldest daughter irene'),\n",
              " (1, 'eldest daughter'),\n",
              " (1, 'during world war'),\n",
              " (1, 'during world'),\n",
              " (1, 'drove to the'),\n",
              " (1, 'drove to'),\n",
              " (1, 'down and killed'),\n",
              " (1, 'down and'),\n",
              " (1, 'doctors in the'),\n",
              " (1, 'doctors in'),\n",
              " (1, 'discovery of new'),\n",
              " (1, 'discovery of another'),\n",
              " (1, 'died on july'),\n",
              " (1, 'died on'),\n",
              " (1, 'devoted herself to'),\n",
              " (1, 'devoted herself'),\n",
              " (1, 'development of rays'),\n",
              " (1, 'development of'),\n",
              " (1, 'despite her success'),\n",
              " (1, 'despite her'),\n",
              " (1, 'daughter of teacher'),\n",
              " (1, 'daughter of'),\n",
              " (1, 'daughter irene was'),\n",
              " (1, 'daughter irene'),\n",
              " (1, 'cut short in'),\n",
              " (1, 'cut short'),\n",
              " (1, 'curies worked together'),\n",
              " (1, 'curies worked'),\n",
              " (1, 'curies eldest daughter'),\n",
              " (1, 'curies eldest'),\n",
              " (1, 'curies announced the'),\n",
              " (1, 'curies announced'),\n",
              " (1, 'curies along with'),\n",
              " (1, 'curies along'),\n",
              " (1, 'curie was polish'),\n",
              " (1, 'curie was'),\n",
              " (1, 'curie research was'),\n",
              " (1, 'curie research'),\n",
              " (1, 'curie professor of'),\n",
              " (1, 'curie professor'),\n",
              " (1, 'curie helped to'),\n",
              " (1, 'curie helped'),\n",
              " (1, 'crucial in the'),\n",
              " (1, 'crucial in'),\n",
              " (1, 'cross made her'),\n",
              " (1, 'cross made'),\n",
              " (1, 'courses for medical'),\n",
              " (1, 'courses for'),\n",
              " (1, 'continuing the work'),\n",
              " (1, 'continuing the'),\n",
              " (1, 'continued to face'),\n",
              " (1, 'continued to'),\n",
              " (1, 'chemistry in 1911'),\n",
              " (1, 'chemistry in'),\n",
              " (1, 'chemist and one'),\n",
              " (1, 'chemist and'),\n",
              " (1, 'chemical element polonium'),\n",
              " (1, 'chemical element'),\n",
              " (1, 'caused by exposure'),\n",
              " (1, 'caused by'),\n",
              " (1, 'by the late'),\n",
              " (1, 'by the'),\n",
              " (1, 'by exposure to'),\n",
              " (1, 'by exposure'),\n",
              " (1, 'by carriage'),\n",
              " (1, 'building on the'),\n",
              " (1, 'building on'),\n",
              " (1, 'born physicist and'),\n",
              " (1, 'born physicist'),\n",
              " (1, 'born in warsaw'),\n",
              " (1, 'born in'),\n",
              " (1, 'benefits from her'),\n",
              " (1, 'benefits from'),\n",
              " (1, 'begun together'),\n",
              " (1, 'beginning to deteriorate'),\n",
              " (1, 'beginning to'),\n",
              " (1, 'becquerel were awarded'),\n",
              " (1, 'becquerel were'),\n",
              " (1, 'becoming the first'),\n",
              " (1, 'becoming the'),\n",
              " (1, 'at the end'),\n",
              " (1, 'another radium'),\n",
              " (1, 'another in 1911'),\n",
              " (1, 'another in'),\n",
              " (1, 'and winner of'),\n",
              " (1, 'and winner'),\n",
              " (1, 'and the french'),\n",
              " (1, 'and the'),\n",
              " (1, 'and she went'),\n",
              " (1, 'and she never'),\n",
              " (1, 'and she held'),\n",
              " (1, 'and one of'),\n",
              " (1, 'and one'),\n",
              " (1, 'and mathematics at'),\n",
              " (1, 'and mathematics'),\n",
              " (1, 'and killed by'),\n",
              " (1, 'and killed'),\n",
              " (1, 'and doctors in'),\n",
              " (1, 'and doctors'),\n",
              " (1, 'and devoted herself'),\n",
              " (1, 'and devoted'),\n",
              " (1, 'and chemist and'),\n",
              " (1, 'and chemist'),\n",
              " (1, 'ambulances with ray'),\n",
              " (1, 'ambulances with'),\n",
              " (1, 'along with becquerel'),\n",
              " (1, 'along with'),\n",
              " (1, '1934 from leukaemia'),\n",
              " (1, '1934 from'),\n",
              " (1, '1920s her health'),\n",
              " (1, '1920s her'),\n",
              " (1, '1906 when he'),\n",
              " (1, '1906 when'),\n",
              " (1, '1903 and she'),\n",
              " (1, '1903 and'),\n",
              " (1, '1898 the curies'),\n",
              " (1, '1898 the'),\n",
              " (1, '1891 she went'),\n",
              " (1, '1891 she'),\n",
              " (1, '1867 the daughter'),\n",
              " (1, '1867 the')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_word_list = sorted([(word_count[i], n_gram) for n_gram, i in vocabulary.items()], reverse=True)\n",
        "\n",
        "sorted_word_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHK7boq0mANb"
      },
      "source": [
        "### Using nltk to find ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFL5ttPZmANb",
        "outputId": "c593f3c5-fa78-4def-933a-d33b6b643af3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A bird in hand is worth two in the bush.',\n",
              " 'Good things come to those who wait.',\n",
              " 'These watches cost $1500! ',\n",
              " 'There are other fish in the sea.',\n",
              " 'The ball is in your court.',\n",
              " 'Mr. Smith Goes to Washington ',\n",
              " 'Doogie Howser M.D.']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icJwMOXImANc"
      },
      "outputs": [],
      "source": [
        "from nltk import bigrams\n",
        "from nltk import trigrams\n",
        "\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYTBJX9amANd",
        "outputId": "14f703db-4ebc-44ec-f717-f347fb507332"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A',\n",
              " 'bird',\n",
              " 'in',\n",
              " 'hand',\n",
              " 'is',\n",
              " 'worth',\n",
              " 'two',\n",
              " 'in',\n",
              " 'the',\n",
              " 'bush',\n",
              " '.',\n",
              " 'Good',\n",
              " 'things',\n",
              " 'come',\n",
              " 'to',\n",
              " 'those',\n",
              " 'who',\n",
              " 'wait',\n",
              " '.',\n",
              " 'These',\n",
              " 'watches',\n",
              " 'cost',\n",
              " '$',\n",
              " '1500',\n",
              " '!',\n",
              " 'There',\n",
              " 'are',\n",
              " 'other',\n",
              " 'fish',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sea',\n",
              " '.',\n",
              " 'The',\n",
              " 'ball',\n",
              " 'is',\n",
              " 'in',\n",
              " 'your',\n",
              " 'court',\n",
              " '.',\n",
              " 'Mr.',\n",
              " 'Smith',\n",
              " 'Goes',\n",
              " 'to',\n",
              " 'Washington',\n",
              " 'Doogie',\n",
              " 'Howser',\n",
              " 'M.D',\n",
              " '.']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = word_tokenize(\" \".join(train_text))\n",
        "\n",
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTi4DV1ImANe",
        "outputId": "b406898a-c8d3-4d9e-c42a-1d392a64cbf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'bird'),\n",
              " ('bird', 'in'),\n",
              " ('in', 'hand'),\n",
              " ('hand', 'is'),\n",
              " ('is', 'worth'),\n",
              " ('worth', 'two'),\n",
              " ('two', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'bush'),\n",
              " ('bush', '.'),\n",
              " ('.', 'Good'),\n",
              " ('Good', 'things'),\n",
              " ('things', 'come'),\n",
              " ('come', 'to'),\n",
              " ('to', 'those'),\n",
              " ('those', 'who'),\n",
              " ('who', 'wait'),\n",
              " ('wait', '.'),\n",
              " ('.', 'These'),\n",
              " ('These', 'watches'),\n",
              " ('watches', 'cost'),\n",
              " ('cost', '$'),\n",
              " ('$', '1500'),\n",
              " ('1500', '!'),\n",
              " ('!', 'There'),\n",
              " ('There', 'are'),\n",
              " ('are', 'other'),\n",
              " ('other', 'fish'),\n",
              " ('fish', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'sea'),\n",
              " ('sea', '.'),\n",
              " ('.', 'The'),\n",
              " ('The', 'ball'),\n",
              " ('ball', 'is'),\n",
              " ('is', 'in'),\n",
              " ('in', 'your'),\n",
              " ('your', 'court'),\n",
              " ('court', '.'),\n",
              " ('.', 'Mr.'),\n",
              " ('Mr.', 'Smith'),\n",
              " ('Smith', 'Goes'),\n",
              " ('Goes', 'to'),\n",
              " ('to', 'Washington'),\n",
              " ('Washington', 'Doogie'),\n",
              " ('Doogie', 'Howser'),\n",
              " ('Howser', 'M.D'),\n",
              " ('M.D', '.')]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_bigrams = bigrams(word_tokens)\n",
        "\n",
        "list(nltk_bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8quQOH3imANf",
        "outputId": "d6aa6b64-5dab-4585-8f2f-a145c85067c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'bird', 'in'),\n",
              " ('bird', 'in', 'hand'),\n",
              " ('in', 'hand', 'is'),\n",
              " ('hand', 'is', 'worth'),\n",
              " ('is', 'worth', 'two'),\n",
              " ('worth', 'two', 'in'),\n",
              " ('two', 'in', 'the'),\n",
              " ('in', 'the', 'bush'),\n",
              " ('the', 'bush', '.'),\n",
              " ('bush', '.', 'Good'),\n",
              " ('.', 'Good', 'things'),\n",
              " ('Good', 'things', 'come'),\n",
              " ('things', 'come', 'to'),\n",
              " ('come', 'to', 'those'),\n",
              " ('to', 'those', 'who'),\n",
              " ('those', 'who', 'wait'),\n",
              " ('who', 'wait', '.'),\n",
              " ('wait', '.', 'These'),\n",
              " ('.', 'These', 'watches'),\n",
              " ('These', 'watches', 'cost'),\n",
              " ('watches', 'cost', '$'),\n",
              " ('cost', '$', '1500'),\n",
              " ('$', '1500', '!'),\n",
              " ('1500', '!', 'There'),\n",
              " ('!', 'There', 'are'),\n",
              " ('There', 'are', 'other'),\n",
              " ('are', 'other', 'fish'),\n",
              " ('other', 'fish', 'in'),\n",
              " ('fish', 'in', 'the'),\n",
              " ('in', 'the', 'sea'),\n",
              " ('the', 'sea', '.'),\n",
              " ('sea', '.', 'The'),\n",
              " ('.', 'The', 'ball'),\n",
              " ('The', 'ball', 'is'),\n",
              " ('ball', 'is', 'in'),\n",
              " ('is', 'in', 'your'),\n",
              " ('in', 'your', 'court'),\n",
              " ('your', 'court', '.'),\n",
              " ('court', '.', 'Mr.'),\n",
              " ('.', 'Mr.', 'Smith'),\n",
              " ('Mr.', 'Smith', 'Goes'),\n",
              " ('Smith', 'Goes', 'to'),\n",
              " ('Goes', 'to', 'Washington'),\n",
              " ('to', 'Washington', 'Doogie'),\n",
              " ('Washington', 'Doogie', 'Howser'),\n",
              " ('Doogie', 'Howser', 'M.D'),\n",
              " ('Howser', 'M.D', '.')]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_trigrams = trigrams(word_tokens)\n",
        "\n",
        "list(nltk_trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUalmZ1bmANg",
        "outputId": "19496b53-98c7-4994-f2b0-0c9b735b49d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('A', 'bird', 'in', 'hand', 'is')\n",
            "('bird', 'in', 'hand', 'is', 'worth')\n",
            "('in', 'hand', 'is', 'worth', 'two')\n",
            "('hand', 'is', 'worth', 'two', 'in')\n",
            "('is', 'worth', 'two', 'in', 'the')\n",
            "('worth', 'two', 'in', 'the', 'bush')\n",
            "('two', 'in', 'the', 'bush', '.')\n",
            "('in', 'the', 'bush', '.', 'Good')\n",
            "('the', 'bush', '.', 'Good', 'things')\n",
            "('bush', '.', 'Good', 'things', 'come')\n",
            "('.', 'Good', 'things', 'come', 'to')\n",
            "('Good', 'things', 'come', 'to', 'those')\n",
            "('things', 'come', 'to', 'those', 'who')\n",
            "('come', 'to', 'those', 'who', 'wait')\n",
            "('to', 'those', 'who', 'wait', '.')\n",
            "('those', 'who', 'wait', '.', 'These')\n",
            "('who', 'wait', '.', 'These', 'watches')\n",
            "('wait', '.', 'These', 'watches', 'cost')\n",
            "('.', 'These', 'watches', 'cost', '$')\n",
            "('These', 'watches', 'cost', '$', '1500')\n",
            "('watches', 'cost', '$', '1500', '!')\n",
            "('cost', '$', '1500', '!', 'There')\n",
            "('$', '1500', '!', 'There', 'are')\n",
            "('1500', '!', 'There', 'are', 'other')\n",
            "('!', 'There', 'are', 'other', 'fish')\n",
            "('There', 'are', 'other', 'fish', 'in')\n",
            "('are', 'other', 'fish', 'in', 'the')\n",
            "('other', 'fish', 'in', 'the', 'sea')\n",
            "('fish', 'in', 'the', 'sea', '.')\n",
            "('in', 'the', 'sea', '.', 'The')\n",
            "('the', 'sea', '.', 'The', 'ball')\n",
            "('sea', '.', 'The', 'ball', 'is')\n",
            "('.', 'The', 'ball', 'is', 'in')\n",
            "('The', 'ball', 'is', 'in', 'your')\n",
            "('ball', 'is', 'in', 'your', 'court')\n",
            "('is', 'in', 'your', 'court', '.')\n",
            "('in', 'your', 'court', '.', 'Mr.')\n",
            "('your', 'court', '.', 'Mr.', 'Smith')\n",
            "('court', '.', 'Mr.', 'Smith', 'Goes')\n",
            "('.', 'Mr.', 'Smith', 'Goes', 'to')\n",
            "('Mr.', 'Smith', 'Goes', 'to', 'Washington')\n",
            "('Smith', 'Goes', 'to', 'Washington', 'Doogie')\n",
            "('Goes', 'to', 'Washington', 'Doogie', 'Howser')\n",
            "('to', 'Washington', 'Doogie', 'Howser', 'M.D')\n",
            "('Washington', 'Doogie', 'Howser', 'M.D', '.')\n"
          ]
        }
      ],
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "fivegrams = ngrams(word_tokens, 5)\n",
        "\n",
        "for grams in fivegrams:\n",
        "    print(grams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qRYVFvKmANh"
      },
      "source": [
        "* https://tedboy.github.io/nlps/generated/generated/nltk.BigramAssocMeasures\n",
        "* http://www.nltk.org/_modules/nltk/collocations.html#BigramCollocationFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqO8-XEqmANh"
      },
      "outputs": [],
      "source": [
        "from nltk.collocations import BigramAssocMeasures\n",
        "from nltk.collocations import BigramCollocationFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "337t9nJ8mANi"
      },
      "outputs": [],
      "source": [
        "word_tokens = word_tokenize(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "638n2dCmmANj",
        "outputId": "c78ed77d-e535-47ec-e3aa-24545d5b970e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('.', 'The'),\n",
              " ('of', 'the'),\n",
              " ('Nobel', 'Prize'),\n",
              " (',', 'and'),\n",
              " ('The', 'Curies'),\n",
              " ('and', 'she'),\n",
              " ('the', 'Nobel')]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_measures = BigramAssocMeasures()\n",
        "\n",
        "finder = BigramCollocationFinder.from_words(word_tokens)\n",
        "\n",
        "finder.apply_freq_filter(3)\n",
        "\n",
        "matches = finder.nbest(bigram_measures.raw_freq, 15)\n",
        "\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlsjsGjrmANk",
        "outputId": "a708a00f-7121-45b4-847d-ca05b3f01929"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('.', 'The'),\n",
              " ('of', 'the'),\n",
              " ('Nobel', 'Prize'),\n",
              " (',', 'and'),\n",
              " ('The', 'Curies'),\n",
              " ('and', 'she'),\n",
              " ('the', 'Nobel'),\n",
              " (',', 'she'),\n",
              " (',', 'the'),\n",
              " ('.', 'In'),\n",
              " ('.', 'Marie'),\n",
              " ('.', 'She'),\n",
              " ('1911', '.'),\n",
              " ('Prize', 'for'),\n",
              " ('announced', 'the')]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_measures = BigramAssocMeasures()\n",
        "\n",
        "finder = BigramCollocationFinder.from_words(word_tokens)\n",
        "\n",
        "finder.apply_freq_filter(2)\n",
        "\n",
        "matches = finder.nbest(bigram_measures.raw_freq, 15)\n",
        "\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP5BOm2lmANl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vKtLw-imANl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3rJHLwzmANm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoPbsSNKmANm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJS5BPLzmANn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vx-EEeEmANn"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 04-VectorizeText_TfidfTransformer_TfidfVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVizwrbymANo"
      },
      "source": [
        "<b>TfidfTransformer</b> :\n",
        "\n",
        "* Transform a count matrix to a normalized tf or tf-idf representation\n",
        "* Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evuJ0TDEmANo"
      },
      "source": [
        "* A <b>Term Frequency</b> is a count of how many times a word occurs in a given document (synonymous with bag of words).\n",
        "* The <b>Inverse Document Frequency</b> is the the number of times a word occurs in a corpus of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKRP-CtRmANp"
      },
      "source": [
        "The first step is to create our training and testing document set and computing the term frequency matrix\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLFWcsxPmANp"
      },
      "source": [
        "### Creating a count vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wggh0FdEmANp"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "train_text = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOIJOen0mANq"
      },
      "outputs": [],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "frequency_term_matrix = count_vectorizer.fit_transform(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYllThnrmANq",
        "outputId": "06f6b7dd-649e-4146-ea33-c94c708f7b73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACP8dz5LmANr",
        "outputId": "5829ff39-5c5a-40fc-a606-31e84a7a86e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_term_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz-5DruWmANr",
        "outputId": "27331609-3da1-41ec-ef4e-d75ab8448fb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_term_matrix.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dscXY6yemANs"
      },
      "source": [
        "### Building the tf-idf matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1q5kKDdmANs"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-qsSMJZmANs",
        "outputId": "ee76e0ee-7540-4d5a-a9ec-50f97b6edb6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector1 = tfidf_transformer.fit_transform(frequency_term_matrix)\n",
        "\n",
        "tfidf_vector1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7BXCmGdmANt",
        "outputId": "67fed9ad-3712-450c-ca45-ed97308bdbb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.34908308, 0.34908308,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34908308, 0.        , 0.49536976,\n",
              "        0.28976893, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24768488, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38665001, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.38665001, 0.38665001,\n",
              "        0.32095271, 0.        , 0.38665001, 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.40801493,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28949879,\n",
              "        0.        , 0.        , 0.40801493, 0.40801493, 0.        ,\n",
              "        0.28949879, 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.3274243 ,\n",
              "        0.38305686, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3274243 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46180424, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46180424, 0.        , 0.        , 0.46180424,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38333718, 0.        , 0.        , 0.46180424, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector1.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrfHtDoumANt",
        "outputId": "c85a981b-ef07-4df2-d735-f5a7335846ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.34908308 0.34908308 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.34908308 0.         0.49536976 0.28976893 0.         0.\n",
            "  0.         0.         0.24768488 0.         0.         0.\n",
            "  0.         0.         0.34908308 0.         0.         0.\n",
            "  0.         0.34908308 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.38665001\n",
            "  0.         0.         0.         0.         0.         0.38665001\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.38665001\n",
            "  0.38665001 0.32095271 0.         0.38665001 0.         0.\n",
            "  0.38665001 0.         0.        ]\n",
            " [0.5        0.         0.         0.         0.         0.\n",
            "  0.5        0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.5        0.\n",
            "  0.         0.         0.         0.         0.         0.5\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.40801493 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.40801493 0.         0.\n",
            "  0.         0.         0.28949879 0.         0.         0.40801493\n",
            "  0.40801493 0.         0.28949879 0.40801493 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.46146654 0.         0.         0.\n",
            "  0.         0.46146654 0.         0.         0.         0.\n",
            "  0.         0.         0.3274243  0.38305686 0.         0.\n",
            "  0.         0.         0.3274243  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.46146654]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.46180424 0.\n",
            "  0.         0.         0.         0.         0.46180424 0.\n",
            "  0.         0.46180424 0.         0.         0.         0.\n",
            "  0.         0.38333718 0.         0.         0.46180424 0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.70710678 0.         0.         0.\n",
            "  0.         0.70710678 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector1.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENAughhXmANu"
      },
      "source": [
        "## TfidfVectorizer = CountVectorizer + TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwrVERV2mANu"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB17y4hVmANu",
        "outputId": "a188bbb0-3623-425c-c472-5ac6dbc5a1e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 3,\n",
              " 'in': 14,\n",
              " 'hand': 12,\n",
              " 'is': 15,\n",
              " 'worth': 31,\n",
              " 'two': 26,\n",
              " 'the': 20,\n",
              " 'bush': 4,\n",
              " 'good': 11,\n",
              " 'things': 23,\n",
              " 'come': 5,\n",
              " 'to': 25,\n",
              " 'those': 24,\n",
              " 'who': 30,\n",
              " 'wait': 27,\n",
              " 'these': 22,\n",
              " 'watches': 29,\n",
              " 'cost': 6,\n",
              " '1500': 0,\n",
              " 'there': 21,\n",
              " 'are': 1,\n",
              " 'other': 17,\n",
              " 'fish': 9,\n",
              " 'sea': 18,\n",
              " 'ball': 2,\n",
              " 'your': 32,\n",
              " 'court': 7,\n",
              " 'mr': 16,\n",
              " 'smith': 19,\n",
              " 'goes': 10,\n",
              " 'washington': 28,\n",
              " 'doogie': 8,\n",
              " 'howser': 13}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2 = tfidf_vectorizer.fit_transform(train_text)\n",
        "\n",
        "tfidf_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DARK4U4hmANv",
        "outputId": "d4db32f4-4cd2-4133-bd0a-77686b644634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55c68TMfmANv",
        "outputId": "dcd5a31f-b2ff-4287-acf2-58923b780a85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.38629436, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436, 2.38629436, 1.69314718,\n",
              "       1.98082925, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       1.69314718, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       1.98082925, 2.38629436, 2.38629436, 2.38629436, 2.38629436,\n",
              "       2.38629436, 2.38629436, 2.38629436])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer.idf_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4oi07IrmANw",
        "outputId": "d439762d-0ea5-4082-d28e-b03b73bfa7d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'1500': 2.386294361119891,\n",
              " 'are': 2.386294361119891,\n",
              " 'ball': 2.386294361119891,\n",
              " 'bird': 2.386294361119891,\n",
              " 'bush': 2.386294361119891,\n",
              " 'come': 2.386294361119891,\n",
              " 'cost': 2.386294361119891,\n",
              " 'court': 2.386294361119891,\n",
              " 'doogie': 2.386294361119891,\n",
              " 'fish': 2.386294361119891,\n",
              " 'goes': 2.386294361119891,\n",
              " 'good': 2.386294361119891,\n",
              " 'hand': 2.386294361119891,\n",
              " 'howser': 2.386294361119891,\n",
              " 'in': 1.6931471805599454,\n",
              " 'is': 1.9808292530117262,\n",
              " 'mr': 2.386294361119891,\n",
              " 'other': 2.386294361119891,\n",
              " 'sea': 2.386294361119891,\n",
              " 'smith': 2.386294361119891,\n",
              " 'the': 1.6931471805599454,\n",
              " 'there': 2.386294361119891,\n",
              " 'these': 2.386294361119891,\n",
              " 'things': 2.386294361119891,\n",
              " 'those': 2.386294361119891,\n",
              " 'to': 1.9808292530117262,\n",
              " 'two': 2.386294361119891,\n",
              " 'wait': 2.386294361119891,\n",
              " 'washington': 2.386294361119891,\n",
              " 'watches': 2.386294361119891,\n",
              " 'who': 2.386294361119891,\n",
              " 'worth': 2.386294361119891,\n",
              " 'your': 2.386294361119891}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_DWohmimANw"
      },
      "source": [
        "### Final scorings of each word from the other words in the vocabulary.\n",
        "* The scores are normalized to values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB6rs8VKmANx",
        "outputId": "d9c02e12-0b83-4595-beeb-66e60306c37e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.34908308, 0.34908308,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34908308, 0.        , 0.49536976,\n",
              "        0.28976893, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24768488, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34908308, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38665001, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.38665001, 0.38665001,\n",
              "        0.32095271, 0.        , 0.38665001, 0.        , 0.        ,\n",
              "        0.38665001, 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.40801493,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.28949879,\n",
              "        0.        , 0.        , 0.40801493, 0.40801493, 0.        ,\n",
              "        0.28949879, 0.40801493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.3274243 ,\n",
              "        0.38305686, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3274243 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46146654],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46180424, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46180424, 0.        , 0.        , 0.46180424,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.38333718, 0.        , 0.        , 0.46180424, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vector2.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O18UNrdEmANx",
        "outputId": "6d5579dd-a30f-4b23-a266-8fbf2722fe7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3)\t0.3490830767264469\n",
            "  (0, 14)\t0.49536975552604884\n",
            "  (0, 12)\t0.3490830767264469\n",
            "  (0, 15)\t0.2897689326921819\n",
            "  (0, 31)\t0.3490830767264469\n",
            "  (0, 26)\t0.3490830767264469\n",
            "  (0, 20)\t0.24768487776302442\n",
            "  (0, 4)\t0.3490830767264469\n",
            "  (1, 11)\t0.386650005027498\n",
            "  (1, 23)\t0.386650005027498\n",
            "  (1, 5)\t0.386650005027498\n",
            "  (1, 25)\t0.32095270940344806\n",
            "  (1, 24)\t0.386650005027498\n",
            "  (1, 30)\t0.386650005027498\n",
            "  (1, 27)\t0.386650005027498\n",
            "  (2, 22)\t0.5\n",
            "  (2, 29)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (2, 0)\t0.5\n",
            "  (3, 14)\t0.2894987873064995\n",
            "  (3, 20)\t0.2894987873064995\n",
            "  (3, 21)\t0.40801492725049476\n",
            "  (3, 1)\t0.40801492725049476\n",
            "  (3, 17)\t0.40801492725049476\n",
            "  (3, 9)\t0.40801492725049476\n",
            "  (3, 18)\t0.40801492725049476\n",
            "  (4, 14)\t0.3274243027464032\n",
            "  (4, 15)\t0.38305685676572565\n",
            "  (4, 20)\t0.3274243027464032\n",
            "  (4, 2)\t0.4614665377636916\n",
            "  (4, 32)\t0.4614665377636916\n",
            "  (4, 7)\t0.4614665377636916\n",
            "  (5, 25)\t0.38333717539523177\n",
            "  (5, 16)\t0.4618042361109319\n",
            "  (5, 19)\t0.4618042361109319\n",
            "  (5, 10)\t0.4618042361109319\n",
            "  (5, 28)\t0.4618042361109319\n",
            "  (6, 8)\t0.7071067811865476\n",
            "  (6, 13)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7GDR7-UmANy",
        "outputId": "969d0f9d-8d79-45fc-a299-ff8a196c1305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 31)\t0.34908307672644684\n",
            "  (0, 26)\t0.34908307672644684\n",
            "  (0, 20)\t0.2476848777630244\n",
            "  (0, 15)\t0.2897689326921819\n",
            "  (0, 14)\t0.4953697555260488\n",
            "  (0, 12)\t0.34908307672644684\n",
            "  (0, 4)\t0.34908307672644684\n",
            "  (0, 3)\t0.34908307672644684\n",
            "  (1, 30)\t0.386650005027498\n",
            "  (1, 27)\t0.386650005027498\n",
            "  (1, 25)\t0.32095270940344806\n",
            "  (1, 24)\t0.386650005027498\n",
            "  (1, 23)\t0.386650005027498\n",
            "  (1, 11)\t0.386650005027498\n",
            "  (1, 5)\t0.386650005027498\n",
            "  (2, 29)\t0.5\n",
            "  (2, 22)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (2, 0)\t0.5\n",
            "  (3, 21)\t0.40801492725049476\n",
            "  (3, 20)\t0.2894987873064995\n",
            "  (3, 18)\t0.40801492725049476\n",
            "  (3, 17)\t0.40801492725049476\n",
            "  (3, 14)\t0.2894987873064995\n",
            "  (3, 9)\t0.40801492725049476\n",
            "  (3, 1)\t0.40801492725049476\n",
            "  (4, 32)\t0.4614665377636916\n",
            "  (4, 20)\t0.3274243027464032\n",
            "  (4, 15)\t0.38305685676572565\n",
            "  (4, 14)\t0.3274243027464032\n",
            "  (4, 7)\t0.4614665377636916\n",
            "  (4, 2)\t0.4614665377636916\n",
            "  (5, 28)\t0.4618042361109319\n",
            "  (5, 25)\t0.38333717539523177\n",
            "  (5, 19)\t0.4618042361109319\n",
            "  (5, 16)\t0.4618042361109319\n",
            "  (5, 10)\t0.4618042361109319\n",
            "  (6, 13)\t0.7071067811865476\n",
            "  (6, 8)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vector1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clpNzfUzmANy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDxjyA9dmANz"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 05-StopwordAndFrequencyFiltering</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnN-O8phmANz"
      },
      "source": [
        "## Remove Stop Words Using NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZK4FvT61mANz"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVOX4wgVmAN0",
        "outputId": "a656019e-6f02-4c1d-d682-bfb7fd435631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['arabic', 'azerbaijani', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish', 'turkish']\n"
          ]
        }
      ],
      "source": [
        "print(stopwords.fileids())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5N_TAeXmAN1",
        "outputId": "a339a1c4-ec90-40e8-d1f0-4f4279904b17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI7egMozmAN1",
        "outputId": "b71ff095-cf68-4bfc-a5b3-b2d752c244f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['إذ',\n",
              " 'إذا',\n",
              " 'إذما',\n",
              " 'إذن',\n",
              " 'أف',\n",
              " 'أقل',\n",
              " 'أكثر',\n",
              " 'ألا',\n",
              " 'إلا',\n",
              " 'التي',\n",
              " 'الذي',\n",
              " 'الذين',\n",
              " 'اللاتي',\n",
              " 'اللائي',\n",
              " 'اللتان',\n",
              " 'اللتيا',\n",
              " 'اللتين',\n",
              " 'اللذان',\n",
              " 'اللذين',\n",
              " 'اللواتي',\n",
              " 'إلى',\n",
              " 'إليك',\n",
              " 'إليكم',\n",
              " 'إليكما',\n",
              " 'إليكن',\n",
              " 'أم',\n",
              " 'أما',\n",
              " 'أما',\n",
              " 'إما',\n",
              " 'أن',\n",
              " 'إن',\n",
              " 'إنا',\n",
              " 'أنا',\n",
              " 'أنت',\n",
              " 'أنتم',\n",
              " 'أنتما',\n",
              " 'أنتن',\n",
              " 'إنما',\n",
              " 'إنه',\n",
              " 'أنى',\n",
              " 'أنى',\n",
              " 'آه',\n",
              " 'آها',\n",
              " 'أو',\n",
              " 'أولاء',\n",
              " 'أولئك',\n",
              " 'أوه',\n",
              " 'آي',\n",
              " 'أي',\n",
              " 'أيها',\n",
              " 'إي',\n",
              " 'أين',\n",
              " 'أين',\n",
              " 'أينما',\n",
              " 'إيه',\n",
              " 'بخ',\n",
              " 'بس',\n",
              " 'بعد',\n",
              " 'بعض',\n",
              " 'بك',\n",
              " 'بكم',\n",
              " 'بكم',\n",
              " 'بكما',\n",
              " 'بكن',\n",
              " 'بل',\n",
              " 'بلى',\n",
              " 'بما',\n",
              " 'بماذا',\n",
              " 'بمن',\n",
              " 'بنا',\n",
              " 'به',\n",
              " 'بها',\n",
              " 'بهم',\n",
              " 'بهما',\n",
              " 'بهن',\n",
              " 'بي',\n",
              " 'بين',\n",
              " 'بيد',\n",
              " 'تلك',\n",
              " 'تلكم',\n",
              " 'تلكما',\n",
              " 'ته',\n",
              " 'تي',\n",
              " 'تين',\n",
              " 'تينك',\n",
              " 'ثم',\n",
              " 'ثمة',\n",
              " 'حاشا',\n",
              " 'حبذا',\n",
              " 'حتى',\n",
              " 'حيث',\n",
              " 'حيثما',\n",
              " 'حين',\n",
              " 'خلا',\n",
              " 'دون',\n",
              " 'ذا',\n",
              " 'ذات',\n",
              " 'ذاك',\n",
              " 'ذان',\n",
              " 'ذانك',\n",
              " 'ذلك',\n",
              " 'ذلكم',\n",
              " 'ذلكما',\n",
              " 'ذلكن',\n",
              " 'ذه',\n",
              " 'ذو',\n",
              " 'ذوا',\n",
              " 'ذواتا',\n",
              " 'ذواتي',\n",
              " 'ذي',\n",
              " 'ذين',\n",
              " 'ذينك',\n",
              " 'ريث',\n",
              " 'سوف',\n",
              " 'سوى',\n",
              " 'شتان',\n",
              " 'عدا',\n",
              " 'عسى',\n",
              " 'عل',\n",
              " 'على',\n",
              " 'عليك',\n",
              " 'عليه',\n",
              " 'عما',\n",
              " 'عن',\n",
              " 'عند',\n",
              " 'غير',\n",
              " 'فإذا',\n",
              " 'فإن',\n",
              " 'فلا',\n",
              " 'فمن',\n",
              " 'في',\n",
              " 'فيم',\n",
              " 'فيما',\n",
              " 'فيه',\n",
              " 'فيها',\n",
              " 'قد',\n",
              " 'كأن',\n",
              " 'كأنما',\n",
              " 'كأي',\n",
              " 'كأين',\n",
              " 'كذا',\n",
              " 'كذلك',\n",
              " 'كل',\n",
              " 'كلا',\n",
              " 'كلاهما',\n",
              " 'كلتا',\n",
              " 'كلما',\n",
              " 'كليكما',\n",
              " 'كليهما',\n",
              " 'كم',\n",
              " 'كم',\n",
              " 'كما',\n",
              " 'كي',\n",
              " 'كيت',\n",
              " 'كيف',\n",
              " 'كيفما',\n",
              " 'لا',\n",
              " 'لاسيما',\n",
              " 'لدى',\n",
              " 'لست',\n",
              " 'لستم',\n",
              " 'لستما',\n",
              " 'لستن',\n",
              " 'لسن',\n",
              " 'لسنا',\n",
              " 'لعل',\n",
              " 'لك',\n",
              " 'لكم',\n",
              " 'لكما',\n",
              " 'لكن',\n",
              " 'لكنما',\n",
              " 'لكي',\n",
              " 'لكيلا',\n",
              " 'لم',\n",
              " 'لما',\n",
              " 'لن',\n",
              " 'لنا',\n",
              " 'له',\n",
              " 'لها',\n",
              " 'لهم',\n",
              " 'لهما',\n",
              " 'لهن',\n",
              " 'لو',\n",
              " 'لولا',\n",
              " 'لوما',\n",
              " 'لي',\n",
              " 'لئن',\n",
              " 'ليت',\n",
              " 'ليس',\n",
              " 'ليسا',\n",
              " 'ليست',\n",
              " 'ليستا',\n",
              " 'ليسوا',\n",
              " 'ما',\n",
              " 'ماذا',\n",
              " 'متى',\n",
              " 'مذ',\n",
              " 'مع',\n",
              " 'مما',\n",
              " 'ممن',\n",
              " 'من',\n",
              " 'منه',\n",
              " 'منها',\n",
              " 'منذ',\n",
              " 'مه',\n",
              " 'مهما',\n",
              " 'نحن',\n",
              " 'نحو',\n",
              " 'نعم',\n",
              " 'ها',\n",
              " 'هاتان',\n",
              " 'هاته',\n",
              " 'هاتي',\n",
              " 'هاتين',\n",
              " 'هاك',\n",
              " 'هاهنا',\n",
              " 'هذا',\n",
              " 'هذان',\n",
              " 'هذه',\n",
              " 'هذي',\n",
              " 'هذين',\n",
              " 'هكذا',\n",
              " 'هل',\n",
              " 'هلا',\n",
              " 'هم',\n",
              " 'هما',\n",
              " 'هن',\n",
              " 'هنا',\n",
              " 'هناك',\n",
              " 'هنالك',\n",
              " 'هو',\n",
              " 'هؤلاء',\n",
              " 'هي',\n",
              " 'هيا',\n",
              " 'هيت',\n",
              " 'هيهات',\n",
              " 'والذي',\n",
              " 'والذين',\n",
              " 'وإذ',\n",
              " 'وإذا',\n",
              " 'وإن',\n",
              " 'ولا',\n",
              " 'ولكن',\n",
              " 'ولو',\n",
              " 'وما',\n",
              " 'ومن',\n",
              " 'وهو',\n",
              " 'يا']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords.words('arabic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqgr0bwCmAN2",
        "outputId": "54cd2e24-8858-4bd1-ac7f-169c380b7404"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A bird in hand is worth two in the bush. Good things come to those who wait. These watches cost $1500!  There are other fish in the sea. The ball is in your court. Mr. Smith Goes to Washington  Doogie Howser M.D.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_array = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]\n",
        "\n",
        "text = \" \".join(text_array)\n",
        "\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWi9NynSmAN2",
        "outputId": "bec62164-e50b-4d4d-c572-e2067f197ab0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A',\n",
              " 'bird',\n",
              " 'in',\n",
              " 'hand',\n",
              " 'is',\n",
              " 'worth',\n",
              " 'two',\n",
              " 'in',\n",
              " 'the',\n",
              " 'bush',\n",
              " '.',\n",
              " 'Good',\n",
              " 'things',\n",
              " 'come',\n",
              " 'to',\n",
              " 'those',\n",
              " 'who',\n",
              " 'wait',\n",
              " '.',\n",
              " 'These',\n",
              " 'watches',\n",
              " 'cost',\n",
              " '$',\n",
              " '1500',\n",
              " '!',\n",
              " 'There',\n",
              " 'are',\n",
              " 'other',\n",
              " 'fish',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sea',\n",
              " '.',\n",
              " 'The',\n",
              " 'ball',\n",
              " 'is',\n",
              " 'in',\n",
              " 'your',\n",
              " 'court',\n",
              " '.',\n",
              " 'Mr.',\n",
              " 'Smith',\n",
              " 'Goes',\n",
              " 'to',\n",
              " 'Washington',\n",
              " 'Doogie',\n",
              " 'Howser',\n",
              " 'M.D',\n",
              " '.']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = word_tokenize(text)\n",
        "\n",
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wob8Y0w0mAN3",
        "outputId": "7ae76f20-7da1-462e-a576-7552eb624952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'bird', 'hand', 'worth', 'two', 'bush', '.', 'Good', 'things', 'come', 'wait', '.', 'These', 'watches', 'cost', '$', '1500', '!', 'There', 'fish', 'sea', '.', 'The', 'ball', 'court', '.', 'Mr.', 'Smith', 'Goes', 'Washington', 'Doogie', 'Howser', 'M.D', '.']\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_words = []\n",
        "\n",
        "for word in word_tokens:\n",
        "    if word not in stop_words:\n",
        "        filtered_words.append(word)\n",
        "\n",
        "print(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYMU69QMmAN3"
      },
      "outputs": [],
      "source": [
        "with open(\"./datasets/file.txt\", \"w\") as f:\n",
        "    for word in filtered_words:\n",
        "        f.write(word)\n",
        "        f.write(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RYiZukNmAN4",
        "outputId": "8a8e739a-2359-4018-dec3-c3ec1622d7a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A bird hand worth two bush . Good things come wait . These watches cost $ 1500 ! There fish sea . The ball court . Mr. Smith Goes Washington Doogie Howser M.D . \n"
          ]
        }
      ],
      "source": [
        "with open(\"./datasets/file.txt\", \"r\") as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irE-y7llmAN4",
        "outputId": "4cc04b1f-1ee1-4e76-c997-13d656dd6e67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit([file_contents])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Acnl-UBgmAN5",
        "outputId": "2237daef-63e7-4168-8e82-4a4098593e56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 25)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector = count_vectorizer.transform(text_array)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spLb8KBhmAN5"
      },
      "outputs": [],
      "source": [
        "feature_names_nltk = count_vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12IwOHDpmAN6",
        "outputId": "81ff6a0f-8b3a-4861-ee26-e5273cd19f2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bird': 2,\n",
              " 'hand': 11,\n",
              " 'worth': 24,\n",
              " 'two': 20,\n",
              " 'bush': 3,\n",
              " 'good': 10,\n",
              " 'things': 19,\n",
              " 'come': 4,\n",
              " 'wait': 21,\n",
              " 'these': 18,\n",
              " 'watches': 23,\n",
              " 'cost': 5,\n",
              " '1500': 0,\n",
              " 'there': 17,\n",
              " 'fish': 8,\n",
              " 'sea': 14,\n",
              " 'the': 16,\n",
              " 'ball': 1,\n",
              " 'court': 6,\n",
              " 'mr': 13,\n",
              " 'smith': 15,\n",
              " 'goes': 9,\n",
              " 'washington': 22,\n",
              " 'doogie': 7,\n",
              " 'howser': 12}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLjxx9wPmAOB",
        "outputId": "56687be1-e2e1-4fa9-d570-ecc9d48f447b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "        0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMnjGTvemAOB",
        "outputId": "1705b81b-709d-41a6-a180-5b652f2ab8d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['bird', 'bush', 'hand', 'the', 'two', 'worth'], dtype='<U10'),\n",
              " array(['come', 'good', 'things', 'wait'], dtype='<U10'),\n",
              " array(['1500', 'cost', 'these', 'watches'], dtype='<U10'),\n",
              " array(['fish', 'sea', 'the', 'there'], dtype='<U10'),\n",
              " array(['ball', 'court', 'the'], dtype='<U10'),\n",
              " array(['goes', 'mr', 'smith', 'washington'], dtype='<U10'),\n",
              " array(['doogie', 'howser'], dtype='<U10')]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.inverse_transform(transformed_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAt7vjLWmAOC"
      },
      "source": [
        "## Remove Stop Words Using sklearn\n",
        "\n",
        "The stop_words='english' parameter is not recommended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzz5NuDMmAOD",
        "outputId": "91410849-ef2a-4192-fb37-a497d2a09e4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 21)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(text_array)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ8FFmSqmAOD"
      },
      "outputs": [],
      "source": [
        "feature_names_sklearn = count_vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnyQjFJgmAOE",
        "outputId": "18e96593-f9d3-435d-f94b-d77589ccbd98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N57p0J-rmAOF",
        "outputId": "8f80dcba-bbd8-40f8-ca97-4d20209edd9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['bush', 'worth', 'hand', 'bird'], dtype='<U10'),\n",
              " array(['wait', 'come', 'things', 'good'], dtype='<U10'),\n",
              " array(['1500', 'cost', 'watches'], dtype='<U10'),\n",
              " array(['sea', 'fish'], dtype='<U10'),\n",
              " array(['court', 'ball'], dtype='<U10'),\n",
              " array(['washington', 'goes', 'smith', 'mr'], dtype='<U10'),\n",
              " array(['howser', 'doogie'], dtype='<U10')]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.inverse_transform(transformed_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13zw8izmmAOF"
      },
      "source": [
        "## Set difference of both"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb0ltBQ5mAOG"
      },
      "outputs": [],
      "source": [
        "def set_diff(first, second):\n",
        "        second = set(second)\n",
        "        return [item for item in first if item not in second]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbfeZnuAmAOH",
        "outputId": "765f8d09-a9f6-4222-d707-9d6b4ffa6d37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_diff(feature_names_sklearn, feature_names_nltk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw4xh2fSmAOI",
        "outputId": "5d096ff4-a36b-4e25-fa81-b58a9412da66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the', 'there', 'these', 'two']"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_diff(feature_names_nltk, feature_names_sklearn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7-FET-HmAOI"
      },
      "source": [
        "## Filtering words based on frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P97pTYlHmAOJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups = fetch_20newsgroups(subset='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMC9aXQPmAOJ",
        "outputId": "e5b463a6-9c88-419d-abfd-ce508823b975"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newsgroups.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-RJdycKmAOK",
        "outputId": "b06768cc-9f97-417e-b16b-fe3f13e179c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(newsgroups.data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI1JV1jGmAOL",
        "outputId": "3ab8ed5a-1bd2-420d-9141-791761f0c789"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newsgroups.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFnyXVv1mAOM"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn-feature-extraction-text-countvectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPcxcrV2mAOM",
        "outputId": "dc0be3ae-f7e0-4b6f-bbc6-0c293accf6e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR5GkzymmAON",
        "outputId": "e97b261a-44fb-4096-cd2e-f9a111ac0189"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 130094)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0.0, max_df=0.7)\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S-RFfzfmAOO",
        "outputId": "250892a2-5359-460c-844f-1c4787ce49e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 2155)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0.01, max_df=0.7)\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GMnaKg1mAOO",
        "outputId": "93c10f32-c5a9-4195-d608-2f9e4204fae3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 127701)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0, max_df=100)\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2JhH9ANmAOP",
        "outputId": "9c920746-3455-4772-a61f-09db909c5550"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 54030)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=2, max_df=100)\n",
        "\n",
        "transformed_vector = count_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "transformed_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHtVMqygmAOQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qag2ze9PmAOQ"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 06-Stemming</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWfumxqumAOR"
      },
      "source": [
        "# Stemming Words with NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19TIHlU5mAOR"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.stem import *\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir_TfP-amAOS"
      },
      "source": [
        "### PorterStemmer\n",
        "* PorterStemmer uses Suffix Stripping to produce stems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKMj2KYSmAOS"
      },
      "outputs": [],
      "source": [
        "input_tokens = ['overwhelming', 'overwhelmingly',\n",
        "                'hushed', 'hush',\n",
        "                'functional', 'functionally',\n",
        "                'lying', 'lied',\n",
        "                'fairly',\n",
        "                'destabilize', 'stability',\n",
        "                'friendship', 'friendships', 'friendly', 'friendless',\n",
        "                'connect', 'connections', 'connected',\n",
        "                'the', 'these', 'those',\n",
        "                'motivational', 'motivate', 'motivating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftjBWANxmAOT"
      },
      "outputs": [],
      "source": [
        "ps = PorterStemmer()\n",
        "\n",
        "ps_stemmed_tokens = []\n",
        "for token in input_tokens:\n",
        "    ps_stemmed_tokens.append(ps.stem(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyy9Z1BzmAOU",
        "outputId": "ef7a3e99-5b89-44a3-ddd4-98b9ba289224"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Porter Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelmingli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fairli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>destabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friendli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words  Porter Stemmer\n",
              "0     overwhelming       overwhelm\n",
              "1   overwhelmingly  overwhelmingli\n",
              "2           hushed            hush\n",
              "3             hush            hush\n",
              "4       functional        function\n",
              "5     functionally        function\n",
              "6            lying             lie\n",
              "7             lied             lie\n",
              "8           fairly          fairli\n",
              "9      destabilize        destabil\n",
              "10       stability          stabil\n",
              "11      friendship      friendship\n",
              "12     friendships      friendship\n",
              "13        friendly        friendli\n",
              "14      friendless      friendless\n",
              "15         connect         connect\n",
              "16     connections         connect\n",
              "17       connected         connect\n",
              "18             the             the\n",
              "19           these           these\n",
              "20           those           those\n",
              "21    motivational           motiv\n",
              "22        motivate           motiv\n",
              "23      motivating           motiv"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Porter Stemmer': ps_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N08Lcrg6mAOU"
      },
      "source": [
        "### LancasterStemmer\n",
        "* The LancasterStemmer (Paice-Husk stemmer) is an iterative algorithm with rules saved externally.\n",
        "* LancasterStemmer is simple, but heavy stemming due to iterations and over-stemming may occur.\n",
        "* Over-stemming causes the stems to be not linguistic, or they may have no meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_pkL23NmAOV"
      },
      "outputs": [],
      "source": [
        "ls = LancasterStemmer()\n",
        "\n",
        "ls_stemmed_tokens = []\n",
        "for token in input_tokens:\n",
        "    ls_stemmed_tokens.append(ls.stem(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XpoWAgCmAOV",
        "outputId": "0ac2db77-ee50-44bf-ad0f-0d9297d862c8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Lancaster Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>funct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>funct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>dest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>thes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>thos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words Lancaster Stemmer\n",
              "0     overwhelming         overwhelm\n",
              "1   overwhelmingly         overwhelm\n",
              "2           hushed              hush\n",
              "3             hush              hush\n",
              "4       functional             funct\n",
              "5     functionally             funct\n",
              "6            lying             lying\n",
              "7             lied              lied\n",
              "8           fairly              fair\n",
              "9      destabilize              dest\n",
              "10       stability             stabl\n",
              "11      friendship            friend\n",
              "12     friendships            friend\n",
              "13        friendly            friend\n",
              "14      friendless        friendless\n",
              "15         connect           connect\n",
              "16     connections           connect\n",
              "17       connected           connect\n",
              "18             the               the\n",
              "19           these              thes\n",
              "20           those              thos\n",
              "21    motivational               mot\n",
              "22        motivate               mot\n",
              "23      motivating               mot"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Lancaster Stemmer': ls_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0DP_6QJmAOW",
        "outputId": "d16782fd-56d1-435b-c762-f3eb36ab50d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Porter Stemmer</th>\n",
              "      <th>Lancaster Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelmingli</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "      <td>funct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "      <td>funct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "      <td>lying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "      <td>lied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fairli</td>\n",
              "      <td>fair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>destabil</td>\n",
              "      <td>dest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabil</td>\n",
              "      <td>stabl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friendli</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "      <td>thes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "      <td>thos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words  Porter Stemmer Lancaster Stemmer\n",
              "0     overwhelming       overwhelm         overwhelm\n",
              "1   overwhelmingly  overwhelmingli         overwhelm\n",
              "2           hushed            hush              hush\n",
              "3             hush            hush              hush\n",
              "4       functional        function             funct\n",
              "5     functionally        function             funct\n",
              "6            lying             lie             lying\n",
              "7             lied             lie              lied\n",
              "8           fairly          fairli              fair\n",
              "9      destabilize        destabil              dest\n",
              "10       stability          stabil             stabl\n",
              "11      friendship      friendship            friend\n",
              "12     friendships      friendship            friend\n",
              "13        friendly        friendli            friend\n",
              "14      friendless      friendless        friendless\n",
              "15         connect         connect           connect\n",
              "16     connections         connect           connect\n",
              "17       connected         connect           connect\n",
              "18             the             the               the\n",
              "19           these           these              thes\n",
              "20           those           those              thos\n",
              "21    motivational           motiv               mot\n",
              "22        motivate           motiv               mot\n",
              "23      motivating           motiv               mot"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Porter Stemmer': ps_stemmed_tokens,\n",
        "    'Lancaster Stemmer': ls_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvwCURUxmAOW"
      },
      "source": [
        "### SnowballStemmer\n",
        "* One can generate its own set of rules for any language that is why Python nltk introduced SnowballStemmers that are used to create non-English Stemmers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndI8Dp4KmAOX",
        "outputId": "0fbc44c7-a3a9-4785-de1a-ece36cebf684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
          ]
        }
      ],
      "source": [
        "print(SnowballStemmer.languages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRy6MGKBmAOY"
      },
      "outputs": [],
      "source": [
        "ss =  SnowballStemmer('english')\n",
        "\n",
        "ss_stemmed_tokens = []\n",
        "for token in input_tokens:\n",
        "    ss_stemmed_tokens.append(ss.stem(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saRVdLFfmAOY",
        "outputId": "572b5b5a-9c03-4ffe-a767-8de9398f7b96"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Snowball Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>destabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words Snowball Stemmer\n",
              "0     overwhelming        overwhelm\n",
              "1   overwhelmingly        overwhelm\n",
              "2           hushed             hush\n",
              "3             hush             hush\n",
              "4       functional         function\n",
              "5     functionally         function\n",
              "6            lying              lie\n",
              "7             lied              lie\n",
              "8           fairly             fair\n",
              "9      destabilize         destabil\n",
              "10       stability           stabil\n",
              "11      friendship       friendship\n",
              "12     friendships       friendship\n",
              "13        friendly           friend\n",
              "14      friendless       friendless\n",
              "15         connect          connect\n",
              "16     connections          connect\n",
              "17       connected          connect\n",
              "18             the              the\n",
              "19           these            these\n",
              "20           those            those\n",
              "21    motivational            motiv\n",
              "22        motivate            motiv\n",
              "23      motivating            motiv"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Snowball Stemmer': ss_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-mbnlC9mAOY",
        "outputId": "68ab3dfb-2d41-4458-9e00-77e5b24505d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Porter Stemmer</th>\n",
              "      <th>Lancaster Stemmer</th>\n",
              "      <th>Snowball Stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>overwhelming</td>\n",
              "      <td>overwhelm</td>\n",
              "      <td>overwhelm</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>overwhelmingly</td>\n",
              "      <td>overwhelmingli</td>\n",
              "      <td>overwhelm</td>\n",
              "      <td>overwhelm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "      <td>funct</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "      <td>funct</td>\n",
              "      <td>function</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fairly</td>\n",
              "      <td>fairli</td>\n",
              "      <td>fair</td>\n",
              "      <td>fair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>destabilize</td>\n",
              "      <td>destabil</td>\n",
              "      <td>dest</td>\n",
              "      <td>destabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stability</td>\n",
              "      <td>stabil</td>\n",
              "      <td>stabl</td>\n",
              "      <td>stabil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friendli</td>\n",
              "      <td>friend</td>\n",
              "      <td>friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>connections</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>connected</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "      <td>thes</td>\n",
              "      <td>these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "      <td>thos</td>\n",
              "      <td>those</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "      <td>mot</td>\n",
              "      <td>motiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words  Porter Stemmer Lancaster Stemmer Snowball Stemmer\n",
              "0     overwhelming       overwhelm         overwhelm        overwhelm\n",
              "1   overwhelmingly  overwhelmingli         overwhelm        overwhelm\n",
              "2           hushed            hush              hush             hush\n",
              "3             hush            hush              hush             hush\n",
              "4       functional        function             funct         function\n",
              "5     functionally        function             funct         function\n",
              "6            lying             lie             lying              lie\n",
              "7             lied             lie              lied              lie\n",
              "8           fairly          fairli              fair             fair\n",
              "9      destabilize        destabil              dest         destabil\n",
              "10       stability          stabil             stabl           stabil\n",
              "11      friendship      friendship            friend       friendship\n",
              "12     friendships      friendship            friend       friendship\n",
              "13        friendly        friendli            friend           friend\n",
              "14      friendless      friendless        friendless       friendless\n",
              "15         connect         connect           connect          connect\n",
              "16     connections         connect           connect          connect\n",
              "17       connected         connect           connect          connect\n",
              "18             the             the               the              the\n",
              "19           these           these              thes            these\n",
              "20           those           those              thos            those\n",
              "21    motivational           motiv               mot            motiv\n",
              "22        motivate           motiv               mot            motiv\n",
              "23      motivating           motiv               mot            motiv"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Porter Stemmer': ps_stemmed_tokens,\n",
        "    'Lancaster Stemmer': ls_stemmed_tokens,\n",
        "    'Snowball Stemmer': ss_stemmed_tokens\n",
        "})\n",
        "\n",
        "stems_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8ccpNnXmAOZ",
        "outputId": "48ba9bff-3c5b-48b9-94c7-66b84f113549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Suffix stripping algorithms may differ in results for a variety of reasons. One such reason is whether the algorithm constrains whether the output word must be a real word in the given language. Some approaches do not require the word to actually exist in the language lexicon (the set of all words in the language). Alternatively, some suffix stripping approaches maintain a database (a large list) of all known morphological word roots that exist as real words. These approaches check the list for the existence of the term prior to making a decision. Typically, if the term does not exist, alternate action is taken. This alternate action may involve several other criteria. The non-existence of an output term may serve to cause the algorithm to try alternate suffix stripping rules.\n",
            "\n",
            "It can be the case that two or more suffix stripping rules apply to the same input term, which creates an ambiguity as to which rule to apply. The algorithm may assign (by human hand or stochastically) a priority to one rule or another. Or the algorithm may reject one rule application because it results in a non-existent term whereas the other overlapping rule does not. For example, given the English term friendlies, the algorithm may identify the ies suffix and apply the appropriate rule and achieve the result of friendl. friendl is likely not found in the lexicon, and therefore the rule is rejected.\n",
            "\n",
            "One improvement upon basic suffix stripping is the use of suffix substitution. Similar to a stripping rule, a substitution rule replaces a suffix with an alternate suffix. For example, there could exist a rule that replaces ies with y. How this affects the algorithm varies on the algorithm's design. To illustrate, the algorithm may identify that both the ies suffix stripping rule as well as the suffix substitution rule apply. Since the stripping rule results in a non-existent term in the lexicon, but the substitution rule does not, the substitution rule is applied instead. In this example, friendlies becomes friendly instead of friendl.\n",
            "\n",
            "Diving further into the details, a common technique is to apply rules in a cyclical fashion (recursively, as computer scientists would say). After applying the suffix substitution rule in this example scenario, a second pass is made to identify matching rules on the term friendly, where the ly stripping rule is likely identified and accepted. In summary, friendlies becomes (via substitution) friendly which becomes (via stripping) friend.\n",
            "\n",
            "This example also helps illustrate the difference between a rule-based approach and a brute force approach. In a brute force approach, the algorithm would search for friendlies in the set of hundreds of thousands of inflected word forms and ideally find the corresponding root form friend. In the rule-based approach, the three rules mentioned above would be applied in succession to converge on the same solution. Chances are that the rule-based approach would be slower, as lookup algorithms have a direct access to the solution, while rule-based should try several options, and combinations of them, and then choose which result seems to be the best.\n",
            "\n",
            "There are two error measurements in stemming algorithms, overstemming and understemming. Overstemming is an error where two separate inflected words are stemmed to the same root, but should not have been—a false positive. Understemming is an error where two separate inflected words should be stemmed to the same root, but are not—a false negative. Stemming algorithms attempt to minimize each type of error, although reducing one type can lead to increasing the other.\n",
            "\n",
            "For example, the widely used Porter stemmer stems \"universal\", \"university\", and \"universe\" to \"univers\". This is a case of overstemming: though these three words are etymologically related, their modern meanings are in widely different domains, so treating them as synonyms in a search engine will likely reduce the relevance of the search results.\n",
            "\n",
            "An example of understemming in the Porter stemmer is \"alumnus\" → \"alumnu\", \"alumni\" → \"alumni\", \"alumna\"/\"alumnae\" → \"alumna\". This English word keeps Latin morphology, and so these near-synonyms are not conflated.\n",
            "\n",
            "Stochastic algorithms involve using probability to identify the root form of a word. Stochastic algorithms are trained (they \"learn\") on a table of root form to inflected form relations to develop a probabilistic model. This model is typically expressed in the form of complex linguistic rules, similar in nature to those in suffix stripping or lemmatisation. Stemming is performed by inputting an inflected form to the trained model and having the model produce the root form according to its internal ruleset, which again is similar to suffix stripping and lemmatisation, except that the decisions involved in applying the most appropriate rule, or whether or not to stem the word and just return the same word, or whether to apply two different rules sequentially, are applied on the grounds that the output word will have the highest probability of being correct (which is to say, the smallest probability of being incorrect, which is how it is typically measured).\n",
            "\n",
            "Some lemmatisation algorithms are stochastic in that, given a word which may belong to multiple parts of speech, a probability is assigned to each possible part. This may take into account the surrounding words, called the context, or not. Context-free grammars do not take into account any additional information. In either case, after assigning the probabilities to each possible part of speech, the most likely part of speech is chosen, and from there the appropriate normalization rules are applied to the input word to produce the normalized (root) form.\n"
          ]
        }
      ],
      "source": [
        "with open('./datasets/stemming.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TnE48camAOZ"
      },
      "outputs": [],
      "source": [
        "word_tokens = word_tokenize(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWzk7FeMmAOa"
      },
      "outputs": [],
      "source": [
        "ss =  SnowballStemmer('english', ignore_stopwords=True)\n",
        "\n",
        "ss_stemmed_words = []\n",
        "for word in word_tokens:\n",
        "    ss_stemmed_words.append(ss.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dryFCyr9mAOb",
        "outputId": "ec79075b-27fe-4ff7-ac5c-1ba70117158b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"suffix strip algorithm may differ in result for a varieti of reason . one such reason is whether the algorithm constrain whether the output word must be a real word in the given languag . some approach do not requir the word to actual exist in the languag lexicon ( the set of all word in the languag ) . altern , some suffix strip approach maintain a databas ( a larg list ) of all known morpholog word root that exist as real word . these approach check the list for the exist of the term prior to make a decis . typic , if the term does not exist , altern action is taken . this altern action may involv sever other criteria . the non-exist of an output term may serv to caus the algorithm to tri altern suffix strip rule . it can be the case that two or more suffix strip rule appli to the same input term , which creat an ambigu as to which rule to appli . the algorithm may assign ( by human hand or stochast ) a prioriti to one rule or anoth . or the algorithm may reject one rule applic because it result in a non-exist term wherea the other overlap rule does not . for exampl , given the english term friend , the algorithm may identifi the ie suffix and appli the appropri rule and achiev the result of friendl . friendl is like not found in the lexicon , and therefor the rule is reject . one improv upon basic suffix strip is the use of suffix substitut . similar to a strip rule , a substitut rule replac a suffix with an altern suffix . for exampl , there could exist a rule that replac ie with y . how this affect the algorithm vari on the algorithm 's design . to illustr , the algorithm may identifi that both the ie suffix strip rule as well as the suffix substitut rule appli . sinc the strip rule result in a non-exist term in the lexicon , but the substitut rule does not , the substitut rule is appli instead . in this exampl , friend becom friend instead of friendl . dive further into the detail , a common techniqu is to appli rule in a cyclic fashion ( recurs , as comput scientist would say ) . after appli the suffix substitut rule in this exampl scenario , a second pass is made to identifi match rule on the term friend , where the ly strip rule is like identifi and accept . in summari , friend becom ( via substitut ) friend which becom ( via strip ) friend . this exampl also help illustr the differ between a rule-bas approach and a brute forc approach . in a brute forc approach , the algorithm would search for friend in the set of hundr of thousand of inflect word form and ideal find the correspond root form friend . in the rule-bas approach , the three rule mention above would be appli in success to converg on the same solut . chanc are that the rule-bas approach would be slower , as lookup algorithm have a direct access to the solut , while rule-bas should tri sever option , and combin of them , and then choos which result seem to be the best . there are two error measur in stem algorithm , overstem and understem . overstem is an error where two separ inflect word are stem to the same root , but should not have been—a fals posit . understem is an error where two separ inflect word should be stem to the same root , but are not—a fals negat . stem algorithm attempt to minim each type of error , although reduc one type can lead to increas the other . for exampl , the wide use porter stemmer stem `` univers '' , `` univers '' , and `` univers '' to `` univ '' . this is a case of overstem : though these three word are etymolog relat , their modern mean are in wide differ domain , so treat them as synonym in a search engin will like reduc the relev of the search result . an exampl of understem in the porter stemmer is `` alumnus '' → `` alumnu '' , `` alumni '' → `` alumni '' , `` alumna '' / '' alumna '' → `` alumna '' . this english word keep latin morpholog , and so these near-synonym are not conflat . stochast algorithm involv use probabl to identifi the root form of a word . stochast algorithm are train ( they `` learn '' ) on a tabl of root form to inflect form relat to develop a probabilist model . this model is typic express in the form of complex linguist rule , similar in natur to those in suffix strip or lemmatis . stem is perform by input an inflect form to the train model and having the model produc the root form accord to its intern ruleset , which again is similar to suffix strip and lemmatis , except that the decis involv in appli the most appropri rule , or whether or not to stem the word and just return the same word , or whether to appli two differ rule sequenti , are appli on the ground that the output word will have the highest probabl of being correct ( which is to say , the smallest probabl of being incorrect , which is how it is typic measur ) . some lemmatis algorithm are stochast in that , given a word which may belong to multipl part of speech , a probabl is assign to each possibl part . this may take into account the surround word , call the context , or not . context-fre grammar do not take into account any addit inform . in either case , after assign the probabl to each possibl part of speech , the most like part of speech is chosen , and from there the appropri normal rule are appli to the input word to produc the normal ( root ) form .\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\" \".join(ss_stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLrVCzLZmAOb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClslWPOhmAOc"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 07-Lemmatization</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UObPa6bLmAOc"
      },
      "source": [
        "## Lemmatizing Words Using WordNet\n",
        "* Part-of-speech constants:\n",
        "* ADJ: a\n",
        "* ADV: r\n",
        "* NOUN: n\n",
        "* VERB: v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y3xd3LpmAOd"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.stem import *\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O7f5Z2umAOd"
      },
      "source": [
        "### Stemming words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oECrGTnmAOe",
        "outputId": "b069c305-c7fd-4edb-cb40-e02b6ae6ddbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "definit\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "print(stemmer.stem('definitions'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIaEXf4TmAOf",
        "outputId": "6bc61fd1-4e1a-4f43-cf6f-d5fb46c0c450"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyCA5WewmAOf"
      },
      "source": [
        "### Lemmatizing Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK1UXAt9mAOg",
        "outputId": "9134b5c4-25a6-45c4-b09f-4061751c4eaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "definition\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wnl = WordNetLemmatizer()\n",
        "print(wnl.lemmatize('definitions'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kisvvbw2mAOg"
      },
      "source": [
        "### Lemmatizing words by specifying parts-of-speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-imf-IJxmAOg",
        "outputId": "1507a7bf-142f-491d-e675-b0be99aebded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjective:  running\n",
            "Adverb:  running\n",
            "Noun:  running\n",
            "Verb:  run\n"
          ]
        }
      ],
      "source": [
        "print('Adjective: ', wnl.lemmatize('running', pos='a'))\n",
        "print('Adverb: ', wnl.lemmatize('running', pos='r'))\n",
        "print('Noun: ', wnl.lemmatize('running', pos='n'))\n",
        "print('Verb: ', wnl.lemmatize('running', pos='v'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jWqP9nTmAOh"
      },
      "outputs": [],
      "source": [
        "input_tokens = ['dictionaries', 'dictionary',\n",
        "                'hushed', 'hush', 'hushing',\n",
        "                'functional', 'functionally',\n",
        "                'lying', 'lied', 'lies',\n",
        "                'flawed', 'flaws', 'flawless',\n",
        "                'friendship', 'friendships', 'friendly', 'friendless',\n",
        "                'definitions', 'definition', 'definitely',\n",
        "                'the', 'these', 'those',\n",
        "                'motivational', 'motivate', 'motivating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te8OODUzmAOh"
      },
      "outputs": [],
      "source": [
        "ss =  SnowballStemmer('english')\n",
        "\n",
        "ss_stemmed_tokens = []\n",
        "for token in input_tokens:\n",
        "    ss_stemmed_tokens.append(ss.stem(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EporcYTImAOi"
      },
      "outputs": [],
      "source": [
        "wnl_lemmatized_tokens = []\n",
        "for token in input_tokens:\n",
        "    wnl_lemmatized_tokens.append(wnl.lemmatize(token, pos='v'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMP65ZTgmAOi",
        "outputId": "55ab20d9-f335-483b-d6df-75c78fb5d992"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>Snowball Stemmer</th>\n",
              "      <th>WordNet Lemmatizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dictionaries</td>\n",
              "      <td>dictionari</td>\n",
              "      <td>dictionaries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dictionary</td>\n",
              "      <td>dictionari</td>\n",
              "      <td>dictionary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hushed</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hushing</td>\n",
              "      <td>hush</td>\n",
              "      <td>hush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>functional</td>\n",
              "      <td>function</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>functionally</td>\n",
              "      <td>function</td>\n",
              "      <td>functionally</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lying</td>\n",
              "      <td>lie</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>lied</td>\n",
              "      <td>lie</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>lies</td>\n",
              "      <td>lie</td>\n",
              "      <td>lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>flawed</td>\n",
              "      <td>flaw</td>\n",
              "      <td>flaw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>flaws</td>\n",
              "      <td>flaw</td>\n",
              "      <td>flaw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>flawless</td>\n",
              "      <td>flawless</td>\n",
              "      <td>flawless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>friendships</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friendships</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>friendly</td>\n",
              "      <td>friend</td>\n",
              "      <td>friendly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "      <td>friendless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>definitions</td>\n",
              "      <td>definit</td>\n",
              "      <td>definitions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>definition</td>\n",
              "      <td>definit</td>\n",
              "      <td>definition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>definitely</td>\n",
              "      <td>definit</td>\n",
              "      <td>definitely</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "      <td>these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "      <td>those</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>motivational</td>\n",
              "      <td>motiv</td>\n",
              "      <td>motivational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>motivate</td>\n",
              "      <td>motiv</td>\n",
              "      <td>motivate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>motivating</td>\n",
              "      <td>motiv</td>\n",
              "      <td>motivate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           words Snowball Stemmer WordNet Lemmatizer\n",
              "0   dictionaries       dictionari       dictionaries\n",
              "1     dictionary       dictionari         dictionary\n",
              "2         hushed             hush               hush\n",
              "3           hush             hush               hush\n",
              "4        hushing             hush               hush\n",
              "5     functional         function         functional\n",
              "6   functionally         function       functionally\n",
              "7          lying              lie                lie\n",
              "8           lied              lie                lie\n",
              "9           lies              lie                lie\n",
              "10        flawed             flaw               flaw\n",
              "11         flaws             flaw               flaw\n",
              "12      flawless         flawless           flawless\n",
              "13    friendship       friendship         friendship\n",
              "14   friendships       friendship        friendships\n",
              "15      friendly           friend           friendly\n",
              "16    friendless       friendless         friendless\n",
              "17   definitions          definit        definitions\n",
              "18    definition          definit         definition\n",
              "19    definitely          definit         definitely\n",
              "20           the              the                the\n",
              "21         these            these              these\n",
              "22         those            those              those\n",
              "23  motivational            motiv       motivational\n",
              "24      motivate            motiv           motivate\n",
              "25    motivating            motiv           motivate"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stems_lemmas_df = pd.DataFrame({\n",
        "    'words': input_tokens,\n",
        "    'Snowball Stemmer': ss_stemmed_tokens,\n",
        "    'WordNet Lemmatizer': wnl_lemmatized_tokens\n",
        "})\n",
        "\n",
        "stems_lemmas_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiVQMc4-mAOi",
        "outputId": "778e567d-8219-4959-fb12-b3bfabc60503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marie Curie was a Polish-born physicist and chemist and one of the most famous scientists of her time.\n",
            "Together with her husband Pierre, she was awarded the Nobel Prize in 1903, and she went on to win another in 1911.\n",
            "Marie Sklodowska was born in Warsaw on 7 November 1867, the daughter of a teacher.\n",
            "In 1891, she went to Paris to study physics and mathematics at the Sorbonne where she met Pierre Curie, professor of the School of Physics.\n",
            "They were married in 1895.\n",
            "The Curies worked together investigating radioactivity, building on the work of the German physicist Roentgen and the French physicist Becquerel.\n",
            "In July 1898, the Curies announced the discovery of a new chemical element, polonium.\n",
            "At the end of the year, they announced the discovery of another, radium.\n",
            "The Curies, along with Becquerel, were awarded the Nobel Prize for Physics in 1903.\n",
            "Pierre's life was cut short in 1906 when he was knocked down and killed by a carriage.\n",
            "Marie took over his teaching post, becoming the first woman to teach at the Sorbonne, and devoted herself to continuing the work that they had begun together.\n",
            "She received a second Nobel Prize, for Chemistry, in 1911.\n",
            "The Curie's research was crucial in the development of x-rays in surgery.\n",
            "During World War One Curie helped to equip ambulances with x-ray equipment, which she herself drove to the front lines.\n",
            "The International Red Cross made her head of its radiological service and she held training courses for medical orderlies and doctors in the new techniques.\n",
            "Despite her success, Marie continued to face great opposition from male scientists in France, and she never received significant financial benefits from her work.\n",
            "By the late 1920s her health was beginning to deteriorate.\n",
            "She died on 4 July 1934 from leukaemia, caused by exposure to high-energy radiation from her research.\n",
            "The Curies' eldest daughter Irene was herself a scientist and winner of the Nobel Prize for Chemistry.\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "with open('./datasets/biography.txt', 'r') as f:\n",
        "    file_contents = f.read()\n",
        "\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uukUwXa1mAOj"
      },
      "outputs": [],
      "source": [
        "word_tokens = word_tokenize(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD7i0Uy3mAOj"
      },
      "outputs": [],
      "source": [
        "wnl = WordNetLemmatizer()\n",
        "lemmatized_words = []\n",
        "\n",
        "for word in word_tokens:\n",
        "    lemmatized_words.append(wnl.lemmatize(word, pos=\"v\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGLRN0oOmAOj",
        "outputId": "b1c5f039-5e36-4202-cfe6-0ddf328a9706"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Marie Curie be a Polish-born physicist and chemist and one of the most famous scientists of her time . Together with her husband Pierre , she be award the Nobel Prize in 1903 , and she go on to win another in 1911 . Marie Sklodowska be bear in Warsaw on 7 November 1867 , the daughter of a teacher . In 1891 , she go to Paris to study physics and mathematics at the Sorbonne where she meet Pierre Curie , professor of the School of Physics . They be marry in 1895 . The Curies work together investigate radioactivity , build on the work of the German physicist Roentgen and the French physicist Becquerel . In July 1898 , the Curies announce the discovery of a new chemical element , polonium . At the end of the year , they announce the discovery of another , radium . The Curies , along with Becquerel , be award the Nobel Prize for Physics in 1903 . Pierre 's life be cut short in 1906 when he be knock down and kill by a carriage . Marie take over his teach post , become the first woman to teach at the Sorbonne , and devote herself to continue the work that they have begin together . She receive a second Nobel Prize , for Chemistry , in 1911 . The Curie 's research be crucial in the development of x-ray in surgery . During World War One Curie help to equip ambulances with x-ray equipment , which she herself drive to the front line . The International Red Cross make her head of its radiological service and she hold train course for medical orderlies and doctor in the new techniques . Despite her success , Marie continue to face great opposition from male scientists in France , and she never receive significant financial benefit from her work . By the late 1920s her health be begin to deteriorate . She die on 4 July 1934 from leukaemia , cause by exposure to high-energy radiation from her research . The Curies ' eldest daughter Irene be herself a scientist and winner of the Nobel Prize for Chemistry .\""
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\" \".join(lemmatized_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_Fc4VRqmAOk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmhFjUAGmAOk"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 08-PartOfSpeechTagging</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfYCJnMdmAOk"
      },
      "source": [
        "# Part-of-Speech Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGMFERicmAOl"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B-z7o-fmAOl",
        "outputId": "0d8b5d03-e78f-450c-bc12-b3919963f6a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package tagsets to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('tagsets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxAzttLLmAOl",
        "outputId": "eedc9c32-a3bd-4e6d-b712-d852cfa2d8b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e4-7MVqmAOm",
        "outputId": "b3bdc8b7-1565-47ec-ece2-500570d5ebf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n"
          ]
        }
      ],
      "source": [
        "nltk.help.upenn_tagset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz9T1ik8mAOm",
        "outputId": "d6dbc0d4-1033-4be5-b5ca-b8e74cde86fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('refuse', 'VBP'),\n",
              " ('to', 'TO'),\n",
              " ('let', 'VB'),\n",
              " ('this', 'DT'),\n",
              " ('refuse', 'NN'),\n",
              " ('get', 'VB'),\n",
              " ('me', 'PRP'),\n",
              " ('down', 'RP')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I refuse to let this refuse get me down\"\n",
        "\n",
        "tokenized_words = word_tokenize(text)\n",
        "tagged_words = nltk.pos_tag(tokenized_words)\n",
        "tagged_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FrOzqpbmAOm",
        "outputId": "070d4dc3-efda-4553-b0c6-eb2ef1965274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Bear', 'NNP'),\n",
              " ('with', 'IN'),\n",
              " ('me', 'PRP'),\n",
              " (',', ','),\n",
              " ('this', 'DT'),\n",
              " ('effort', 'NN'),\n",
              " ('with', 'IN'),\n",
              " ('soon', 'RB'),\n",
              " ('bear', 'JJ'),\n",
              " ('fruit', 'NN'),\n",
              " (',', ','),\n",
              " ('otherwise', 'RB'),\n",
              " ('we', 'PRP'),\n",
              " (\"'ll\", 'MD'),\n",
              " ('have', 'VB'),\n",
              " ('to', 'TO'),\n",
              " ('run', 'VB'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('bear', 'NN')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"\"\"Bear with me, this effort with soon bear fruit,\n",
        "          otherwise we'll have to run from the bear\"\"\"\n",
        "\n",
        "tokenized_words = word_tokenize(text)\n",
        "tagged_words = nltk.pos_tag(tokenized_words)\n",
        "tagged_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZWxlfPWmAOn",
        "outputId": "4010a2bd-bfc1-4729-b876-dc7999b8e344"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('A', 'DT'),\n",
              " ('bird', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('hand', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('worth', 'JJ'),\n",
              " ('two', 'CD'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('bush', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Good', 'JJ'),\n",
              " ('things', 'NNS'),\n",
              " ('come', 'VBP'),\n",
              " ('to', 'TO'),\n",
              " ('those', 'DT'),\n",
              " ('who', 'WP'),\n",
              " ('wait', 'VBP'),\n",
              " ('.', '.'),\n",
              " ('There', 'EX'),\n",
              " ('are', 'VBP'),\n",
              " ('other', 'JJ'),\n",
              " ('fish', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('sea', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('ball', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('in', 'IN'),\n",
              " ('your', 'PRP$'),\n",
              " ('court', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"A bird in hand is worth two in the bush. \" +\\\n",
        "       \"Good things come to those who wait. \" +\\\n",
        "       \"There are other fish in the sea. \" +\\\n",
        "       \"The ball is in your court.\"\n",
        "\n",
        "tokenized_words = word_tokenize(text)\n",
        "tagged_words = nltk.pos_tag(tokenized_words)\n",
        "tagged_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPmztP9imAOn",
        "outputId": "dbfda151-d7e1-4c32-9bf4-158a0bbf9577"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('NN', 7),\n",
              " ('DT', 5),\n",
              " ('IN', 4),\n",
              " ('.', 4),\n",
              " ('JJ', 3),\n",
              " ('VBP', 3),\n",
              " ('VBZ', 2),\n",
              " ('CD', 1),\n",
              " ('NNS', 1),\n",
              " ('TO', 1)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "fd = FreqDist(tagged_words)\n",
        "fd_tagged = FreqDist(tag for (word, tag) in tagged_words)\n",
        "fd_tagged.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fEbactBmAOo"
      },
      "source": [
        "The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University. This corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, and so on. 1.1 gives an example of each genre (for a complete list, see http://icame.uib.no/brown/bcm-los.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7gm6PAwmAOo",
        "outputId": "a7a78a14-54bb-47cb-9477-51e321b15096"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /Users/loonycorn/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY_25LshmAOo",
        "outputId": "7378f1db-6acc-41f7-e7f9-932c5824ddf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'Grand',\n",
              " 'Jury',\n",
              " 'said',\n",
              " 'Friday',\n",
              " 'an',\n",
              " 'investigation',\n",
              " 'of']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.corpus.brown.words()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9kBqR7lmAOp"
      },
      "outputs": [],
      "source": [
        "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ3MRrskmAOp"
      },
      "source": [
        "Lexical categories like \"noun\" and part-of-speech tags like NN seem to have their uses, but the details will be obscure to many readers. You might wonder what justification there is for introducing this extra level of information. Many of these categories arise from superficial analysis the distribution of words in text. Consider the following analysis involving woman (a noun), bought (a verb), over (a preposition), and the (a determiner). The text.similar() method takes a word w, finds all contexts w1w w2, then finds all words w' that appear in the same context, i.e. w1w'w2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T1P6UnVmAOq"
      },
      "source": [
        "#### Similar words here belong to the same part of speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2gkvlgKmAOq",
        "outputId": "03904bb9-352d-4741-c80f-cabbf182d764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "man time day way girl year house people world city family state room\n",
            "country car woman program church government job\n"
          ]
        }
      ],
      "source": [
        "text.similar('boy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmezAr31mAOr",
        "outputId": "12412732-99c5-4675-85b8-70ffbfcd916c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get be do in see work go have take make put and find time look day say\n",
            "use come show\n"
          ]
        }
      ],
      "source": [
        "text.similar('run')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnyp1J0HmAOs",
        "outputId": "48a2ee06-1773-48c6-9836-2e8a0e0bde64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in on to of and for with from at by that into as up out down through\n",
            "is all about\n"
          ]
        }
      ],
      "source": [
        "text.similar('over')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoGautmdmAOs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9widVIe9mAOt"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 09-ReduceDimensionsInText_HashingTrick</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl2_IRV-mAOt"
      },
      "source": [
        "## Hashing trick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkfBp3GkmAOu"
      },
      "source": [
        "Instead of building a hash table of the features encountered in training, as the vectorizers do, instances of FeatureHasher apply a hash function to the features to determine their column index in sample matrices directly. The result is increased speed and reduced memory usage, at the expense of inspectability; the hasher does not remember what the input features looked like and has no inverse_transform method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc18UOhhmAOv"
      },
      "source": [
        "* https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html\n",
        "* https://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cqgFBb0mAOv",
        "outputId": "4a1b4f1b-5ecd-4362-cfd7-aafa92e19572"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 8)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "text = [\"A bird in hand is worth two in the bush.\",\n",
        "        \"Good things come to those who wait.\",\n",
        "        \"These watches cost $1500! \",\n",
        "        \"These are other fish in the sea.\",\n",
        "        \"The ball is in your court.\",\n",
        "        \"Mr. Smith Goes to Washington \",\n",
        "        \"Doogie Howser M.D.\"]\n",
        "\n",
        "hasher = FeatureHasher(n_features=8, input_type='string')\n",
        "hashed_features = hasher.fit_transform(text)\n",
        "\n",
        "hashed_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk_kCVABmAOw",
        "outputId": "f7adc0cd-0be1-48e7-cab3-79c8c7760a6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 10.,   0.,   1.,   1.,  -3., -11.,   1.,  -1.],\n",
              "       [  6.,  -2.,   0.,   3.,   0.,  -6.,   0.,   0.],\n",
              "       [  4.,  -5.,   1.,  -1.,   2.,  -3.,   0.,   0.],\n",
              "       [  6.,   2.,   2.,   0.,  -1.,  -8.,   0.,   3.],\n",
              "       [  7.,   1.,   1.,   1.,   1.,  -6.,   1.,   0.],\n",
              "       [  4.,   2.,   1.,   0.,  -2.,  -5.,   0.,  -1.],\n",
              "       [  2.,   1.,   0.,   3.,   0.,  -3.,   2.,   1.]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hashed_features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ONQZ39JmAOw",
        "outputId": "83c96e4a-706c-4563-e727-c36c53711a07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 16)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasher = FeatureHasher(n_features=16, input_type='string')\n",
        "hashed_features = hasher.fit_transform(text)\n",
        "\n",
        "hashed_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym9HakcAmAOx",
        "outputId": "fcd7938d-cf07-4043-c971-dfd759335e13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.,  0.,  1.,  1., -3., -4.,  0.,  1.,  9.,  0.,  0.,  0.,  0.,\n",
              "        -7.,  1., -2.],\n",
              "       [ 0., -3.,  1.,  3., -1., -2.,  0.,  2.,  6.,  1., -1.,  0.,  1.,\n",
              "        -4.,  0., -2.],\n",
              "       [ 0., -5.,  1., -1.,  2.,  1.,  0.,  3.,  4.,  0.,  0.,  0.,  0.,\n",
              "        -4.,  0., -3.],\n",
              "       [ 0.,  2.,  2., -1., -1., -2.,  0.,  6.,  6.,  0.,  0.,  1.,  0.,\n",
              "        -6.,  0., -3.],\n",
              "       [ 2.,  1.,  1.,  1., -1., -2.,  1.,  1.,  5.,  0.,  0.,  0.,  2.,\n",
              "        -4.,  0., -1.],\n",
              "       [-1.,  1.,  1.,  0., -2., -2.,  0.,  1.,  5.,  1.,  0.,  0.,  0.,\n",
              "        -3.,  0., -2.],\n",
              "       [ 0.,  0.,  0.,  3.,  0., -1.,  2.,  2.,  2.,  1.,  0.,  0.,  0.,\n",
              "        -2.,  0., -1.]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hashed_features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1t-gVRzmAOy",
        "outputId": "57575021-72a2-4f45-9e4b-694172927f85"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'FeatureHasher' object has no attribute 'inverse_transform'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-acc2ce62ec0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashed_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'FeatureHasher' object has no attribute 'inverse_transform'"
          ]
        }
      ],
      "source": [
        "hasher.inverse_transform(hashed_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnuPCnj7mAOz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR6i3BmFmAOz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmob23aumAO0"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 10-VectorizingTextData_HashingVectorizer</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1uasza-mAO0"
      },
      "source": [
        "## HashingVectorizer\n",
        "* <b>HashingVectorizer</b> is the combination of <b>FeatureHasher</b> and <b>CountVectorizer</b> i.e, we get the Term frequency of words as well as the reduced dimension\n",
        "* When we used FeatureHasher the dimension of vector reduced but we couldn't get any understandable format in output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cU76Q_0mAO1"
      },
      "source": [
        "#### If we have large vocabulary of words we can choose to use the HashingVectorizer rather than the CountVectorizer\n",
        "* The use of hashing buckets to represent words allows us to scale large data sets when we use the HashingVectorizer.\n",
        "* The input argument to the vectorizer is the number of hash buckets (n_features)\n",
        "* Result : numeric representation of all the words in documents.\n",
        "* Word ids are from 0 to (n_features - 1) because total of n_features buckets.\n",
        "* Because the size of vocabulary is larger than the number of buckets, multiple words can hash to the same bucket.\n",
        "* No way to get back to the original value from the hash bucket value.\n",
        "* Frequencies of each is represented in normalized from\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html#vectorizing-a-large-text-corpus-with-the-hashing-trick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D-0I1yrmAO1"
      },
      "source": [
        "##### words are mapped directly to indices with a hashing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qiRGTAemAO1",
        "outputId": "4c24d637-fdd3-409d-bf46-e6df8699bbc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 27)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text_array = [\"Good things come to those who wait.\",\n",
        "              \"These watches cost $1500! \",\n",
        "              \"These are other fish in the sea.\",\n",
        "              \"The ball is in your court.\",\n",
        "              \"Mr. Smith Goes to Washington \",\n",
        "              \"Doogie Howser M.D.\"]\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "feature_vector = count_vectorizer.fit_transform(text_array)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPqdPJz1mAO1",
        "outputId": "370778ca-296f-4e61-b518-6eeb9f5eb70d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        1, 0, 0, 1, 0],\n",
              "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "        0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfGy5Yc7mAO2",
        "outputId": "1b703236-a3b1-4e3f-fc17-f9943656b64a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'good': 9,\n",
              " 'things': 19,\n",
              " 'come': 3,\n",
              " 'to': 21,\n",
              " 'those': 20,\n",
              " 'who': 25,\n",
              " 'wait': 22,\n",
              " 'these': 18,\n",
              " 'watches': 24,\n",
              " 'cost': 4,\n",
              " '1500': 0,\n",
              " 'are': 1,\n",
              " 'other': 14,\n",
              " 'fish': 7,\n",
              " 'in': 11,\n",
              " 'the': 17,\n",
              " 'sea': 15,\n",
              " 'ball': 2,\n",
              " 'is': 12,\n",
              " 'your': 26,\n",
              " 'court': 5,\n",
              " 'mr': 13,\n",
              " 'smith': 16,\n",
              " 'goes': 8,\n",
              " 'washington': 23,\n",
              " 'doogie': 6,\n",
              " 'howser': 10}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aymMAMDYmAO2"
      },
      "outputs": [],
      "source": [
        "analyzer = count_vectorizer.build_analyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi11HmrsmAO3",
        "outputId": "567d27b5-7d20-4bcd-c215-9207d5544ca3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['good', 'things', 'come', 'to', 'those', 'who', 'wait']"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = analyzer(text_array[0])\n",
        "\n",
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzWTZ1D0mAO3"
      },
      "outputs": [],
      "source": [
        "frequency_list = []\n",
        "\n",
        "for i, text in enumerate(text_array):\n",
        "    tokens = analyzer(text)\n",
        "\n",
        "    word_frequency = {}\n",
        "\n",
        "    for token in tokens:\n",
        "        word_idx = count_vectorizer.vocabulary_[token]\n",
        "\n",
        "        word_frequency[token] = feature_vector[i, word_idx]\n",
        "\n",
        "    frequency_list.append(word_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVGoNqugmAO4",
        "outputId": "bc697fd9-e390-4b0b-b5bf-68e0007b8d6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'good': 1, 'things': 1, 'come': 1, 'to': 1, 'those': 1, 'who': 1, 'wait': 1},\n",
              " {'these': 1, 'watches': 1, 'cost': 1, '1500': 1},\n",
              " {'these': 1, 'are': 1, 'other': 1, 'fish': 1, 'in': 1, 'the': 1, 'sea': 1},\n",
              " {'the': 1, 'ball': 1, 'is': 1, 'in': 1, 'your': 1, 'court': 1},\n",
              " {'mr': 1, 'smith': 1, 'goes': 1, 'to': 1, 'washington': 1},\n",
              " {'doogie': 1, 'howser': 1}]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequency_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odHpEMlQmAO5",
        "outputId": "476e1c80-a951-4dad-beb7-3d9ca33d5ea3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 8)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "hasher = FeatureHasher(n_features=8, input_type='string')\n",
        "hashed_features = hasher.fit_transform(frequency_list)\n",
        "\n",
        "hashed_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccXs7b1emAO5",
        "outputId": "058e63ca-3c27-4877-f2a4-4631ae644193"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.,  3.,  0.,  1., -2., -1.,  0.,  0.],\n",
              "       [ 0.,  0., -1.,  0., -1.,  0.,  2.,  0.],\n",
              "       [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  1.],\n",
              "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
              "       [ 0., -1.,  0.,  1.,  0., -1.,  0.,  0.],\n",
              "       [ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.]])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hashed_features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV2sc9bhmAO6",
        "outputId": "fda6bf0f-65f6-435c-cbb4-5fd0806d37e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 8)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "vectorizer = HashingVectorizer(n_features=8, norm=None)\n",
        "feature_vector = vectorizer.transform(text_array)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn094ai-mAO7",
        "outputId": "81415a23-de67-46c5-af4b-2ef288d6e50c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.,  3.,  0.,  1., -2., -1.,  0.,  0.],\n",
              "       [ 0.,  0., -1.,  0., -1.,  0.,  2.,  0.],\n",
              "       [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  1.],\n",
              "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
              "       [ 0., -1.,  0.,  1.,  0., -1.,  0.,  0.],\n",
              "       [ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.]])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw4yo-2RmAO8",
        "outputId": "68f05aa9-8ae9-48dc-b1f8-9cc1d16f70ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 8)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = HashingVectorizer(n_features=8, norm='l1')\n",
        "feature_vector = vectorizer.transform(text_array)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ascI6x4hmAO8",
        "outputId": "878a344c-8316-48bf-c7db-bd33c34c7fdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.42857143,  0.        ,  0.14285714, -0.28571429,\n",
              "        -0.14285714,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        , -0.25      ,  0.        , -0.25      ,\n",
              "         0.        ,  0.5       ,  0.        ],\n",
              "       [ 0.        ,  0.33333333, -0.33333333,  0.        ,  0.        ,\n",
              "         0.        ,  0.        ,  0.33333333],\n",
              "       [ 0.        ,  0.5       ,  0.        ,  0.        ,  0.        ,\n",
              "         0.5       ,  0.        ,  0.        ],\n",
              "       [ 0.        , -0.33333333,  0.        ,  0.33333333,  0.        ,\n",
              "        -0.33333333,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.5       ,  0.        ,  0.        ,  0.5       ,\n",
              "         0.        ,  0.        ,  0.        ]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqGEJaOsmAO9",
        "outputId": "5525e53d-8d30-4df5-bc1a-91359ef8c680"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 8)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = HashingVectorizer(n_features=8, norm='l2')\n",
        "feature_vector = vectorizer.transform(text_array)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Vg3yiwmAO9",
        "outputId": "887ec810-4ab1-4999-a68c-69970932fc46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.77459667,  0.        ,  0.25819889, -0.51639778,\n",
              "        -0.25819889,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        , -0.40824829,  0.        , -0.40824829,\n",
              "         0.        ,  0.81649658,  0.        ],\n",
              "       [ 0.        ,  0.57735027, -0.57735027,  0.        ,  0.        ,\n",
              "         0.        ,  0.        ,  0.57735027],\n",
              "       [ 0.        ,  0.70710678,  0.        ,  0.        ,  0.        ,\n",
              "         0.70710678,  0.        ,  0.        ],\n",
              "       [ 0.        , -0.57735027,  0.        ,  0.57735027,  0.        ,\n",
              "        -0.57735027,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.70710678,  0.        ,  0.        ,  0.70710678,\n",
              "         0.        ,  0.        ,  0.        ]])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzD_y6y6mAO-",
        "outputId": "0e8dc852-ef36-49b2-b226-40214dc5bda5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 3., 0., 1., 2., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 1., 0., 2., 0.],\n",
              "       [2., 1., 1., 0., 0., 0., 2., 1.],\n",
              "       [0., 1., 0., 0., 2., 1., 2., 0.],\n",
              "       [0., 1., 0., 3., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 1., 0., 0., 0.]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = HashingVectorizer(n_features=8, norm=None, alternate_sign=False)\n",
        "feature_vector = vectorizer.transform(text_array)\n",
        "\n",
        "feature_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6LC7mhGmAO-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqiRJWgbmAO_"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 11-SimplifyTextDataUsingLocallySensitiveHashing </h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtsxJKgDmAO_"
      },
      "source": [
        "### Datasketch\n",
        "https://pypi.org/project/datasketch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maRc9IOQmAO_",
        "outputId": "a7655688-e3ac-41f2-8fef-2d8773ec417a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasketch in /anaconda3/lib/python3.7/site-packages (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.11 in /anaconda3/lib/python3.7/site-packages (from datasketch) (1.16.1)\n",
            "Requirement already satisfied: redis>=2.10.0 in /anaconda3/lib/python3.7/site-packages (from datasketch) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasketch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR4TbK4LmAPA"
      },
      "outputs": [],
      "source": [
        "from datasketch import MinHash, MinHashLSH\n",
        "\n",
        "from nltk import ngrams\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwb0GHMRmAPA"
      },
      "outputs": [],
      "source": [
        "text_array = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I33n-tZ2mAPB",
        "outputId": "27479070-62b0-4060-b434-82788a34ec3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['A', 'bird', 'in', 'hand', 'is', 'worth', 'two', 'in', 'the', 'bush', '.'],\n",
              " ['Good', 'things', 'come', 'to', 'those', 'who', 'wait', '.'],\n",
              " ['There', 'are', 'other', 'fish', 'in', 'the', 'sea', '.'],\n",
              " ['The', 'ball', 'is', 'in', 'your', 'court', '.']]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_token_array = [word_tokenize(text) for text in text_array]\n",
        "\n",
        "word_token_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KCVJ8dimAPB",
        "outputId": "d2b2cdfc-122a-4e71-85f9-6a89896a4d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 ('A', 'bird', 'in')\n",
            "0 ('bird', 'in', 'hand')\n",
            "0 ('in', 'hand', 'is')\n",
            "0 ('hand', 'is', 'worth')\n",
            "0 ('is', 'worth', 'two')\n",
            "0 ('worth', 'two', 'in')\n",
            "0 ('two', 'in', 'the')\n",
            "0 ('in', 'the', 'bush')\n",
            "0 ('the', 'bush', '.')\n",
            "1 ('Good', 'things', 'come')\n",
            "1 ('things', 'come', 'to')\n",
            "1 ('come', 'to', 'those')\n",
            "1 ('to', 'those', 'who')\n",
            "1 ('those', 'who', 'wait')\n",
            "1 ('who', 'wait', '.')\n",
            "2 ('There', 'are', 'other')\n",
            "2 ('are', 'other', 'fish')\n",
            "2 ('other', 'fish', 'in')\n",
            "2 ('fish', 'in', 'the')\n",
            "2 ('in', 'the', 'sea')\n",
            "2 ('the', 'sea', '.')\n",
            "3 ('The', 'ball', 'is')\n",
            "3 ('ball', 'is', 'in')\n",
            "3 ('is', 'in', 'your')\n",
            "3 ('in', 'your', 'court')\n",
            "3 ('your', 'court', '.')\n"
          ]
        }
      ],
      "source": [
        "for index, word_tokens in enumerate(word_token_array):\n",
        "    for n_gram in ngrams(word_tokens, 3):\n",
        "        print(index, n_gram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-S3laAGomAPC"
      },
      "outputs": [],
      "source": [
        "min_hash_lsh = MinHashLSH(threshold=0.5, num_perm=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-pjntXtmAPC"
      },
      "outputs": [],
      "source": [
        "min_hashes = {}\n",
        "\n",
        "for index, text in enumerate(text_array):\n",
        "    min_hash = MinHash(num_perm=128)\n",
        "\n",
        "    for n_gram in ngrams(text, 3):\n",
        "        min_hash.update(\"\".join(n_gram).encode('utf-8'))\n",
        "\n",
        "    min_hash_lsh.insert(index, min_hash)\n",
        "    min_hashes[index] = min_hash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wAv1MuvmAPC",
        "outputId": "70c7ec0f-7d2b-4124-f6e4-78c4f69db5a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: <datasketch.minhash.MinHash at 0x11bc3a9b0>,\n",
              " 1: <datasketch.minhash.MinHash at 0x11bc3ab00>,\n",
              " 2: <datasketch.minhash.MinHash at 0x11bc392e8>,\n",
              " 3: <datasketch.minhash.MinHash at 0x11bc39320>}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "min_hashes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPKToiEamAPD",
        "outputId": "a481ee6a-7486-4f3e-b7d1-0d051a7799a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidate pairs with Jaccard similarity > 0.5 for input 0 : [0]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 1 : [1]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 2 : [2]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 3 : [3]\n"
          ]
        }
      ],
      "source": [
        "for i in min_hashes.keys():\n",
        "    result = min_hash_lsh.query(min_hashes[i])\n",
        "    print(\"Candidate pairs with Jaccard similarity > 0.5 for input\", i, \":\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iwEDoNamAPD"
      },
      "outputs": [],
      "source": [
        "text_array = [\"A bird in hand is worth two in the bush.\",\n",
        "              \"A bird in hands is worth three in the bushes.\",\n",
        "              \"Good things come to those who wait.\",\n",
        "              \"Good tpings cxme to those who wait long.\",\n",
        "              \"There are other fish in the sea.\",\n",
        "              \"The ball is in your court.\"\n",
        "             ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khhQZm1WmAPD"
      },
      "outputs": [],
      "source": [
        "min_hash_lsh = MinHashLSH(threshold=0.5, num_perm=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYrVJhe5mAPE"
      },
      "outputs": [],
      "source": [
        "min_hashes = {}\n",
        "\n",
        "for index, text in enumerate(text_array):\n",
        "    min_hash = MinHash(num_perm=128)\n",
        "\n",
        "    for n_gram in ngrams(text, 3):\n",
        "        min_hash.update(\"\".join(n_gram).encode('utf-8'))\n",
        "\n",
        "    min_hash_lsh.insert(index, min_hash)\n",
        "    min_hashes[index] = min_hash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwMEG5qxmAPE",
        "outputId": "3f6c28df-526f-4b5f-dc10-eca79ca1493d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidate pairs with Jaccard similarity > 0.5 for input 0 : [0, 1]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 1 : [0, 1]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 2 : [2, 3]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 3 : [2, 3]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 4 : [4]\n",
            "Candidate pairs with Jaccard similarity > 0.5 for input 5 : [5]\n"
          ]
        }
      ],
      "source": [
        "for i in min_hashes.keys():\n",
        "    result = min_hash_lsh.query(min_hashes[i])\n",
        "    print(\"Candidate pairs with Jaccard similarity > 0.5 for input\", i, \":\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxlUaabimAPE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXOTniPemAPF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buiu0mgqmAPF"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 12a-HashingVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjFkPwM_mAPF"
      },
      "source": [
        "Dataset link : https://github.com/pyk/dbpedia_csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlGI9nWamAPG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-woWMl6mAPG"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a2EPj87mAPG",
        "outputId": "e1f0a3d2-c884-415c-883f-4ab2fc8c815e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqGAWLUHmAPH"
      },
      "source": [
        "### DBPedia classes\n",
        "\n",
        "- Company\n",
        "- EducationalInstitution\n",
        "- Artist\n",
        "- Athlete\n",
        "- OfficeHolder\n",
        "- MeanOfTransportation\n",
        "- Building\n",
        "- NaturalPlace\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- WrittenWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J37AtSeCmAPH",
        "outputId": "c36d8c8c-c076-4731-9316-9493ea2988f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPB7TkjtmAPO"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vI943HLmAPP",
        "outputId": "e9cfe80f-8ebd-4550-e90c-f7c781d7720b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>494483</th>\n",
              "      <td>13</td>\n",
              "      <td>A Wedding Suit</td>\n",
              "      <td>A Wedding Suit (Persian: لباسی برای عروسی‎ Le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548491</th>\n",
              "      <td>14</td>\n",
              "      <td>Into Thin Air</td>\n",
              "      <td>Into Thin Air: A Personal Account of the Mt. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339369</th>\n",
              "      <td>9</td>\n",
              "      <td>Banavchan</td>\n",
              "      <td>Banavchan (Persian: بناوچان‎ also Romanized a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295828</th>\n",
              "      <td>8</td>\n",
              "      <td>Icalma Lake</td>\n",
              "      <td>Icalma Lake is a lake located in the Andes of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416552</th>\n",
              "      <td>11</td>\n",
              "      <td>Pouteria sandwicensis</td>\n",
              "      <td>Pouteria sandwicensis is a species of floweri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503849</th>\n",
              "      <td>13</td>\n",
              "      <td>Pepo (film)</td>\n",
              "      <td>Pepo (Armenian: Պեպո) is a 1935 Soviet film d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364384</th>\n",
              "      <td>10</td>\n",
              "      <td>Puebla deer mouse</td>\n",
              "      <td>The Puebla deer mouse (Peromyscus mekisturus)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265465</th>\n",
              "      <td>7</td>\n",
              "      <td>Waleffe Castle</td>\n",
              "      <td>Waleffe Castle is a castle in Belgium.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528364</th>\n",
              "      <td>14</td>\n",
              "      <td>Through the Arc of the Rain Forest</td>\n",
              "      <td>Through the Arc of the Rain Forest is a novel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423816</th>\n",
              "      <td>11</td>\n",
              "      <td>Guarianthe</td>\n",
              "      <td>Guarianthe abbreviated Gur. in the horticultu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                                Name  \\\n",
              "494483     13                      A Wedding Suit   \n",
              "548491     14                       Into Thin Air   \n",
              "339369      9                           Banavchan   \n",
              "295828      8                         Icalma Lake   \n",
              "416552     11               Pouteria sandwicensis   \n",
              "503849     13                         Pepo (film)   \n",
              "364384     10                   Puebla deer mouse   \n",
              "265465      7                      Waleffe Castle   \n",
              "528364     14  Through the Arc of the Rain Forest   \n",
              "423816     11                          Guarianthe   \n",
              "\n",
              "                                                     Text  \n",
              "494483   A Wedding Suit (Persian: لباسی برای عروسی‎ Le...  \n",
              "548491   Into Thin Air: A Personal Account of the Mt. ...  \n",
              "339369   Banavchan (Persian: بناوچان‎ also Romanized a...  \n",
              "295828   Icalma Lake is a lake located in the Andes of...  \n",
              "416552   Pouteria sandwicensis is a species of floweri...  \n",
              "503849   Pepo (Armenian: Պեպո) is a 1935 Soviet film d...  \n",
              "364384   The Puebla deer mouse (Peromyscus mekisturus)...  \n",
              "265465             Waleffe Castle is a castle in Belgium.  \n",
              "528364   Through the Arc of the Rain Forest is a novel...  \n",
              "423816   Guarianthe abbreviated Gur. in the horticultu...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W5Tr7cbmAPP",
        "outputId": "b1cfd48a-10ca-49a5-dd98-e76a4732d1a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsjIA-6imAPQ"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwzMBK3vmAPQ",
        "outputId": "ebb1fa46-c997-43e8-a65a-91c40098d914"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "187313     Bruce Cameron Young is an Australian Liberal ...\n",
              "94935      Daniel Douglas Orlando (born May 29 1981) als...\n",
              "93329      John Hultberg (February 8 1922 – April 15 200...\n",
              "530642     The Oxford University Commonwealth Law Journa...\n",
              "361874     Stensioella heintzi (Heintz's Little Stensio)...\n",
              "Name: Text, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I2JnaEZmAPR",
        "outputId": "23c7602e-5807-48d1-9591-e998809a0d99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "187313     5\n",
              "94935      3\n",
              "93329      3\n",
              "530642    14\n",
              "361874    10\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz517RnvmAPR"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mltPucXEmAPR",
        "outputId": "75468083-7b79-4858-93b8-e1785b10aa84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 1024)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = HashingVectorizer(n_features=2**10, norm='l2')\n",
        "\n",
        "feature_vector = vectorizer.transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVZOWmxXmAPR",
        "outputId": "f3511e44-de67-4dce-927a-3c5fc0ad764a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 39)\t0.15811388300841897\n",
            "  (0, 53)\t-0.15811388300841897\n",
            "  (0, 54)\t0.15811388300841897\n",
            "  (0, 61)\t-0.15811388300841897\n",
            "  (0, 152)\t0.15811388300841897\n",
            "  (0, 158)\t-0.4743416490252569\n",
            "  (0, 175)\t-0.15811388300841897\n",
            "  (0, 203)\t-0.15811388300841897\n",
            "  (0, 300)\t0.31622776601683794\n",
            "  (0, 308)\t-0.15811388300841897\n",
            "  (0, 311)\t-0.15811388300841897\n",
            "  (0, 352)\t-0.15811388300841897\n",
            "  (0, 362)\t-0.15811388300841897\n",
            "  (0, 363)\t0.15811388300841897\n",
            "  (0, 365)\t0.31622776601683794\n",
            "  (0, 399)\t0.15811388300841897\n",
            "  (0, 426)\t0.15811388300841897\n",
            "  (0, 470)\t0.15811388300841897\n",
            "  (0, 513)\t-0.15811388300841897\n",
            "  (0, 534)\t0.15811388300841897\n",
            "  (0, 540)\t-0.15811388300841897\n",
            "  (0, 663)\t-0.15811388300841897\n",
            "  (0, 665)\t-0.15811388300841897\n",
            "  (0, 819)\t-0.15811388300841897\n",
            "  (0, 1002)\t-0.15811388300841897\n",
            "  (0, 1011)\t-0.15811388300841897\n"
          ]
        }
      ],
      "source": [
        "print(feature_vector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Laoa5qFomAPS"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADFyx5GLmAPS",
        "outputId": "7d3c4910-5c57-4b50-dd88-f71958d3c0fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 1024)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWoAHGlimAPS"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V6TuYTTmAPS",
        "outputId": "b50292e0-c728-45da-9723-b01950d214ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 1024), (2000, 1024))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKBk-vrumAPT",
        "outputId": "92793376-ef2f-4690-980f-2728bb42f8ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000,), (2000,))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqpBM_b3mAPT"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqj0ErSvmAPT",
        "outputId": "a17e0aa2-d2cc-4c6b-cf7b-1b7f223277ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7, 11, 13, ...,  5,  6,  7])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jN0KJ0QmAPU",
        "outputId": "8d1d35ca-885f-4c2d-dd54-1357c4ad5084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1153\n",
            "accuracy_score :  0.5765\n",
            "precision_score :  0.5891110304184962\n",
            "recall_score :  0.5765\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9T8fIkcmAPU",
        "outputId": "5a289303-f2c4-48b1-921a-919ee118cb4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "267097     7\n",
              "364326    10\n",
              "509624    13\n",
              "466990    12\n",
              "145918     4\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxijqsCvmAPU"
      },
      "outputs": [],
      "source": [
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUaitcCrmAPV",
        "outputId": "f646911c-28ba-4eda-d2c4-a5b851d237b6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1746</th>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1851</th>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      y_test  y_pred\n",
              "1486       1       1\n",
              "494        9       8\n",
              "1039       3       3\n",
              "985        9       9\n",
              "711        8      10\n",
              "532        1       1\n",
              "1249      11      10\n",
              "1746       8      11\n",
              "766        1       7\n",
              "1851      12       4"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_results = pd.DataFrame({'y_test': pd.Series(y_test),\n",
        "                             'y_pred': pd.Series(y_pred)})\n",
        "\n",
        "pred_results.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyVwXI_VmAPV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYpa3MhamAPW"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 12b-Stemmer_HashingVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXAzNH1kmAPW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppGKjvw8mAPW"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3ULIGQNmAPX",
        "outputId": "69dc381c-b97b-4546-e7a1-a51f78cfab80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui9aA37vmAPX"
      },
      "source": [
        "### DBPedia classes\n",
        "\n",
        "- Company\n",
        "- EducationalInstitution\n",
        "- Artist\n",
        "- Athlete\n",
        "- OfficeHolder\n",
        "- MeanOfTransportation\n",
        "- Building\n",
        "- NaturalPlace\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- WrittenWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcKyVGGLmAPX",
        "outputId": "738ce34f-33ee-4d8a-ede6-cf2de4531b33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kYy7ZrOmAPY"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuXel0jXmAPY",
        "outputId": "f90e408a-002b-47a5-fbf4-a743445861e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>328754</th>\n",
              "      <td>9</td>\n",
              "      <td>Sadabad-e Sofla</td>\n",
              "      <td>Sadabad-e Sofla (Persian: سعدابادسفلي‎ also R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268204</th>\n",
              "      <td>7</td>\n",
              "      <td>Westgate Mall (Spartanburg)</td>\n",
              "      <td>Westgate Mall is a shopping mall in Spartanbu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53524</th>\n",
              "      <td>2</td>\n",
              "      <td>North Rockland High School</td>\n",
              "      <td>North Rockland High School is a high school l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435646</th>\n",
              "      <td>11</td>\n",
              "      <td>Tillandsia diguetii</td>\n",
              "      <td>Tillandsia diguetii is a species of the genus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254752</th>\n",
              "      <td>7</td>\n",
              "      <td>Palais Wilczek</td>\n",
              "      <td>Palais Wilczek is a palace in Vienna Austria....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29074</th>\n",
              "      <td>1</td>\n",
              "      <td>Canfor</td>\n",
              "      <td>Canfor Corporation is a Canadian integrated f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155059</th>\n",
              "      <td>4</td>\n",
              "      <td>Gerry Rioux</td>\n",
              "      <td>Gerard Rioux (born February 17 1959) is a Can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137451</th>\n",
              "      <td>4</td>\n",
              "      <td>Jerry DePoyster</td>\n",
              "      <td>Jerry Dean DePoyster (born July 6 1946 in Oma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363022</th>\n",
              "      <td>10</td>\n",
              "      <td>Pieris (butterfly)</td>\n",
              "      <td>Pieris the whites or garden whites is a wides...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499846</th>\n",
              "      <td>13</td>\n",
              "      <td>Gunah Aur Kanoon</td>\n",
              "      <td>Gunah Aur Kanoon is a 1970 Bollywood drama fi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                         Name  \\\n",
              "328754      9              Sadabad-e Sofla   \n",
              "268204      7  Westgate Mall (Spartanburg)   \n",
              "53524       2   North Rockland High School   \n",
              "435646     11          Tillandsia diguetii   \n",
              "254752      7               Palais Wilczek   \n",
              "29074       1                       Canfor   \n",
              "155059      4                  Gerry Rioux   \n",
              "137451      4              Jerry DePoyster   \n",
              "363022     10           Pieris (butterfly)   \n",
              "499846     13             Gunah Aur Kanoon   \n",
              "\n",
              "                                                     Text  \n",
              "328754   Sadabad-e Sofla (Persian: سعدابادسفلي‎ also R...  \n",
              "268204   Westgate Mall is a shopping mall in Spartanbu...  \n",
              "53524    North Rockland High School is a high school l...  \n",
              "435646   Tillandsia diguetii is a species of the genus...  \n",
              "254752   Palais Wilczek is a palace in Vienna Austria....  \n",
              "29074    Canfor Corporation is a Canadian integrated f...  \n",
              "155059   Gerard Rioux (born February 17 1959) is a Can...  \n",
              "137451   Jerry Dean DePoyster (born July 6 1946 in Oma...  \n",
              "363022   Pieris the whites or garden whites is a wides...  \n",
              "499846   Gunah Aur Kanoon is a 1970 Bollywood drama fi...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nER6sCUmAPY",
        "outputId": "8fe73075-f173-4ef8-ea26-675fb4e96b40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtCTp3SvmAPZ"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSPtfctBmAPZ",
        "outputId": "05482034-059b-4ac5-cdce-dacaf693e8d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "346354     Hoseynabad-e Sarzeh (Persian: حسين ابادسرزه‎ ...\n",
              "198538     Milton Berkes (born September 29 1924) is a f...\n",
              "550592     R.M. Williams Outback (or simply Outback) is ...\n",
              "387637     Metasia carnealis is a species of moth in the...\n",
              "366618     The Father Basilio's Striped Mouse or Bioko H...\n",
              "Name: Text, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfec-PC5mAPa",
        "outputId": "834ecc88-db3a-4bd8-c21d-116d34aa71d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "346354     9\n",
              "198538     5\n",
              "550592    14\n",
              "387637    10\n",
              "366618    10\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k5POzinmAPa"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10b-fe0zmAPa"
      },
      "outputs": [],
      "source": [
        "stemmer =  SnowballStemmer('english')\n",
        "analyzer = HashingVectorizer().build_analyzer()\n",
        "\n",
        "def stemmed_words(doc):\n",
        "    return (stemmer.stem(w) for w in analyzer(doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXdKXrfhmAPb",
        "outputId": "5ff1ad46-02ce-4fb1-9474-2eb7e2d010bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 1024)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stem_vectorizer = HashingVectorizer(n_features=2**10, norm='l2', analyzer=stemmed_words)\n",
        "\n",
        "feature_vector = stem_vectorizer.transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7Clz96KmAPb",
        "outputId": "97e8154a-f76e-409d-ada2-0b7fe286fc7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 21)\t0.25607375986579195\n",
            "  (0, 24)\t-0.12803687993289598\n",
            "  (0, 27)\t0.12803687993289598\n",
            "  (0, 61)\t-0.12803687993289598\n",
            "  (0, 62)\t0.12803687993289598\n",
            "  (0, 69)\t-0.12803687993289598\n",
            "  (0, 71)\t-0.25607375986579195\n",
            "  (0, 145)\t-0.12803687993289598\n",
            "  (0, 158)\t-0.12803687993289598\n",
            "  (0, 215)\t0.12803687993289598\n",
            "  (0, 273)\t0.25607375986579195\n",
            "  (0, 301)\t-0.12803687993289598\n",
            "  (0, 304)\t0.12803687993289598\n",
            "  (0, 355)\t0.12803687993289598\n",
            "  (0, 365)\t0.12803687993289598\n",
            "  (0, 424)\t-0.12803687993289598\n",
            "  (0, 540)\t0.25607375986579195\n",
            "  (0, 550)\t-0.12803687993289598\n",
            "  (0, 569)\t0.12803687993289598\n",
            "  (0, 595)\t-0.3841106397986879\n",
            "  (0, 643)\t0.12803687993289598\n",
            "  (0, 659)\t0.12803687993289598\n",
            "  (0, 697)\t0.12803687993289598\n",
            "  (0, 745)\t-0.12803687993289598\n",
            "  (0, 758)\t-0.12803687993289598\n",
            "  (0, 799)\t0.12803687993289598\n",
            "  (0, 832)\t-0.12803687993289598\n",
            "  (0, 877)\t0.12803687993289598\n",
            "  (0, 883)\t0.12803687993289598\n",
            "  (0, 884)\t-0.12803687993289598\n",
            "  (0, 885)\t0.25607375986579195\n",
            "  (0, 913)\t0.12803687993289598\n",
            "  (0, 914)\t-0.12803687993289598\n",
            "  (0, 971)\t-0.25607375986579195\n",
            "  (0, 983)\t-0.12803687993289598\n"
          ]
        }
      ],
      "source": [
        "print(feature_vector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXleGmmEmAPb"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmLDZBysmAPc",
        "outputId": "a508355c-987e-44a3-ae3f-70e8e41b34f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 1024)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FiuyAmXmAPc"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kB6PWlkmAPc",
        "outputId": "fa0375ee-a8fc-4cd6-8d54-b4d21217ecb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 1024), (2000, 1024))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgGdxB1-mAPd",
        "outputId": "d12a7f8f-d9a4-4ef6-b0db-bd23e86454e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000,), (2000,))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4IMUVHFmAPd"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB_Fr-o8mAPe",
        "outputId": "353d31f8-e683-43b1-f215-9cc06b10d509"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3,  3, 11, ...,  2,  2,  4])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGYMmriMmAPe",
        "outputId": "fb2d0ec4-8a29-4c36-c698-da13cd716823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1120\n",
            "accuracy_score :  0.56\n",
            "precision_score :  0.5663465185830068\n",
            "recall_score :  0.56\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_cHtFx1mAPe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f80OJOh7mAPf"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 13a-CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ivbyyc4mAPf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w8JO0uVmAPf"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdpT1TmEmAPg",
        "outputId": "8e73aed0-f952-49a9-8ab3-738dcedd6418"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIOaBi6tmAPg"
      },
      "source": [
        "### DBPedia classes\n",
        "\n",
        "- Company\n",
        "- EducationalInstitution\n",
        "- Artist\n",
        "- Athlete\n",
        "- OfficeHolder\n",
        "- MeanOfTransportation\n",
        "- Building\n",
        "- NaturalPlace\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- WrittenWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ6TktjamAPh",
        "outputId": "63f5c2c6-850c-4b28-8023-001732237ff5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1FQ0AE_mAPh"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-KmBZcTmAPi",
        "outputId": "5e77533f-878d-497e-d13c-90acb7abbaef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>500996</th>\n",
              "      <td>13</td>\n",
              "      <td>The County Chairman</td>\n",
              "      <td>The County Chairman is a 1935 comedy film dir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40795</th>\n",
              "      <td>2</td>\n",
              "      <td>Our Lady of Mount Carmel High School (Baltimor...</td>\n",
              "      <td>Our Lady of Mount Carmel High School (OLMC HS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131453</th>\n",
              "      <td>4</td>\n",
              "      <td>Jim Kleinsasser</td>\n",
              "      <td>Jimmy Carter Kleinsasser (/ˈklaɪnsɑːsər/; bor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122291</th>\n",
              "      <td>4</td>\n",
              "      <td>August Klingler</td>\n",
              "      <td>August Klingler (24 February 1918 – 23 Novemb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38965</th>\n",
              "      <td>1</td>\n",
              "      <td>Fine Fare</td>\n",
              "      <td>Fine Fare was the name of a chain of supermar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89852</th>\n",
              "      <td>3</td>\n",
              "      <td>Desmond Devlin</td>\n",
              "      <td>Desmond Devlin is an American comedy writer. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481930</th>\n",
              "      <td>13</td>\n",
              "      <td>A Sister to Assist 'Er (1938 film)</td>\n",
              "      <td>A Sister to Assist 'Er is a 1938 British come...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95008</th>\n",
              "      <td>3</td>\n",
              "      <td>Megumi Makihara</td>\n",
              "      <td>Megumi Makihara (槇原めぐみ or 槙原めぐみ or 慎原めぐみ Maki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543571</th>\n",
              "      <td>14</td>\n",
              "      <td>Annals of Science</td>\n",
              "      <td>Annals of Science is a peer-reviewed academic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356791</th>\n",
              "      <td>9</td>\n",
              "      <td>Dula Gavabar</td>\n",
              "      <td>Dula Gavabar (Persian: دولاگوابر‎ also Romani...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                                               Name  \\\n",
              "500996     13                                The County Chairman   \n",
              "40795       2  Our Lady of Mount Carmel High School (Baltimor...   \n",
              "131453      4                                    Jim Kleinsasser   \n",
              "122291      4                                    August Klingler   \n",
              "38965       1                                          Fine Fare   \n",
              "89852       3                                     Desmond Devlin   \n",
              "481930     13                 A Sister to Assist 'Er (1938 film)   \n",
              "95008       3                                    Megumi Makihara   \n",
              "543571     14                                  Annals of Science   \n",
              "356791      9                                       Dula Gavabar   \n",
              "\n",
              "                                                     Text  \n",
              "500996   The County Chairman is a 1935 comedy film dir...  \n",
              "40795    Our Lady of Mount Carmel High School (OLMC HS...  \n",
              "131453   Jimmy Carter Kleinsasser (/ˈklaɪnsɑːsər/; bor...  \n",
              "122291   August Klingler (24 February 1918 – 23 Novemb...  \n",
              "38965    Fine Fare was the name of a chain of supermar...  \n",
              "89852    Desmond Devlin is an American comedy writer. ...  \n",
              "481930   A Sister to Assist 'Er is a 1938 British come...  \n",
              "95008    Megumi Makihara (槇原めぐみ or 槙原めぐみ or 慎原めぐみ Maki...  \n",
              "543571   Annals of Science is a peer-reviewed academic...  \n",
              "356791   Dula Gavabar (Persian: دولاگوابر‎ also Romani...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmUpH4axmAPi",
        "outputId": "fb50f29e-74fd-45fe-a4ba-0c8b83e905b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUFsoP-gmAPi"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8dx5VdwmAPj",
        "outputId": "396cce73-1fb7-4fcc-a1ef-9bde5dd82fc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "113209     Eisuke Yoshiyuki (吉行 エイスケ Yoshiyuki Eisuke Ma...\n",
              "10443      Schroders plc is a British multinational asse...\n",
              "152897     Patrice Ferri is a retired French association...\n",
              "485929     Honey 2 is a dance film which is a sequel to ...\n",
              "312910     Marjanah is an impact crater in the northern ...\n",
              "Name: Text, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AbvPaubmAPj",
        "outputId": "571658f0-be5b-4c4c-c172-a83aaabb3fec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "113209     3\n",
              "10443      1\n",
              "152897     4\n",
              "485929    13\n",
              "312910     8\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8f1bYWUmAPj"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7laUA0y7mAPk",
        "outputId": "5a40e65e-362f-43d0-d130-ddb521151674"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48133)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFkYfRjUmAPk",
        "outputId": "fdceafc1-0b56-43ae-e50e-c7b1b60afb73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 44965)\t1\n",
            "  (0, 45159)\t1\n",
            "  (0, 24477)\t1\n",
            "  (0, 30174)\t1\n",
            "  (0, 5353)\t1\n",
            "  (0, 2617)\t2\n",
            "  (0, 4213)\t1\n",
            "  (0, 29184)\t1\n",
            "  (0, 770)\t1\n",
            "  (0, 41370)\t1\n",
            "  (0, 2229)\t1\n",
            "  (0, 22994)\t1\n",
            "  (0, 44731)\t1\n",
            "  (0, 22447)\t1\n",
            "  (0, 11806)\t1\n",
            "  (0, 3406)\t1\n",
            "  (0, 29564)\t1\n",
            "  (0, 3087)\t1\n",
            "  (0, 21905)\t1\n",
            "  (0, 38741)\t1\n",
            "  (0, 19410)\t3\n",
            "  (0, 32904)\t1\n",
            "  (0, 30043)\t1\n",
            "  (0, 20446)\t1\n",
            "  (0, 6733)\t1\n",
            "  (0, 18881)\t1\n",
            "  (0, 4662)\t2\n",
            "  (0, 21408)\t1\n",
            "  (0, 44526)\t4\n",
            "  (0, 696)\t1\n",
            "  (0, 21879)\t1\n",
            "  (0, 653)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 26417)\t1\n",
            "  (0, 47763)\t1\n",
            "  (0, 47850)\t1\n",
            "  (0, 45736)\t4\n",
            "  (0, 13969)\t3\n"
          ]
        }
      ],
      "source": [
        "print(feature_vector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ailgBeWGmAPl"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIJMbVjhmAPl",
        "outputId": "3708defe-17d8-42cd-bd99-89200c6a1135"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48133)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJOq2y88mAPl"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdbE3kkRmAPm",
        "outputId": "0f666537-e077-46d8-9e1f-95666c4c9c15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 48133), (2000, 48133))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te4ox-OWmAPm",
        "outputId": "22971d26-915f-432e-93a0-ce6490005801"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000,), (2000,))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntDOf4N-mAPm"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0cnrnYEmAPn",
        "outputId": "95f2190b-8832-4522-cd6c-7fd4261fbf0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 5, 10,  4, ...,  5,  1, 14])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkmqG_KTmAPn",
        "outputId": "ca6546eb-f289-40e6-eed5-e2fdce5a3a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1464\n",
            "accuracy_score :  0.732\n",
            "precision_score :  0.7480649828741391\n",
            "recall_score :  0.732\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsD-rA42mAPo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_rxbFItmAPo"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 13b-StopwordRemoval_CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5760mnpDmAPo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC6KjKOmmAPp"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtNIVQR5mAPp",
        "outputId": "107865dd-e2cf-424e-a11a-1175b6229966"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHCxz-rUmAPp"
      },
      "source": [
        "### DBPedia classes\n",
        "\n",
        "- Company\n",
        "- EducationalInstitution\n",
        "- Artist\n",
        "- Athlete\n",
        "- OfficeHolder\n",
        "- MeanOfTransportation\n",
        "- Building\n",
        "- NaturalPlace\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- WrittenWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te0Zv8eWmAPq",
        "outputId": "a77c9a0a-53c4-4188-ff87-d714cfd052da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCCANPR5mAPq"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3Ux6H2wmAPq",
        "outputId": "0f5a5ff9-2dd3-498e-8b4d-def89d87feac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>524463</th>\n",
              "      <td>14</td>\n",
              "      <td>Open Sesame (manga)</td>\n",
              "      <td>Open Sesame is a Japanese manga series writte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214954</th>\n",
              "      <td>6</td>\n",
              "      <td>USS Porter (DDG-78)</td>\n",
              "      <td>USS Porter (DDG-78) is an Arleigh Burke-class...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369188</th>\n",
              "      <td>10</td>\n",
              "      <td>Chionodes luctuella</td>\n",
              "      <td>Chionodes luctuella is a moth of the Gelechii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15537</th>\n",
              "      <td>1</td>\n",
              "      <td>Rashtriya Chemicals &amp; Fertilizers</td>\n",
              "      <td>Rashtriya Chemicals &amp; Fertilizers Ltd. (RCF) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434426</th>\n",
              "      <td>11</td>\n",
              "      <td>Salix gilgiana</td>\n",
              "      <td>Salix gilgiana is a species of willow native ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315086</th>\n",
              "      <td>8</td>\n",
              "      <td>Devlins Creek</td>\n",
              "      <td>Devlins Creek an urban watercourse that is pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133194</th>\n",
              "      <td>4</td>\n",
              "      <td>Warren Donald</td>\n",
              "      <td>Warren Donald (born 7 October 1964) is an Eng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138090</th>\n",
              "      <td>4</td>\n",
              "      <td>Chris Hatcher (outfielder)</td>\n",
              "      <td>Christopher Kenneth Hatcher (born January 7 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358873</th>\n",
              "      <td>9</td>\n",
              "      <td>Królewskie Ostrzeszów County</td>\n",
              "      <td>Królewskie [kruˈlɛfskʲɛ] is a village in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108048</th>\n",
              "      <td>3</td>\n",
              "      <td>Hamuera Tamahau Mahupuku</td>\n",
              "      <td>Hamuera Tamahau Mahupuku (c.1842 – 14 January...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                               Name  \\\n",
              "524463     14                Open Sesame (manga)   \n",
              "214954      6                USS Porter (DDG-78)   \n",
              "369188     10                Chionodes luctuella   \n",
              "15537       1  Rashtriya Chemicals & Fertilizers   \n",
              "434426     11                     Salix gilgiana   \n",
              "315086      8                      Devlins Creek   \n",
              "133194      4                      Warren Donald   \n",
              "138090      4         Chris Hatcher (outfielder)   \n",
              "358873      9       Królewskie Ostrzeszów County   \n",
              "108048      3           Hamuera Tamahau Mahupuku   \n",
              "\n",
              "                                                     Text  \n",
              "524463   Open Sesame is a Japanese manga series writte...  \n",
              "214954   USS Porter (DDG-78) is an Arleigh Burke-class...  \n",
              "369188   Chionodes luctuella is a moth of the Gelechii...  \n",
              "15537    Rashtriya Chemicals & Fertilizers Ltd. (RCF) ...  \n",
              "434426   Salix gilgiana is a species of willow native ...  \n",
              "315086   Devlins Creek an urban watercourse that is pa...  \n",
              "133194   Warren Donald (born 7 October 1964) is an Eng...  \n",
              "138090   Christopher Kenneth Hatcher (born January 7 1...  \n",
              "358873   Królewskie [kruˈlɛfskʲɛ] is a village in the ...  \n",
              "108048   Hamuera Tamahau Mahupuku (c.1842 – 14 January...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-QMHPpomAPr",
        "outputId": "b26ee5e0-63ab-4958-cb1e-edcdc6a3349c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO6quPu6mAPr"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yRtjQVRmAPr",
        "outputId": "33e7a718-d3ab-4ef8-b2d1-55123a6afdad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77514      Phillips University was a private coeducation...\n",
              "341059     Nowiny [nɔˈvinɨ] is a village in the administ...\n",
              "517834     Capricious Summer (Czech: Rozmarné léto) is a...\n",
              "215388     Maumelle Ordnance Works Locomotive 1 is a gas...\n",
              "250923     Grace Reformed Church is a historic church lo...\n",
              "Name: Text, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wgEOpAkmAPs",
        "outputId": "9ffcac9e-f66a-445a-b9bd-c4b066ccd01c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77514      2\n",
              "341059     9\n",
              "517834    13\n",
              "215388     6\n",
              "250923     7\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_-POjJnmAPs"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEjYJYsmmAPt",
        "outputId": "c327f091-e31e-410e-a63b-e8233ef0b9ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47886)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSK0Wjt0mAPt",
        "outputId": "c6fb8dba-fa69-4357-8ee6-af7d98349498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 15329)\t1\n",
            "  (0, 28116)\t1\n",
            "  (0, 39106)\t1\n",
            "  (0, 42005)\t1\n",
            "  (0, 14627)\t1\n",
            "  (0, 19453)\t1\n",
            "  (0, 34423)\t1\n",
            "  (0, 7888)\t1\n",
            "  (0, 30095)\t1\n",
            "  (0, 40200)\t1\n",
            "  (0, 19281)\t1\n",
            "  (0, 36984)\t1\n",
            "  (0, 17534)\t1\n",
            "  (0, 9770)\t1\n",
            "  (0, 42720)\t1\n",
            "  (0, 20178)\t1\n",
            "  (0, 9116)\t1\n",
            "  (0, 12475)\t1\n",
            "  (0, 9188)\t1\n",
            "  (0, 9127)\t1\n",
            "  (0, 2428)\t1\n",
            "  (0, 786)\t1\n",
            "  (0, 666)\t1\n",
            "  (0, 39115)\t1\n",
            "  (0, 42819)\t1\n",
            "  (0, 29834)\t1\n",
            "  (0, 14115)\t2\n",
            "  (0, 24524)\t1\n",
            "  (0, 13596)\t1\n",
            "  (0, 19001)\t1\n",
            "  (0, 20458)\t1\n",
            "  (0, 9679)\t1\n",
            "  (0, 32870)\t1\n",
            "  (0, 42838)\t2\n",
            "  (0, 31628)\t2\n"
          ]
        }
      ],
      "source": [
        "print(feature_vector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVsQ9za_mAPt"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8a6sPXomAPu",
        "outputId": "c864affc-93be-4a6c-8d0a-aaac93fd47fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47886)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qxexzTkmAPu"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqafBPONmAPu",
        "outputId": "6e1a7cac-f292-462f-91b1-f5577c491840"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 47886), (2000, 47886))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWqQorJ0mAPv",
        "outputId": "cb0fba18-ea73-4514-d1fd-0af5d8e12687"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000,), (2000,))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKiWCXiHmAPv"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ7abMfZmAPw",
        "outputId": "07efde97-c5f0-4285-fd4e-0ba62467b9c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 8, 13,  4, ...,  6,  4, 13])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yph1j0RvmAPw",
        "outputId": "8c55372a-5947-4db4-d0ab-2e2172d8d419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1472\n",
            "accuracy_score :  0.736\n",
            "precision_score :  0.746912711601029\n",
            "recall_score :  0.736\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucWiGvIQmAPx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3kioAa7mAPx"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 13c-StopwordRemoval_FrequencyFiltering_CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5iyysQmmAPy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iweocLummAPy"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkg8lULtmAPz",
        "outputId": "1bb4300f-971e-4ce8-ee1b-a5dd47be9558"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7f5b1-3mAPz",
        "outputId": "b4cbf227-76f2-4ef8-c51f-31cee4507eb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d5yepTDmAP0"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE3gdCNlmAP0",
        "outputId": "7857304c-ef1d-467a-ef81-4424bd7808bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>293816</th>\n",
              "      <td>8</td>\n",
              "      <td>Sheep Mountain (Flathead County Montana)</td>\n",
              "      <td>Sheep Mountain (8530 feet (2600 m)) is locate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379389</th>\n",
              "      <td>10</td>\n",
              "      <td>Argyropelecus hemigymnus</td>\n",
              "      <td>Argyropelecus hemigymnus the half-naked hatch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553602</th>\n",
              "      <td>14</td>\n",
              "      <td>Double Identity (novel)</td>\n",
              "      <td>Double Identity is a 2005 young adult novel b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104503</th>\n",
              "      <td>3</td>\n",
              "      <td>Picaflor de los Andes</td>\n",
              "      <td>Víctor Alberto Gil Mallma (1930; Huancayo - J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338288</th>\n",
              "      <td>9</td>\n",
              "      <td>Jerry City Ohio</td>\n",
              "      <td>Jerry City is a village in Wood County Ohio U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244140</th>\n",
              "      <td>7</td>\n",
              "      <td>John Hosford House</td>\n",
              "      <td>The John Hosford House built in 1860 is an hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182565</th>\n",
              "      <td>5</td>\n",
              "      <td>Hunt Downer</td>\n",
              "      <td>Major General Huntington Blair Downer Jr. kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252037</th>\n",
              "      <td>7</td>\n",
              "      <td>Brea City Hall and Park</td>\n",
              "      <td>Brea City Hall and Park in Brea California wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98721</th>\n",
              "      <td>3</td>\n",
              "      <td>Christian Jacob (musician)</td>\n",
              "      <td>Christian Jacob is a lyrical jazz pianist. He...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188815</th>\n",
              "      <td>5</td>\n",
              "      <td>George Forbes (New Zealand politician)</td>\n",
              "      <td>George William Forbes (12 March 1869 – 17 May...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                                      Name  \\\n",
              "293816      8  Sheep Mountain (Flathead County Montana)   \n",
              "379389     10                  Argyropelecus hemigymnus   \n",
              "553602     14                   Double Identity (novel)   \n",
              "104503      3                     Picaflor de los Andes   \n",
              "338288      9                           Jerry City Ohio   \n",
              "244140      7                        John Hosford House   \n",
              "182565      5                               Hunt Downer   \n",
              "252037      7                   Brea City Hall and Park   \n",
              "98721       3                Christian Jacob (musician)   \n",
              "188815      5    George Forbes (New Zealand politician)   \n",
              "\n",
              "                                                     Text  \n",
              "293816   Sheep Mountain (8530 feet (2600 m)) is locate...  \n",
              "379389   Argyropelecus hemigymnus the half-naked hatch...  \n",
              "553602   Double Identity is a 2005 young adult novel b...  \n",
              "104503   Víctor Alberto Gil Mallma (1930; Huancayo - J...  \n",
              "338288   Jerry City is a village in Wood County Ohio U...  \n",
              "244140   The John Hosford House built in 1860 is an hi...  \n",
              "182565   Major General Huntington Blair Downer Jr. kno...  \n",
              "252037   Brea City Hall and Park in Brea California wa...  \n",
              "98721    Christian Jacob is a lyrical jazz pianist. He...  \n",
              "188815   George William Forbes (12 March 1869 – 17 May...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kit3_m2CmAP1",
        "outputId": "8f5a3ad5-0885-49ba-e803-ba9e4da35dd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8363_rejmAP1"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu0LqF9gmAP1"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5iexWxBmAP2",
        "outputId": "c6931515-cae5-445e-8fad-cef70b8a0f89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "503033"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = word_tokenize(\"\\n\".join(X.values))\n",
        "\n",
        "len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNmfTuUnmAP2",
        "outputId": "fe6c984d-c22c-426e-9bc4-7b8249f47c31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FreqDist({'the': 23584, '.': 23365, 'in': 16237, 'of': 15558, 'is': 13472, 'a': 13075, 'and': 12741, '(': 7078, ')': 7048, 'was': 6816, ...})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq = FreqDist(tokens)\n",
        "freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpYc-e_SmAP3",
        "outputId": "e93d2f89-d445-46d8-f0a7-4ed573d5f260"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "491"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequent_words = []\n",
        "\n",
        "for key, value in freq.items():\n",
        "    if value >= 100:\n",
        "        frequent_words.append(key.lower())\n",
        "\n",
        "len(frequent_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HzlOUFWmAP3",
        "outputId": "0653df08-250f-40e3-a857-ed4251d28cca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['columbia',\n",
              " '(',\n",
              " ')',\n",
              " 'was',\n",
              " 'an',\n",
              " 'american',\n",
              " 'company',\n",
              " 'that',\n",
              " 'from',\n",
              " '1994',\n",
              " 'to',\n",
              " '2002',\n",
              " '.',\n",
              " 'it',\n",
              " 'operated',\n",
              " 'as',\n",
              " 'the',\n",
              " 'third',\n",
              " 'name',\n",
              " 'of',\n",
              " 'early',\n",
              " 'studio',\n",
              " 'and',\n",
              " 'part',\n",
              " 'second']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequent_words[:25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXuXAWsRmAP3"
      },
      "outputs": [],
      "source": [
        "stop_words = text.ENGLISH_STOP_WORDS.union(frequent_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WHGE-XmmAP4",
        "outputId": "1abdab1b-3114-446c-e5d9-65a86c1e0876"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['st'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(10000, 47434)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(stop_words=stop_words)\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWVkaP1NmAP4"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEYZqTZymAP5",
        "outputId": "e8060579-0295-4bca-9d43-3a0b4aca3245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47434)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SJiZwCYmAP5"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ccc_QUSPmAP5"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MdimnIimAP6",
        "outputId": "32250d5c-eaba-4b7c-ce49-71273acf6346"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([13,  9, 13, ...,  7, 11,  5])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5v1apIFmAP6",
        "outputId": "d0f14f5a-5928-41e1-e8f2-985d4e08a7e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1397\n",
            "accuracy_score :  0.6985\n",
            "precision_score :  0.7009864007615241\n",
            "recall_score :  0.6985\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clWFjwEmmAP6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPJTW22ZmAP7"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 13d-Bigrams_CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gFDmjBamAP7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DFvGrxCmAP7"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU-e3uYCmAP8",
        "outputId": "aaaadd8b-f1c8-4ed2-ae51-9261306d18e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxxDORnHmAP8",
        "outputId": "b279aa93-b0b1-4ef5-bdfa-56f39c837cb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGoiFkXOmAP8"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S39jubaBmAP9",
        "outputId": "0ac9f51e-a387-4579-bc0d-c3a9c7b4bcda"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>427520</th>\n",
              "      <td>11</td>\n",
              "      <td>Guzmania remyi</td>\n",
              "      <td>Guzmania remyi is a species of plant in the B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522145</th>\n",
              "      <td>14</td>\n",
              "      <td>Villa Aurore</td>\n",
              "      <td>Villa Aurore is a novel written in French by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462552</th>\n",
              "      <td>12</td>\n",
              "      <td>Monk's Casino</td>\n",
              "      <td>Monk's Casino is a live album by German free ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2460</th>\n",
              "      <td>1</td>\n",
              "      <td>Kiss Technology</td>\n",
              "      <td>Kiss Technology is an entertainment technolog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83743</th>\n",
              "      <td>3</td>\n",
              "      <td>S.M. Zakir</td>\n",
              "      <td>S.M. Zakir (born 4 February 1969 in Kota Bhar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554887</th>\n",
              "      <td>14</td>\n",
              "      <td>New York Law Journal</td>\n",
              "      <td>The New York Law Journal founded in 1888 is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270857</th>\n",
              "      <td>7</td>\n",
              "      <td>Latham United Methodist Church</td>\n",
              "      <td>Latham United Methodist Church is a historic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323989</th>\n",
              "      <td>9</td>\n",
              "      <td>Nalavadi</td>\n",
              "      <td>Nalavadi is a village in Dharwad district in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193352</th>\n",
              "      <td>5</td>\n",
              "      <td>Richard Ottley (judge)</td>\n",
              "      <td>Sir Richard Ottley was the 5th Chief Justice ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78104</th>\n",
              "      <td>2</td>\n",
              "      <td>Umatilla High School (Oregon)</td>\n",
              "      <td>Umatilla High School is a public high school ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                            Name  \\\n",
              "427520     11                  Guzmania remyi   \n",
              "522145     14                    Villa Aurore   \n",
              "462552     12                   Monk's Casino   \n",
              "2460        1                 Kiss Technology   \n",
              "83743       3                      S.M. Zakir   \n",
              "554887     14            New York Law Journal   \n",
              "270857      7  Latham United Methodist Church   \n",
              "323989      9                        Nalavadi   \n",
              "193352      5          Richard Ottley (judge)   \n",
              "78104       2   Umatilla High School (Oregon)   \n",
              "\n",
              "                                                     Text  \n",
              "427520   Guzmania remyi is a species of plant in the B...  \n",
              "522145   Villa Aurore is a novel written in French by ...  \n",
              "462552   Monk's Casino is a live album by German free ...  \n",
              "2460     Kiss Technology is an entertainment technolog...  \n",
              "83743    S.M. Zakir (born 4 February 1969 in Kota Bhar...  \n",
              "554887   The New York Law Journal founded in 1888 is a...  \n",
              "270857   Latham United Methodist Church is a historic ...  \n",
              "323989   Nalavadi is a village in Dharwad district in ...  \n",
              "193352   Sir Richard Ottley was the 5th Chief Justice ...  \n",
              "78104    Umatilla High School is a public high school ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eGASa-fmAP9",
        "outputId": "660b9e22-8ae7-4978-e588-37d1e0052dc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah4D6hXpmAP-"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpyVwzPcmAP-"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVUdPFKsmAP_",
        "outputId": "dcdbaa4a-c08a-4884-96bb-3d806c750d06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217709)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuGkRrsEmAP_"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAvU8q26mAQA",
        "outputId": "b136d98d-98b1-4469-e168-808c295424cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217709)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4KJGxobmAQB"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djGGRauMmAQC"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhMaYL5DmAQD",
        "outputId": "f30d5a85-5665-4791-d4dd-f5e34292b9a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 1, 5, ..., 4, 7, 8])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MyHrLEPmAQD",
        "outputId": "729e99a9-8af2-4f03-b6ab-2193e156e9b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1812\n",
            "accuracy_score :  0.906\n",
            "precision_score :  0.9071432275572098\n",
            "recall_score :  0.906\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5Qw8X18mAQE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8KbG2jimAQF"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 14-TfidfVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW4O0sinmAQF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdDGqUq4mAQG"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1oB6NohmAQG",
        "outputId": "2d50803c-7f73-4074-9696-310598925da4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_fa09DPmAQH",
        "outputId": "d85843a4-dc98-4f61-841c-fc5a349662c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrrYJFaYmAQI"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD0kayPImAQJ",
        "outputId": "5282731e-3c8f-4d74-c3a3-bc074f3d0f0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>252405</th>\n",
              "      <td>7</td>\n",
              "      <td>Prowers Bridge</td>\n",
              "      <td>The Prowers Bridge over the Arkansas River ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504457</th>\n",
              "      <td>13</td>\n",
              "      <td>Que sera sera (film)</td>\n",
              "      <td>Que sera sera (Portuguese: Seja o que Deus Qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270494</th>\n",
              "      <td>7</td>\n",
              "      <td>The Esplanade (Kenner Louisiana)</td>\n",
              "      <td>The Esplanade also known as the Esplanade Mal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546058</th>\n",
              "      <td>14</td>\n",
              "      <td>The 1974 Annual World's Best SF</td>\n",
              "      <td>The 1974 Annual World's Best SF is an antholo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461279</th>\n",
              "      <td>12</td>\n",
              "      <td>Just Go (album)</td>\n",
              "      <td>Just Go is the ninth studio album by American...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277143</th>\n",
              "      <td>7</td>\n",
              "      <td>Steyning Methodist Church</td>\n",
              "      <td>Steyning Methodist Church is a Methodist plac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266867</th>\n",
              "      <td>7</td>\n",
              "      <td>Smith Estate (Ridge New York)</td>\n",
              "      <td>Smith Estate also known as Longwood Estate - ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283712</th>\n",
              "      <td>8</td>\n",
              "      <td>Yr Eifl</td>\n",
              "      <td>Yr Eifl is a mountain on the north coast of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33861</th>\n",
              "      <td>1</td>\n",
              "      <td>IBM India</td>\n",
              "      <td>IBM India Private Limited is the Indian subsi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70953</th>\n",
              "      <td>2</td>\n",
              "      <td>Loreto College of Rose-Hill</td>\n",
              "      <td>Loreto College Rose Hill is a private seconda...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                              Name  \\\n",
              "252405      7                    Prowers Bridge   \n",
              "504457     13              Que sera sera (film)   \n",
              "270494      7  The Esplanade (Kenner Louisiana)   \n",
              "546058     14   The 1974 Annual World's Best SF   \n",
              "461279     12                   Just Go (album)   \n",
              "277143      7         Steyning Methodist Church   \n",
              "266867      7     Smith Estate (Ridge New York)   \n",
              "283712      8                           Yr Eifl   \n",
              "33861       1                         IBM India   \n",
              "70953       2       Loreto College of Rose-Hill   \n",
              "\n",
              "                                                     Text  \n",
              "252405   The Prowers Bridge over the Arkansas River ne...  \n",
              "504457   Que sera sera (Portuguese: Seja o que Deus Qu...  \n",
              "270494   The Esplanade also known as the Esplanade Mal...  \n",
              "546058   The 1974 Annual World's Best SF is an antholo...  \n",
              "461279   Just Go is the ninth studio album by American...  \n",
              "277143   Steyning Methodist Church is a Methodist plac...  \n",
              "266867   Smith Estate also known as Longwood Estate - ...  \n",
              "283712   Yr Eifl is a mountain on the north coast of t...  \n",
              "33861    IBM India Private Limited is the Indian subsi...  \n",
              "70953    Loreto College Rose Hill is a private seconda...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN047CL_mAQJ",
        "outputId": "c3e095ea-73b1-4f71-edde-090e3926a53b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUTlfRmrmAQJ"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeHb-bTnmAQK"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68yiHRYZmAQK",
        "outputId": "eae5814d-76ee-4005-8693-36e6ab18083c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48401)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "feature_vector = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7_rf_-3mAQL"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PffvjYFwmAQL",
        "outputId": "3d093879-f222-4b74-c3c5-13eb14fa1250"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48401)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDNt-bJTmAQM"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrsiWq8nmAQN"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0riS64KmAQN",
        "outputId": "c919f92d-1217-4087-d6cd-77f3311a0abd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10,  7,  7, ...,  7,  4, 12])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmqM_ZfjmAQO",
        "outputId": "33a7f255-0373-4a28-c7fa-b067435f5882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1398\n",
            "accuracy_score :  0.699\n",
            "precision_score :  0.7100351307095724\n",
            "recall_score :  0.699\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Qp9XlS5mAQP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5tsuYK7mAQP"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 15a-CountVectorizer_TfidfTransformer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f85bN61tmAQQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4wcV-23mAQQ"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ITdo4XimAQR",
        "outputId": "43e1479b-4091-4553-bd68-b1b541d206ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWpJxoZDmAQS",
        "outputId": "55690abc-773a-4c04-fc26-eeceb35baf44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIsjVtXymAQS"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8ColABJmAQT",
        "outputId": "66f35450-8ea4-4fa0-8eb7-b39bfd618f11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>445879</th>\n",
              "      <td>12</td>\n",
              "      <td>Lucas (album)</td>\n",
              "      <td>Lucas is the second album by Ghostly Internat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120854</th>\n",
              "      <td>4</td>\n",
              "      <td>Pat McGehee</td>\n",
              "      <td>Patrick Henry McGehee (July 2 1888 – December...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449608</th>\n",
              "      <td>12</td>\n",
              "      <td>One Too Many Hearts</td>\n",
              "      <td>One Too Many Hearts is the third EP by Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171512</th>\n",
              "      <td>5</td>\n",
              "      <td>Arken Arystanov</td>\n",
              "      <td>Arkén Kenesbékovich Arystánov (Kazakh: Аркен ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26868</th>\n",
              "      <td>1</td>\n",
              "      <td>Cineplex Odeon Films</td>\n",
              "      <td>Cineplex Odeon Films (also known as Cineplex ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402498</th>\n",
              "      <td>11</td>\n",
              "      <td>Steirachne</td>\n",
              "      <td>Steirachne is a genus of grass in the Poaceae...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102353</th>\n",
              "      <td>3</td>\n",
              "      <td>Harry Thumann</td>\n",
              "      <td>Harry Thumann (28 February 1952 – 2001) was a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337385</th>\n",
              "      <td>9</td>\n",
              "      <td>Chah Sheykh</td>\n",
              "      <td>Chah Sheykh (Persian: چاه شيخ‎ also Romanized...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485176</th>\n",
              "      <td>13</td>\n",
              "      <td>Emmtan-Magan</td>\n",
              "      <td>Em Magan is a 2006 Tamil drama film directed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295129</th>\n",
              "      <td>8</td>\n",
              "      <td>Hot Springs Range</td>\n",
              "      <td>The Hot Springs Range is a mountain range in ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                  Name  \\\n",
              "445879     12         Lucas (album)   \n",
              "120854      4           Pat McGehee   \n",
              "449608     12   One Too Many Hearts   \n",
              "171512      5       Arken Arystanov   \n",
              "26868       1  Cineplex Odeon Films   \n",
              "402498     11            Steirachne   \n",
              "102353      3         Harry Thumann   \n",
              "337385      9           Chah Sheykh   \n",
              "485176     13          Emmtan-Magan   \n",
              "295129      8     Hot Springs Range   \n",
              "\n",
              "                                                     Text  \n",
              "445879   Lucas is the second album by Ghostly Internat...  \n",
              "120854   Patrick Henry McGehee (July 2 1888 – December...  \n",
              "449608   One Too Many Hearts is the third EP by Americ...  \n",
              "171512   Arkén Kenesbékovich Arystánov (Kazakh: Аркен ...  \n",
              "26868    Cineplex Odeon Films (also known as Cineplex ...  \n",
              "402498   Steirachne is a genus of grass in the Poaceae...  \n",
              "102353   Harry Thumann (28 February 1952 – 2001) was a...  \n",
              "337385   Chah Sheykh (Persian: چاه شيخ‎ also Romanized...  \n",
              "485176   Em Magan is a 2006 Tamil drama film directed ...  \n",
              "295129   The Hot Springs Range is a mountain range in ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBFdVhjtmAQT",
        "outputId": "2dec55d7-4adf-49fd-f083-819bc9bb166b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYDn7N4ymAQU"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRbBhvXomAQV"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NTEMLyQmAQV",
        "outputId": "25678ea7-6ce8-4228-fbf1-f9d2984210fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48318)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByFIphwmAQW",
        "outputId": "5dd9fd53-6e0b-4ccc-aac2-ee1e308eaa13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48318)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "feature_vector = tfidf_transformer.fit_transform(feature_vector)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpjRCCAtmAQX"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vL2iwy7YmAQX",
        "outputId": "7a1a8a7b-e856-407c-9863-58d3108d9210"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 48318)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9vjXSpkmAQY"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqpE_oiqmAQY"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRdDFnO-mAQZ",
        "outputId": "37ad9bfd-4275-4694-c0fd-c0b33e9b919c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  1,  3, ..., 12, 10,  5])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd8lX9HHmAQa",
        "outputId": "2b8e956f-3873-49ae-f668-6dd2e07a28df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1438\n",
            "accuracy_score :  0.719\n",
            "precision_score :  0.7284791775245764\n",
            "recall_score :  0.719\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcQg6nVamAQa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCbCZ0LSmAQb"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 15b-FrequencyFiltering_CountVectorizer_TfidfTransformer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON1TRI-umAQb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKIQZJu8mAQc"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrD2bwlymAQc",
        "outputId": "3ac2bd90-0859-43d6-a826-3299f88ab469"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDseFFwKmAQd",
        "outputId": "724c7389-bae4-461c-e8fa-d9143f5e001e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-fsbqzFmAQe"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJlv7DBYmAQe",
        "outputId": "f8bad3cc-4426-4157-fc72-9b4fec658555"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>510378</th>\n",
              "      <td>13</td>\n",
              "      <td>Unknown (2006 film)</td>\n",
              "      <td>Unknown is a 2006 American crime-thriller fil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510665</th>\n",
              "      <td>13</td>\n",
              "      <td>World Without Sun</td>\n",
              "      <td>World Without Sun (French: Le Monde sans sole...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392655</th>\n",
              "      <td>10</td>\n",
              "      <td>Argyresthia pseudotsuga</td>\n",
              "      <td>Argyresthia pseudotsuga is a moth of the Ypon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419827</th>\n",
              "      <td>11</td>\n",
              "      <td>Erythronium multiscapoideum</td>\n",
              "      <td>Erythronium multiscapoideum is a species of f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217867</th>\n",
              "      <td>6</td>\n",
              "      <td>Simca 5</td>\n",
              "      <td>The Simca 5 is a small Franco-Italian passeng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377408</th>\n",
              "      <td>10</td>\n",
              "      <td>Bucculatrix zophopasta</td>\n",
              "      <td>Bucculatrix zophopasta is a moth in the Buccu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232485</th>\n",
              "      <td>6</td>\n",
              "      <td>HMS Ajax (F114)</td>\n",
              "      <td>HMS Ajax was a Leander-class frigate of the R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327195</th>\n",
              "      <td>9</td>\n",
              "      <td>Ruś Ostróda County</td>\n",
              "      <td>Ruś [ruɕ] (German Reussen) is a village in th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478293</th>\n",
              "      <td>12</td>\n",
              "      <td>Mortal Kombat: The Album</td>\n",
              "      <td>Mortal Kombat: The Album is an album by The I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533360</th>\n",
              "      <td>14</td>\n",
              "      <td>Makers (novel)</td>\n",
              "      <td>Makers is a novel by Cory Doctorow. It was re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                         Name  \\\n",
              "510378     13          Unknown (2006 film)   \n",
              "510665     13            World Without Sun   \n",
              "392655     10      Argyresthia pseudotsuga   \n",
              "419827     11  Erythronium multiscapoideum   \n",
              "217867      6                      Simca 5   \n",
              "377408     10       Bucculatrix zophopasta   \n",
              "232485      6              HMS Ajax (F114)   \n",
              "327195      9           Ruś Ostróda County   \n",
              "478293     12     Mortal Kombat: The Album   \n",
              "533360     14               Makers (novel)   \n",
              "\n",
              "                                                     Text  \n",
              "510378   Unknown is a 2006 American crime-thriller fil...  \n",
              "510665   World Without Sun (French: Le Monde sans sole...  \n",
              "392655   Argyresthia pseudotsuga is a moth of the Ypon...  \n",
              "419827   Erythronium multiscapoideum is a species of f...  \n",
              "217867   The Simca 5 is a small Franco-Italian passeng...  \n",
              "377408   Bucculatrix zophopasta is a moth in the Buccu...  \n",
              "232485   HMS Ajax was a Leander-class frigate of the R...  \n",
              "327195   Ruś [ruɕ] (German Reussen) is a village in th...  \n",
              "478293   Mortal Kombat: The Album is an album by The I...  \n",
              "533360   Makers is a novel by Cory Doctorow. It was re...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRM6ds7cmAQf",
        "outputId": "c8eb0819-0cc9-4914-ced8-29aca79fdaa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbW00NuomAQf"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUghH-uRmAQg"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MvXoagPmAQg",
        "outputId": "788960a0-672f-408b-f745-8a90c0a63cea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47544)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0, max_df=80)\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2dm1xGdmAQh",
        "outputId": "080020d8-4020-4b00-f1f4-b246f39a7c99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47544)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "feature_vector = tfidf_transformer.fit_transform(feature_vector)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XlYs29ImAQh"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFN9HbL0mAQi",
        "outputId": "8245aaed-1218-4fce-bd70-9028062c7b7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47544)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6UavFpTmAQj"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idbctpzdmAQj"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqraBZkRmAQk",
        "outputId": "a7ffd13b-3b42-4830-e6a7-66f825001828"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10,  4,  1, ..., 13,  6,  2])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsDSsO5VmAQk",
        "outputId": "b9263d4b-6902-4181-d0fa-c7c65b249213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1316\n",
            "accuracy_score :  0.658\n",
            "precision_score :  0.6650727642789968\n",
            "recall_score :  0.658\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c_9aFEcmAQl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poXPkNkvmAQm"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 15c-StopwordRemoval_FrequencyFiltering_CountVectorizer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wezI4N0ZmAQm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I6KA7zCmAQn"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDi5PXEImAQo",
        "outputId": "aee3f166-0281-4efe-fded-7445ad006279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7elsvVzmAQo",
        "outputId": "326a7d65-f2b3-4f7d-f24a-326a5699228d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqAmYvPWmAQp"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFoPNMC6mAQq",
        "outputId": "c6989218-3601-4300-8201-e53e37a24ef7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>179975</th>\n",
              "      <td>5</td>\n",
              "      <td>Ramreddy Damodar Reddy</td>\n",
              "      <td>Ramreddy Damodar Reddy (Telugu: రాంరెడ్డి దామ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558672</th>\n",
              "      <td>14</td>\n",
              "      <td>Sonora Review</td>\n",
              "      <td>Sonora Review is a biannual graduate student-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503492</th>\n",
              "      <td>13</td>\n",
              "      <td>Luz en el páramo</td>\n",
              "      <td>Luz en el páramo is a 1953 Venezuelan film di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40980</th>\n",
              "      <td>2</td>\n",
              "      <td>Oswaldo Cruz Foundation</td>\n",
              "      <td>The Oswaldo Cruz Foundation (Portuguese Funda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199065</th>\n",
              "      <td>5</td>\n",
              "      <td>Tate Reeves</td>\n",
              "      <td>Jonathon Tate Reeves (born June 5 1974) a Rep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20373</th>\n",
              "      <td>1</td>\n",
              "      <td>Indie Boyz</td>\n",
              "      <td>Indie Boyz is a European company based in Lon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131192</th>\n",
              "      <td>4</td>\n",
              "      <td>Hanna Mazgunova</td>\n",
              "      <td>Hanna Mazgunova (Belarusian: Ганна Мазгунова;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438389</th>\n",
              "      <td>11</td>\n",
              "      <td>Platystemon</td>\n",
              "      <td>Platystemon is a monotypic genus of flowering...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295233</th>\n",
              "      <td>8</td>\n",
              "      <td>Paddys River (South West Slopes New South Wales)</td>\n",
              "      <td>Paddys River a watercourse of the Murray catc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481401</th>\n",
              "      <td>13</td>\n",
              "      <td>The Ragged Edge (film)</td>\n",
              "      <td>The Ragged Edge is a lost 1923 silent film So...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                                              Name  \\\n",
              "179975      5                            Ramreddy Damodar Reddy   \n",
              "558672     14                                     Sonora Review   \n",
              "503492     13                                  Luz en el páramo   \n",
              "40980       2                           Oswaldo Cruz Foundation   \n",
              "199065      5                                       Tate Reeves   \n",
              "20373       1                                        Indie Boyz   \n",
              "131192      4                                   Hanna Mazgunova   \n",
              "438389     11                                       Platystemon   \n",
              "295233      8  Paddys River (South West Slopes New South Wales)   \n",
              "481401     13                            The Ragged Edge (film)   \n",
              "\n",
              "                                                     Text  \n",
              "179975   Ramreddy Damodar Reddy (Telugu: రాంరెడ్డి దామ...  \n",
              "558672   Sonora Review is a biannual graduate student-...  \n",
              "503492   Luz en el páramo is a 1953 Venezuelan film di...  \n",
              "40980    The Oswaldo Cruz Foundation (Portuguese Funda...  \n",
              "199065   Jonathon Tate Reeves (born June 5 1974) a Rep...  \n",
              "20373    Indie Boyz is a European company based in Lon...  \n",
              "131192   Hanna Mazgunova (Belarusian: Ганна Мазгунова;...  \n",
              "438389   Platystemon is a monotypic genus of flowering...  \n",
              "295233   Paddys River a watercourse of the Murray catc...  \n",
              "481401   The Ragged Edge is a lost 1923 silent film So...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkTRytrNmAQq",
        "outputId": "149be8a7-c9e5-465c-be27-f5599990e407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-YfpI7zmAQs"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQAgIIFpmAQt"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFKxHDG2mAQt",
        "outputId": "a6b0a4c3-c714-4b5d-934c-9f47e04533ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "504495"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = word_tokenize(\"\\n\".join(X.values))\n",
        "\n",
        "len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISmEGPNjmAQu",
        "outputId": "afde1f1d-2955-4465-b98b-b761a7448111"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FreqDist({'the': 23494, '.': 23437, 'in': 16379, 'of': 15332, 'is': 13499, 'and': 12934, 'a': 12862, '(': 7204, ')': 7199, 'was': 6950, ...})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq = FreqDist(tokens)\n",
        "freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8oJ8uGDmAQv",
        "outputId": "3ed9811a-4e32-4679-eabc-9af709b12e36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "487"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequent_words = []\n",
        "\n",
        "for key, value in freq.items():\n",
        "    if value >= 100:\n",
        "        frequent_words.append(key.lower())\n",
        "\n",
        "len(frequent_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HK5hwAVmAQw",
        "outputId": "4ebb61e0-b441-4271-dfc9-6a3ece5bb5c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['(',\n",
              " ':',\n",
              " '[',\n",
              " ']',\n",
              " '.',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'lake',\n",
              " 'in',\n",
              " 'located',\n",
              " 'north',\n",
              " 'of',\n",
              " 'the',\n",
              " 'town',\n",
              " 'district',\n",
              " 'not',\n",
              " '1',\n",
              " 'the',\n",
              " 'area',\n",
              " 'by',\n",
              " 'including',\n",
              " '2001',\n",
              " 'was',\n",
              " 'international']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequent_words[:25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTiu6ycMmAQw"
      },
      "outputs": [],
      "source": [
        "stop_words = text.ENGLISH_STOP_WORDS.union(frequent_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMoIWT2cmAQx",
        "outputId": "88ba7938-4e20-41c1-c1a7-68fdc58cf5bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47573)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(stop_words=stop_words)\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMsxma2zmAQx",
        "outputId": "80655685-bedb-4221-dd21-e46d0a6dbbb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47573)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "feature_vector = tfidf_transformer.fit_transform(feature_vector)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ocZXnjbmAQy"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR-JZExOmAQy",
        "outputId": "7870c4f3-b02e-4d42-f557-28642f3d72b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 47573)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10FXp9HymAQz"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tivYN9JmAQz"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQFrD6aJmAQ0",
        "outputId": "ab22afce-fcea-41c2-d98e-742d8a797924"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7,  7,  1, ..., 13, 14, 11])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgiKFFpXmAQ0",
        "outputId": "c66e61e8-d3d5-4c35-e9d3-4e8b4b904e33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1335\n",
            "accuracy_score :  0.6675\n",
            "precision_score :  0.6803619205404001\n",
            "recall_score :  0.6675\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffYVCuYjmAQ0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INku_boQmAQ1"
      },
      "source": [
        "<hr><font color=\"green\"><h1>from file: 15d-Bigrams_CountVectorizer_TfidfTransformer_NaiveBayesClassifier</h1></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc7pAJivmAQ1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1pPOiaymAQ1"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = pd.read_csv('./datasets/dbpedia_csv/train.csv',\n",
        "                       skiprows=1, names = ['Label', 'Name', 'Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-ki5-g6mAQ2",
        "outputId": "5ec857e9-a882-445a-d1df-fbbdfda976d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(559999, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXMzjqbsmAQ2",
        "outputId": "330fa11b-7e92-4c1b-b706-47dbfcce57f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXnY826xmAQ3"
      },
      "outputs": [],
      "source": [
        "dbpedia_df = dbpedia_df.sample(10000, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjbyDXQymAQ3",
        "outputId": "7cb75aea-060d-456b-df77-227ceda1c779"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>521705</th>\n",
              "      <td>14</td>\n",
              "      <td>Woodstock (novel)</td>\n",
              "      <td>Woodstock or The Cavalier. A Tale of the Year...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373693</th>\n",
              "      <td>10</td>\n",
              "      <td>Cryptophagidae</td>\n",
              "      <td>Cryptophagidae is a family of beetles with re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333934</th>\n",
              "      <td>9</td>\n",
              "      <td>Dehliz-e Yek</td>\n",
              "      <td>Dehliz-e Yek (Persian: دهليزيك‎ also Romanize...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125305</th>\n",
              "      <td>4</td>\n",
              "      <td>Roland Osabutey</td>\n",
              "      <td>Roland Osabutey (born 11 March 1980) is a Gha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100866</th>\n",
              "      <td>3</td>\n",
              "      <td>Ann Voskamp</td>\n",
              "      <td>Ann Voskamp (born August 10 1973 in Listowel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58320</th>\n",
              "      <td>2</td>\n",
              "      <td>Robert Bateman High School</td>\n",
              "      <td>Robert Bateman High School (also known as Rob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419470</th>\n",
              "      <td>11</td>\n",
              "      <td>Vriesea languida</td>\n",
              "      <td>Vriesea languida is a species of the genus Vr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164430</th>\n",
              "      <td>5</td>\n",
              "      <td>Gilbert Wellington Ostrom</td>\n",
              "      <td>Gilbert Wellington Ostrom (June 1837 – Decemb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426098</th>\n",
              "      <td>11</td>\n",
              "      <td>Banara regia</td>\n",
              "      <td>Banara regia is a species of plant in the Sal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281236</th>\n",
              "      <td>8</td>\n",
              "      <td>Calder River (Western Australia)</td>\n",
              "      <td>For other Rivers Calder see River Calder (dis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Label                              Name  \\\n",
              "521705     14                 Woodstock (novel)   \n",
              "373693     10                    Cryptophagidae   \n",
              "333934      9                      Dehliz-e Yek   \n",
              "125305      4                   Roland Osabutey   \n",
              "100866      3                       Ann Voskamp   \n",
              "58320       2        Robert Bateman High School   \n",
              "419470     11                  Vriesea languida   \n",
              "164430      5         Gilbert Wellington Ostrom   \n",
              "426098     11                      Banara regia   \n",
              "281236      8  Calder River (Western Australia)   \n",
              "\n",
              "                                                     Text  \n",
              "521705   Woodstock or The Cavalier. A Tale of the Year...  \n",
              "373693   Cryptophagidae is a family of beetles with re...  \n",
              "333934   Dehliz-e Yek (Persian: دهليزيك‎ also Romanize...  \n",
              "125305   Roland Osabutey (born 11 March 1980) is a Gha...  \n",
              "100866   Ann Voskamp (born August 10 1973 in Listowel ...  \n",
              "58320    Robert Bateman High School (also known as Rob...  \n",
              "419470   Vriesea languida is a species of the genus Vr...  \n",
              "164430   Gilbert Wellington Ostrom (June 1837 – Decemb...  \n",
              "426098   Banara regia is a species of plant in the Sal...  \n",
              "281236   For other Rivers Calder see River Calder (dis...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pCf0K9VmAQ4",
        "outputId": "824d6138-7c2d-4c0a-9e7f-c5a0febd2951"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dbpedia_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0q11iEjmAQ4"
      },
      "outputs": [],
      "source": [
        "X = dbpedia_df['Text']\n",
        "\n",
        "Y = dbpedia_df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVRnNZySmAQ4"
      },
      "outputs": [],
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(\"Length of testing data: \", len(y_test))\n",
        "    print(\"accuracy_count : \" , num_acc)\n",
        "    print(\"accuracy_score : \" , acc)\n",
        "    print(\"precision_score : \" , prec)\n",
        "    print(\"recall_score : \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6hs7STcmAQ5",
        "outputId": "9cdca1d4-a8d6-4fe9-9203-f8420e9c4c76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217434)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0, max_df=80, ngram_range=(2, 2))\n",
        "\n",
        "feature_vector = count_vectorizer.fit_transform(X)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxWV-HUrmAQ5",
        "outputId": "5af05295-f3a6-4acc-8fa9-38b90f9d3961"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217434)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "feature_vector = tfidf_transformer.fit_transform(feature_vector)\n",
        "\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R-C31qwmAQ6"
      },
      "outputs": [],
      "source": [
        "X_dense = feature_vector.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1Ear7r1mAQ6",
        "outputId": "2a72887f-d912-40e7-9448-1394ed2752ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 217434)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dense.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHstR3VFmAQ7"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-y_j0SmmAQ8"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu-ZjRwhmAQ8",
        "outputId": "f9d08435-f4ba-41d7-8d9c-7f13d00d25c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7, 12,  6, ...,  1, 12,  3])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3EfcPqFmAQ9",
        "outputId": "457f97e4-be6b-46de-dc77-495bfd0a6ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of testing data:  2000\n",
            "accuracy_count :  1778\n",
            "accuracy_score :  0.889\n",
            "precision_score :  0.8902761517734769\n",
            "recall_score :  0.889\n"
          ]
        }
      ],
      "source": [
        "summarize_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs-4eLk1mAQ9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}